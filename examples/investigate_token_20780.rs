/// Token 20780ãŒå¸¸ã«äºˆæ¸¬ã•ã‚Œã‚‹åŸå› ã‚’èª¿æŸ»
///
/// ã™ã¹ã¦ã®ç•°ãªã‚‹å…¥åŠ›ã§åŒã˜Token 20780ãŒäºˆæ¸¬ã•ã‚Œã‚‹ã®ã¯ç•°å¸¸ã€‚
/// LM headã®weightåˆ—ã‚’è©³ã—ãèª¿ã¹ã‚‹ã€‚

use rustorch::hybrid_f32::models::{F32LlamaModel, DeviceType};
use rustorch::hybrid_f32::error::F32Result;
use rustorch::formats::gguf::GGUFLoader;

fn main() -> F32Result<()> {
    println!("ğŸ” Token 20780ã®è¬ã‚’è§£æ˜\n");

    let model_path = std::env::var("HOME").unwrap() +
        "/.rustorch/models/TheBloke_TinyLlama-1.1B-Chat-v1.0-GGUF/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf";

    // GGUFLoaderã§ç›´æ¥weightã‚’èª­ã¿è¾¼ã‚€
    println!("ğŸ“‚ output.weightã‚’ç›´æ¥èª­ã¿è¾¼ã¿ä¸­...");
    let loader = GGUFLoader::from_file(&model_path)
        .map_err(|e| rustorch::hybrid_f32::error::F32Error::device_error(format!("GGUF load failed: {}", e)))?;

    let output_tensor = loader.load_tensor("output.weight")
        .map_err(|e| rustorch::hybrid_f32::error::F32Error::device_error(format!("Tensor load failed: {}", e)))?;

    println!("âœ… output.weightèª­ã¿è¾¼ã¿å®Œäº†");
    println!("   Shape: {:?}", output_tensor.shape());
    println!("   Expected: [2048, 32000] (hidden_size, vocab_size)");

    let output_data: Vec<f64> = output_tensor.data.iter().cloned().collect();
    println!("   Data length: {}", output_data.len());

    // Token 20780ã®weightåˆ—ã‚’æŠ½å‡º
    // Shape [2048, 32000] ã§ row-major ã®å ´åˆ:
    // Token tã®åˆ— = [data[0*32000 + t], data[1*32000 + t], ..., data[2047*32000 + t]]

    println!("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("ğŸ“Š Token 20780ã®Weightåˆ—ã‚’èª¿æŸ»");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    let token_id = 20780;
    let hidden_size = 2048;
    let vocab_size = 32000;

    let mut token_20780_weights = Vec::new();
    for dim in 0..hidden_size {
        let idx = dim * vocab_size + token_id;
        token_20780_weights.push(output_data[idx]);
    }

    // çµ±è¨ˆã‚’è¨ˆç®—
    let sum: f64 = token_20780_weights.iter().sum();
    let mean = sum / hidden_size as f64;
    let max = token_20780_weights.iter().cloned().fold(f64::NEG_INFINITY, f64::max);
    let min = token_20780_weights.iter().cloned().fold(f64::INFINITY, f64::min);
    let abs_sum: f64 = token_20780_weights.iter().map(|x| x.abs()).sum();
    let abs_mean = abs_sum / hidden_size as f64;

    println!("Token 20780ã®weightçµ±è¨ˆ:");
    println!("   Sum: {:.8}", sum);
    println!("   Mean: {:.8}", mean);
    println!("   Abs Mean: {:.8}", abs_mean);
    println!("   Max: {:.8}", max);
    println!("   Min: {:.8}", min);

    println!("\næœ€åˆã®10å€‹ã®å€¤:");
    for i in 0..10 {
        println!("   [{}]: {:.8}", i, token_20780_weights[i]);
    }

    // Token 450ã¨æ¯”è¼ƒ
    println!("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("ğŸ“Š Token 450 (\" The\")ã®Weightåˆ—ã‚’èª¿æŸ»");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    let token_450 = 450;
    let mut token_450_weights = Vec::new();
    for dim in 0..hidden_size {
        let idx = dim * vocab_size + token_450;
        token_450_weights.push(output_data[idx]);
    }

    let sum_450: f64 = token_450_weights.iter().sum();
    let mean_450 = sum_450 / hidden_size as f64;
    let max_450 = token_450_weights.iter().cloned().fold(f64::NEG_INFINITY, f64::max);
    let min_450 = token_450_weights.iter().cloned().fold(f64::INFINITY, f64::min);
    let abs_sum_450: f64 = token_450_weights.iter().map(|x| x.abs()).sum();
    let abs_mean_450 = abs_sum_450 / hidden_size as f64;

    println!("Token 450ã®weightçµ±è¨ˆ:");
    println!("   Sum: {:.8}", sum_450);
    println!("   Mean: {:.8}", mean_450);
    println!("   Abs Mean: {:.8}", abs_mean_450);
    println!("   Max: {:.8}", max_450);
    println!("   Min: {:.8}", min_450);

    println!("\næœ€åˆã®10å€‹ã®å€¤:");
    for i in 0..10 {
        println!("   [{}]: {:.8}", i, token_450_weights[i]);
    }

    // ä»–ã®ã„ãã¤ã‹ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚‚ç¢ºèª
    println!("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("ğŸ“Š ä»–ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã®æ¯”è¼ƒ");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    let test_tokens = vec![
        (1, "<s>"),
        (450, " The"),
        (1552, "the"),
        (3681, "Paris"),
        (12517, "?"),
        (20780, "?"),
    ];

    println!("| Token | Name | Abs Mean Weight | Sum |");
    println!("|-------|------|-----------------|-----|");

    for (token_id, name) in test_tokens {
        let mut weights = Vec::new();
        for dim in 0..hidden_size {
            let idx = dim * vocab_size + token_id;
            weights.push(output_data[idx]);
        }
        let sum: f64 = weights.iter().sum();
        let abs_mean = weights.iter().map(|x| x.abs()).sum::<f64>() / hidden_size as f64;
        println!("| {} | {} | {:.8} | {:.8} |", token_id, name, abs_mean, sum);
    }

    // æ‰‹å‹•ã§logitã‚’è¨ˆç®—ã—ã¦ã¿ã‚‹
    println!("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("ğŸ§® æ‰‹å‹•Logitè¨ˆç®—");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    println!("ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§å®Ÿéš›ã®hidden stateã‚’å–å¾—...");
    let mut model = F32LlamaModel::from_gguf_with_device(&model_path, DeviceType::Cpu)?;

    let input = vec![1]; // BOS
    let output = model.forward(&input)?;
    let logits = output.as_slice();

    println!("å®Ÿéš›ã®logit:");
    println!("   Token 450: {:.8}", logits[450]);
    println!("   Token 20780: {:.8}", logits[20780]);
    println!("   Token 12517: {:.8}", logits[12517]);

    println!("\nğŸ” åˆ†æ:");
    if abs_mean > abs_mean_450 * 2.0 {
        println!("   âš ï¸  Token 20780ã®weightå€¤ãŒç•°å¸¸ã«å¤§ãã„ï¼");
        println!("   ã“ã‚ŒãŒå¸¸ã«Token 20780ãŒäºˆæ¸¬ã•ã‚Œã‚‹åŸå› ã®å¯èƒ½æ€§å¤§");
    } else {
        println!("   âœ… Weightå€¤ã¯æ­£å¸¸ç¯„å›²å†…");
        println!("   å•é¡Œã¯åˆ¥ã®å ´æ‰€ã«ã‚ã‚‹å¯èƒ½æ€§");
    }

    Ok(())
}
