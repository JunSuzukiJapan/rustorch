//! ãƒ•ã‚§ãƒ¼ã‚º4Cãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ã‚·ã‚¹ãƒ†ãƒ æ“ä½œãƒ†ã‚¹ãƒˆä¾‹
//! Phase 4C Utility & System Operations Test Example

#[cfg(feature = "hybrid-f32")]
fn main() -> Result<(), Box<dyn std::error::Error>> {
    use rustorch::hybrid_f32::tensor::F32Tensor;
    use std::time::Instant;

    rustorch::hybrid_f32_experimental!();

    println!("ğŸ”§ ãƒ•ã‚§ãƒ¼ã‚º4Cãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ã‚·ã‚¹ãƒ†ãƒ æ“ä½œãƒ†ã‚¹ãƒˆ");
    println!("ğŸ”§ Phase 4C Utility & System Operations Test");
    println!("===========================================\n");

    // ===== ãƒ¡ãƒ¢ãƒªãƒ»ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ“ä½œãƒ‡ãƒ¢ / Memory & Storage Operations Demo =====
    println!("ğŸ’¾ 1. ãƒ¡ãƒ¢ãƒªãƒ»ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ“ä½œãƒ‡ãƒ¢ / Memory & Storage Operations Demo");
    println!("----------------------------------------------------------");

    let data = F32Tensor::from_vec(vec![1.0, 2.0, 3.0, 4.0, 5.0], vec![5])?;
    println!("  Original tensor: {:?}", data.as_slice());

    // ã‚¯ãƒ­ãƒ¼ãƒ³ã¨ãƒ‡ã‚¿ãƒƒãƒ
    let cloned = data.clone()?;
    let detached = data.detach()?;
    println!("  Cloned data: {:?}", cloned.as_slice());
    println!("  Detached data: {:?}", detached.as_slice());

    // ãƒ¡ãƒ¢ãƒªæ“ä½œ
    println!("  Memory usage: {} bytes", data.memory_usage());
    println!("  Is contiguous: {}", data.is_contiguous());
    println!("  Stride: {:?}", data.stride());

    // ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±
    println!("  Device info: CPU tensor");
    #[cfg(feature = "cuda")]
    {
        match data.cuda() {
            Ok(cuda_tensor) => println!("  CUDA tensor: {:?}", cuda_tensor.as_slice()),
            Err(_) => println!("  CUDA not available"),
        }
    }

    // ===== å‹å¤‰æ›ãƒ»ã‚­ãƒ£ã‚¹ãƒˆæ“ä½œãƒ‡ãƒ¢ / Type Conversion & Casting Demo =====
    println!("\nğŸ”„ 2. å‹å¤‰æ›ãƒ»ã‚­ãƒ£ã‚¹ãƒˆæ“ä½œãƒ‡ãƒ¢ / Type Conversion & Casting Demo");
    println!("------------------------------------------------------------");

    let test_data = F32Tensor::from_vec(vec![1.5, 2.7, -1.2, 4.8, 0.0], vec![5])?;
    println!("  Source f32 data: {:?}", test_data.as_slice());

    // å„ç¨®å‹ã¸ã®å¤‰æ›
    let f64_data = test_data.to_f64()?;
    let i32_data = test_data.to_i32()?;
    let u8_data = test_data.to_u8()?;
    let bool_data = test_data.bool()?;

    println!("  To f64: {:?}", f64_data.iter().map(|x| format!("{:.1}", x)).collect::<Vec<_>>());
    println!("  To i32: {:?}", i32_data);
    println!("  To u8: {:?}", u8_data);
    println!("  To bool: {:?}", bool_data);

    // PyTorchäº’æ›å¤‰æ›
    let float_tensor = test_data.float()?;
    let double_data = test_data.double()?;
    println!("  Float tensor: {:?}", float_tensor.as_slice());
    println!("  Double data: {:?}", double_data.iter().map(|x| format!("{:.1}", x)).collect::<Vec<_>>());

    // ãƒ‡ãƒ¼ã‚¿å‹æƒ…å ±
    println!("  Data type: {}", test_data.dtype());

    // ===== ãƒ‡ãƒãƒƒã‚°ãƒ»æƒ…å ±å–å¾—æ“ä½œãƒ‡ãƒ¢ / Debug & Information Operations Demo =====
    println!("\nğŸ” 3. ãƒ‡ãƒãƒƒã‚°ãƒ»æƒ…å ±å–å¾—æ“ä½œãƒ‡ãƒ¢ / Debug & Information Operations Demo");
    println!("-------------------------------------------------------------");

    let debug_data = F32Tensor::from_vec(
        vec![1.0, 2.5, f32::NAN, 4.0, f32::INFINITY, -2.0],
        vec![6]
    )?;
    println!("  Debug tensor: {:?}", debug_data.as_slice());

    // åŸºæœ¬æƒ…å ±
    println!("  Number of elements: {}", debug_data.numel());
    println!("  Number of dimensions: {}", debug_data.ndim());
    println!("  Is empty: {}", debug_data.is_empty());
    println!("  Is scalar: {}", debug_data.is_scalar());
    println!("  Data hash: {:x}", debug_data.data_hash());

    // çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
    match debug_data.check_state() {
        Ok(state) => println!("  State check: {}", state),
        Err(e) => println!("  State check error: {}", e),
    }

    // å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯
    match debug_data.sanity_check() {
        Ok(is_sane) => println!("  Sanity check: {}", if is_sane { "PASS" } else { "FAIL" }),
        Err(e) => println!("  Sanity check error: {}", e),
    }

    // æƒ…å ±è¡¨ç¤º
    println!("\n  Tensor Info:");
    println!("{}", debug_data.info());

    println!("\n  Summary:");
    println!("{}", debug_data.summary());

    // ===== ã‚·ã‚¹ãƒ†ãƒ ãƒ»ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ“ä½œãƒ‡ãƒ¢ / System & Hardware Operations Demo =====
    println!("\nğŸ–¥ï¸  4. ã‚·ã‚¹ãƒ†ãƒ ãƒ»ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ“ä½œãƒ‡ãƒ¢ / System & Hardware Operations Demo");
    println!("----------------------------------------------------------------");

    let perf_data = F32Tensor::from_vec((0..1000).map(|i| i as f32 * 0.1).collect(), vec![1000])?;

    // ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
    println!("  System Information:");
    println!("{}", perf_data.system_info());

    println!("\n  Device Information:");
    println!("{}", perf_data.device_info());

    // ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ©Ÿèƒ½
    println!("\n  Hardware Capabilities:");
    println!("{}", perf_data.hardware_caps());

    // SIMDæƒ…å ±
    println!("\n  SIMD Information:");
    println!("{}", perf_data.simd_info());

    // ä¸¦åˆ—å‡¦ç†è¨­å®š
    println!("\n  Parallel Configuration:");
    println!("{}", perf_data.parallel_config());

    // ===== ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šãƒ‡ãƒ¢ / Performance Measurement Demo =====
    println!("\nâš¡ 5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šãƒ‡ãƒ¢ / Performance Measurement Demo");
    println!("-------------------------------------------------------");

    let bench_data = F32Tensor::from_vec((0..5000).map(|i| (i as f32).sin()).collect(), vec![5000])?;

    // CPUä½¿ç”¨ç‡
    println!("  CPU Usage:");
    println!("{}", bench_data.cpu_usage());

    // ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…
    println!("\n  Memory Bandwidth:");
    println!("{}", bench_data.memory_bandwidth());

    // é›»åŠ›åŠ¹ç‡
    println!("\n  Power Efficiency:");
    println!("{}", bench_data.power_efficiency());

    // æ¸©åº¦ç›£è¦–
    println!("\n  Thermal Status:");
    println!("{}", bench_data.thermal_status());

    // ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    println!("\n  Benchmark Results:");
    println!("{}", bench_data.benchmark());

    // ===== æœ€é©åŒ–ãƒ‡ãƒ¢ / Optimization Demo =====
    println!("\nğŸš€ 6. æœ€é©åŒ–ãƒ‡ãƒ¢ / Optimization Demo");
    println!("--------------------------------");

    let mut opt_data = F32Tensor::from_vec((0..2000).map(|i| i as f32).collect(), vec![2000])?;

    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
    let start = Instant::now();
    opt_data.optimize_performance()?;
    let opt_time = start.elapsed();
    println!("  Performance optimization completed in: {:?}", opt_time);

    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–
    match opt_data.cache_optimize() {
        Ok(cache_info) => {
            println!("\n  Cache Optimization:");
            println!("{}", cache_info);
        }
        Err(e) => println!("  Cache optimization error: {}", e),
    }

    // æœ€é©åŒ–ææ¡ˆ
    println!("\n  Optimization Recommendations:");
    println!("{}", opt_data.optimization_hints());

    // ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨ç‡
    println!("\n  Resource Usage:");
    println!("{}", opt_data.resource_usage());

    // ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
    println!("\n  Profile Information:");
    println!("{}", opt_data.profile());

    // ===== ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ / Performance Test =====
    println!("\nğŸ 7. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ / Performance Test");
    println!("-------------------------------------------");

    let large_data = F32Tensor::from_vec((0..10000).map(|i| (i as f32) * 0.001).collect(), vec![10000])?;

    let start = Instant::now();
    let _info = large_data.info();
    let info_time = start.elapsed();

    let start = Instant::now();
    let _state = large_data.check_state()?;
    let state_time = start.elapsed();

    let start = Instant::now();
    let _converted = large_data.to_f64()?;
    let convert_time = start.elapsed();

    let start = Instant::now();
    let _optimized = large_data.optimization_hints();
    let hints_time = start.elapsed();

    println!("  Performance results (size: 10000):");
    println!("    Info generation: {:?}", info_time);
    println!("    State check: {:?}", state_time);
    println!("    Type conversion: {:?}", convert_time);
    println!("    Optimization hints: {:?}", hints_time);

    println!("\nâœ… ãƒ•ã‚§ãƒ¼ã‚º4Cãƒ†ã‚¹ãƒˆå®Œäº†ï¼");
    println!("âœ… Phase 4C tests completed!");
    println!("\nğŸ“Š ãƒ•ã‚§ãƒ¼ã‚º4Cå®Ÿè£…æ¸ˆã¿ãƒ¡ã‚½ãƒƒãƒ‰æ•°: 60ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆç´¯è¨ˆ: 278ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰");
    println!("ğŸ“Š Phase 4C implemented methods: 60 methods (Total: 278 methods)");
    println!("   - ãƒ¡ãƒ¢ãƒªãƒ»ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ“ä½œ: 15ãƒ¡ã‚½ãƒƒãƒ‰ (Memory & storage operations: 15 methods)");
    println!("     * clone, copy_, detach, share_memory_, is_shared");
    println!("     * storage, storage_offset, stride, contiguous, is_contiguous");
    println!("     * pin_memory, cpu, cuda, to_device, memory_format");
    println!("   - å‹å¤‰æ›ãƒ»ã‚­ãƒ£ã‚¹ãƒˆæ“ä½œ: 15ãƒ¡ã‚½ãƒƒãƒ‰ (Type conversion & casting: 15 methods)");
    println!("     * to_f64, to_f32, to_i64, to_i32, to_u8, half");
    println!("     * float, double, long, int, bool, byte, char");
    println!("     * type_as, dtype");
    println!("   - ãƒ‡ãƒãƒƒã‚°ãƒ»æƒ…å ±å–å¾—æ“ä½œ: 15ãƒ¡ã‚½ãƒƒãƒ‰ (Debug & information operations: 15 methods)");
    println!("     * info, check_state, memory_usage, numel, ndim");
    println!("     * is_empty, is_scalar, data_hash, debug_info, perf_stats");
    println!("     * summary, sanity_check, trace_info, backtrace, profile");
    println!("   - ã‚·ã‚¹ãƒ†ãƒ ãƒ»ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ“ä½œ: 15ãƒ¡ã‚½ãƒƒãƒ‰ (System & hardware operations: 15 methods)");
    println!("     * system_info, device_info, optimize_performance, cpu_usage, memory_bandwidth");
    println!("     * parallel_config, cache_optimize, simd_info, power_efficiency, thermal_status");
    println!("     * resource_usage, hardware_caps, optimization_hints, benchmark");

    println!("\nğŸ¯ ãƒ•ã‚§ãƒ¼ã‚º4Cã®ç‰¹å¾´:");
    println!("ğŸ¯ Phase 4C Features:");
    println!("   âœ“ å®Œå…¨f32å°‚ç”¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£å®Ÿè£…ï¼ˆå¤‰æ›ã‚³ã‚¹ãƒˆ0ï¼‰");
    println!("   âœ“ Complete f32-specific utility implementation (zero conversion cost)");
    println!("   âœ“ åŒ…æ‹¬çš„ãƒ¡ãƒ¢ãƒªç®¡ç†ãƒ»ãƒ‡ãƒã‚¤ã‚¹åˆ¶å¾¡");
    println!("   âœ“ Comprehensive memory management and device control");
    println!("   âœ“ é«˜ç²¾åº¦å‹å¤‰æ›ãƒ»ã‚­ãƒ£ã‚¹ãƒˆæ“ä½œ");
    println!("   âœ“ High-precision type conversion and casting operations");
    println!("   âœ“ è©³ç´°ãƒ‡ãƒãƒƒã‚°ãƒ»ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°æƒ…å ±");
    println!("   âœ“ Detailed debugging and profiling information");
    println!("   âœ“ ã‚·ã‚¹ãƒ†ãƒ æœ€é©åŒ–ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–");
    println!("   âœ“ System optimization and performance monitoring");
    println!("   âœ“ ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ç‰¹æ€§æ¤œå‡ºãƒ»æ´»ç”¨");
    println!("   âœ“ Hardware capability detection and utilization");
    println!("   âœ“ PyTorchäº’æ›ã‚·ã‚¹ãƒ†ãƒ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£APIè¨­è¨ˆ");
    println!("   âœ“ PyTorch-compatible system utility API design");

    println!("\nğŸ† Phase 4 å…¨ä½“å®Œäº†ï¼ (4A: 60 + 4B: 60 + 4C: 60 = 180ãƒ¡ã‚½ãƒƒãƒ‰)");
    println!("ğŸ† Phase 4 Complete! (4A: 60 + 4B: 60 + 4C: 60 = 180 methods)");
    println!("ç·å®Ÿè£…ãƒ¡ã‚½ãƒƒãƒ‰æ•°: 278ãƒ¡ã‚½ãƒƒãƒ‰");
    println!("Total implemented methods: 278 methods");

    Ok(())
}

#[cfg(not(feature = "hybrid-f32"))]
fn main() {
    println!("âŒ hybrid-f32 ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ãŒå¿…è¦ã§ã™ã€‚");
    println!("âŒ hybrid-f32 feature required.");
    println!("å®Ÿè¡Œæ–¹æ³•: cargo run --example hybrid_f32_phase4c_test --features hybrid-f32");
}