//! é›†ä¸­æ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ - ä¸»è¦ãƒ¢ãƒ¼ãƒ‰ã®è©³ç´°æ¯”è¼ƒ
//! Focused Comparison Benchmark - Detailed comparison of key modes
//!
//! ã“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ä¸»è¦ãªå®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã‚’åŠ¹ç‡çš„ã«æ¯”è¼ƒã—ã¾ã™ï¼š
//! This benchmark efficiently compares key execution modes:
//!
//! 1. CPUå˜ä½“å®Ÿè¡Œ (CPU-only execution)
//! 2. Metal GPUå˜ä½“å®Ÿè¡Œ (Metal GPU-only execution)
//! 3. æ—¢å­˜ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å®Ÿè¡Œ (Existing hybrid execution)
//! 4. hybrid_f32å®Ÿè¡Œ (hybrid_f32 execution)
//!
//! å®Ÿè¡Œæ–¹æ³• / Usage:
//! ```bash
//! timeout 1800 cargo run --example focused_comparison_benchmark --features hybrid-f32 --release
//! ```

#[cfg(feature = "hybrid-f32")]
use rustorch::hybrid_f32::{
    gpu::F32UnifiedGPUContext, tensor::F32Tensor, unified::F32HybridExecutor,
};

#[cfg(feature = "hybrid-f32")]
use rustorch::gpu::{hybrid_executor::HybridExecutor, DeviceType, OpType};

#[cfg(feature = "hybrid-f32")]
fn main() -> rustorch::error::RusTorchResult<()> {
    println!("ğŸš€ Focused Comparison Benchmark");
    println!("================================");
    println!("ğŸ“Š Detailed comparison: CPU, Metal GPU, True Existing Hybrid, Hybrid_f32");
    println!("â±ï¸ Optimized for comprehensive results within reasonable time");
    println!();

    // ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    let mut hybrid_executor = F32HybridExecutor::new()?;
    let _gpu_context = F32UnifiedGPUContext::new();

    // æ—¢å­˜ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¨ã‚°ã‚¼ã‚­ãƒ¥ãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–
    let existing_hybrid_executor = HybridExecutor::new();

    println!("ğŸ¯ Target modes for focused comparison:");
    println!("  CPU: Apple M1 CPU (0.5 TFLOPS f32) - Baseline");
    println!("  Metal GPU: Apple M1 GPU (2.6 TFLOPS f32) - GPU acceleration");
    println!("  True Existing Hybrid: Metal(0) â†’ CoreML(0) â†’ CPU (improved chain)");
    println!("  Hybrid_f32: f32 unified with zero conversion cost");
    println!();

    // é›†ä¸­ãƒ†ã‚¹ãƒˆè¨­å®š - æ˜ç¢ºãªå·®ãŒå‡ºã‚‹ã‚µã‚¤ã‚ºã§åŠ¹ç‡çš„ã«
    let test_size = 2048;
    let iterations = 1;

    println!(
        "ğŸ”¥ Focused Test - {}x{} matrix, {} iterations",
        test_size, test_size, iterations
    );
    println!(
        "Memory usage: ~{:.1} GB per matrix",
        (test_size * test_size * 4) as f64 / 1_000_000_000.0
    );
    println!("=====================================");

    // ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    println!("ğŸ“Š Creating test matrices...");

    // f32ãƒ‡ãƒ¼ã‚¿ï¼ˆhybrid_f32ç”¨ï¼‰
    let data_a_f32: Vec<f32> = (0..test_size * test_size)
        .map(|i| (i as f32 % 100.0) + 1.0)
        .collect();
    let data_b_f32: Vec<f32> = (0..test_size * test_size)
        .map(|i| ((i + test_size) as f32 % 100.0) + 1.0)
        .collect();
    let matrix_a_f32 = F32Tensor::new(data_a_f32, &[test_size, test_size])?;
    let matrix_b_f32 = F32Tensor::new(data_b_f32, &[test_size, test_size])?;

    // f64ãƒ‡ãƒ¼ã‚¿ï¼ˆæ—¢å­˜hybridç”¨ï¼‰
    let data_a_f64: Vec<f64> = (0..test_size * test_size)
        .map(|i| (i as f64 % 100.0) + 1.0)
        .collect();
    let data_b_f64: Vec<f64> = (0..test_size * test_size)
        .map(|i| ((i + test_size) as f64 % 100.0) + 1.0)
        .collect();
    let matrix_a_f64 = Tensor::from_vec(data_a_f64, vec![test_size, test_size]);
    let matrix_b_f64 = Tensor::from_vec(data_b_f64, vec![test_size, test_size]);

    // æ¨™æº–åŒ–ã•ã‚ŒãŸæ¼”ç®—ãƒã‚§ãƒ¼ãƒ³
    let perform_standard_operations_f32 = |a: &F32Tensor,
                                           b: &F32Tensor,
                                           executor: &mut F32HybridExecutor|
     -> rustorch::error::RusTorchResult<f64> {
        let start = Instant::now();

        // 1. è¡Œåˆ—ä¹—ç®—
        let (result1, _) = executor.execute_matmul(a, b)?;
        // 2. è»¢ç½®
        let result2 = result1.transpose()?;
        // 3. åŠ ç®—
        let result3 = result2.add(&result1)?;
        // 4. å†åº¦è¡Œåˆ—ä¹—ç®—
        let (result4, _) = executor.execute_matmul(&result3, &result1)?;
        // 5. çµ±è¨ˆæ“ä½œ
        let _ = result4.sum();

        Ok(start.elapsed().as_millis() as f64)
    };

    let perform_standard_operations_f64 =
        |a: &Tensor<f64>, b: &Tensor<f64>| -> rustorch::error::RusTorchResult<f64> {
            let start = Instant::now();

            // 1. è¡Œåˆ—ä¹—ç®—
            let result1 = a.matmul(b)?;
            // 2. è»¢ç½®
            let result2 = result1.transpose()?;
            // 3. åŠ ç®—
            let result3 = result2.add(&result1)?;
            // 4. å†åº¦è¡Œåˆ—ä¹—ç®—
            let result4 = result3.matmul(&result1)?;
            // 5. çµ±è¨ˆæ“ä½œ
            let _ = result4.sum();

            Ok(start.elapsed().as_millis() as f64)
        };

    // 1ï¸âƒ£ CPUå˜ä½“å®Ÿè¡Œ
    println!("\nğŸ’» CPU-Only Test:");
    println!("  ğŸ”¥ Standard operation chain on CPU (f64)");
    let mut cpu_times = Vec::new();
    for i in 0..iterations {
        println!("  ğŸ’» CPU iteration {}/{}", i + 1, iterations);
        let time = perform_standard_operations_f64(&matrix_a_f64, &matrix_b_f64)?;
        cpu_times.push(time);
        println!("    â±ï¸ CPU operations: {:.0}ms", time);
    }
    let cpu_avg = cpu_times.iter().sum::<f64>() / iterations as f64;
    println!("  ğŸ’» CPU average: {:.0}ms per operation chain", cpu_avg);

    // 2ï¸âƒ£ Metal GPUå˜ä½“å®Ÿè¡Œï¼ˆhybrid_executorçµŒç”±ï¼‰
    println!("\nâš¡ Metal GPU-Only Test:");
    println!("  ğŸ”¥ Standard operation chain on Metal GPU (f32)");
    let mut metal_times = Vec::new();
    for i in 0..iterations {
        println!("  âš¡ Metal GPU iteration {}/{}", i + 1, iterations);
        let time =
            perform_standard_operations_f32(&matrix_a_f32, &matrix_b_f32, &mut hybrid_executor)?;
        metal_times.push(time);
        println!("    â±ï¸ Metal GPU operations: {:.0}ms", time);
    }
    let metal_avg = metal_times.iter().sum::<f64>() / iterations as f64;
    println!(
        "  âš¡ Metal GPU average: {:.0}ms per operation chain",
        metal_avg
    );

    // æ—¢å­˜ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¼”ç®—ï¼ˆGPUå¼·åˆ¶å®Ÿè¡Œï¼‰
    let perform_existing_hybrid_operations = |a: &Tensor<f64>,
                                              b: &Tensor<f64>,
                                              executor: &HybridExecutor|
     -> rustorch::error::RusTorchResult<f64> {
        use rustorch::gpu::hybrid_executor::HybridExecution;

        let start = Instant::now();

        // HybridExecutionãƒˆãƒ¬ã‚¤ãƒˆã‚’ä½¿ç”¨ã—ã¦GPUå¼·åˆ¶å®Ÿè¡Œ
        let result1 = a.hybrid_operation(OpType::LinearAlgebra, |device| {
            if device == DeviceType::Cpu {
                return Err(rustorch::error::RusTorchError::tensor_op(
                    "CPU fallback prohibited - GPU execution required",
                ));
            }
            println!("    ğŸ¯ Executing matmul on device: {:?}", device);
            a.matmul(b)
        })?;

        let result2 = result1.hybrid_operation(OpType::LinearAlgebra, |device| {
            if device == DeviceType::Cpu {
                return Err(rustorch::error::RusTorchError::tensor_op(
                    "CPU fallback prohibited - GPU execution required",
                ));
            }
            println!("    ğŸ¯ Executing transpose on device: {:?}", device);
            result1.transpose()
        })?;

        let result3 = result2.hybrid_operation(OpType::LinearAlgebra, |device| {
            if device == DeviceType::Cpu {
                return Err(rustorch::error::RusTorchError::tensor_op(
                    "CPU fallback prohibited - GPU execution required",
                ));
            }
            println!("    ğŸ¯ Executing add on device: {:?}", device);
            result2.add(&result1)
        })?;

        let result4 = result3.hybrid_operation(OpType::LinearAlgebra, |device| {
            if device == DeviceType::Cpu {
                return Err(rustorch::error::RusTorchError::tensor_op(
                    "CPU fallback prohibited - GPU execution required",
                ));
            }
            println!("    ğŸ¯ Executing final matmul on device: {:?}", device);
            result3.matmul(&result1)
        })?;

        let _ = result4.sum();
        Ok(start.elapsed().as_millis() as f64)
    };

    // 3ï¸âƒ£ çœŸã®æ—¢å­˜ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å®Ÿè¡Œï¼ˆCPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç¦æ­¢ï¼‰
    println!("\nğŸ”„ True Existing Hybrid Test (NO CPU Fallback):");
    println!("  ğŸ”¥ HybridExecution trait with GPU enforcement");
    let mut existing_times = Vec::new();
    for i in 0..iterations {
        println!(
            "  ğŸ”„ True existing hybrid iteration {}/{}",
            i + 1,
            iterations
        );
        println!("    ğŸ”„ Using HybridExecution trait with CPU fallback prohibition");

        let time = perform_existing_hybrid_operations(
            &matrix_a_f64,
            &matrix_b_f64,
            &existing_hybrid_executor,
        )?;
        existing_times.push(time);
        println!("    â±ï¸ True existing hybrid operations: {:.0}ms", time);
    }
    let existing_avg = existing_times.iter().sum::<f64>() / iterations as f64;
    println!(
        "  ğŸ”„ True existing hybrid average: {:.0}ms per operation chain",
        existing_avg
    );

    // 4ï¸âƒ£ hybrid_f32å®Ÿè¡Œ
    println!("\nğŸš€ Hybrid_f32 Test:");
    println!("  ğŸ”¥ Standard operation chain with hybrid_f32 (f32)");
    let mut f32_times = Vec::new();
    for i in 0..iterations {
        println!("  ğŸš€ Hybrid_f32 iteration {}/{}", i + 1, iterations);
        println!("    ğŸš€ f32 unified execution with zero conversion cost");
        println!("    ğŸ“Š Automatic device selection for optimal performance");

        let time =
            perform_standard_operations_f32(&matrix_a_f32, &matrix_b_f32, &mut hybrid_executor)?;
        f32_times.push(time);
        println!("    â±ï¸ Hybrid_f32 operations: {:.0}ms", time);
    }
    let f32_avg = f32_times.iter().sum::<f64>() / iterations as f64;
    println!(
        "  ğŸš€ Hybrid_f32 average: {:.0}ms per operation chain",
        f32_avg
    );

    // ğŸ“Š è©³ç´°åˆ†æ
    println!(
        "\nğŸ“Š Focused Comparison Analysis for {}x{} matrix:",
        test_size, test_size
    );
    println!("  Operation chain: matmul â†’ transpose â†’ add â†’ matmul â†’ sum");
    println!(
        "  Memory per matrix: {:.1} GB",
        (test_size * test_size * 4) as f64 / 1_000_000_000.0
    );
    println!();

    println!("  ğŸ’» CPU-Only:         {:.0}ms per chain", cpu_avg);
    println!("  âš¡ Metal GPU-Only:   {:.0}ms per chain", metal_avg);
    println!("  ğŸ”„ True Existing Hybrid: {:.0}ms per chain", existing_avg);
    println!("  ğŸš€ Hybrid_f32:       {:.0}ms per chain", f32_avg);

    // ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—åˆ†æ
    let speedup_metal = cpu_avg / metal_avg;
    let speedup_existing = cpu_avg / existing_avg;
    let speedup_f32 = cpu_avg / f32_avg;

    println!("\nğŸƒ Focused Speedup Analysis (vs CPU):");
    println!("  Metal GPU vs CPU:      {:.2}x speedup", speedup_metal);
    println!(
        "  True Existing Hybrid vs CPU: {:.2}x speedup",
        speedup_existing
    );
    println!("  Hybrid_f32 vs CPU:     {:.2}x speedup", speedup_f32);

    // ç›¸å¯¾æ¯”è¼ƒ
    let metal_vs_existing = existing_avg / metal_avg;
    let metal_vs_f32 = f32_avg / metal_avg;
    let f32_vs_existing = existing_avg / f32_avg;

    println!("\nğŸ”¬ Relative Performance Analysis:");
    println!(
        "  Metal GPU vs True Existing Hybrid: {:.2}x ratio",
        metal_vs_existing
    );
    println!("  Metal GPU vs Hybrid_f32:      {:.2}x ratio", metal_vs_f32);
    println!(
        "  Hybrid_f32 vs True Existing Hybrid: {:.2}x ratio",
        f32_vs_existing
    );

    // æœ€é«˜æ€§èƒ½ã®åˆ¤å®š
    let times = [cpu_avg, metal_avg, existing_avg, f32_avg];
    let best_time = times.iter().fold(f64::INFINITY, |a, &b| a.min(b));

    if (best_time - cpu_avg).abs() < best_time * 0.01 {
        println!("  ğŸ† Focused Winner: CPU-Only");
    } else if (best_time - metal_avg).abs() < best_time * 0.01 {
        println!("  ğŸ† Focused Winner: Metal GPU-Only");
    } else if (best_time - existing_avg).abs() < best_time * 0.01 {
        println!("  ğŸ† Focused Winner: True Existing Hybrid");
    } else {
        println!("  ğŸ† Focused Winner: Hybrid_f32");
    }

    // åŠ¹ç‡æ€§åˆ¤å®š
    let max_speedup = [speedup_metal, speedup_existing, speedup_f32]
        .iter()
        .fold(0.0f64, |a, &b| a.max(b));

    if max_speedup > 5.0 {
        println!("  ğŸš€ Exceptional acceleration achieved!");
    } else if max_speedup > 2.0 {
        println!("  ğŸš€ Excellent acceleration achieved!");
    } else if max_speedup > 1.5 {
        println!("  âœ… Good acceleration achieved");
    } else if max_speedup > 1.2 {
        println!("  ğŸ“ˆ Modest acceleration achieved");
    } else {
        println!("  âš ï¸ Limited acceleration observed");
    }

    // hybrid_f32ã®å„ªä½æ€§åˆ†æ
    println!("\nğŸ¯ Hybrid_f32 Advantages:");
    if f32_vs_existing > 1.5 {
        println!(
            "  ğŸ¯ Major advantage over true existing hybrid ({:.2}x faster)",
            f32_vs_existing
        );
    } else if f32_vs_existing > 1.2 {
        println!(
            "  ğŸ“ˆ Significant advantage over true existing hybrid ({:.2}x faster)",
            f32_vs_existing
        );
    } else if f32_vs_existing > 1.05 {
        println!(
            "  ğŸ“ˆ Moderate advantage over true existing hybrid ({:.2}x faster)",
            f32_vs_existing
        );
    } else {
        println!("  âš–ï¸ Similar performance to true existing hybrid");
    }

    if metal_vs_f32 > 0.95 && metal_vs_f32 < 1.05 {
        println!("  âœ… Hybrid_f32 matches Metal GPU performance");
    } else if metal_vs_f32 > 1.05 {
        println!(
            "  ğŸš€ Hybrid_f32 outperforms Metal GPU ({:.2}x faster)",
            1.0 / metal_vs_f32
        );
    } else {
        println!(
            "  ğŸ“Š Metal GPU slightly faster than Hybrid_f32 ({:.2}x)",
            metal_vs_f32
        );
    }

    println!("\nâœ… Focused comparison benchmark completed!");
    println!("ğŸ“ Clear performance hierarchy established across all key execution modes");

    Ok(())
}

#[cfg(not(feature = "hybrid-f32"))]
fn main() {
    println!("âŒ This benchmark requires the 'hybrid-f32' feature to be enabled.");
    println!("ğŸ“‹ Run with: timeout 1800 cargo run --example focused_comparison_benchmark --features hybrid-f32 --release");
}
