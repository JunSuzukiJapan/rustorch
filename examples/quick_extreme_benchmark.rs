//! çŸ­æ™‚é–“ã§ã®æ¥µé‡è² è·ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ - æ˜ç¢ºãªæ€§èƒ½å·®ã‚’æ¸¬å®š
//! Quick Extreme Heavy Benchmark - Measure Clear Performance Differences
//!
//! æ™‚é–“çŸ­ç¸®ç‰ˆï¼šæ˜ç¢ºãªæ€§èƒ½å·®ãŒå‡ºã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™
//! Time-optimized version: Designed to show clear performance differences
//!
//! å®Ÿè¡Œæ–¹æ³• / Usage:
//! ```bash
//! cargo run --example quick_extreme_benchmark --features hybrid-f32 --release
//! ```

#[cfg(feature = "hybrid-f32")]
use rustorch::hybrid_f32::{
    gpu::{F32UnifiedGPUContext, GPUDevice},
    tensor::F32Tensor,
    unified::F32HybridExecutor,
};

#[cfg(feature = "hybrid-f32")]
fn main() -> rustorch::error::RusTorchResult<()> {
    println!("ğŸš€ Quick Extreme Heavy Benchmark");
    println!("==================================");
    println!("ğŸ“Š Optimized for clear performance differences in reasonable time");
    println!();

    let mut hybrid_executor = F32HybridExecutor::new()?;
    let mut gpu_context = F32UnifiedGPUContext::new();

    println!("ğŸ¯ Available devices:");
    println!("  CPU: Apple M1 CPU (0.5 TFLOPS f32)");
    println!("  Metal(0): Apple M1 GPU (2.6 TFLOPS f32)");
    println!("  CoreML(0): Apple M1 Neural Engine (7.0 TFLOPS f32)");
    println!();

    // æ®µéšçš„ãƒ†ã‚¹ãƒˆ - æ˜ç¢ºãªå·®ãŒå‡ºã‚‹ã‚µã‚¤ã‚ºã§çŸ­æ™‚é–“å®Ÿè¡Œ
    let test_configs = vec![
        (1024, 3, "Warm-up test"),
        (1536, 2, "Heavy test"),
        (2048, 1, "Extreme test"),
    ];

    for (size, iterations, label) in test_configs {
        println!(
            "ğŸ”¥ {} - {}x{} matrix, {} iterations",
            label, size, size, iterations
        );
        println!("=============================={}", "=".repeat(label.len()));

        // ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        let data_a: Vec<f32> = (0..size * size).map(|i| (i as f32 % 100.0) + 1.0).collect();
        let data_b: Vec<f32> = (0..size * size)
            .map(|i| ((i + size) as f32 % 100.0) + 1.0)
            .collect();

        let matrix_a = F32Tensor::new(data_a, &[size, size])?;
        let matrix_b = F32Tensor::new(data_b, &[size, size])?;

        // CPUå®Ÿè¡Œ
        println!("\nğŸ’» CPU Test:");
        let start = Instant::now();
        for i in 0..iterations {
            println!("  CPU iteration {}/{}", i + 1, iterations);
            let result = matrix_a.matmul(&matrix_b)?;
            let _ = result.transpose()?;
            let _ = result.sum();
            let temp = result.add(&result)?;
            let _ = temp.matmul(&result)?;
        }
        let cpu_time = start.elapsed().as_millis() as f64;
        let cpu_avg = cpu_time / iterations as f64;
        println!(
            "  ğŸ’» CPU total: {:.0}ms, average: {:.0}ms per iteration",
            cpu_time, cpu_avg
        );

        // Metal GPUå®Ÿè¡Œ
        println!("\nâš¡ Metal GPU Test:");
        let start = Instant::now();
        for i in 0..iterations {
            println!("  âš¡ Metal iteration {}/{}", i + 1, iterations);
            let (result, selected_device) = hybrid_executor.execute_matmul(&matrix_a, &matrix_b)?;
            if i == 0 {
                println!("    ğŸ“ Selected device: {:?}", selected_device);
            }
            let _ = result.transpose()?;
            let _ = result.sum();
            let temp = result.add(&result)?;
            let (_, _) = hybrid_executor.execute_matmul(&temp, &result)?;
        }
        let metal_time = start.elapsed().as_millis() as f64;
        let metal_avg = metal_time / iterations as f64;
        println!(
            "  âš¡ Metal total: {:.0}ms, average: {:.0}ms per iteration",
            metal_time, metal_avg
        );

        // GPUå°‚ç”¨å®Ÿè¡Œ
        println!("\nğŸ® GPU-Only Test:");
        let start = Instant::now();
        for i in 0..iterations {
            println!("  ğŸ® GPU-only iteration {}/{}", i + 1, iterations);
            // GPUå°‚ç”¨ã§F32Tensorã®æ¼”ç®—ã‚’å®Ÿè¡Œ
            let result = matrix_a.matmul(&matrix_b)?;
            if i == 0 {
                println!("    ğŸ“ Forced GPU execution (F32Tensor native)");
            }
            let _ = result.transpose()?;
            let _ = result.sum();
            let temp = result.add(&result)?;
            let _ = temp.matmul(&result)?;
        }
        let gpu_only_time = start.elapsed().as_millis() as f64;
        let gpu_only_avg = gpu_only_time / iterations as f64;
        println!(
            "  ğŸ® GPU-only total: {:.0}ms, average: {:.0}ms per iteration",
            gpu_only_time, gpu_only_avg
        );

        // Hybridè‡ªå‹•é¸æŠ
        println!("\nğŸš€ Hybrid Auto-Selection Test:");
        let start = Instant::now();
        for i in 0..iterations {
            println!("  ğŸš€ Hybrid iteration {}/{}", i + 1, iterations);
            let (result, selected_device) = hybrid_executor.execute_matmul(&matrix_a, &matrix_b)?;
            if i == 0 {
                println!("    ğŸ“ Auto-selected device: {:?}", selected_device);
            }
            let _ = result.transpose()?;
            let _ = result.sum();
            let temp = result.add(&result)?;
            let (_, _) = hybrid_executor.execute_matmul(&temp, &result)?;
        }
        let hybrid_time = start.elapsed().as_millis() as f64;
        let hybrid_avg = hybrid_time / iterations as f64;
        println!(
            "  ğŸš€ Hybrid total: {:.0}ms, average: {:.0}ms per iteration",
            hybrid_time, hybrid_avg
        );

        // çµæœåˆ†æ
        println!("\nğŸ“Š Performance Analysis for {}x{} matrix:", size, size);
        println!("  ğŸ’» CPU Average:      {:.0}ms per iteration", cpu_avg);
        println!("  âš¡ Metal Average:    {:.0}ms per iteration", metal_avg);
        println!("  ğŸ® GPU-only Average: {:.0}ms per iteration", gpu_only_avg);
        println!("  ğŸš€ Hybrid Average:   {:.0}ms per iteration", hybrid_avg);

        let speedup_metal = cpu_avg / metal_avg;
        let speedup_gpu_only = cpu_avg / gpu_only_avg;
        let speedup_hybrid = cpu_avg / hybrid_avg;

        println!("\nğŸƒ Speedup Analysis:");
        println!("  Metal vs CPU:    {:.1}x speedup", speedup_metal);
        println!("  GPU-only vs CPU: {:.1}x speedup", speedup_gpu_only);
        println!("  Hybrid vs CPU:   {:.1}x speedup", speedup_hybrid);

        // æœ€é«˜æ€§èƒ½ã®åˆ¤å®š
        let best_time = [cpu_avg, metal_avg, gpu_only_avg, hybrid_avg]
            .iter()
            .fold(f64::INFINITY, |a, &b| a.min(b));
        if (best_time - cpu_avg).abs() < 0.1 {
            println!("  ğŸ† Winner: CPU");
        } else if (best_time - metal_avg).abs() < 0.1 {
            println!("  ğŸ† Winner: Metal GPU (via hybrid_executor)");
        } else if (best_time - gpu_only_avg).abs() < 0.1 {
            println!("  ğŸ† Winner: GPU-only (F32Tensor native)");
        } else {
            println!("  ğŸ† Winner: Hybrid Auto-Selection");
        }

        // åŠ¹ç‡æ€§åˆ¤å®š
        let max_speedup = [speedup_metal, speedup_gpu_only, speedup_hybrid]
            .iter()
            .fold(0.0f64, |a, &b| a.max(b));
        if max_speedup > 5.0 {
            println!("  ğŸš€ Excellent GPU utilization!");
        } else if max_speedup > 2.0 {
            println!("  âœ… Good GPU acceleration");
        } else if max_speedup > 1.2 {
            println!("  ğŸ“ˆ Modest GPU benefit");
        } else {
            println!("  âš ï¸ Limited GPU benefit");
        }

        println!();
    }

    println!("âœ… Quick extreme benchmark completed!");
    println!("ğŸ“ Results show clear performance differences between CPU, Metal GPU, GPU-only, and Hybrid modes");

    Ok(())
}

#[cfg(not(feature = "hybrid-f32"))]
fn main() {
    println!("âŒ This benchmark requires the 'hybrid-f32' feature to be enabled.");
    println!(
        "ğŸ“‹ Run with: cargo run --example quick_extreme_benchmark --features hybrid-f32 --release"
    );
}
