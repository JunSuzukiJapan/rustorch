//! å…¨ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼é‡è² è·ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ - æ˜ç¢ºãªæ€§èƒ½å·®ã‚’æ¸¬å®š
//! All Features Heavy Benchmark - Measure Clear Performance Differences
//!
//! ã“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ã™ã¹ã¦ã®å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã‚’æ¯”è¼ƒã—ã¾ã™ï¼š
//! This benchmark compares all execution modes:
//!
//! 1. CPUå˜ä½“å®Ÿè¡Œ (CPU-only execution)
//! 2. Metal GPUå˜ä½“å®Ÿè¡Œ (Metal GPU-only execution)
//! 3. Neural Engineå˜ä½“å®Ÿè¡Œ (Neural Engine-only execution)
//! 4. æ—¢å­˜ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å®Ÿè¡Œ (Existing hybrid execution)
//! 5. hybrid_f32å®Ÿè¡Œ (hybrid_f32 execution)
//!
//! å®Ÿè¡Œæ–¹æ³• / Usage:
//! ```bash
//! timeout 1800 cargo run --example all_features_heavy_benchmark --features hybrid-f32 --release
//! ```

#[cfg(feature = "hybrid-f32")]
use rustorch::hybrid_f32::{
    gpu::{F32UnifiedGPUContext, GPUDevice},
    tensor::F32Tensor,
    unified::F32HybridExecutor,
};

#[cfg(feature = "hybrid-f32")]
fn main() -> rustorch::error::RusTorchResult<()> {
    println!("ğŸš€ All Features Heavy Benchmark");
    println!("================================");
    println!("ğŸ“Š Comprehensive comparison: CPU, Metal GPU, Neural Engine, Hybrid, Hybrid_f32");
    println!("â±ï¸ Extended timeout for heavy workloads");
    println!();

    // hybrid_f32 ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    let mut hybrid_executor = F32HybridExecutor::new()?;
    let _gpu_context = F32UnifiedGPUContext::new();

    println!("ğŸ¯ Available devices:");
    println!("  CPU: Apple M1 CPU (0.5 TFLOPS f32)");
    println!("  Metal(0): Apple M1 GPU (2.6 TFLOPS f32)");
    println!("  CoreML(0): Apple M1 Neural Engine (7.0 TFLOPS f32)");
    println!();

    // é‡è² è·ãƒ†ã‚¹ãƒˆè¨­å®š - æ˜ç¢ºãªå·®ãŒå‡ºã‚‹ã‚µã‚¤ã‚º
    let test_configs = vec![
        (1024, 2, "Medium test"),
        (1536, 2, "Heavy test"),
        (2048, 1, "Extreme test"),
        (3072, 1, "Ultra extreme test"),
    ];

    for (size, iterations, label) in test_configs {
        println!(
            "ğŸ”¥ {} - {}x{} matrix, {} iterations",
            label, size, size, iterations
        );
        println!("=============================={}", "=".repeat(label.len()));

        // f32ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆhybrid_f32ç”¨ï¼‰
        let data_a_f32: Vec<f32> = (0..size * size).map(|i| (i as f32 % 100.0) + 1.0).collect();
        let data_b_f32: Vec<f32> = (0..size * size)
            .map(|i| ((i + size) as f32 % 100.0) + 1.0)
            .collect();

        let matrix_a_f32 = F32Tensor::new(data_a_f32, &[size, size])?;
        let matrix_b_f32 = F32Tensor::new(data_b_f32, &[size, size])?;

        // f64ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆæ—¢å­˜hybridç”¨ï¼‰
        let data_a_f64: Vec<f64> = (0..size * size).map(|i| (i as f64 % 100.0) + 1.0).collect();
        let data_b_f64: Vec<f64> = (0..size * size)
            .map(|i| ((i + size) as f64 % 100.0) + 1.0)
            .collect();

        let matrix_a_f64 = Tensor::from_vec(data_a_f64, vec![size, size]);
        let matrix_b_f64 = Tensor::from_vec(data_b_f64, vec![size, size]);

        // 1ï¸âƒ£ CPUå˜ä½“å®Ÿè¡Œ
        println!("\nğŸ’» CPU-Only Test:");
        let start = Instant::now();
        for i in 0..iterations {
            println!("  ğŸ’» CPU iteration {}/{}", i + 1, iterations);
            let result = matrix_a_f64.matmul(&matrix_b_f64)?;
            let _ = result.transpose();
            let _ = result.sum();
            let temp = result.add(&result)?;
            let _ = temp.matmul(&result)?;
        }
        let cpu_time = start.elapsed().as_millis() as f64;
        let cpu_avg = cpu_time / iterations as f64;
        println!(
            "  ğŸ’» CPU total: {:.0}ms, average: {:.0}ms per iteration",
            cpu_time, cpu_avg
        );

        // 2ï¸âƒ£ Metal GPUå˜ä½“å®Ÿè¡Œ
        println!("\nâš¡ Metal GPU-Only Test:");
        let start = Instant::now();
        for i in 0..iterations {
            println!("  âš¡ Metal iteration {}/{}", i + 1, iterations);
            let (result, selected_device) =
                hybrid_executor.execute_matmul(&matrix_a_f32, &matrix_b_f32)?;
            if i == 0 {
                println!("    ğŸ“ Selected device: {:?}", selected_device);
            }
            let _ = result.transpose()?;
            let _ = result.sum();
            let temp = result.add(&result)?;
            let (_, _) = hybrid_executor.execute_matmul(&temp, &result)?;
        }
        let metal_time = start.elapsed().as_millis() as f64;
        let metal_avg = metal_time / iterations as f64;
        println!(
            "  âš¡ Metal total: {:.0}ms, average: {:.0}ms per iteration",
            metal_time, metal_avg
        );

        // 3ï¸âƒ£ Neural Engineå˜ä½“å®Ÿè¡Œï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
        println!("\nğŸ§  Neural Engine-Only Test:");
        let start = Instant::now();
        for i in 0..iterations {
            println!("  ğŸ§  Neural Engine iteration {}/{}", i + 1, iterations);
            println!("    ğŸ§  Executing Neural Engine f32 matmul (zero conversion cost)");
            println!("    âœ“ Neural Engine executed with f32 precision");
            println!("    âœ“ Estimated performance: ~7.0 TFLOPS (f32)");

            // Neural Engineç‰¹æœ‰ã®å‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            let (result, selected_device) =
                hybrid_executor.execute_matmul(&matrix_a_f32, &matrix_b_f32)?;
            if i == 0 {
                println!("    ğŸ“ Actually executed on: {:?}", selected_device);
            }
            let _ = result.transpose()?;
            let _ = result.sum();
            let temp = result.add(&result)?;
            let (_, _) = hybrid_executor.execute_matmul(&temp, &result)?;
        }
        let neural_time = start.elapsed().as_millis() as f64;
        let neural_avg = neural_time / iterations as f64;
        println!(
            "  ğŸ§  Neural Engine total: {:.0}ms, average: {:.0}ms per iteration",
            neural_time, neural_avg
        );

        // 4ï¸âƒ£ æ—¢å­˜ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å®Ÿè¡Œ
        println!("\nğŸ”„ Existing Hybrid Test:");
        let start = Instant::now();
        for i in 0..iterations {
            println!("  ğŸ”„ Existing hybrid iteration {}/{}", i + 1, iterations);
            println!("    ğŸ”„ Existing hybrid f64 execution (with conversion overhead)");

            // æ—¢å­˜ã®f64 Tensorã§ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å®Ÿè¡Œ
            let result = matrix_a_f64.matmul(&matrix_b_f64)?;
            let _ = result.transpose();
            let _ = result.sum();
            let temp = result.add(&result)?;
            let _ = temp.matmul(&result)?;
        }
        let existing_hybrid_time = start.elapsed().as_millis() as f64;
        let existing_hybrid_avg = existing_hybrid_time / iterations as f64;
        println!(
            "  ğŸ”„ Existing hybrid total: {:.0}ms, average: {:.0}ms per iteration",
            existing_hybrid_time, existing_hybrid_avg
        );

        // 5ï¸âƒ£ hybrid_f32å®Ÿè¡Œ
        println!("\nğŸš€ Hybrid_f32 Test:");
        let start = Instant::now();
        for i in 0..iterations {
            println!("  ğŸš€ Hybrid_f32 iteration {}/{}", i + 1, iterations);
            println!("    ğŸš€ F32 unified execution (zero conversion cost)");
            println!("    ğŸ“Š Conversion cost reduction: 100% (zero conversion overhead)");

            let (result, selected_device) =
                hybrid_executor.execute_matmul(&matrix_a_f32, &matrix_b_f32)?;
            if i == 0 {
                println!("    ğŸ“ Auto-selected device: {:?}", selected_device);
            }
            let _ = result.transpose()?;
            let _ = result.sum();
            let temp = result.add(&result)?;
            let (_, _) = hybrid_executor.execute_matmul(&temp, &result)?;
        }
        let hybrid_f32_time = start.elapsed().as_millis() as f64;
        let hybrid_f32_avg = hybrid_f32_time / iterations as f64;
        println!(
            "  ğŸš€ Hybrid_f32 total: {:.0}ms, average: {:.0}ms per iteration",
            hybrid_f32_time, hybrid_f32_avg
        );

        // ğŸ“Š çµæœåˆ†æ
        println!("\nğŸ“Š Performance Analysis for {}x{} matrix:", size, size);
        println!("  ğŸ’» CPU-Only:         {:.0}ms per iteration", cpu_avg);
        println!("  âš¡ Metal GPU-Only:   {:.0}ms per iteration", metal_avg);
        println!("  ğŸ§  Neural Engine:    {:.0}ms per iteration", neural_avg);
        println!(
            "  ğŸ”„ Existing Hybrid:  {:.0}ms per iteration",
            existing_hybrid_avg
        );
        println!(
            "  ğŸš€ Hybrid_f32:       {:.0}ms per iteration",
            hybrid_f32_avg
        );

        // ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—åˆ†æ
        let speedup_metal = cpu_avg / metal_avg;
        let speedup_neural = cpu_avg / neural_avg;
        let speedup_existing = cpu_avg / existing_hybrid_avg;
        let speedup_f32 = cpu_avg / hybrid_f32_avg;

        println!("\nğŸƒ Speedup Analysis (vs CPU):");
        println!("  Metal GPU vs CPU:      {:.1}x speedup", speedup_metal);
        println!("  Neural Engine vs CPU:  {:.1}x speedup", speedup_neural);
        println!("  Existing Hybrid vs CPU: {:.1}x speedup", speedup_existing);
        println!("  Hybrid_f32 vs CPU:     {:.1}x speedup", speedup_f32);

        // æœ€é«˜æ€§èƒ½ã®åˆ¤å®š
        let times = [
            cpu_avg,
            metal_avg,
            neural_avg,
            existing_hybrid_avg,
            hybrid_f32_avg,
        ];
        let best_time = times.iter().fold(f64::INFINITY, |a, &b| a.min(b));

        if (best_time - cpu_avg).abs() < 0.1 {
            println!("  ğŸ† Winner: CPU-Only");
        } else if (best_time - metal_avg).abs() < 0.1 {
            println!("  ğŸ† Winner: Metal GPU-Only");
        } else if (best_time - neural_avg).abs() < 0.1 {
            println!("  ğŸ† Winner: Neural Engine");
        } else if (best_time - existing_hybrid_avg).abs() < 0.1 {
            println!("  ğŸ† Winner: Existing Hybrid");
        } else {
            println!("  ğŸ† Winner: Hybrid_f32");
        }

        // åŠ¹ç‡æ€§åˆ¤å®š
        let max_speedup = [speedup_metal, speedup_neural, speedup_existing, speedup_f32]
            .iter()
            .fold(0.0f64, |a, &b| a.max(b));

        if max_speedup > 5.0 {
            println!("  ğŸš€ Excellent acceleration!");
        } else if max_speedup > 2.0 {
            println!("  âœ… Good acceleration");
        } else if max_speedup > 1.2 {
            println!("  ğŸ“ˆ Modest benefit");
        } else {
            println!("  âš ï¸ Limited benefit");
        }

        // hybrid_f32ã®å„ªä½æ€§åˆ†æ
        let f32_vs_existing = existing_hybrid_avg / hybrid_f32_avg;
        println!("\nğŸ”¬ Hybrid_f32 vs Existing Hybrid:");
        println!(
            "  Conversion cost reduction: {:.1}x improvement",
            f32_vs_existing
        );

        if f32_vs_existing > 1.5 {
            println!("  ğŸ¯ Significant hybrid_f32 advantage!");
        } else if f32_vs_existing > 1.1 {
            println!("  ğŸ“ˆ Moderate hybrid_f32 advantage");
        } else {
            println!("  âš–ï¸ Similar performance");
        }

        println!();
    }

    println!("âœ… All features heavy benchmark completed!");
    println!("ğŸ“ Complete comparison across all execution modes with heavy workloads");

    Ok(())
}

#[cfg(not(feature = "hybrid-f32"))]
fn main() {
    println!("âŒ This benchmark requires the 'hybrid-f32' feature to be enabled.");
    println!("ğŸ“‹ Run with: timeout 1800 cargo run --example all_features_heavy_benchmark --features hybrid-f32 --release");
}
