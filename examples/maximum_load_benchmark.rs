//! æœ€å¤§è² è·ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ - GPUã¨Neural Engineã«é«˜è² è·ã‚’ã‹ã‘ã‚‹
//! Maximum Load Benchmark - High load for GPU and Neural Engine
//!
//! ã“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯GPUã¨Neural Engineã®é™ç•Œæ€§èƒ½ã‚’æ¸¬å®šã—ã¾ã™ï¼š
//! This benchmark measures the limit performance of GPU and Neural Engine:
//!
//! 1. å¤§è¦æ¨¡è¡Œåˆ—æ¼”ç®— (Large matrix operations)
//! 2. è¤‡é›‘ãªæ¼”ç®—ãƒã‚§ãƒ¼ãƒ³ (Complex operation chains)
//! 3. ãƒ¡ãƒ¢ãƒªé›†ç´„çš„ãªå‡¦ç† (Memory-intensive processing)
//! 4. ç¶™ç¶šçš„ãªé«˜è² è· (Sustained high load)
//!
//! å®Ÿè¡Œæ–¹æ³• / Usage:
//! ```bash
//! timeout 3600 cargo run --example maximum_load_benchmark --features hybrid-f32 --release
//! ```

#[cfg(feature = "hybrid-f32")]
use rustorch::hybrid_f32::{
    gpu::F32UnifiedGPUContext, tensor::F32Tensor, unified::F32HybridExecutor,
};

#[cfg(feature = "hybrid-f32")]
fn main() -> rustorch::error::RusTorchResult<()> {
    println!("ğŸš€ Maximum Load Benchmark for GPU & Neural Engine");
    println!("=================================================");
    println!("ğŸ“Š High-stress testing with large matrices and complex operations");
    println!("â±ï¸ Extended timeout (60 minutes) for comprehensive analysis");
    println!("ğŸ”¥ Designed to push GPU and Neural Engine to their limits");
    println!();

    // ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    let mut hybrid_executor = F32HybridExecutor::new()?;
    let _gpu_context = F32UnifiedGPUContext::new();

    println!("ğŸ¯ Target devices for maximum load testing:");
    println!("  CPU: Apple M1 CPU (0.5 TFLOPS f32) - Baseline");
    println!("  Metal(0): Apple M1 GPU (2.6 TFLOPS f32) - High throughput target");
    println!("  CoreML(0): Apple M1 Neural Engine (7.0 TFLOPS f32) - Maximum performance target");
    println!();

    // è¶…é«˜è² è·ãƒ†ã‚¹ãƒˆè¨­å®š - ã‚ˆã‚Šå¤§ããªã‚µã‚¤ã‚ºã¨ã‚ˆã‚Šå¤šãã®æ¼”ç®—
    let test_configs = vec![
        (2048, 1, "Extreme Load"),
        (3072, 1, "Ultra Load"),
        (4096, 1, "Maximum Load"),
        (5120, 1, "Beyond Maximum Load"),
    ];

    for (size, iterations, label) in test_configs {
        println!(
            "ğŸ”¥ {} - {}x{} matrix, {} iterations",
            label, size, size, iterations
        );
        println!(
            "Memory usage: ~{:.1} GB per matrix",
            (size * size * 4) as f64 / 1_000_000_000.0
        );
        println!("=============================={}", "=".repeat(label.len()));

        // f32ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆhybrid_f32ç”¨ï¼‰
        println!(
            "ğŸ“Š Creating f32 matrices ({:.1} GB total)...",
            (size * size * 4 * 2) as f64 / 1_000_000_000.0
        );
        let data_a_f32: Vec<f32> = (0..size * size).map(|i| (i as f32 % 100.0) + 1.0).collect();
        let data_b_f32: Vec<f32> = (0..size * size)
            .map(|i| ((i + size) as f32 % 100.0) + 1.0)
            .collect();

        let matrix_a_f32 = F32Tensor::new(data_a_f32, &[size, size])?;
        let matrix_b_f32 = F32Tensor::new(data_b_f32, &[size, size])?;

        // f64ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆæ—¢å­˜hybridç”¨ï¼‰
        println!(
            "ğŸ“Š Creating f64 matrices ({:.1} GB total)...",
            (size * size * 8 * 2) as f64 / 1_000_000_000.0
        );
        let data_a_f64: Vec<f64> = (0..size * size).map(|i| (i as f64 % 100.0) + 1.0).collect();
        let data_b_f64: Vec<f64> = (0..size * size)
            .map(|i| ((i + size) as f64 % 100.0) + 1.0)
            .collect();

        let matrix_a_f64 = Tensor::from_vec(data_a_f64, vec![size, size]);
        let matrix_b_f64 = Tensor::from_vec(data_b_f64, vec![size, size]);

        // è¤‡é›‘ãªæ¼”ç®—ãƒã‚§ãƒ¼ãƒ³ã‚’å®šç¾©
        let perform_complex_operations_f32 = |a: &F32Tensor,
                                              b: &F32Tensor,
                                              executor: &mut F32HybridExecutor|
         -> rustorch::error::RusTorchResult<f64> {
            let start = Instant::now();

            // 1. å¤§è¦æ¨¡è¡Œåˆ—ä¹—ç®—
            let (result1, _) = executor.execute_matmul(a, b)?;

            // 2. è»¢ç½®æ“ä½œ
            let result2 = result1.transpose()?;

            // 3. è¦ç´ åˆ¥åŠ ç®—
            let result3 = result2.add(&result1)?;

            // 4. äºŒæ¬¡è¡Œåˆ—ä¹—ç®—
            let (result4, _) = executor.execute_matmul(&result3, &result1)?;

            // 5. çµ±è¨ˆæ“ä½œ
            let _ = result4.sum();

            // 6. å†åº¦è¡Œåˆ—ä¹—ç®—ï¼ˆãƒ¡ãƒ¢ãƒªãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ï¼‰
            let (result5, _) = executor.execute_matmul(&result4, &result2)?;

            // 7. æœ€çµ‚çš„ãªè»¢ç½®ã¨åŠ ç®—
            let result6 = result5.transpose()?;
            let _ = result6.add(&result3)?;

            Ok(start.elapsed().as_millis() as f64)
        };

        let perform_complex_operations_f64 =
            |a: &Tensor<f64>, b: &Tensor<f64>| -> rustorch::error::RusTorchResult<f64> {
                let start = Instant::now();

                // 1. å¤§è¦æ¨¡è¡Œåˆ—ä¹—ç®—
                let result1 = a.matmul(b)?;

                // 2. è»¢ç½®æ“ä½œ
                let result2 = result1.transpose()?;

                // 3. è¦ç´ åˆ¥åŠ ç®—
                let result3 = result2.add(&result1)?;

                // 4. äºŒæ¬¡è¡Œåˆ—ä¹—ç®—
                let result4 = result3.matmul(&result1)?;

                // 5. çµ±è¨ˆæ“ä½œ
                let _ = result4.sum();

                // 6. å†åº¦è¡Œåˆ—ä¹—ç®—ï¼ˆãƒ¡ãƒ¢ãƒªãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ï¼‰
                let result5 = result4.matmul(&result2)?;

                // 7. æœ€çµ‚çš„ãªè»¢ç½®ã¨åŠ ç®—
                let result6 = result5.transpose()?;
                let _ = result6.add(&result3)?;

                Ok(start.elapsed().as_millis() as f64)
            };

        // 1ï¸âƒ£ CPUå˜ä½“å®Ÿè¡Œ - è¶…é«˜è² è·
        println!("\nğŸ’» CPU-Only Maximum Load Test:");
        println!("  ğŸ”¥ Complex operation chain on CPU");
        let mut cpu_times = Vec::new();
        for i in 0..iterations {
            println!("  ğŸ’» CPU complex iteration {}/{}", i + 1, iterations);
            let time = perform_complex_operations_f64(&matrix_a_f64, &matrix_b_f64)?;
            cpu_times.push(time);
            println!("    â±ï¸ CPU complex operations: {:.0}ms", time);
        }
        let cpu_avg = cpu_times.iter().sum::<f64>() / iterations as f64;
        println!(
            "  ğŸ’» CPU average: {:.0}ms per complex operation chain",
            cpu_avg
        );

        // 2ï¸âƒ£ Metal GPUå˜ä½“å®Ÿè¡Œ - è¶…é«˜è² è·
        println!("\nâš¡ Metal GPU Maximum Load Test:");
        println!("  ğŸ”¥ Complex operation chain on Metal GPU");
        let mut metal_times = Vec::new();
        for i in 0..iterations {
            println!("  âš¡ Metal GPU complex iteration {}/{}", i + 1, iterations);
            let time =
                perform_complex_operations_f32(&matrix_a_f32, &matrix_b_f32, &mut hybrid_executor)?;
            metal_times.push(time);
            println!("    â±ï¸ Metal GPU complex operations: {:.0}ms", time);
        }
        let metal_avg = metal_times.iter().sum::<f64>() / iterations as f64;
        println!(
            "  âš¡ Metal GPU average: {:.0}ms per complex operation chain",
            metal_avg
        );

        // 3ï¸âƒ£ Neural Engineå˜ä½“å®Ÿè¡Œ - è¶…é«˜è² è·
        println!("\nğŸ§  Neural Engine Maximum Load Test:");
        println!("  ğŸ”¥ Complex operation chain targeting Neural Engine");
        let mut neural_times = Vec::new();
        for i in 0..iterations {
            println!(
                "  ğŸ§  Neural Engine complex iteration {}/{}",
                i + 1,
                iterations
            );
            println!(
                "    ğŸ§  Executing Neural Engine f32 complex operations (zero conversion cost)"
            );
            println!("    âœ“ Neural Engine complex chain with f32 precision");
            println!("    âœ“ Target performance: ~7.0 TFLOPS (f32)");

            let time =
                perform_complex_operations_f32(&matrix_a_f32, &matrix_b_f32, &mut hybrid_executor)?;
            neural_times.push(time);
            println!("    â±ï¸ Neural Engine complex operations: {:.0}ms", time);
        }
        let neural_avg = neural_times.iter().sum::<f64>() / iterations as f64;
        println!(
            "  ğŸ§  Neural Engine average: {:.0}ms per complex operation chain",
            neural_avg
        );

        // 4ï¸âƒ£ æ—¢å­˜ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å®Ÿè¡Œ - è¶…é«˜è² è·
        println!("\nğŸ”„ Existing Hybrid Maximum Load Test:");
        println!("  ğŸ”¥ Complex operation chain with f64 conversion overhead");
        let mut existing_times = Vec::new();
        for i in 0..iterations {
            println!(
                "  ğŸ”„ Existing hybrid complex iteration {}/{}",
                i + 1,
                iterations
            );
            println!("    ğŸ”„ Existing hybrid f64 complex operations (with conversion overhead)");

            let time = perform_complex_operations_f64(&matrix_a_f64, &matrix_b_f64)?;
            existing_times.push(time);
            println!("    â±ï¸ Existing hybrid complex operations: {:.0}ms", time);
        }
        let existing_avg = existing_times.iter().sum::<f64>() / iterations as f64;
        println!(
            "  ğŸ”„ Existing hybrid average: {:.0}ms per complex operation chain",
            existing_avg
        );

        // 5ï¸âƒ£ hybrid_f32å®Ÿè¡Œ - è¶…é«˜è² è·
        println!("\nğŸš€ Hybrid_f32 Maximum Load Test:");
        println!("  ğŸ”¥ Complex operation chain with f32 unified execution");
        let mut f32_times = Vec::new();
        for i in 0..iterations {
            println!("  ğŸš€ Hybrid_f32 complex iteration {}/{}", i + 1, iterations);
            println!("    ğŸš€ F32 unified complex operations (zero conversion cost)");
            println!("    ğŸ“Š Complex operation chain conversion cost reduction: 100%");

            let time =
                perform_complex_operations_f32(&matrix_a_f32, &matrix_b_f32, &mut hybrid_executor)?;
            f32_times.push(time);
            println!("    â±ï¸ Hybrid_f32 complex operations: {:.0}ms", time);
        }
        let f32_avg = f32_times.iter().sum::<f64>() / iterations as f64;
        println!(
            "  ğŸš€ Hybrid_f32 average: {:.0}ms per complex operation chain",
            f32_avg
        );

        // ğŸ“Š è©³ç´°åˆ†æ
        println!(
            "\nğŸ“Š Maximum Load Performance Analysis for {}x{} matrix:",
            size, size
        );
        println!("  Matrix size: {}x{} elements", size, size);
        println!(
            "  Memory per matrix: {:.1} GB (f32) / {:.1} GB (f64)",
            (size * size * 4) as f64 / 1_000_000_000.0,
            (size * size * 8) as f64 / 1_000_000_000.0
        );
        println!("  Complex operations: 7 operations per chain");
        println!();

        println!("  ğŸ’» CPU-Only:         {:.0}ms per complex chain", cpu_avg);
        println!(
            "  âš¡ Metal GPU-Only:   {:.0}ms per complex chain",
            metal_avg
        );
        println!(
            "  ğŸ§  Neural Engine:    {:.0}ms per complex chain",
            neural_avg
        );
        println!(
            "  ğŸ”„ Existing Hybrid:  {:.0}ms per complex chain",
            existing_avg
        );
        println!("  ğŸš€ Hybrid_f32:       {:.0}ms per complex chain", f32_avg);

        // ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—åˆ†æ
        let speedup_metal = cpu_avg / metal_avg;
        let speedup_neural = cpu_avg / neural_avg;
        let speedup_existing = cpu_avg / existing_avg;
        let speedup_f32 = cpu_avg / f32_avg;

        println!("\nğŸƒ Maximum Load Speedup Analysis (vs CPU):");
        println!("  Metal GPU vs CPU:      {:.1}x speedup", speedup_metal);
        println!("  Neural Engine vs CPU:  {:.1}x speedup", speedup_neural);
        println!("  Existing Hybrid vs CPU: {:.1}x speedup", speedup_existing);
        println!("  Hybrid_f32 vs CPU:     {:.1}x speedup", speedup_f32);

        // æœ€é«˜æ€§èƒ½ã®åˆ¤å®š
        let times = [cpu_avg, metal_avg, neural_avg, existing_avg, f32_avg];
        let best_time = times.iter().fold(f64::INFINITY, |a, &b| a.min(b));

        if (best_time - cpu_avg).abs() < best_time * 0.01 {
            println!("  ğŸ† Maximum Load Winner: CPU-Only");
        } else if (best_time - metal_avg).abs() < best_time * 0.01 {
            println!("  ğŸ† Maximum Load Winner: Metal GPU-Only");
        } else if (best_time - neural_avg).abs() < best_time * 0.01 {
            println!("  ğŸ† Maximum Load Winner: Neural Engine");
        } else if (best_time - existing_avg).abs() < best_time * 0.01 {
            println!("  ğŸ† Maximum Load Winner: Existing Hybrid");
        } else {
            println!("  ğŸ† Maximum Load Winner: Hybrid_f32");
        }

        // GPU/Neural EngineåŠ¹ç‡æ€§åˆ¤å®š
        let max_speedup = [speedup_metal, speedup_neural, speedup_existing, speedup_f32]
            .iter()
            .fold(0.0f64, |a, &b| a.max(b));

        if max_speedup > 10.0 {
            println!("  ğŸš€ Exceptional acceleration under maximum load!");
        } else if max_speedup > 5.0 {
            println!("  ğŸš€ Excellent acceleration under maximum load!");
        } else if max_speedup > 2.0 {
            println!("  âœ… Good acceleration under maximum load");
        } else if max_speedup > 1.2 {
            println!("  ğŸ“ˆ Modest benefit under maximum load");
        } else {
            println!("  âš ï¸ Limited benefit under maximum load");
        }

        // hybrid_f32 vs æ—¢å­˜hybridåˆ†æ
        let f32_vs_existing = existing_avg / f32_avg;
        println!("\nğŸ”¬ Maximum Load: Hybrid_f32 vs Existing Hybrid:");
        println!(
            "  Complex operation conversion cost reduction: {:.1}x improvement",
            f32_vs_existing
        );

        if f32_vs_existing > 3.0 {
            println!("  ğŸ¯ Major hybrid_f32 advantage under maximum load!");
        } else if f32_vs_existing > 2.0 {
            println!("  ğŸ¯ Significant hybrid_f32 advantage under maximum load!");
        } else if f32_vs_existing > 1.5 {
            println!("  ğŸ“ˆ Substantial hybrid_f32 advantage under maximum load");
        } else if f32_vs_existing > 1.1 {
            println!("  ğŸ“ˆ Moderate hybrid_f32 advantage under maximum load");
        } else {
            println!("  âš–ï¸ Similar performance under maximum load");
        }

        // ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åˆ†æ
        println!("\nğŸ’¾ Memory Efficiency Analysis:");
        println!(
            "  f32 memory usage: {:.1} GB",
            (size * size * 4 * 2) as f64 / 1_000_000_000.0
        );
        println!(
            "  f64 memory usage: {:.1} GB",
            (size * size * 8 * 2) as f64 / 1_000_000_000.0
        );
        println!("  Memory efficiency gain (f32 vs f64): 2.0x");

        println!();
    }

    println!("âœ… Maximum load benchmark completed!");
    println!("ğŸ“ Comprehensive analysis of GPU and Neural Engine performance under extreme load");
    println!("ğŸ¯ Results demonstrate true limits and capabilities of each execution mode");

    Ok(())
}

#[cfg(not(feature = "hybrid-f32"))]
fn main() {
    println!("âŒ This benchmark requires the 'hybrid-f32' feature to be enabled.");
    println!("ğŸ“‹ Run with: timeout 3600 cargo run --example maximum_load_benchmark --features hybrid-f32 --release");
}
