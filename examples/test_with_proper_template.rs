/// æ­£ã—ã„ãƒãƒ£ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¦llama.cppã¨æ¯”è¼ƒå¯èƒ½ãªçµæœã‚’å¾—ã‚‹

use rustorch::hybrid_f32::models::{F32LlamaModel, DeviceType};
use rustorch::hybrid_f32::error::F32Result;

fn main() -> F32Result<()> {
    println!("ğŸ§ª ãƒãƒ£ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä»˜ããƒ†ã‚¹ãƒˆ\n");

    let model_path = std::env::var("HOME").unwrap() +
        "/.rustorch/models/TheBloke_TinyLlama-1.1B-Chat-v1.0-GGUF/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf";

    println!("ğŸ“‚ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...");
    let mut model = F32LlamaModel::from_gguf_with_device(&model_path, DeviceType::Cpu)?;

    // TinyLlamaã®ãƒãƒ£ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    // llama-tokenizeã§ç¢ºèªã—ãŸãƒˆãƒ¼ã‚¯ãƒ³IDåˆ—
    let chat_template = vec![
        1,      // <s>
        529,    // <
        29989,  // |
        5205,   // system
        29989,  // |
        29958,  // >
        13,     // \n
        3492,   // You
        526,    // are
        263,    // a
        8444,   // helpful
        20255,  // assistant
        29889,  // .
        2,      // </s>
        29871,  // (space)
        13,     // \n
        29966,  // <
        29989,  // |
        1792,   // user
        29989,  // |
        29958,  // >
        13,     // \n
        5618,   // What
        338,    // is
        278,    // the
        7483,   // capital
        310,    // of
        3444,   // France
        29973,  // ?
        2,      // </s>
        29871,  // (space)
        13,     // \n
        29966,  // <
        29989,  // |
        465,    // ass
        22137,  // istant
        29989,  // |
        29958,  // >
        13,     // \n
    ];

    println!("ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: \"What is the capital of France?\"");
    println!("   ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {}", chat_template.len());

    println!("\nğŸ”„ æ¨è«–ä¸­...");
    let logits = model.forward(&chat_template)?;
    let logits_data = logits.as_slice();

    // Top 10ã‚’è¡¨ç¤º
    let mut indexed: Vec<(usize, f32)> = logits_data.iter()
        .enumerate()
        .map(|(i, &v)| (i, v))
        .collect();
    indexed.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());

    println!("\nğŸ† Top 10äºˆæ¸¬:");
    for (i, (token, logit)) in indexed.iter().take(10).enumerate() {
        println!("   {}. Token {}: {:.6}", i + 1, token, logit);
    }

    // æœŸå¾…ã•ã‚Œã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
    // "Paris"ã¯ä»¥ä¸‹ã®ã„ãšã‚Œã‹:
    // - 3681: "Paris"
    // - 9626: " Paris"
    println!("\nğŸ“Š ç‰¹å®šãƒˆãƒ¼ã‚¯ãƒ³ã®logit:");
    println!("   Token 3681 (\"Paris\"): {:.6}", logits_data[3681]);
    println!("   Token 9626 (\" Paris\"): {:.6}", logits_data[9626]);
    println!("   Token 450 (\" The\"): {:.6}", logits_data[450]);
    println!("   Token 20780: {:.6}", logits_data[20780]);

    // llama.cppã¨æ¯”è¼ƒ
    println!("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("ğŸ” llama.cppã¨ã®æ¯”è¼ƒ");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    println!("äºˆæƒ³ã•ã‚Œã‚‹å‹•ä½œ:");
    println!("  - llama.cppã¯åŒã˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ \"Paris\" ã¾ãŸã¯ \"The capital\" ã‚’ç”Ÿæˆ");
    println!("  - RusTorchã‚‚åŒæ§˜ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’äºˆæ¸¬ã™ã¹ã");
    println!();

    if indexed[0].0 == 3681 || indexed[0].0 == 9626 {
        println!("âœ… SUCCESS! \"Paris\"ã‚’æ­£ã—ãäºˆæ¸¬ï¼");
    } else if indexed[0].0 == 450 {
        println!("âœ… GOOD! \"The\"ã‚’äºˆæ¸¬ï¼ˆå¦¥å½“ãªå›ç­”ã®å§‹ã¾ã‚Šï¼‰");
    } else {
        println!("ğŸ¤” Token {}ã‚’äºˆæ¸¬", indexed[0].0);
        println!("   ã“ã‚ŒãŒæ­£ã—ã„ã‹llama.cppã§ç¢ºèªã™ã‚‹å¿…è¦ã‚ã‚Š");
    }

    // ç°¡å˜ãªç”Ÿæˆã‚‚ãƒ†ã‚¹ãƒˆ
    println!("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("ğŸ”„ 3ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆãƒ†ã‚¹ãƒˆ");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    let mut current_tokens = chat_template.clone();
    println!("ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³:");

    for step in 0..3 {
        let logits_step = if step == 0 {
            logits.clone()
        } else {
            model.forward(&current_tokens[current_tokens.len()-1..])?
        };

        let logits_step_data = logits_step.as_slice();
        let mut indexed_step: Vec<(usize, f32)> = logits_step_data.iter()
            .enumerate()
            .map(|(i, &v)| (i, v))
            .collect();
        indexed_step.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());

        let next_token = indexed_step[0].0;
        println!("  Step {}: Token {} (logit: {:.3})", step + 1, next_token, indexed_step[0].1);
        current_tokens.push(next_token);
    }

    println!("\nğŸ’¡ ãƒ’ãƒ³ãƒˆ:");
    println!("  åŒã˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’llama.cppã§è©¦ã™ã«ã¯:");
    println!("  echo \"What is the capital of France?\" | llama-cli -m <model> -n 3");

    Ok(())
}
