<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="RusTorch ğŸš€"><title>rustorch - Rust</title><script>if(window.location.protocol!=="file:")document.head.insertAdjacentHTML("beforeend","SourceSerif4-Regular-6b053e98.ttf.woff2,FiraSans-Italic-81dc35de.woff2,FiraSans-Regular-0fe48ade.woff2,FiraSans-MediumItalic-ccf7e434.woff2,FiraSans-Medium-e1aa3f0a.woff2,SourceCodePro-Regular-8badfe75.ttf.woff2,SourceCodePro-Semibold-aa29a496.ttf.woff2".split(",").map(f=>`<link rel="preload" as="font" type="font/woff2" crossorigin href="../static.files/${f}">`).join(""))</script><link rel="stylesheet" href="../static.files/normalize-9960930a.css"><link rel="stylesheet" href="../static.files/rustdoc-aa0817cf.css"><meta name="rustdoc-vars" data-root-path="../" data-static-root-path="../static.files/" data-current-crate="rustorch" data-themes="" data-resource-suffix="" data-rustdoc-version="1.90.0 (1159e78c4 2025-09-14)" data-channel="1.90.0" data-search-js="search-fa3e91e5.js" data-settings-js="settings-5514c975.js" ><script src="../static.files/storage-68b7e25d.js"></script><script defer src="../crates.js"></script><script defer src="../static.files/main-eebb9057.js"></script><noscript><link rel="stylesheet" href="../static.files/noscript-32bb7600.css"></noscript><link rel="alternate icon" type="image/png" href="../static.files/favicon-32x32-6580c154.png"><link rel="icon" type="image/svg+xml" href="../static.files/favicon-044be391.svg"></head><body class="rustdoc mod crate"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="mobile-topbar"><button class="sidebar-menu-toggle" title="show sidebar"></button></nav><nav class="sidebar"><div class="sidebar-crate"><h2><a href="../rustorch/index.html">rustorch</a><span class="version">0.6.29</span></h2></div><div class="sidebar-elems"><ul class="block"><li><a id="all-types" href="all.html">All Items</a></li></ul><section id="rustdoc-toc"><h3><a href="#">Sections</a></h3><ul class="block top-toc"><li><a href="#rustorch-" title="RusTorch ğŸš€">RusTorch ğŸš€</a><ul><li><a href="#-key-features" title="âœ¨ Key Features">âœ¨ Key Features</a></li><li><a href="#-quick-start" title="ğŸš€ Quick Start">ğŸš€ Quick Start</a></li><li><a href="#-safe-operations-with-error-handling" title="ğŸ”§ Safe Operations with Error Handling">ğŸ”§ Safe Operations with Error Handling</a></li><li><a href="#-architecture-overview" title="ğŸ—ï¸ Architecture Overview">ğŸ—ï¸ Architecture Overview</a></li><li><a href="#-parallel-operations" title="ğŸ”„ Parallel Operations">ğŸ”„ Parallel Operations</a></li><li><a href="#-gpu-integration" title="ğŸ® GPU Integration">ğŸ® GPU Integration</a></li><li><a href="#-memory-optimization" title="ğŸ’¾ Memory Optimization">ğŸ’¾ Memory Optimization</a></li><li><a href="#-webassembly-integration" title="ğŸŒ WebAssembly Integration">ğŸŒ WebAssembly Integration</a></li></ul></li></ul><h3><a href="#modules">Crate Items</a></h3><ul class="block"><li><a href="#modules" title="Modules">Modules</a></li><li><a href="#macros" title="Macros">Macros</a></li></ul></section><div id="rustdoc-modnav"></div></div></nav><div class="sidebar-resizer" title="Drag to resize sidebar"></div><main><div class="width-limiter"><rustdoc-search></rustdoc-search><section id="main-content" class="content"><div class="main-heading"><h1>Crate <span>rustorch</span><button id="copy-path" title="Copy item path to clipboard">Copy item path</button></h1><rustdoc-toolbar></rustdoc-toolbar><span class="sub-heading"><a class="src" href="../src/rustorch/lib.rs.html#1-464">Source</a> </span></div><details class="toggle top-doc" open><summary class="hideme"><span>Expand description</span></summary><div class="docblock"><h2 id="rustorch-"><a class="doc-anchor" href="#rustorch-">Â§</a>RusTorch ğŸš€</h2>
<div class="example-wrap"><pre class="rust rust-example-rendered"><code></code></pre></div>
<p><strong>A production-ready deep learning library in Rust with PyTorch-like API, data validation, debugging tools, and enterprise-grade reliability</strong></p>
<p>RusTorch v0.5.14 is a fully functional deep learning library that leverages Rustâ€™s safety and performance,
providing comprehensive tensor operations, automatic differentiation, neural network layers,
transformer architectures, GPU acceleration, unified error handling system, advanced memory optimization features,
data validation &amp; quality assurance, and comprehensive debug &amp; logging systems.</p>
<h3 id="-key-features"><a class="doc-anchor" href="#-key-features">Â§</a>âœ¨ Key Features</h3>
<ul>
<li><strong>ğŸ”¥ Comprehensive Tensor Operations</strong>: Math operations, broadcasting, indexing, and statistics</li>
<li><strong>ğŸ¤– Transformer Architecture</strong>: Complete transformer implementation with multi-head attention</li>
<li><strong>âš¡ SIMD Optimizations</strong>: AVX2/SSE4.1 vectorized operations for high performance</li>
<li><strong>ğŸ”„ Unified Parallel Operations</strong>: Trait-based parallel tensor operations with intelligent scheduling</li>
<li><strong>ğŸ® GPU Integration</strong>: CUDA/Metal/OpenCL support with automatic device selection</li>
<li><strong>ğŸ’¾ Advanced Memory Management</strong>: Zero-copy operations, SIMD-aligned allocation, and memory pools</li>
<li><strong>ğŸ§  Automatic Differentiation</strong>: Tape-based computational graph for gradient computation</li>
<li><strong>ğŸ—ï¸ Neural Network Layers</strong>: Linear, Conv1d/2d/3d, ConvTranspose, RNN/LSTM/GRU, BatchNorm, Dropout, and more</li>
<li><strong>ğŸ›¡ï¸ Unified Error Handling</strong>: Single <code>RusTorchError</code> type with 61+ specialized helper functions and <code>RusTorchResult&lt;T&gt;</code> for cleaner APIs</li>
<li><strong>ğŸ”§ Safe Operations</strong>: Type-safe tensor operations with comprehensive error handling and ReLU activation</li>
<li><strong>âš™ï¸ Shared Base Traits</strong>: Reusable convolution and pooling base implementations for code efficiency</li>
<li><strong>ğŸŒ WebAssembly Support</strong>: Browser-compatible WASM bindings with optimized performance</li>
<li><strong>ğŸ” Data Validation &amp; Quality Assurance</strong>: Statistical analysis, anomaly detection, consistency checking, real-time monitoring</li>
<li><strong>ğŸ› Comprehensive Debug &amp; Logging</strong>: Structured logging, performance profiling, memory tracking, automated alerts</li>
<li><strong>ğŸ’¾ Phase 9 Serialization</strong>: Model save/load, JIT compilation, PyTorch compatibility, cross-platform format support</li>
</ul>
<h3 id="-quick-start"><a class="doc-anchor" href="#-quick-start">Â§</a>ğŸš€ Quick Start</h3>
<div class="example-wrap"><pre class="rust rust-example-rendered"><code><span class="kw">use </span>rustorch::prelude::<span class="kw-2">*</span>;

<span class="comment">// Create tensors
</span><span class="kw">let </span>a = Tensor::from_vec(<span class="macro">vec!</span>[<span class="number">1.0f32</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>], <span class="macro">vec!</span>[<span class="number">2</span>, <span class="number">2</span>]);
<span class="kw">let </span>b = Tensor::from_vec(<span class="macro">vec!</span>[<span class="number">5.0f32</span>, <span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">8.0</span>], <span class="macro">vec!</span>[<span class="number">2</span>, <span class="number">2</span>]);

<span class="comment">// Basic operations
</span><span class="kw">let </span>c = <span class="kw-2">&amp;</span>a + <span class="kw-2">&amp;</span>b;  <span class="comment">// Addition
</span><span class="kw">let </span>d = a.matmul(<span class="kw-2">&amp;</span>b);  <span class="comment">// Matrix multiplication

// Mathematical functions (using methods from tensor ops)
</span><span class="kw">let </span>e = a.data.mapv(|x| x.sin());  <span class="comment">// Sine function
</span><span class="kw">let </span>f = a.data.mapv(|x| x.exp());  <span class="comment">// Exponential function

</span><span class="macro">println!</span>(<span class="string">"Shape: {:?}"</span>, c.shape());
<span class="macro">println!</span>(<span class="string">"Result: {:?}"</span>, c.as_slice());</code></pre></div>
<h3 id="-safe-operations-with-error-handling"><a class="doc-anchor" href="#-safe-operations-with-error-handling">Â§</a>ğŸ”§ Safe Operations with Error Handling</h3>
<div class="example-wrap"><pre class="rust rust-example-rendered"><code><span class="kw">use </span>rustorch::nn::safe_ops::SafeOps;

<span class="comment">// Create variables safely with validation
</span><span class="kw">let </span>var = SafeOps::create_variable(<span class="macro">vec!</span>[-<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>], <span class="macro">vec!</span>[<span class="number">3</span>], <span class="bool-val">false</span>).unwrap();

<span class="comment">// Apply ReLU activation function
</span><span class="kw">let </span>relu_result = SafeOps::relu(<span class="kw-2">&amp;</span>var).unwrap();
<span class="macro">println!</span>(<span class="string">"ReLU: {:?}"</span>, relu_result.data().read().unwrap().as_array()); <span class="comment">// [0.0, 0.0, 1.0]

// Get tensor statistics
</span><span class="kw">let </span>stats = SafeOps::get_stats(<span class="kw-2">&amp;</span>var).unwrap();
<span class="macro">println!</span>(<span class="string">"Mean: {:.2}, Std: {:.2}"</span>, stats.mean, stats.std_dev());</code></pre></div>
<h3 id="-architecture-overview"><a class="doc-anchor" href="#-architecture-overview">Â§</a>ğŸ—ï¸ Architecture Overview</h3>
<p>The library is organized into several key modules:</p>
<ul>
<li>[<code>tensor</code>]: Core tensor operations with parallel and GPU acceleration</li>
<li><a href="nn/index.html" title="mod rustorch::nn"><code>nn</code></a>: Neural network layers and building blocks
<ul>
<li><a href="nn/safe_ops/index.html" title="mod rustorch::nn::safe_ops"><code>nn::safe_ops</code></a>: Safe tensor operations with error handling and ReLU activation</li>
<li><a href="nn/conv_base/index.html" title="mod rustorch::nn::conv_base"><code>nn::conv_base</code></a>: Shared base traits for convolution and pooling layers</li>
</ul>
</li>
<li><a href="autograd/index.html" title="mod rustorch::autograd"><code>autograd</code></a>: Automatic differentiation system</li>
<li><a href="vision/index.html" title="mod rustorch::vision"><code>vision</code></a>: Computer vision utilities including transforms and datasets</li>
<li><a href="optim/index.html" title="mod rustorch::optim"><code>optim</code></a>: Optimization algorithms (SGD, Adam, etc.)</li>
<li><a href="gpu/index.html" title="mod rustorch::gpu"><code>gpu</code></a>: GPU acceleration support (CUDA, Metal, OpenCL)</li>
<li><a href="simd/index.html" title="mod rustorch::simd"><code>simd</code></a>: SIMD vectorized operations</li>
<li><code>wasm</code>: WebAssembly bindings for browser deployment</li>
<li><a href="memory/index.html" title="mod rustorch::memory"><code>memory</code></a>: Advanced memory management and pooling</li>
<li><a href="data/index.html" title="mod rustorch::data"><code>data</code></a>: Phase 5 data loading API with modern <code>Dataset</code> and <code>DataLoader</code> traits</li>
</ul>
<h3 id="-parallel-operations"><a class="doc-anchor" href="#-parallel-operations">Â§</a>ğŸ”„ Parallel Operations</h3>
<p>RusTorch provides a unified trait-based system for parallel tensor operations:</p>

<div class="example-wrap"><pre class="rust rust-example-rendered"><code><span class="kw">use </span>rustorch::tensor::{Tensor, parallel_traits::<span class="kw-2">*</span>};

<span class="kw">let </span>tensor1 = Tensor::&lt;f32&gt;::ones(<span class="kw-2">&amp;</span>[<span class="number">4</span>, <span class="number">4</span>]);  <span class="comment">// 2D matrices for simplicity
</span><span class="kw">let </span>tensor2 = Tensor::&lt;f32&gt;::ones(<span class="kw-2">&amp;</span>[<span class="number">4</span>, <span class="number">4</span>]);

<span class="comment">// Basic tensor operations
</span><span class="kw">let </span>result = <span class="kw-2">&amp;</span>tensor1 + <span class="kw-2">&amp;</span>tensor2; <span class="comment">// Element-wise addition

// Matrix multiplication
</span><span class="kw">let </span>matmul_result = tensor1.matmul(<span class="kw-2">&amp;</span>tensor2);

<span class="comment">// Basic reduction operations
</span><span class="kw">let </span>sum = tensor1.sum();</code></pre></div>
<h3 id="-gpu-integration"><a class="doc-anchor" href="#-gpu-integration">Â§</a>ğŸ® GPU Integration</h3>
<p>Seamless GPU acceleration with automatic device selection:</p>

<div class="example-wrap"><pre class="rust rust-example-rendered"><code><span class="kw">use </span>rustorch::tensor::Tensor;

<span class="kw">let </span>tensor1 = Tensor::&lt;f32&gt;::ones(<span class="kw-2">&amp;</span>[<span class="number">4</span>, <span class="number">4</span>]);
<span class="kw">let </span>tensor2 = Tensor::&lt;f32&gt;::ones(<span class="kw-2">&amp;</span>[<span class="number">4</span>, <span class="number">4</span>]);

<span class="comment">// GPU-accelerated operations (when available)
</span><span class="kw">let </span>result = <span class="kw-2">&amp;</span>tensor1 + <span class="kw-2">&amp;</span>tensor2;  <span class="comment">// Basic tensor operations</span></code></pre></div>
<h3 id="-memory-optimization"><a class="doc-anchor" href="#-memory-optimization">Â§</a>ğŸ’¾ Memory Optimization</h3>
<p>Advanced memory management for optimal performance:</p>

<div class="example-wrap"><pre class="rust rust-example-rendered"><code><span class="kw">use </span>rustorch::tensor::Tensor;

<span class="kw">let </span>tensor = Tensor::&lt;f32&gt;::ones(<span class="kw-2">&amp;</span>[<span class="number">4</span>, <span class="number">4</span>]);

<span class="comment">// Basic tensor operations
</span><span class="kw">let </span>result = <span class="kw-2">&amp;</span>tensor * <span class="kw-2">&amp;</span>tensor; <span class="comment">// Element-wise multiplication</span></code></pre></div>
<h3 id="-webassembly-integration"><a class="doc-anchor" href="#-webassembly-integration">Â§</a>ğŸŒ WebAssembly Integration</h3>
<p>Run neural networks directly in browsers with optimized WASM bindings:</p>
<div class="example-wrap"><pre class="language-javascript"><code>// Browser usage (JavaScript)
import init, * as rustorch from &#39;./pkg/rustorch.js&#39;;

await init();

// Create and manipulate tensors
const tensor1 = rustorch.WasmTensor.ones([2, 3]);
const tensor2 = rustorch.WasmTensor.random([2, 3]);
const sum = tensor1.add(tensor2);

// Neural network inference
const model = new rustorch.WasmModel();
model.add_linear(10, 5, true);
model.add_relu();

const input = rustorch.WasmTensor.random([1, 10]);
const output = model.forward(input);

console.log(&#39;Output:&#39;, output.data());</code></pre></div></div></details><h2 id="modules" class="section-header">Modules<a href="#modules" class="anchor">Â§</a></h2><dl class="item-table"><dt><a class="mod" href="amp/index.html" title="mod rustorch::amp">amp</a></dt><dd>Automatic Mixed Precision (AMP) training support
è‡ªå‹•æ··åˆç²¾åº¦(AMP)å­¦ç¿’ã‚µãƒãƒ¼ãƒˆ
Automatic Mixed Precision (AMP) training support
è‡ªå‹•æ··åˆç²¾åº¦å­¦ç¿’ã®ã‚µãƒãƒ¼ãƒˆ</dd><dt><a class="mod" href="autograd/index.html" title="mod rustorch::autograd">autograd</a></dt><dd>Automatic differentiation module
è‡ªå‹•å¾®åˆ†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«</dd><dt><a class="mod" href="backends/index.html" title="mod rustorch::backends">backends</a></dt><dd>Unified compute backend abstraction layer<br />
çµ±ä¸€è¨ˆç®—ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æŠ½è±¡åŒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼
Unified compute backend abstraction for RusTorch v0.4.0
RusTorch v0.4.0ã®çµ±ä¸€è¨ˆç®—ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æŠ½è±¡åŒ–</dd><dt><a class="mod" href="common/index.html" title="mod rustorch::common">common</a></dt><dd>Common utilities and shared functionality
å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã¨å…±æœ‰æ©Ÿèƒ½
Common utilities and shared functionality for RusTorch
RusTorchã®å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã¨å…±æœ‰æ©Ÿèƒ½</dd><dt><a class="mod" href="convert/index.html" title="mod rustorch::convert">convert</a></dt><dd>PyTorch to RusTorch conversion system
PyTorchã‹ã‚‰RusTorchå¤‰æ›ã‚·ã‚¹ãƒ†ãƒ 
PyTorch to RusTorch conversion module
PyTorchã‹ã‚‰RusTorchã¸ã®å¤‰æ›ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«</dd><dt><a class="mod" href="data/index.html" title="mod rustorch::data">data</a></dt><dd>Data loading and processing utilities (Phase 5 API)
ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å‡¦ç†ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆãƒ•ã‚§ãƒ¼ã‚º5 APIï¼‰</dd><dt><a class="mod" href="debug/index.html" title="mod rustorch::debug">debug</a></dt><dd>Debug and logging system
ãƒ‡ãƒãƒƒã‚°ãƒ»ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ 
RusTorch Debug &amp; Logging Framework</dd><dt><a class="mod" href="distributed/index.html" title="mod rustorch::distributed">distributed</a></dt><dd>Distributed training support for multi-GPU and multi-machine training
ãƒãƒ«ãƒGPUãŠã‚ˆã³ãƒãƒ«ãƒãƒã‚·ãƒ³å­¦ç¿’ç”¨åˆ†æ•£å­¦ç¿’ã‚µãƒãƒ¼ãƒˆ
Distributed training support for RusTorch
RusTorchã®åˆ†æ•£å­¦ç¿’ã‚µãƒãƒ¼ãƒˆ</dd><dt><a class="mod" href="distributions/index.html" title="mod rustorch::distributions">distributions</a></dt><dd>Statistical distributions module providing PyTorch-compatible probability distributions
PyTorchäº’æ›ã®ç¢ºç‡åˆ†å¸ƒã‚’æä¾›ã™ã‚‹çµ±è¨ˆåˆ†å¸ƒãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«</dd><dt><a class="mod" href="dtype/index.html" title="mod rustorch::dtype">dtype</a></dt><dd>Data types for tensors
ãƒ†ãƒ³ã‚½ãƒ«ç”¨ãƒ‡ãƒ¼ã‚¿å‹</dd><dt><a class="mod" href="error/index.html" title="mod rustorch::error">error</a></dt><dd>Unified error handling system
çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 
Unified error handling system for RusTorch
RusTorchç”¨çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ </dd><dt><a class="mod" href="execution/index.html" title="mod rustorch::execution">execution</a></dt><dd>Dynamic execution engine for runtime graph optimization
å®Ÿè¡Œæ™‚ã‚°ãƒ©ãƒ•æœ€é©åŒ–ã®ãŸã‚ã®å‹•çš„å®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³
Dynamic execution engine for runtime graph optimization
å®Ÿè¡Œæ™‚ã‚°ãƒ©ãƒ•æœ€é©åŒ–ã®ãŸã‚ã®å‹•çš„å®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³</dd><dt><a class="mod" href="formats/index.html" title="mod rustorch::formats">formats</a></dt><dd>Model format support and conversion utilities
ãƒ¢ãƒ‡ãƒ«å½¢å¼ã‚µãƒãƒ¼ãƒˆã¨å¤‰æ›ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
Model format support for RusTorch
RusTorchã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚µãƒãƒ¼ãƒˆ</dd><dt><a class="mod" href="gpu/index.html" title="mod rustorch::gpu">gpu</a></dt><dd>GPU acceleration support (CUDA, Metal, OpenCL)
GPUåŠ é€Ÿã‚µãƒãƒ¼ãƒˆï¼ˆCUDAã€Metalã€OpenCLï¼‰</dd><dt><a class="mod" href="linalg/index.html" title="mod rustorch::linalg">linalg</a></dt><dd>High-performance linear algebra with BLAS integration
BLASçµ±åˆã«ã‚ˆã‚‹é«˜æ€§èƒ½ç·šå½¢ä»£æ•°
Linear Algebra Module with High-Performance Optimizations
é«˜æ€§èƒ½æœ€é©åŒ–ä»˜ãç·šå½¢ä»£æ•°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«</dd><dt><a class="mod" href="memory/index.html" title="mod rustorch::memory">memory</a></dt><dd>Memory management and pooling utilities
ãƒ¡ãƒ¢ãƒªç®¡ç†ã¨ãƒ—ãƒ¼ãƒªãƒ³ã‚°ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
Enhanced Memory Management System for RusTorch
RusTorchç”¨ã®é«˜åº¦ãƒ¡ãƒ¢ãƒªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ </dd><dt><a class="mod" href="model_import/index.html" title="mod rustorch::model_import">model_<wbr>import</a></dt><dd>Model import functionality for PyTorch and ONNX models
PyTorchã¨ONNXãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ©Ÿèƒ½</dd><dt><a class="mod" href="models/index.html" title="mod rustorch::models">models</a></dt><dd>Pre-built models and architectures
äº‹å‰æ§‹ç¯‰ãƒ¢ãƒ‡ãƒ«ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
Machine learning model architectures</dd><dt><a class="mod" href="nn/index.html" title="mod rustorch::nn">nn</a></dt><dd>Neural network layers and building blocks
ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨æ§‹æˆè¦ç´ 
ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å®šç¾©
Neural network module definitions.</dd><dt><a class="mod" href="optim/index.html" title="mod rustorch::optim">optim</a></dt><dd>Optimization algorithms
æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ </dd><dt><a class="mod" href="optimization/index.html" title="mod rustorch::optimization">optimization</a></dt><dd>Cross-platform optimization module
ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æœ€é©åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
Cross-platform optimization module
ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æœ€é©åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«</dd><dt><a class="mod" href="parallel/index.html" title="mod rustorch::parallel">parallel</a></dt><dd>Parallel processing utilities
ä¸¦åˆ—å‡¦ç†ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£</dd><dt><a class="mod" href="prelude/index.html" title="mod rustorch::prelude">prelude</a></dt><dd>Re-exports of commonly used items</dd><dt><a class="mod" href="profiler/index.html" title="mod rustorch::profiler">profiler</a></dt><dd>Performance profiler
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼
Performance Profiling &amp; Benchmarking Framework (Phase 1 Component 5)
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚­ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼ˆãƒ•ã‚§ãƒ¼ã‚º1ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ5ï¼‰</dd><dt><a class="mod" href="quantization/index.html" title="mod rustorch::quantization">quantization</a></dt><dd>Quantization support for model compression and acceleration (Phase 11)
ãƒ¢ãƒ‡ãƒ«åœ§ç¸®ãƒ»é«˜é€ŸåŒ–ã®ãŸã‚ã®é‡å­åŒ–ã‚µãƒãƒ¼ãƒˆï¼ˆãƒ•ã‚§ãƒ¼ã‚º11ï¼‰
Quantization support for RusTorch - Phase 11 Implementation
RusTorchç”¨é‡å­åŒ–ã‚µãƒãƒ¼ãƒˆ - ãƒ•ã‚§ãƒ¼ã‚º11å®Ÿè£…</dd><dt><a class="mod" href="serialization/index.html" title="mod rustorch::serialization">serialization</a></dt><dd>Serialization and model I/O system (Phase 9)
ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ãƒ¢ãƒ‡ãƒ«I/Oã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒ•ã‚§ãƒ¼ã‚º9ï¼‰
Serialization system for Phase 9
ãƒ•ã‚§ãƒ¼ã‚º9ç”¨ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ </dd><dt><a class="mod" href="simd/index.html" title="mod rustorch::simd">simd</a></dt><dd>SIMD vectorized operations for performance optimization
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã®ãŸã‚ã®SIMDãƒ™ã‚¯ãƒˆãƒ«åŒ–æ“ä½œ</dd><dt><a class="mod" href="sparse/index.html" title="mod rustorch::sparse">sparse</a></dt><dd>Sparse tensor support and operations (Phase 12)
ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ†ãƒ³ã‚½ãƒ«ã‚µãƒãƒ¼ãƒˆã¨æ¼”ç®—ï¼ˆãƒ•ã‚§ãƒ¼ã‚º12ï¼‰
Sparse tensor support for RusTorch (Phase 12)
RusTorchã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ†ãƒ³ã‚½ãƒ«ã‚µãƒãƒ¼ãƒˆï¼ˆãƒ•ã‚§ãƒ¼ã‚º12ï¼‰</dd><dt><a class="mod" href="special/index.html" title="mod rustorch::special">special</a></dt><dd>Special mathematical functions (gamma, Bessel, error functions)
ç‰¹æ®Šæ•°å­¦é–¢æ•°ï¼ˆã‚¬ãƒ³ãƒã€ãƒ™ãƒƒã‚»ãƒ«ã€èª¤å·®é–¢æ•°ï¼‰
Special mathematical functions module
ç‰¹æ®Šæ•°å­¦é–¢æ•°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«</dd><dt><a class="mod" href="tensor/index.html" title="mod rustorch::tensor">tensor</a></dt><dd>Tensor operations and data structures
ãƒ†ãƒ³ã‚½ãƒ«æ“ä½œã¨ãƒ‡ãƒ¼ã‚¿æ§‹é€ </dd><dt><a class="mod" href="tensorboard/index.html" title="mod rustorch::tensorboard">tensorboard</a></dt><dd>TensorBoard integration
TensorBoardçµ±åˆ
TensorBoard integration for RusTorch
RusTorchç”¨TensorBoardçµ±åˆ</dd><dt><a class="mod" href="training/index.html" title="mod rustorch::training">training</a></dt><dd>Training loop abstractions and utilities<br />
å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã®æŠ½è±¡åŒ–ã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£</dd><dt><a class="mod" href="utils/index.html" title="mod rustorch::utils">utils</a></dt><dd>Utility functions
ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
Utility functions and types</dd><dt><a class="mod" href="validation/index.html" title="mod rustorch::validation">validation</a></dt><dd>Data validation and quality assurance system
ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ»å“è³ªä¿è¨¼ã‚·ã‚¹ãƒ†ãƒ 
Data Validation &amp; Quality Assurance Framework (Phase 1 Component 6)
ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ»å“è³ªä¿è¨¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼ˆãƒ•ã‚§ãƒ¼ã‚º1ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ6ï¼‰</dd><dt><a class="mod" href="vision/index.html" title="mod rustorch::vision">vision</a></dt><dd>Computer vision module providing image transforms, data augmentation, and built-in datasets
ç”»åƒå¤‰æ›ã€ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã€çµ„ã¿è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æä¾›ã™ã‚‹ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
Computer Vision utilities for RusTorch
RusTorchç”¨ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£</dd><dt><a class="mod" href="visualization/index.html" title="mod rustorch::visualization">visualization</a></dt><dd>Visualization tools for plots, graphs, and data analysis
ãƒ—ãƒ­ãƒƒãƒˆã€ã‚°ãƒ©ãƒ•ã€ãƒ‡ãƒ¼ã‚¿è§£æç”¨ã®å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«</dd></dl><h2 id="macros" class="section-header">Macros<a href="#macros" class="anchor">Â§</a></h2><dl class="item-table"><dt><a class="macro" href="macro.autocast_op.html" title="macro rustorch::autocast_op">autocast_<wbr>op</a></dt><dd>Macro for autocast-aware operations</dd><dt><a class="macro" href="macro.diagnostic_context.html" title="macro rustorch::diagnostic_context">diagnostic_<wbr>context</a></dt><dd>Macro for easy diagnostic context creation</dd><dt><a class="macro" href="macro.distributed_error.html" title="macro rustorch::distributed_error">distributed_<wbr>error</a></dt><dd>Macro for creating distributed errors easily
åˆ†æ•£ã‚¨ãƒ©ãƒ¼ã‚’ç°¡å˜ã«ä½œæˆã™ã‚‹ãŸã‚ã®ãƒã‚¯ãƒ­</dd><dt><a class="macro" href="macro.error_context.html" title="macro rustorch::error_context">error_<wbr>context</a></dt><dd>Macro for creating error context with file location
ãƒ•ã‚¡ã‚¤ãƒ«ä½ç½®ä»˜ãã®ã‚¨ãƒ©ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆã™ã‚‹ãƒã‚¯ãƒ­</dd><dt><a class="macro" href="macro.gpu_error.html" title="macro rustorch::gpu_error">gpu_<wbr>error</a></dt><dd>Macro for creating GPU errors easily
GPUã‚¨ãƒ©ãƒ¼ã‚’ç°¡å˜ã«ä½œæˆã™ã‚‹ãŸã‚ã®ãƒã‚¯ãƒ­</dd><dt><a class="macro" href="macro.log_structured.html" title="macro rustorch::log_structured">log_<wbr>structured</a></dt><dd>Convenience macro for structured logging</dd><dt><a class="macro" href="macro.perf_timer.html" title="macro rustorch::perf_timer">perf_<wbr>timer</a></dt><dd>Macro for performance timing</dd><dt><a class="macro" href="macro.profile.html" title="macro rustorch::profile">profile</a></dt><dd>Profile a code block
ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«</dd><dt><a class="macro" href="macro.profile_fn.html" title="macro rustorch::profile_fn">profile_<wbr>fn</a></dt><dd>Profile a function
é–¢æ•°ã‚’ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«</dd><dt><a class="macro" href="macro.shape_ops.html" title="macro rustorch::shape_ops">shape_<wbr>ops</a></dt><dd>Convenience macro for chaining shape operations
å½¢çŠ¶æ“ä½œé€£é–ã®ä¾¿åˆ©ãƒã‚¯ãƒ­</dd><dt><a class="macro" href="macro.tb_log.html" title="macro rustorch::tb_log">tb_log</a></dt><dd>Macro for easy TensorBoard logging
ç°¡å˜ãªTensorBoardãƒ­ã‚°ç”¨ãƒã‚¯ãƒ­</dd><dt><a class="macro" href="macro.tensor.html" title="macro rustorch::tensor">tensor</a></dt><dd>Convenient macro for creating tensors with literal syntax</dd><dt><a class="macro" href="macro.tensor_error.html" title="macro rustorch::tensor_error">tensor_<wbr>error</a></dt><dd>Helper macros for error creation
ã‚¨ãƒ©ãƒ¼ä½œæˆç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒã‚¯ãƒ­
Macro for creating tensor errors easily
ãƒ†ãƒ³ã‚½ãƒ«ã‚¨ãƒ©ãƒ¼ã‚’ç°¡å˜ã«ä½œæˆã™ã‚‹ãŸã‚ã®ãƒã‚¯ãƒ­</dd><dt><a class="macro" href="macro.tensor_nd.html" title="macro rustorch::tensor_nd">tensor_<wbr>nd</a></dt><dd>Creates an N-dimensional tensor with compile-time shape inference.</dd><dt><a class="macro" href="macro.time_block.html" title="macro rustorch::time_block">time_<wbr>block</a></dt><dd>Macro for timed code blocks</dd><dt><a class="macro" href="macro.track_allocation.html" title="macro rustorch::track_allocation">track_<wbr>allocation</a></dt><dd>Convenience macro for tracking allocations</dd><dt><a class="macro" href="macro.track_deallocation.html" title="macro rustorch::track_deallocation">track_<wbr>deallocation</a></dt><dt><a class="macro" href="macro.with_context.html" title="macro rustorch::with_context">with_<wbr>context</a></dt><dd>Macro for adding context to results
çµæœã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ ã™ã‚‹ãƒã‚¯ãƒ­</dd></dl></section></div></main></body></html>