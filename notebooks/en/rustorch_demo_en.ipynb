{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# RusTorch English Demo ðŸš€\n",
    "\n",
    "Welcome to RusTorch! This notebook demonstrates the core capabilities of our production-ready deep learning library in Rust with PyTorch-like API.\n",
    "\n",
    "## Features Demonstrated:\n",
    "- ðŸ”¥ **Tensor Operations**: Create, manipulate, and compute with tensors\n",
    "- ðŸ§® **Matrix Operations**: Linear algebra with optimized performance\n",
    "- ðŸ§  **Neural Network Layers**: Building blocks for deep learning\n",
    "- âš¡ **Performance**: Rust-powered speed with GPU acceleration\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RusTorch and other required libraries\n",
    "import rustorch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(\"RusTorch imported successfully!\")\n",
    "print(f\"Available operations: {dir(rustorch)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-tensors",
   "metadata": {},
   "source": [
    "## 1. Basic Tensor Creation\n",
    "\n",
    "RusTorch provides multiple ways to create tensors, similar to PyTorch but with Rust's performance benefits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tensor-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different types of tensors\n",
    "zeros_tensor = rustorch.zeros([3, 4])\n",
    "ones_tensor = rustorch.ones([3, 4])\n",
    "random_tensor = rustorch.randn([3, 4])\n",
    "custom_tensor = rustorch.PyTensor([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], [2, 3])\n",
    "\n",
    "print(\"Zero tensor:\")\n",
    "print(f\"  Shape: {zeros_tensor.shape()}\")\n",
    "print(f\"  Data: {zeros_tensor.data()}\")\n",
    "\n",
    "print(\"\\nOnes tensor:\")\n",
    "print(f\"  Shape: {ones_tensor.shape()}\")\n",
    "print(f\"  Data: {ones_tensor.data()}\")\n",
    "\n",
    "print(\"\\nRandom tensor (normal distribution):\")\n",
    "print(f\"  Shape: {random_tensor.shape()}\")\n",
    "print(f\"  Data: {random_tensor.data()}\")\n",
    "\n",
    "print(\"\\nCustom tensor:\")\n",
    "print(f\"  Shape: {custom_tensor.shape()}\")\n",
    "print(f\"  Data: {custom_tensor.data()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tensor-ops",
   "metadata": {},
   "source": [
    "## 2. Tensor Operations\n",
    "\n",
    "Perform mathematical operations on tensors with optimized Rust backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic arithmetic operations\n",
    "a = rustorch.PyTensor([1.0, 2.0, 3.0, 4.0], [2, 2])\n",
    "b = rustorch.PyTensor([5.0, 6.0, 7.0, 8.0], [2, 2])\n",
    "\n",
    "# Addition\n",
    "addition = a.add(b)\n",
    "print(\"Tensor Addition:\")\n",
    "print(f\"  A: {a.data()}\")\n",
    "print(f\"  B: {b.data()}\")\n",
    "print(f\"  A + B: {addition.data()}\")\n",
    "\n",
    "# Element-wise multiplication\n",
    "multiplication = a.mul(b)\n",
    "print(\"\\nElement-wise Multiplication:\")\n",
    "print(f\"  A * B: {multiplication.data()}\")\n",
    "\n",
    "# Matrix multiplication\n",
    "matmul = a.matmul(b)\n",
    "print(\"\\nMatrix Multiplication:\")\n",
    "print(f\"  A @ B: {matmul.data()}\")\n",
    "print(f\"  Shape: {matmul.shape()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activations",
   "metadata": {},
   "source": [
    "## 3. Activation Functions\n",
    "\n",
    "Essential neural network activation functions implemented efficiently in Rust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activation-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input tensor with various values\n",
    "input_values = [-3.0, -1.5, 0.0, 1.5, 3.0]\n",
    "input_tensor = rustorch.PyTensor(input_values, [5])\n",
    "\n",
    "print(f\"Input values: {input_values}\")\n",
    "print()\n",
    "\n",
    "# Apply different activation functions\n",
    "relu_output = input_tensor.relu()\n",
    "sigmoid_output = input_tensor.sigmoid()\n",
    "tanh_output = input_tensor.tanh()\n",
    "\n",
    "print(\"Activation Functions:\")\n",
    "print(f\"  ReLU:    {relu_output.data()}\")\n",
    "print(f\"  Sigmoid: {sigmoid_output.data()}\")\n",
    "print(f\"  Tanh:    {tanh_output.data()}\")\n",
    "\n",
    "# Demonstrate the mathematical properties\n",
    "print(\"\\nMathematical Properties:\")\n",
    "print(f\"  ReLU clamps negative values to zero\")\n",
    "print(f\"  Sigmoid outputs range from 0 to 1\")\n",
    "print(f\"  Tanh outputs range from -1 to 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-network",
   "metadata": {},
   "source": [
    "## 4. Simple Neural Network Example\n",
    "\n",
    "Build a basic neural network using RusTorch's tensor operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-network-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple 2-layer neural network\n",
    "def simple_forward_pass(input_data, weights1, bias1, weights2, bias2):\n",
    "    \"\"\"\n",
    "    Perform a forward pass through a 2-layer neural network.\n",
    "    \"\"\"\n",
    "    # Layer 1: Linear transformation + ReLU activation\n",
    "    layer1_linear = input_data.matmul(weights1).add(bias1)\n",
    "    layer1_output = layer1_linear.relu()\n",
    "    \n",
    "    # Layer 2: Linear transformation + Sigmoid activation\n",
    "    layer2_linear = layer1_output.matmul(weights2).add(bias2)\n",
    "    output = layer2_linear.sigmoid()\n",
    "    \n",
    "    return output, layer1_output\n",
    "\n",
    "# Initialize network parameters\n",
    "input_size, hidden_size, output_size = 3, 4, 2\n",
    "\n",
    "# Create input data (batch_size=2, input_size=3)\n",
    "input_data = rustorch.PyTensor([0.5, -0.2, 1.0, -1.0, 0.8, 0.3], [2, 3])\n",
    "\n",
    "# Initialize weights and biases with small random values\n",
    "weights1 = rustorch.randn([input_size, hidden_size]).mul(rustorch.PyTensor([0.1], [1]))\n",
    "bias1 = rustorch.zeros([1, hidden_size])\n",
    "weights2 = rustorch.randn([hidden_size, output_size]).mul(rustorch.PyTensor([0.1], [1]))\n",
    "bias2 = rustorch.zeros([1, output_size])\n",
    "\n",
    "# Forward pass\n",
    "output, hidden = simple_forward_pass(input_data, weights1, bias1, weights2, bias2)\n",
    "\n",
    "print(\"Neural Network Forward Pass:\")\n",
    "print(f\"  Input shape: {input_data.shape()}\")\n",
    "print(f\"  Input data: {input_data.data()}\")\n",
    "print(f\"  Hidden layer shape: {hidden.shape()}\")\n",
    "print(f\"  Hidden layer output: {hidden.data()}\")\n",
    "print(f\"  Final output shape: {output.shape()}\")\n",
    "print(f\"  Final output: {output.data()}\")\n",
    "print(f\"  (Output values between 0-1 due to sigmoid activation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "performance",
   "metadata": {},
   "source": [
    "## 5. Performance Comparison\n",
    "\n",
    "Compare RusTorch performance against NumPy for matrix operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance benchmark: Matrix multiplication\n",
    "sizes = [100, 500, 1000]\n",
    "\n",
    "print(\"Performance Comparison: RusTorch vs NumPy\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for size in sizes:\n",
    "    print(f\"\\nMatrix size: {size}x{size}\")\n",
    "    \n",
    "    # RusTorch benchmark\n",
    "    start_time = time.time()\n",
    "    rust_a = rustorch.randn([size, size])\n",
    "    rust_b = rustorch.randn([size, size])\n",
    "    rust_result = rust_a.matmul(rust_b)\n",
    "    rust_time = time.time() - start_time\n",
    "    \n",
    "    # NumPy benchmark\n",
    "    start_time = time.time()\n",
    "    numpy_a = np.random.randn(size, size).astype(np.float32)\n",
    "    numpy_b = np.random.randn(size, size).astype(np.float32)\n",
    "    numpy_result = np.dot(numpy_a, numpy_b)\n",
    "    numpy_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate speedup\n",
    "    speedup = numpy_time / rust_time if rust_time > 0 else float('inf')\n",
    "    \n",
    "    print(f\"  RusTorch: {rust_time:.4f}s\")\n",
    "    print(f\"  NumPy:    {numpy_time:.4f}s\")\n",
    "    print(f\"  Speedup:  {speedup:.2f}x {'(RusTorch faster)' if speedup > 1 else '(NumPy faster)'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Note: Performance may vary based on system configuration and available optimizations.\")\n",
    "print(\"RusTorch performance improves significantly with GPU acceleration enabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Conclusion\n",
    "\n",
    "This demo showcased RusTorch's core capabilities:\n",
    "\n",
    "âœ… **Tensor Creation & Manipulation**: Easy-to-use API similar to PyTorch  \n",
    "âœ… **Mathematical Operations**: Optimized linear algebra operations  \n",
    "âœ… **Neural Network Building Blocks**: Activation functions and layer operations  \n",
    "âœ… **Performance**: Rust-powered speed with potential GPU acceleration  \n",
    "\n",
    "### Next Steps:\n",
    "- Explore GPU acceleration with CUDA/Metal/OpenCL backends\n",
    "- Build more complex neural network architectures\n",
    "- Try transformer models and advanced optimizers\n",
    "- Check out WebGPU support for browser-based ML\n",
    "\n",
    "### Resources:\n",
    "- ðŸ“š [Documentation](https://docs.rs/rustorch)\n",
    "- ðŸš€ [GitHub Repository](https://github.com/JunSuzukiJapan/rustorch)\n",
    "- ðŸ““ [Complete Jupyter Setup Guide](../../README_JUPYTER.md)\n",
    "\n",
    "Happy coding with RusTorch! ðŸ¦€âš¡"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}