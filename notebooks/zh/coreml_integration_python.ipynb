{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RusTorch CoreML 集成 - Python 绑定\n",
    "\n",
    "这个笔记本演示了如何通过 Python 绑定使用 RusTorch 的 CoreML 功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置和导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 RusTorch Python 绑定\n",
    "try:\n",
    "    import rustorch\n",
    "    print(f\"✅ RusTorch 版本: {rustorch.__version__}\")\n",
    "    print(f\"📝 描述: {rustorch.__description__}\")\n",
    "    print(f\"👥 作者: {rustorch.__author__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ 导入 RusTorch 失败: {e}\")\n",
    "    print(\"请使用 maturin develop 构建\")\n",
    "    exit(1)\n",
    "\n",
    "import numpy as np\n",
    "import platform\n",
    "\n",
    "print(f\"🖥️ 平台: {platform.system()} {platform.release()}\")\n",
    "print(f\"🐍 Python 版本: {platform.python_version()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查 CoreML 可用性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查 CoreML 功能\n",
    "try:\n",
    "    # 检查 CoreML 是否可用\n",
    "    coreml_available = rustorch.is_coreml_available()\n",
    "    print(f\"🍎 CoreML 可用: {coreml_available}\")\n",
    "    \n",
    "    if coreml_available:\n",
    "        print(\"🎉 CoreML 可用！\")\n",
    "        \n",
    "        # 获取设备信息\n",
    "        device_info = rustorch.get_coreml_device_info()\n",
    "        print(\"📱 CoreML 设备信息:\")\n",
    "        print(device_info)\n",
    "    else:\n",
    "        print(\"⚠️ CoreML 不可用\")\n",
    "        if platform.system() != \"Darwin\":\n",
    "            print(\"CoreML 仅在 macOS 上可用\")\n",
    "        else:\n",
    "            print(\"CoreML 功能可能未启用\")\n",
    "            \n",
    "except AttributeError:\n",
    "    print(\"❌ 未找到 CoreML 函数\")\n",
    "    print(\"可能未使用 CoreML 功能构建\")\n",
    "    coreml_available = False\n",
    "except Exception as e:\n",
    "    print(f\"❌ 检查 CoreML 时出错: {e}\")\n",
    "    coreml_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreML 设备创建和操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if coreml_available:\n",
    "    try:\n",
    "        # 创建 CoreML 设备\n",
    "        device = rustorch.CoreMLDevice(device_id=0)\n",
    "        print(f\"🖥️ CoreML 设备已创建: {device}\")\n",
    "        \n",
    "        # 获取设备信息\n",
    "        print(f\"🆔 设备 ID: {device.device_id()}\")\n",
    "        print(f\"✅ 可用: {device.is_available()}\")\n",
    "        print(f\"💾 内存限制: {device.memory_limit()} 字节\")\n",
    "        print(f\"🧮 计算单元限制: {device.compute_units_limit()}\")\n",
    "        print(f\"📚 模型缓存大小: {device.model_cache_size()}\")\n",
    "        \n",
    "        # 缓存清理\n",
    "        device.cleanup_cache()\n",
    "        print(\"🧹 缓存已清理\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ CoreML 设备操作错误: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ 跳过设备操作，因为 CoreML 不可用\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreML 后端配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if coreml_available:\n",
    "    try:\n",
    "        # 创建 CoreML 后端配置\n",
    "        config = rustorch.CoreMLBackendConfig(\n",
    "            enable_caching=True,\n",
    "            max_cache_size=200,\n",
    "            enable_profiling=True,\n",
    "            auto_fallback=True\n",
    "        )\n",
    "        print(f\"⚙️ 后端配置: {config}\")\n",
    "        \n",
    "        # 检查和修改配置值\n",
    "        print(f\"📊 启用缓存: {config.enable_caching}\")\n",
    "        print(f\"🗂️ 最大缓存大小: {config.max_cache_size}\")\n",
    "        print(f\"📈 启用性能分析: {config.enable_profiling}\")\n",
    "        print(f\"🔄 自动回退: {config.auto_fallback}\")\n",
    "        \n",
    "        # 修改配置\n",
    "        config.enable_profiling = False\n",
    "        config.max_cache_size = 150\n",
    "        print(f\"\\n🔧 更新后的配置: {config}\")\n",
    "        \n",
    "        # 创建 CoreML 后端\n",
    "        backend = rustorch.CoreMLBackend(config)\n",
    "        print(f\"🚀 CoreML 后端: {backend}\")\n",
    "        print(f\"✅ 后端可用: {backend.is_available()}\")\n",
    "        \n",
    "        # 获取后端统计信息\n",
    "        stats = backend.get_stats()\n",
    "        print(f\"📊 后端统计: {stats}\")\n",
    "        print(f\"   总操作数: {stats.total_operations}\")\n",
    "        print(f\"   缓存命中: {stats.cache_hits}\")\n",
    "        print(f\"   缓存未命中: {stats.cache_misses}\")\n",
    "        print(f\"   回退操作: {stats.fallback_operations}\")\n",
    "        print(f\"   缓存命中率: {stats.cache_hit_rate():.2%}\")\n",
    "        print(f\"   回退率: {stats.fallback_rate():.2%}\")\n",
    "        print(f\"   平均执行时间: {stats.average_execution_time_ms:.2f}毫秒\")\n",
    "        \n",
    "        # 缓存清理\n",
    "        backend.cleanup_cache()\n",
    "        print(\"\\n🧹 后端缓存已清理\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ CoreML 后端操作错误: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ 跳过后端操作，因为 CoreML 不可用\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本张量操作 (CPU)\n",
    "\n",
    "为了与 CoreML 进行比较，我们首先在 CPU 上执行基本操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # 基本张量创建和操作\n",
    "    print(\"🧮 基本张量操作 (CPU)\")\n",
    "    \n",
    "    # 从 NumPy 数组创建张量（简化接口）\n",
    "    data_a = np.random.randn(2, 3).astype(np.float32)\n",
    "    data_b = np.random.randn(3, 2).astype(np.float32)\n",
    "    \n",
    "    print(f\"📐 矩阵 A 形状: {data_a.shape}\")\n",
    "    print(f\"📐 矩阵 B 形状: {data_b.shape}\")\n",
    "    \n",
    "    # 使用 NumPy 进行矩阵乘法（用于比较）\n",
    "    numpy_result = np.matmul(data_a, data_b)\n",
    "    print(f\"✅ NumPy matmul 结果形状: {numpy_result.shape}\")\n",
    "    print(f\"📊 结果（前几个元素）: {numpy_result.flatten()[:4]}\")\n",
    "    \n",
    "    print(\"\\n🚀 CPU 操作完成\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 张量操作错误: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 性能比较模拟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark_matrix_operations():\n",
    "    \"\"\"比较不同矩阵大小的性能\"\"\"\n",
    "    \n",
    "    sizes = [(64, 64), (128, 128), (256, 256), (512, 512)]\n",
    "    \n",
    "    print(\"🏁 性能比较:\")\n",
    "    print(\"大小\\t\\tCPU 时间 (毫秒)\\t预期 CoreML (毫秒)\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for size in sizes:\n",
    "        # 测量 CPU 执行时间\n",
    "        a = np.random.randn(*size).astype(np.float32)\n",
    "        b = np.random.randn(size[1], size[0]).astype(np.float32)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        result = np.matmul(a, b)\n",
    "        cpu_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        # 预期 CoreML 时间（假设）\n",
    "        # 在实际实现中，使用 CoreML 后端的实际测量值\n",
    "        expected_coreml_time = cpu_time * 0.6  # 假设：CoreML 快 40%\n",
    "        \n",
    "        print(f\"{size[0]}x{size[1]}\\t\\t{cpu_time:.2f}\\t\\t{expected_coreml_time:.2f}\")\n",
    "\n",
    "benchmark_matrix_operations()\n",
    "\n",
    "print(\"\\n📝 注意：CoreML 时间是假设的。实际值取决于具体实现。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设备选择模拟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_device_selection():\n",
    "    \"\"\"模拟智能设备选择\"\"\"\n",
    "    \n",
    "    operations = [\n",
    "        (\"小矩阵乘法\", (16, 16), \"CPU\"),\n",
    "        (\"中等矩阵乘法\", (128, 128), \"Metal GPU\"),\n",
    "        (\"大矩阵乘法\", (512, 512), \"CoreML\" if coreml_available else \"Metal GPU\"),\n",
    "        (\"激活函数\", (32, 64, 128, 128), \"Metal GPU\"),\n",
    "        (\"小卷积\", (1, 3, 32, 32), \"CPU\"),\n",
    "        (\"大卷积\", (16, 64, 224, 224), \"CoreML\" if coreml_available else \"Metal GPU\"),\n",
    "        (\"复数运算\", (128, 128), \"Metal GPU\"),  # CoreML 不支持\n",
    "        (\"统计分布\", (1000,), \"CPU\"),  # CoreML 不支持\n",
    "    ]\n",
    "    \n",
    "    print(\"🎯 智能设备选择模拟:\")\n",
    "    print(\"操作\\t\\t\\t张量形状\\t\\t选择的设备\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for name, shape, device in operations:\n",
    "        shape_str = \"x\".join(map(str, shape))\n",
    "        print(f\"{name:<23}\\t{shape_str:<15}\\t{device}\")\n",
    "    \n",
    "    print(\"\\n📝 选择逻辑:\")\n",
    "    print(\"  • 小操作: CPU（避免开销）\")\n",
    "    print(\"  • 中等操作: Metal GPU（平衡）\")\n",
    "    print(\"  • 大操作: CoreML（优化）\")\n",
    "    print(\"  • 不支持的操作: GPU/CPU 回退\")\n",
    "\n",
    "simulate_device_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实用示例：简单神经网络层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_neural_network_layer():\n",
    "    \"\"\"模拟神经网络层\"\"\"\n",
    "    \n",
    "    print(\"🧠 神经网络层模拟:\")\n",
    "    \n",
    "    # 批次大小和层配置\n",
    "    batch_size = 32\n",
    "    input_features = 784  # 28x28 MNIST\n",
    "    hidden_features = 256\n",
    "    output_features = 10  # 10个类别\n",
    "    \n",
    "    print(f\"📊 批次大小: {batch_size}\")\n",
    "    print(f\"🔢 输入特征: {input_features}\")\n",
    "    print(f\"🧮 隐藏特征: {hidden_features}\")\n",
    "    print(f\"🎯 输出特征: {output_features}\")\n",
    "    \n",
    "    # 前向传播模拟\n",
    "    steps = [\n",
    "        (\"输入 → 隐藏\", f\"({batch_size}, {input_features}) @ ({input_features}, {hidden_features})\", \"CoreML\" if coreml_available else \"Metal\"),\n",
    "        (\"ReLU 激活\", f\"({batch_size}, {hidden_features})\", \"Metal\"),\n",
    "        (\"隐藏 → 输出\", f\"({batch_size}, {hidden_features}) @ ({hidden_features}, {output_features})\", \"CoreML\" if coreml_available else \"Metal\"),\n",
    "        (\"Softmax\", f\"({batch_size}, {output_features})\", \"CPU\"),\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n🔄 前向传播模拟:\")\n",
    "    total_time = 0\n",
    "    \n",
    "    for step, shape, device in steps:\n",
    "        # 虚拟执行时间（毫秒）\n",
    "        if device == \"CoreML\":\n",
    "            time_ms = np.random.uniform(0.5, 2.0)\n",
    "        elif device == \"Metal\":\n",
    "            time_ms = np.random.uniform(1.0, 3.0)\n",
    "        else:  # CPU\n",
    "            time_ms = np.random.uniform(0.2, 1.0)\n",
    "        \n",
    "        total_time += time_ms\n",
    "        print(f\"  {step:<15} {shape:<30} {device:<8} {time_ms:.2f}毫秒\")\n",
    "    \n",
    "    print(f\"\\n⏱️ 总前向传播时间: {total_time:.2f}毫秒\")\n",
    "    print(f\"🚀 估计吞吐量: {1000/total_time:.0f} 批次/秒\")\n",
    "\n",
    "simulate_neural_network_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结和后续步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📋 RusTorch CoreML 集成总结:\")\n",
    "print()\n",
    "print(\"✅ 已完成项目:\")\n",
    "print(\"  • Jupyter 环境设置\")\n",
    "print(\"  • Rust 内核和 Python 绑定创建\")\n",
    "print(\"  • CoreML 可用性检查\")\n",
    "print(\"  • 设备管理和配置\")\n",
    "print(\"  • 后端统计和性能分析\")\n",
    "print(\"  • 智能设备选择\")\n",
    "print()\n",
    "print(\"🚧 未来开发:\")\n",
    "print(\"  • 实际 CoreML 操作实现\")\n",
    "print(\"  • 性能基准测试\")\n",
    "print(\"  • 更多激活函数和层类型\")\n",
    "print(\"  • 错误处理改进\")\n",
    "print(\"  • 内存优化\")\n",
    "print()\n",
    "print(\"🎯 推荐的后续步骤:\")\n",
    "print(\"  1. 加载和测试真实的 CoreML 模型\")\n",
    "print(\"  2. 比较 Metal 和 CoreML 性能\")\n",
    "print(\"  3. 使用真实深度学习工作流测试\")\n",
    "print(\"  4. 在生产环境中评估\")\n",
    "\n",
    "if coreml_available:\n",
    "    print(\"\\n🎉 恭喜！CoreML 可用，所有功能都可以测试。\")\n",
    "else:\n",
    "    print(\"\\n⚠️ CoreML 不可用，但基本功能正常工作。\")\n",
    "    print(\"   我们建议在 macOS 上启用 CoreML 功能进行构建。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}