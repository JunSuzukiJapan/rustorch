{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RusTorch CoreML é›†æˆ - Python ç»‘å®š\n",
    "\n",
    "è¿™ä¸ªç¬”è®°æœ¬æ¼”ç¤ºäº†å¦‚ä½•é€šè¿‡ Python ç»‘å®šä½¿ç”¨ RusTorch çš„ CoreML åŠŸèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è®¾ç½®å’Œå¯¼å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥ RusTorch Python ç»‘å®š\n",
    "try:\n",
    "    import rustorch\n",
    "    print(f\"âœ… RusTorch ç‰ˆæœ¬: {rustorch.__version__}\")\n",
    "    print(f\"ğŸ“ æè¿°: {rustorch.__description__}\")\n",
    "    print(f\"ğŸ‘¥ ä½œè€…: {rustorch.__author__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ å¯¼å…¥ RusTorch å¤±è´¥: {e}\")\n",
    "    print(\"è¯·ä½¿ç”¨ maturin develop æ„å»º\")\n",
    "    exit(1)\n",
    "\n",
    "import numpy as np\n",
    "import platform\n",
    "\n",
    "print(f\"ğŸ–¥ï¸ å¹³å°: {platform.system()} {platform.release()}\")\n",
    "print(f\"ğŸ Python ç‰ˆæœ¬: {platform.python_version()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ£€æŸ¥ CoreML å¯ç”¨æ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥ CoreML åŠŸèƒ½\n",
    "try:\n",
    "    # æ£€æŸ¥ CoreML æ˜¯å¦å¯ç”¨\n",
    "    coreml_available = rustorch.is_coreml_available()\n",
    "    print(f\"ğŸ CoreML å¯ç”¨: {coreml_available}\")\n",
    "    \n",
    "    if coreml_available:\n",
    "        print(\"ğŸ‰ CoreML å¯ç”¨ï¼\")\n",
    "        \n",
    "        # è·å–è®¾å¤‡ä¿¡æ¯\n",
    "        device_info = rustorch.get_coreml_device_info()\n",
    "        print(\"ğŸ“± CoreML è®¾å¤‡ä¿¡æ¯:\")\n",
    "        print(device_info)\n",
    "    else:\n",
    "        print(\"âš ï¸ CoreML ä¸å¯ç”¨\")\n",
    "        if platform.system() != \"Darwin\":\n",
    "            print(\"CoreML ä»…åœ¨ macOS ä¸Šå¯ç”¨\")\n",
    "        else:\n",
    "            print(\"CoreML åŠŸèƒ½å¯èƒ½æœªå¯ç”¨\")\n",
    "            \n",
    "except AttributeError:\n",
    "    print(\"âŒ æœªæ‰¾åˆ° CoreML å‡½æ•°\")\n",
    "    print(\"å¯èƒ½æœªä½¿ç”¨ CoreML åŠŸèƒ½æ„å»º\")\n",
    "    coreml_available = False\n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ£€æŸ¥ CoreML æ—¶å‡ºé”™: {e}\")\n",
    "    coreml_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreML è®¾å¤‡åˆ›å»ºå’Œæ“ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if coreml_available:\n",
    "    try:\n",
    "        # åˆ›å»º CoreML è®¾å¤‡\n",
    "        device = rustorch.CoreMLDevice(device_id=0)\n",
    "        print(f\"ğŸ–¥ï¸ CoreML è®¾å¤‡å·²åˆ›å»º: {device}\")\n",
    "        \n",
    "        # è·å–è®¾å¤‡ä¿¡æ¯\n",
    "        print(f\"ğŸ†” è®¾å¤‡ ID: {device.device_id()}\")\n",
    "        print(f\"âœ… å¯ç”¨: {device.is_available()}\")\n",
    "        print(f\"ğŸ’¾ å†…å­˜é™åˆ¶: {device.memory_limit()} å­—èŠ‚\")\n",
    "        print(f\"ğŸ§® è®¡ç®—å•å…ƒé™åˆ¶: {device.compute_units_limit()}\")\n",
    "        print(f\"ğŸ“š æ¨¡å‹ç¼“å­˜å¤§å°: {device.model_cache_size()}\")\n",
    "        \n",
    "        # ç¼“å­˜æ¸…ç†\n",
    "        device.cleanup_cache()\n",
    "        print(\"ğŸ§¹ ç¼“å­˜å·²æ¸…ç†\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ CoreML è®¾å¤‡æ“ä½œé”™è¯¯: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸ è·³è¿‡è®¾å¤‡æ“ä½œï¼Œå› ä¸º CoreML ä¸å¯ç”¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreML åç«¯é…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if coreml_available:\n",
    "    try:\n",
    "        # åˆ›å»º CoreML åç«¯é…ç½®\n",
    "        config = rustorch.CoreMLBackendConfig(\n",
    "            enable_caching=True,\n",
    "            max_cache_size=200,\n",
    "            enable_profiling=True,\n",
    "            auto_fallback=True\n",
    "        )\n",
    "        print(f\"âš™ï¸ åç«¯é…ç½®: {config}\")\n",
    "        \n",
    "        # æ£€æŸ¥å’Œä¿®æ”¹é…ç½®å€¼\n",
    "        print(f\"ğŸ“Š å¯ç”¨ç¼“å­˜: {config.enable_caching}\")\n",
    "        print(f\"ğŸ—‚ï¸ æœ€å¤§ç¼“å­˜å¤§å°: {config.max_cache_size}\")\n",
    "        print(f\"ğŸ“ˆ å¯ç”¨æ€§èƒ½åˆ†æ: {config.enable_profiling}\")\n",
    "        print(f\"ğŸ”„ è‡ªåŠ¨å›é€€: {config.auto_fallback}\")\n",
    "        \n",
    "        # ä¿®æ”¹é…ç½®\n",
    "        config.enable_profiling = False\n",
    "        config.max_cache_size = 150\n",
    "        print(f\"\\nğŸ”§ æ›´æ–°åçš„é…ç½®: {config}\")\n",
    "        \n",
    "        # åˆ›å»º CoreML åç«¯\n",
    "        backend = rustorch.CoreMLBackend(config)\n",
    "        print(f\"ğŸš€ CoreML åç«¯: {backend}\")\n",
    "        print(f\"âœ… åç«¯å¯ç”¨: {backend.is_available()}\")\n",
    "        \n",
    "        # è·å–åç«¯ç»Ÿè®¡ä¿¡æ¯\n",
    "        stats = backend.get_stats()\n",
    "        print(f\"ğŸ“Š åç«¯ç»Ÿè®¡: {stats}\")\n",
    "        print(f\"   æ€»æ“ä½œæ•°: {stats.total_operations}\")\n",
    "        print(f\"   ç¼“å­˜å‘½ä¸­: {stats.cache_hits}\")\n",
    "        print(f\"   ç¼“å­˜æœªå‘½ä¸­: {stats.cache_misses}\")\n",
    "        print(f\"   å›é€€æ“ä½œ: {stats.fallback_operations}\")\n",
    "        print(f\"   ç¼“å­˜å‘½ä¸­ç‡: {stats.cache_hit_rate():.2%}\")\n",
    "        print(f\"   å›é€€ç‡: {stats.fallback_rate():.2%}\")\n",
    "        print(f\"   å¹³å‡æ‰§è¡Œæ—¶é—´: {stats.average_execution_time_ms:.2f}æ¯«ç§’\")\n",
    "        \n",
    "        # ç¼“å­˜æ¸…ç†\n",
    "        backend.cleanup_cache()\n",
    "        print(\"\\nğŸ§¹ åç«¯ç¼“å­˜å·²æ¸…ç†\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ CoreML åç«¯æ“ä½œé”™è¯¯: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸ è·³è¿‡åç«¯æ“ä½œï¼Œå› ä¸º CoreML ä¸å¯ç”¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åŸºæœ¬å¼ é‡æ“ä½œ (CPU)\n",
    "\n",
    "ä¸ºäº†ä¸ CoreML è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬é¦–å…ˆåœ¨ CPU ä¸Šæ‰§è¡ŒåŸºæœ¬æ“ä½œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # åŸºæœ¬å¼ é‡åˆ›å»ºå’Œæ“ä½œ\n",
    "    print(\"ğŸ§® åŸºæœ¬å¼ é‡æ“ä½œ (CPU)\")\n",
    "    \n",
    "    # ä» NumPy æ•°ç»„åˆ›å»ºå¼ é‡ï¼ˆç®€åŒ–æ¥å£ï¼‰\n",
    "    data_a = np.random.randn(2, 3).astype(np.float32)\n",
    "    data_b = np.random.randn(3, 2).astype(np.float32)\n",
    "    \n",
    "    print(f\"ğŸ“ çŸ©é˜µ A å½¢çŠ¶: {data_a.shape}\")\n",
    "    print(f\"ğŸ“ çŸ©é˜µ B å½¢çŠ¶: {data_b.shape}\")\n",
    "    \n",
    "    # ä½¿ç”¨ NumPy è¿›è¡ŒçŸ©é˜µä¹˜æ³•ï¼ˆç”¨äºæ¯”è¾ƒï¼‰\n",
    "    numpy_result = np.matmul(data_a, data_b)\n",
    "    print(f\"âœ… NumPy matmul ç»“æœå½¢çŠ¶: {numpy_result.shape}\")\n",
    "    print(f\"ğŸ“Š ç»“æœï¼ˆå‰å‡ ä¸ªå…ƒç´ ï¼‰: {numpy_result.flatten()[:4]}\")\n",
    "    \n",
    "    print(\"\\nğŸš€ CPU æ“ä½œå®Œæˆ\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ å¼ é‡æ“ä½œé”™è¯¯: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€§èƒ½æ¯”è¾ƒæ¨¡æ‹Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark_matrix_operations():\n",
    "    \"\"\"æ¯”è¾ƒä¸åŒçŸ©é˜µå¤§å°çš„æ€§èƒ½\"\"\"\n",
    "    \n",
    "    sizes = [(64, 64), (128, 128), (256, 256), (512, 512)]\n",
    "    \n",
    "    print(\"ğŸ æ€§èƒ½æ¯”è¾ƒ:\")\n",
    "    print(\"å¤§å°\\t\\tCPU æ—¶é—´ (æ¯«ç§’)\\té¢„æœŸ CoreML (æ¯«ç§’)\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for size in sizes:\n",
    "        # æµ‹é‡ CPU æ‰§è¡Œæ—¶é—´\n",
    "        a = np.random.randn(*size).astype(np.float32)\n",
    "        b = np.random.randn(size[1], size[0]).astype(np.float32)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        result = np.matmul(a, b)\n",
    "        cpu_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        # é¢„æœŸ CoreML æ—¶é—´ï¼ˆå‡è®¾ï¼‰\n",
    "        # åœ¨å®é™…å®ç°ä¸­ï¼Œä½¿ç”¨ CoreML åç«¯çš„å®é™…æµ‹é‡å€¼\n",
    "        expected_coreml_time = cpu_time * 0.6  # å‡è®¾ï¼šCoreML å¿« 40%\n",
    "        \n",
    "        print(f\"{size[0]}x{size[1]}\\t\\t{cpu_time:.2f}\\t\\t{expected_coreml_time:.2f}\")\n",
    "\n",
    "benchmark_matrix_operations()\n",
    "\n",
    "print(\"\\nğŸ“ æ³¨æ„ï¼šCoreML æ—¶é—´æ˜¯å‡è®¾çš„ã€‚å®é™…å€¼å–å†³äºå…·ä½“å®ç°ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è®¾å¤‡é€‰æ‹©æ¨¡æ‹Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_device_selection():\n",
    "    \"\"\"æ¨¡æ‹Ÿæ™ºèƒ½è®¾å¤‡é€‰æ‹©\"\"\"\n",
    "    \n",
    "    operations = [\n",
    "        (\"å°çŸ©é˜µä¹˜æ³•\", (16, 16), \"CPU\"),\n",
    "        (\"ä¸­ç­‰çŸ©é˜µä¹˜æ³•\", (128, 128), \"Metal GPU\"),\n",
    "        (\"å¤§çŸ©é˜µä¹˜æ³•\", (512, 512), \"CoreML\" if coreml_available else \"Metal GPU\"),\n",
    "        (\"æ¿€æ´»å‡½æ•°\", (32, 64, 128, 128), \"Metal GPU\"),\n",
    "        (\"å°å·ç§¯\", (1, 3, 32, 32), \"CPU\"),\n",
    "        (\"å¤§å·ç§¯\", (16, 64, 224, 224), \"CoreML\" if coreml_available else \"Metal GPU\"),\n",
    "        (\"å¤æ•°è¿ç®—\", (128, 128), \"Metal GPU\"),  # CoreML ä¸æ”¯æŒ\n",
    "        (\"ç»Ÿè®¡åˆ†å¸ƒ\", (1000,), \"CPU\"),  # CoreML ä¸æ”¯æŒ\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ¯ æ™ºèƒ½è®¾å¤‡é€‰æ‹©æ¨¡æ‹Ÿ:\")\n",
    "    print(\"æ“ä½œ\\t\\t\\tå¼ é‡å½¢çŠ¶\\t\\té€‰æ‹©çš„è®¾å¤‡\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for name, shape, device in operations:\n",
    "        shape_str = \"x\".join(map(str, shape))\n",
    "        print(f\"{name:<23}\\t{shape_str:<15}\\t{device}\")\n",
    "    \n",
    "    print(\"\\nğŸ“ é€‰æ‹©é€»è¾‘:\")\n",
    "    print(\"  â€¢ å°æ“ä½œ: CPUï¼ˆé¿å…å¼€é”€ï¼‰\")\n",
    "    print(\"  â€¢ ä¸­ç­‰æ“ä½œ: Metal GPUï¼ˆå¹³è¡¡ï¼‰\")\n",
    "    print(\"  â€¢ å¤§æ“ä½œ: CoreMLï¼ˆä¼˜åŒ–ï¼‰\")\n",
    "    print(\"  â€¢ ä¸æ”¯æŒçš„æ“ä½œ: GPU/CPU å›é€€\")\n",
    "\n",
    "simulate_device_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å®ç”¨ç¤ºä¾‹ï¼šç®€å•ç¥ç»ç½‘ç»œå±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_neural_network_layer():\n",
    "    \"\"\"æ¨¡æ‹Ÿç¥ç»ç½‘ç»œå±‚\"\"\"\n",
    "    \n",
    "    print(\"ğŸ§  ç¥ç»ç½‘ç»œå±‚æ¨¡æ‹Ÿ:\")\n",
    "    \n",
    "    # æ‰¹æ¬¡å¤§å°å’Œå±‚é…ç½®\n",
    "    batch_size = 32\n",
    "    input_features = 784  # 28x28 MNIST\n",
    "    hidden_features = 256\n",
    "    output_features = 10  # 10ä¸ªç±»åˆ«\n",
    "    \n",
    "    print(f\"ğŸ“Š æ‰¹æ¬¡å¤§å°: {batch_size}\")\n",
    "    print(f\"ğŸ”¢ è¾“å…¥ç‰¹å¾: {input_features}\")\n",
    "    print(f\"ğŸ§® éšè—ç‰¹å¾: {hidden_features}\")\n",
    "    print(f\"ğŸ¯ è¾“å‡ºç‰¹å¾: {output_features}\")\n",
    "    \n",
    "    # å‰å‘ä¼ æ’­æ¨¡æ‹Ÿ\n",
    "    steps = [\n",
    "        (\"è¾“å…¥ â†’ éšè—\", f\"({batch_size}, {input_features}) @ ({input_features}, {hidden_features})\", \"CoreML\" if coreml_available else \"Metal\"),\n",
    "        (\"ReLU æ¿€æ´»\", f\"({batch_size}, {hidden_features})\", \"Metal\"),\n",
    "        (\"éšè— â†’ è¾“å‡º\", f\"({batch_size}, {hidden_features}) @ ({hidden_features}, {output_features})\", \"CoreML\" if coreml_available else \"Metal\"),\n",
    "        (\"Softmax\", f\"({batch_size}, {output_features})\", \"CPU\"),\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nğŸ”„ å‰å‘ä¼ æ’­æ¨¡æ‹Ÿ:\")\n",
    "    total_time = 0\n",
    "    \n",
    "    for step, shape, device in steps:\n",
    "        # è™šæ‹Ÿæ‰§è¡Œæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰\n",
    "        if device == \"CoreML\":\n",
    "            time_ms = np.random.uniform(0.5, 2.0)\n",
    "        elif device == \"Metal\":\n",
    "            time_ms = np.random.uniform(1.0, 3.0)\n",
    "        else:  # CPU\n",
    "            time_ms = np.random.uniform(0.2, 1.0)\n",
    "        \n",
    "        total_time += time_ms\n",
    "        print(f\"  {step:<15} {shape:<30} {device:<8} {time_ms:.2f}æ¯«ç§’\")\n",
    "    \n",
    "    print(f\"\\nâ±ï¸ æ€»å‰å‘ä¼ æ’­æ—¶é—´: {total_time:.2f}æ¯«ç§’\")\n",
    "    print(f\"ğŸš€ ä¼°è®¡ååé‡: {1000/total_time:.0f} æ‰¹æ¬¡/ç§’\")\n",
    "\n",
    "simulate_neural_network_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€»ç»“å’Œåç»­æ­¥éª¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“‹ RusTorch CoreML é›†æˆæ€»ç»“:\")\n",
    "print()\n",
    "print(\"âœ… å·²å®Œæˆé¡¹ç›®:\")\n",
    "print(\"  â€¢ Jupyter ç¯å¢ƒè®¾ç½®\")\n",
    "print(\"  â€¢ Rust å†…æ ¸å’Œ Python ç»‘å®šåˆ›å»º\")\n",
    "print(\"  â€¢ CoreML å¯ç”¨æ€§æ£€æŸ¥\")\n",
    "print(\"  â€¢ è®¾å¤‡ç®¡ç†å’Œé…ç½®\")\n",
    "print(\"  â€¢ åç«¯ç»Ÿè®¡å’Œæ€§èƒ½åˆ†æ\")\n",
    "print(\"  â€¢ æ™ºèƒ½è®¾å¤‡é€‰æ‹©\")\n",
    "print()\n",
    "print(\"ğŸš§ æœªæ¥å¼€å‘:\")\n",
    "print(\"  â€¢ å®é™… CoreML æ“ä½œå®ç°\")\n",
    "print(\"  â€¢ æ€§èƒ½åŸºå‡†æµ‹è¯•\")\n",
    "print(\"  â€¢ æ›´å¤šæ¿€æ´»å‡½æ•°å’Œå±‚ç±»å‹\")\n",
    "print(\"  â€¢ é”™è¯¯å¤„ç†æ”¹è¿›\")\n",
    "print(\"  â€¢ å†…å­˜ä¼˜åŒ–\")\n",
    "print()\n",
    "print(\"ğŸ¯ æ¨èçš„åç»­æ­¥éª¤:\")\n",
    "print(\"  1. åŠ è½½å’Œæµ‹è¯•çœŸå®çš„ CoreML æ¨¡å‹\")\n",
    "print(\"  2. æ¯”è¾ƒ Metal å’Œ CoreML æ€§èƒ½\")\n",
    "print(\"  3. ä½¿ç”¨çœŸå®æ·±åº¦å­¦ä¹ å·¥ä½œæµæµ‹è¯•\")\n",
    "print(\"  4. åœ¨ç”Ÿäº§ç¯å¢ƒä¸­è¯„ä¼°\")\n",
    "\n",
    "if coreml_available:\n",
    "    print(\"\\nğŸ‰ æ­å–œï¼CoreML å¯ç”¨ï¼Œæ‰€æœ‰åŠŸèƒ½éƒ½å¯ä»¥æµ‹è¯•ã€‚\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ CoreML ä¸å¯ç”¨ï¼Œä½†åŸºæœ¬åŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚\")\n",
    "    print(\"   æˆ‘ä»¬å»ºè®®åœ¨ macOS ä¸Šå¯ç”¨ CoreML åŠŸèƒ½è¿›è¡Œæ„å»ºã€‚\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}