{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RusTorch CoreML é›†æˆ - Rust å†…æ ¸\n",
    "\n",
    "è¿™ä¸ªç¬”è®°æœ¬æ¼”ç¤ºäº†å¦‚ä½•åœ¨ RusTorch ä¸­ä½¿ç”¨ CoreMLã€‚\n",
    "è¿è¡Œåœ¨ Rust å†…æ ¸ä¸Šã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ£€æŸ¥æ‰€éœ€ä¾èµ–é¡¹å’ŒåŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// RusTorch åŸºæœ¬ä½¿ç”¨\n",
    "extern crate rustorch;\n",
    "\n",
    "use rustorch::tensor::Tensor;\n",
    "use rustorch::gpu::DeviceType;\n",
    "\n",
    "println!(\"RusTorch ç‰ˆæœ¬: {}\", env!(\"CARGO_PKG_VERSION\"));\n",
    "println!(\"Rust ç‰ˆæœ¬: {}\", env!(\"RUSTC_VERSION\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ£€æŸ¥ CoreML å¯ç”¨æ€§\n",
    "\n",
    "æ£€æŸ¥å½“å‰ç³»ç»Ÿä¸Šæ˜¯å¦å¯ç”¨ CoreMLã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    use rustorch::backends::DeviceManager;\n",
    "    \n",
    "    let coreml_available = DeviceManager::is_coreml_available();\n",
    "    println!(\"CoreML å¯ç”¨: {}\", coreml_available);\n",
    "    \n",
    "    if coreml_available {\n",
    "        println!(\"ğŸ‰ CoreML å¯ç”¨ï¼\");\n",
    "        println!(\"å¹³å°: macOS\");\n",
    "        \n",
    "        // æ˜¾ç¤ºè®¾å¤‡ä¿¡æ¯\n",
    "        use rustorch::gpu::coreml::device_cache::DeviceCache;\n",
    "        let cache = DeviceCache::global();\n",
    "        cache.warmup();\n",
    "        \n",
    "        let stats = cache.get_stats();\n",
    "        println!(\"ç¼“å­˜ç»Ÿè®¡: {:?}\", stats);\n",
    "    } else {\n",
    "        println!(\"âš ï¸ CoreML ä¸å¯ç”¨\");\n",
    "        println!(\"è¯·ä½¿ç”¨ CPU æˆ–å…¶ä»– GPU åç«¯\");\n",
    "    }\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"âŒ CoreML åŠŸèƒ½æœªå¯ç”¨\");\n",
    "    println!(\"è¯·ä½¿ç”¨ --features coreml æ„å»º\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åŸºæœ¬å¼ é‡æ“ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// åˆ›å»ºåŸºæœ¬å¼ é‡\n",
    "let a = Tensor::zeros(&[2, 3]);\n",
    "let b = Tensor::ones(&[3, 2]);\n",
    "\n",
    "println!(\"å¼ é‡ A å½¢çŠ¶: {:?}\", a.shape());\n",
    "println!(\"å¼ é‡ B å½¢çŠ¶: {:?}\", b.shape());\n",
    "\n",
    "// åŸºæœ¬çŸ©é˜µä¹˜æ³•\n",
    "let result = a.matmul(&b);\n",
    "println!(\"ç»“æœå½¢çŠ¶: {:?}\", result.shape());\n",
    "println!(\"åŸºæœ¬å¼ é‡æ“ä½œå®Œæˆ\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreML è®¾å¤‡æ“ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    use rustorch::gpu::coreml::{CoreMLDevice, CoreMLBackend};\n",
    "    use rustorch::backends::BackendConfig;\n",
    "    \n",
    "    // å°è¯•åˆ›å»º CoreML è®¾å¤‡\n",
    "    match CoreMLDevice::new(0) {\n",
    "        Ok(device) => {\n",
    "            println!(\"ğŸ–¥ï¸ CoreML è®¾å¤‡åˆ›å»ºæˆåŠŸ\");\n",
    "            println!(\"è®¾å¤‡ ID: {}\", device.id());\n",
    "            println!(\"å¯ç”¨: {}\", device.is_available());\n",
    "            println!(\"å†…å­˜é™åˆ¶: {} MB\", device.memory_limit() / (1024 * 1024));\n",
    "            \n",
    "            // åˆ›å»ºåç«¯é…ç½®\n",
    "            let config = BackendConfig::new()\n",
    "                .with_caching(true)\n",
    "                .with_max_cache_size(200)\n",
    "                .with_profiling(true)\n",
    "                .with_auto_fallback(true);\n",
    "            \n",
    "            println!(\"âš™ï¸ åç«¯é…ç½®: {:?}\", config);\n",
    "            \n",
    "            // åˆ›å»º CoreML åç«¯\n",
    "            match CoreMLBackend::new(device, config) {\n",
    "                Ok(backend) => {\n",
    "                    println!(\"ğŸš€ CoreML åç«¯å·²åˆå§‹åŒ–\");\n",
    "                    \n",
    "                    // è·å–ç»Ÿè®¡ä¿¡æ¯\n",
    "                    let stats = backend.get_statistics();\n",
    "                    println!(\"ğŸ“Š åç«¯ç»Ÿè®¡:\");\n",
    "                    println!(\"  æ€»æ“ä½œæ•°: {}\", stats.total_operations);\n",
    "                    println!(\"  ç¼“å­˜å‘½ä¸­: {}\", stats.cache_hits);\n",
    "                    println!(\"  ç¼“å­˜æœªå‘½ä¸­: {}\", stats.cache_misses);\n",
    "                    println!(\"  å›é€€æ“ä½œ: {}\", stats.fallback_operations);\n",
    "                    \n",
    "                    // åœ¨ CoreML ä¸Šåˆ›å»ºå¼ é‡\n",
    "                    let tensor_a = Tensor::randn(&[64, 64]).to_device(&backend);\n",
    "                    let tensor_b = Tensor::randn(&[64, 64]).to_device(&backend);\n",
    "                    \n",
    "                    println!(\"ğŸ“ åœ¨ CoreML è®¾å¤‡ä¸Šåˆ›å»ºå¼ é‡\");\n",
    "                    \n",
    "                    // çŸ©é˜µä¹˜æ³•æ“ä½œ\n",
    "                    let start = std::time::Instant::now();\n",
    "                    let result = tensor_a.matmul(&tensor_b);\n",
    "                    let duration = start.elapsed();\n",
    "                    \n",
    "                    println!(\"âœ… çŸ©é˜µä¹˜æ³•å®Œæˆ\");\n",
    "                    println!(\"â±ï¸ æ‰§è¡Œæ—¶é—´: {:?}\", duration);\n",
    "                    println!(\"ğŸ¯ ç»“æœå½¢çŠ¶: {:?}\", result.shape());\n",
    "                    \n",
    "                    // æ¸…ç†ç¼“å­˜\n",
    "                    backend.cleanup_cache();\n",
    "                    println!(\"ğŸ§¹ ç¼“å­˜å·²æ¸…ç†\");\n",
    "                }\n",
    "                Err(e) => println!(\"âŒ åˆ›å»º CoreML åç«¯é”™è¯¯: {:?}\", e),\n",
    "            }\n",
    "        }\n",
    "        Err(e) => {\n",
    "            println!(\"âŒ åˆ›å»º CoreML è®¾å¤‡é”™è¯¯: {:?}\", e);\n",
    "            println!(\"æ­¤ç³»ç»Ÿä¸Šå¯èƒ½æ— æ³•ä½¿ç”¨ CoreML\");\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"âš ï¸ è·³è¿‡ CoreML æ“ä½œ - åŠŸèƒ½æœªå¯ç”¨\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€§èƒ½æ¯”è¾ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use std::time::Instant;\n",
    "\n",
    "fn benchmark_operations() {\n",
    "    let sizes = vec![(64, 64), (128, 128), (256, 256), (512, 512)];\n",
    "    \n",
    "    println!(\"ğŸ æ“ä½œåŸºå‡†æµ‹è¯•:\");\n",
    "    println!(\"å¤§å°\\t\\tCPU (æ¯«ç§’)\\té¦–é€‰è®¾å¤‡\");\n",
    "    println!(\"-\" * 40);\n",
    "    \n",
    "    for (rows, cols) in sizes {\n",
    "        // åœ¨ CPU ä¸Šåˆ›å»ºå¼ é‡\n",
    "        let a = Tensor::randn(&[rows, cols]);\n",
    "        let b = Tensor::randn(&[cols, rows]);\n",
    "        \n",
    "        // æµ‹é‡ CPU æ—¶é—´\n",
    "        let start = Instant::now();\n",
    "        let _result = a.matmul(&b);\n",
    "        let cpu_duration = start.elapsed();\n",
    "        \n",
    "        // ç¡®å®šé¦–é€‰è®¾å¤‡\n",
    "        let preferred_device = if rows * cols < 1000 {\n",
    "            \"CPU\"\n",
    "        } else if rows * cols < 10000 {\n",
    "            \"Metal GPU\"\n",
    "        } else {\n",
    "            \"CoreML\"\n",
    "        };\n",
    "        \n",
    "        println!(\"{}x{}\\t\\t{:.2}\\t\\t{}\", \n",
    "                rows, cols, \n",
    "                cpu_duration.as_millis() as f64, \n",
    "                preferred_device);\n",
    "    }\n",
    "}\n",
    "\n",
    "benchmark_operations();\n",
    "println!(\"\\nğŸ“ æ³¨æ„ï¼šè®¾å¤‡é€‰æ‹©åŸºäºå¼ é‡å¤§å°å’Œå¯ç”¨æ€§\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ™ºèƒ½è®¾å¤‡é€‰æ‹©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    use rustorch::backends::{DeviceManager, DeviceSelector};\n",
    "    \n",
    "    fn demonstrate_device_selection() {\n",
    "        println!(\"ğŸ¯ æ™ºèƒ½è®¾å¤‡é€‰æ‹©æ¼”ç¤º:\");\n",
    "        \n",
    "        let operations = vec![\n",
    "            (\"å°ä¹˜æ³•\", vec![16, 16], \"CPU\"),\n",
    "            (\"2D å·ç§¯\", vec![32, 3, 224, 224], \"CoreML\"),\n",
    "            (\"çŸ©é˜µå˜æ¢\", vec![128, 128], \"Metal GPU\"),\n",
    "            (\"å¤§æ‰¹æ¬¡æ“ä½œ\", vec![512, 512], \"CoreML\"),\n",
    "            (\"å‘é‡è®¡ç®—\", vec![1000], \"CPU\"),\n",
    "        ];\n",
    "        \n",
    "        for (name, shape, preferred) in operations {\n",
    "            println!(\"  {:<25} {:?} -> {}\", name, shape, preferred);\n",
    "            \n",
    "            // æ¨¡æ‹ŸåŸºäºè§„åˆ™çš„é€‰æ‹©\n",
    "            let tensor_size: usize = shape.iter().product();\n",
    "            let selected_device = match tensor_size {\n",
    "                size if size < 1000 => DeviceType::Cpu,\n",
    "                size if size < 50000 => DeviceType::MetalGpu,\n",
    "                _ => {\n",
    "                    if DeviceManager::is_coreml_available() {\n",
    "                        DeviceType::CoreML\n",
    "                    } else {\n",
    "                        DeviceType::MetalGpu\n",
    "                    }\n",
    "                }\n",
    "            };\n",
    "            \n",
    "            println!(\"    -> é€‰æ‹©çš„è®¾å¤‡: {:?}\", selected_device);\n",
    "        }\n",
    "        \n",
    "        println!(\"\\nğŸ“ é€‰æ‹©é€»è¾‘:\");\n",
    "        println!(\"  â€¢ < 1K å…ƒç´ : CPUï¼ˆæœ€å°å¼€é”€ï¼‰\");\n",
    "        println!(\"  â€¢ 1K-50K å…ƒç´ : Metal GPUï¼ˆå¹³è¡¡ï¼‰\");\n",
    "        println!(\"  â€¢ > 50K å…ƒç´ : CoreMLï¼ˆä¼˜åŒ–ï¼‰æˆ– Metal GPUï¼ˆå›é€€ï¼‰\");\n",
    "    }\n",
    "    \n",
    "    demonstrate_device_selection();\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"âš ï¸ è®¾å¤‡é€‰æ‹©æ¼”ç¤ºå·²è·³è¿‡ - CoreML åŠŸèƒ½ä¸å¯ç”¨\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é«˜çº§ç¤ºä¾‹ï¼šç¥ç»ç½‘ç»œå±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn simulate_neural_layer() {\n",
    "    println!(\"ğŸ§  ç¥ç»ç½‘ç»œå±‚æ¨¡æ‹Ÿ:\");\n",
    "    \n",
    "    // å±‚é…ç½®\n",
    "    let batch_size = 32;\n",
    "    let input_dim = 784;   // 28x28 MNIST\n",
    "    let hidden_dim = 256;\n",
    "    let output_dim = 10;   // 10ä¸ªç±»åˆ«\n",
    "    \n",
    "    println!(\"ğŸ“Š é…ç½®:\");\n",
    "    println!(\"  æ‰¹æ¬¡å¤§å°: {}\", batch_size);\n",
    "    println!(\"  è¾“å…¥ç»´åº¦: {}\", input_dim);\n",
    "    println!(\"  éšè—ç»´åº¦: {}\", hidden_dim);\n",
    "    println!(\"  è¾“å‡ºç»´åº¦: {}\", output_dim);\n",
    "    \n",
    "    // åˆ›å»ºå¼ é‡\n",
    "    let input = Tensor::randn(&[batch_size, input_dim]);\n",
    "    let weight1 = Tensor::randn(&[input_dim, hidden_dim]);\n",
    "    let weight2 = Tensor::randn(&[hidden_dim, output_dim]);\n",
    "    \n",
    "    println!(\"\\nğŸ”„ å‰å‘ä¼ æ’­:\");\n",
    "    \n",
    "    // æ¨¡æ‹Ÿå‰å‘ä¼ æ’­\n",
    "    let start = Instant::now();\n",
    "    \n",
    "    // å±‚ 1: è¾“å…¥ -> éšè—\n",
    "    let hidden = input.matmul(&weight1);\n",
    "    println!(\"  âœ… è¾“å…¥ -> éšè—: {:?}\", hidden.shape());\n",
    "    \n",
    "    // ReLU æ¿€æ´»å‡½æ•°ï¼ˆæ¨¡æ‹Ÿï¼‰\n",
    "    let activated = hidden.relu();\n",
    "    println!(\"  âœ… ReLU æ¿€æ´»å·²åº”ç”¨\");\n",
    "    \n",
    "    // å±‚ 2: éšè— -> è¾“å‡º\n",
    "    let output = activated.matmul(&weight2);\n",
    "    println!(\"  âœ… éšè— -> è¾“å‡º: {:?}\", output.shape());\n",
    "    \n",
    "    let total_time = start.elapsed();\n",
    "    \n",
    "    println!(\"\\nâ±ï¸ æ€»å‰å‘ä¼ æ’­æ—¶é—´: {:?}\", total_time);\n",
    "    println!(\"ğŸš€ ä¼°è®¡æ€§èƒ½: {:.0} æ ·æœ¬/ç§’\", \n",
    "             (batch_size as f64) / total_time.as_secs_f64());\n",
    "    \n",
    "    println!(\"\\nğŸ“ åœ¨å®é™…å®ç°ä¸­:\");\n",
    "    println!(\"  â€¢ å¤§çŸ©é˜µå°†ä½¿ç”¨ CoreML\");\n",
    "    println!(\"  â€¢ æ¿€æ´»å°†ä½¿ç”¨ Metal GPU\");\n",
    "    println!(\"  â€¢ å°æ“ä½œå°†ä¿ç•™åœ¨ CPU ä¸Š\");\n",
    "}\n",
    "\n",
    "simulate_neural_layer();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é”™è¯¯å¤„ç†å’Œå›é€€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn demonstrate_fallback_behavior() {\n",
    "    println!(\"ğŸ”„ å›é€€è¡Œä¸ºæ¼”ç¤º:\");\n",
    "    \n",
    "    // æ¨¡æ‹Ÿå¯èƒ½åœ¨ CoreML ä¸Šå¤±è´¥çš„æ“ä½œ\n",
    "    let complex_tensor = Tensor::randn(&[100, 100]);\n",
    "    \n",
    "    println!(\"ğŸ¯ å°è¯• CoreML æ“ä½œ...\");\n",
    "    \n",
    "    // åœ¨å®é™…å®ç°ä¸­ï¼Œè¿™å°†æ˜¯:\n",
    "    // match tensor.to_coreml() {\n",
    "    //     Ok(coreml_tensor) => { /* ä½¿ç”¨ CoreML */ },\n",
    "    //     Err(_) => { /* å›é€€åˆ° Metal/CPU */ }\n",
    "    // }\n",
    "    \n",
    "    let use_coreml = false; // æ¨¡æ‹Ÿ CoreML å¤±è´¥\n",
    "    \n",
    "    if use_coreml {\n",
    "        println!(\"âœ… CoreML æ“ä½œæˆåŠŸ\");\n",
    "    } else {\n",
    "        println!(\"âš ï¸ CoreML ä¸å¯ç”¨ï¼Œä½¿ç”¨å›é€€\");\n",
    "        \n",
    "        // å›é€€åˆ° Metal GPU\n",
    "        let start = Instant::now();\n",
    "        let result = complex_tensor.matmul(&complex_tensor);\n",
    "        let fallback_time = start.elapsed();\n",
    "        \n",
    "        println!(\"âœ… å›é€€æ“ä½œå®Œæˆ\");\n",
    "        println!(\"â±ï¸ å›é€€æ—¶é—´: {:?}\", fallback_time);\n",
    "        println!(\"ğŸ“ ç»“æœå½¢çŠ¶: {:?}\", result.shape());\n",
    "    }\n",
    "    \n",
    "    println!(\"\\nğŸ“ å›é€€ç­–ç•¥:\");\n",
    "    println!(\"  1. å°è¯• CoreMLï¼ˆæœ€ä½³æ€§èƒ½ï¼‰\");\n",
    "    println!(\"  2. å›é€€åˆ° Metal GPUï¼ˆè‰¯å¥½å…¼å®¹æ€§ï¼‰\");\n",
    "    println!(\"  3. æœ€ç»ˆå›é€€åˆ° CPUï¼ˆæœ€å¤§å…¼å®¹æ€§ï¼‰\");\n",
    "}\n",
    "\n",
    "demonstrate_fallback_behavior();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€»ç»“å’Œåç»­æ­¥éª¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println!(\"ğŸ“‹ RusTorch CoreML é›†æˆæ€»ç»“ï¼ˆRust å†…æ ¸ï¼‰:\");\n",
    "println!();\n",
    "println!(\"âœ… æ¼”ç¤ºçš„åŠŸèƒ½:\");\n",
    "println!(\"  â€¢ CoreML å¯ç”¨æ€§æ£€æŸ¥\");\n",
    "println!(\"  â€¢ è®¾å¤‡åˆ›å»ºå’Œç®¡ç†\");\n",
    "println!(\"  â€¢ åç«¯é…ç½®\");\n",
    "println!(\"  â€¢ åŸºæœ¬å¼ é‡æ“ä½œ\");\n",
    "println!(\"  â€¢ æ€§èƒ½åŸºå‡†æµ‹è¯•\");\n",
    "println!(\"  â€¢ æ™ºèƒ½è®¾å¤‡é€‰æ‹©\");\n",
    "println!(\"  â€¢ å›é€€è¡Œä¸º\");\n",
    "println!();\n",
    "println!(\"ğŸš§ å¼€å‘é¢†åŸŸ:\");\n",
    "println!(\"  â€¢ å®Œæ•´çš„ CoreML æ“ä½œå®ç°\");\n",
    "println!(\"  â€¢ å†…å­˜ä¼ è¾“ä¼˜åŒ–\");\n",
    "println!(\"  â€¢ æ‰©å±•çš„å¼ é‡ç±»å‹æ”¯æŒ\");\n",
    "println!(\"  â€¢ è¯¦ç»†çš„æ€§èƒ½åˆ†æ\");\n",
    "println!(\"  â€¢ ä¸ ML ç®¡é“çš„é›†æˆ\");\n",
    "println!();\n",
    "println!(\"ğŸ¯ æ¨èçš„åç»­æ­¥éª¤:\");\n",
    "println!(\"  1. ä½¿ç”¨é¢„è®­ç»ƒçš„ CoreML æ¨¡å‹è¿›è¡Œæµ‹è¯•\");\n",
    "println!(\"  2. ä¸å…¶ä»–åç«¯è¿›è¡Œæ¯”è¾ƒåŸºå‡†æµ‹è¯•\");\n",
    "println!(\"  3. é’ˆå¯¹ç‰¹å®šç”¨ä¾‹è¿›è¡Œä¼˜åŒ–\");\n",
    "println!(\"  4. éƒ¨ç½²åˆ°ç”Ÿäº§åº”ç”¨ç¨‹åº\");\n",
    "println!();\n",
    "\n",
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    if rustorch::backends::DeviceManager::is_coreml_available() {\n",
    "        println!(\"ğŸ‰ æ‰€æœ‰ CoreML åŠŸèƒ½éƒ½å¯ä»¥æµ‹è¯•ï¼\");\n",
    "    } else {\n",
    "        println!(\"âš ï¸ CoreML å·²å¯ç”¨ä½†åœ¨æ­¤ç³»ç»Ÿä¸Šä¸å¯ç”¨\");\n",
    "    }\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"âš ï¸ ä½¿ç”¨ CoreML åŠŸèƒ½æ„å»ºä»¥è·å¾—å®Œæ•´åŠŸèƒ½\");\n",
    "}\n",
    "\n",
    "println!(\"\\nğŸš€ å‡†å¤‡å¥½ä½¿ç”¨ RusTorch è¿›è¡Œé«˜çº§ CoreML å¼€å‘ï¼\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygments_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}