{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RusTorch CoreML 集成 - Rust 内核\n",
    "\n",
    "这个笔记本演示了如何在 RusTorch 中使用 CoreML。\n",
    "运行在 Rust 内核上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查所需依赖项和功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// RusTorch 基本使用\n",
    "extern crate rustorch;\n",
    "\n",
    "use rustorch::tensor::Tensor;\n",
    "use rustorch::gpu::DeviceType;\n",
    "\n",
    "println!(\"RusTorch 版本: {}\", env!(\"CARGO_PKG_VERSION\"));\n",
    "println!(\"Rust 版本: {}\", env!(\"RUSTC_VERSION\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查 CoreML 可用性\n",
    "\n",
    "检查当前系统上是否可用 CoreML。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    use rustorch::backends::DeviceManager;\n",
    "    \n",
    "    let coreml_available = DeviceManager::is_coreml_available();\n",
    "    println!(\"CoreML 可用: {}\", coreml_available);\n",
    "    \n",
    "    if coreml_available {\n",
    "        println!(\"🎉 CoreML 可用！\");\n",
    "        println!(\"平台: macOS\");\n",
    "        \n",
    "        // 显示设备信息\n",
    "        use rustorch::gpu::coreml::device_cache::DeviceCache;\n",
    "        let cache = DeviceCache::global();\n",
    "        cache.warmup();\n",
    "        \n",
    "        let stats = cache.get_stats();\n",
    "        println!(\"缓存统计: {:?}\", stats);\n",
    "    } else {\n",
    "        println!(\"⚠️ CoreML 不可用\");\n",
    "        println!(\"请使用 CPU 或其他 GPU 后端\");\n",
    "    }\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"❌ CoreML 功能未启用\");\n",
    "    println!(\"请使用 --features coreml 构建\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本张量操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 创建基本张量\n",
    "let a = Tensor::zeros(&[2, 3]);\n",
    "let b = Tensor::ones(&[3, 2]);\n",
    "\n",
    "println!(\"张量 A 形状: {:?}\", a.shape());\n",
    "println!(\"张量 B 形状: {:?}\", b.shape());\n",
    "\n",
    "// 基本矩阵乘法\n",
    "let result = a.matmul(&b);\n",
    "println!(\"结果形状: {:?}\", result.shape());\n",
    "println!(\"基本张量操作完成\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreML 设备操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    use rustorch::gpu::coreml::{CoreMLDevice, CoreMLBackend};\n",
    "    use rustorch::backends::BackendConfig;\n",
    "    \n",
    "    // 尝试创建 CoreML 设备\n",
    "    match CoreMLDevice::new(0) {\n",
    "        Ok(device) => {\n",
    "            println!(\"🖥️ CoreML 设备创建成功\");\n",
    "            println!(\"设备 ID: {}\", device.id());\n",
    "            println!(\"可用: {}\", device.is_available());\n",
    "            println!(\"内存限制: {} MB\", device.memory_limit() / (1024 * 1024));\n",
    "            \n",
    "            // 创建后端配置\n",
    "            let config = BackendConfig::new()\n",
    "                .with_caching(true)\n",
    "                .with_max_cache_size(200)\n",
    "                .with_profiling(true)\n",
    "                .with_auto_fallback(true);\n",
    "            \n",
    "            println!(\"⚙️ 后端配置: {:?}\", config);\n",
    "            \n",
    "            // 创建 CoreML 后端\n",
    "            match CoreMLBackend::new(device, config) {\n",
    "                Ok(backend) => {\n",
    "                    println!(\"🚀 CoreML 后端已初始化\");\n",
    "                    \n",
    "                    // 获取统计信息\n",
    "                    let stats = backend.get_statistics();\n",
    "                    println!(\"📊 后端统计:\");\n",
    "                    println!(\"  总操作数: {}\", stats.total_operations);\n",
    "                    println!(\"  缓存命中: {}\", stats.cache_hits);\n",
    "                    println!(\"  缓存未命中: {}\", stats.cache_misses);\n",
    "                    println!(\"  回退操作: {}\", stats.fallback_operations);\n",
    "                    \n",
    "                    // 在 CoreML 上创建张量\n",
    "                    let tensor_a = Tensor::randn(&[64, 64]).to_device(&backend);\n",
    "                    let tensor_b = Tensor::randn(&[64, 64]).to_device(&backend);\n",
    "                    \n",
    "                    println!(\"📐 在 CoreML 设备上创建张量\");\n",
    "                    \n",
    "                    // 矩阵乘法操作\n",
    "                    let start = std::time::Instant::now();\n",
    "                    let result = tensor_a.matmul(&tensor_b);\n",
    "                    let duration = start.elapsed();\n",
    "                    \n",
    "                    println!(\"✅ 矩阵乘法完成\");\n",
    "                    println!(\"⏱️ 执行时间: {:?}\", duration);\n",
    "                    println!(\"🎯 结果形状: {:?}\", result.shape());\n",
    "                    \n",
    "                    // 清理缓存\n",
    "                    backend.cleanup_cache();\n",
    "                    println!(\"🧹 缓存已清理\");\n",
    "                }\n",
    "                Err(e) => println!(\"❌ 创建 CoreML 后端错误: {:?}\", e),\n",
    "            }\n",
    "        }\n",
    "        Err(e) => {\n",
    "            println!(\"❌ 创建 CoreML 设备错误: {:?}\", e);\n",
    "            println!(\"此系统上可能无法使用 CoreML\");\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"⚠️ 跳过 CoreML 操作 - 功能未启用\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 性能比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use std::time::Instant;\n",
    "\n",
    "fn benchmark_operations() {\n",
    "    let sizes = vec![(64, 64), (128, 128), (256, 256), (512, 512)];\n",
    "    \n",
    "    println!(\"🏁 操作基准测试:\");\n",
    "    println!(\"大小\\t\\tCPU (毫秒)\\t首选设备\");\n",
    "    println!(\"-\" * 40);\n",
    "    \n",
    "    for (rows, cols) in sizes {\n",
    "        // 在 CPU 上创建张量\n",
    "        let a = Tensor::randn(&[rows, cols]);\n",
    "        let b = Tensor::randn(&[cols, rows]);\n",
    "        \n",
    "        // 测量 CPU 时间\n",
    "        let start = Instant::now();\n",
    "        let _result = a.matmul(&b);\n",
    "        let cpu_duration = start.elapsed();\n",
    "        \n",
    "        // 确定首选设备\n",
    "        let preferred_device = if rows * cols < 1000 {\n",
    "            \"CPU\"\n",
    "        } else if rows * cols < 10000 {\n",
    "            \"Metal GPU\"\n",
    "        } else {\n",
    "            \"CoreML\"\n",
    "        };\n",
    "        \n",
    "        println!(\"{}x{}\\t\\t{:.2}\\t\\t{}\", \n",
    "                rows, cols, \n",
    "                cpu_duration.as_millis() as f64, \n",
    "                preferred_device);\n",
    "    }\n",
    "}\n",
    "\n",
    "benchmark_operations();\n",
    "println!(\"\\n📝 注意：设备选择基于张量大小和可用性\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 智能设备选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    use rustorch::backends::{DeviceManager, DeviceSelector};\n",
    "    \n",
    "    fn demonstrate_device_selection() {\n",
    "        println!(\"🎯 智能设备选择演示:\");\n",
    "        \n",
    "        let operations = vec![\n",
    "            (\"小乘法\", vec![16, 16], \"CPU\"),\n",
    "            (\"2D 卷积\", vec![32, 3, 224, 224], \"CoreML\"),\n",
    "            (\"矩阵变换\", vec![128, 128], \"Metal GPU\"),\n",
    "            (\"大批次操作\", vec![512, 512], \"CoreML\"),\n",
    "            (\"向量计算\", vec![1000], \"CPU\"),\n",
    "        ];\n",
    "        \n",
    "        for (name, shape, preferred) in operations {\n",
    "            println!(\"  {:<25} {:?} -> {}\", name, shape, preferred);\n",
    "            \n",
    "            // 模拟基于规则的选择\n",
    "            let tensor_size: usize = shape.iter().product();\n",
    "            let selected_device = match tensor_size {\n",
    "                size if size < 1000 => DeviceType::Cpu,\n",
    "                size if size < 50000 => DeviceType::MetalGpu,\n",
    "                _ => {\n",
    "                    if DeviceManager::is_coreml_available() {\n",
    "                        DeviceType::CoreML\n",
    "                    } else {\n",
    "                        DeviceType::MetalGpu\n",
    "                    }\n",
    "                }\n",
    "            };\n",
    "            \n",
    "            println!(\"    -> 选择的设备: {:?}\", selected_device);\n",
    "        }\n",
    "        \n",
    "        println!(\"\\n📝 选择逻辑:\");\n",
    "        println!(\"  • < 1K 元素: CPU（最小开销）\");\n",
    "        println!(\"  • 1K-50K 元素: Metal GPU（平衡）\");\n",
    "        println!(\"  • > 50K 元素: CoreML（优化）或 Metal GPU（回退）\");\n",
    "    }\n",
    "    \n",
    "    demonstrate_device_selection();\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"⚠️ 设备选择演示已跳过 - CoreML 功能不可用\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高级示例：神经网络层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn simulate_neural_layer() {\n",
    "    println!(\"🧠 神经网络层模拟:\");\n",
    "    \n",
    "    // 层配置\n",
    "    let batch_size = 32;\n",
    "    let input_dim = 784;   // 28x28 MNIST\n",
    "    let hidden_dim = 256;\n",
    "    let output_dim = 10;   // 10个类别\n",
    "    \n",
    "    println!(\"📊 配置:\");\n",
    "    println!(\"  批次大小: {}\", batch_size);\n",
    "    println!(\"  输入维度: {}\", input_dim);\n",
    "    println!(\"  隐藏维度: {}\", hidden_dim);\n",
    "    println!(\"  输出维度: {}\", output_dim);\n",
    "    \n",
    "    // 创建张量\n",
    "    let input = Tensor::randn(&[batch_size, input_dim]);\n",
    "    let weight1 = Tensor::randn(&[input_dim, hidden_dim]);\n",
    "    let weight2 = Tensor::randn(&[hidden_dim, output_dim]);\n",
    "    \n",
    "    println!(\"\\n🔄 前向传播:\");\n",
    "    \n",
    "    // 模拟前向传播\n",
    "    let start = Instant::now();\n",
    "    \n",
    "    // 层 1: 输入 -> 隐藏\n",
    "    let hidden = input.matmul(&weight1);\n",
    "    println!(\"  ✅ 输入 -> 隐藏: {:?}\", hidden.shape());\n",
    "    \n",
    "    // ReLU 激活函数（模拟）\n",
    "    let activated = hidden.relu();\n",
    "    println!(\"  ✅ ReLU 激活已应用\");\n",
    "    \n",
    "    // 层 2: 隐藏 -> 输出\n",
    "    let output = activated.matmul(&weight2);\n",
    "    println!(\"  ✅ 隐藏 -> 输出: {:?}\", output.shape());\n",
    "    \n",
    "    let total_time = start.elapsed();\n",
    "    \n",
    "    println!(\"\\n⏱️ 总前向传播时间: {:?}\", total_time);\n",
    "    println!(\"🚀 估计性能: {:.0} 样本/秒\", \n",
    "             (batch_size as f64) / total_time.as_secs_f64());\n",
    "    \n",
    "    println!(\"\\n📝 在实际实现中:\");\n",
    "    println!(\"  • 大矩阵将使用 CoreML\");\n",
    "    println!(\"  • 激活将使用 Metal GPU\");\n",
    "    println!(\"  • 小操作将保留在 CPU 上\");\n",
    "}\n",
    "\n",
    "simulate_neural_layer();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 错误处理和回退"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn demonstrate_fallback_behavior() {\n",
    "    println!(\"🔄 回退行为演示:\");\n",
    "    \n",
    "    // 模拟可能在 CoreML 上失败的操作\n",
    "    let complex_tensor = Tensor::randn(&[100, 100]);\n",
    "    \n",
    "    println!(\"🎯 尝试 CoreML 操作...\");\n",
    "    \n",
    "    // 在实际实现中，这将是:\n",
    "    // match tensor.to_coreml() {\n",
    "    //     Ok(coreml_tensor) => { /* 使用 CoreML */ },\n",
    "    //     Err(_) => { /* 回退到 Metal/CPU */ }\n",
    "    // }\n",
    "    \n",
    "    let use_coreml = false; // 模拟 CoreML 失败\n",
    "    \n",
    "    if use_coreml {\n",
    "        println!(\"✅ CoreML 操作成功\");\n",
    "    } else {\n",
    "        println!(\"⚠️ CoreML 不可用，使用回退\");\n",
    "        \n",
    "        // 回退到 Metal GPU\n",
    "        let start = Instant::now();\n",
    "        let result = complex_tensor.matmul(&complex_tensor);\n",
    "        let fallback_time = start.elapsed();\n",
    "        \n",
    "        println!(\"✅ 回退操作完成\");\n",
    "        println!(\"⏱️ 回退时间: {:?}\", fallback_time);\n",
    "        println!(\"📐 结果形状: {:?}\", result.shape());\n",
    "    }\n",
    "    \n",
    "    println!(\"\\n📝 回退策略:\");\n",
    "    println!(\"  1. 尝试 CoreML（最佳性能）\");\n",
    "    println!(\"  2. 回退到 Metal GPU（良好兼容性）\");\n",
    "    println!(\"  3. 最终回退到 CPU（最大兼容性）\");\n",
    "}\n",
    "\n",
    "demonstrate_fallback_behavior();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结和后续步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println!(\"📋 RusTorch CoreML 集成总结（Rust 内核）:\");\n",
    "println!();\n",
    "println!(\"✅ 演示的功能:\");\n",
    "println!(\"  • CoreML 可用性检查\");\n",
    "println!(\"  • 设备创建和管理\");\n",
    "println!(\"  • 后端配置\");\n",
    "println!(\"  • 基本张量操作\");\n",
    "println!(\"  • 性能基准测试\");\n",
    "println!(\"  • 智能设备选择\");\n",
    "println!(\"  • 回退行为\");\n",
    "println!();\n",
    "println!(\"🚧 开发领域:\");\n",
    "println!(\"  • 完整的 CoreML 操作实现\");\n",
    "println!(\"  • 内存传输优化\");\n",
    "println!(\"  • 扩展的张量类型支持\");\n",
    "println!(\"  • 详细的性能分析\");\n",
    "println!(\"  • 与 ML 管道的集成\");\n",
    "println!();\n",
    "println!(\"🎯 推荐的后续步骤:\");\n",
    "println!(\"  1. 使用预训练的 CoreML 模型进行测试\");\n",
    "println!(\"  2. 与其他后端进行比较基准测试\");\n",
    "println!(\"  3. 针对特定用例进行优化\");\n",
    "println!(\"  4. 部署到生产应用程序\");\n",
    "println!();\n",
    "\n",
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    if rustorch::backends::DeviceManager::is_coreml_available() {\n",
    "        println!(\"🎉 所有 CoreML 功能都可以测试！\");\n",
    "    } else {\n",
    "        println!(\"⚠️ CoreML 已启用但在此系统上不可用\");\n",
    "    }\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"⚠️ 使用 CoreML 功能构建以获得完整功能\");\n",
    "}\n",
    "\n",
    "println!(\"\\n🚀 准备好使用 RusTorch 进行高级 CoreML 开发！\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygments_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}