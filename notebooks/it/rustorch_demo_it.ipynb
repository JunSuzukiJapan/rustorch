{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Demo RusTorch in Italiano ðŸš€\n",
    "\n",
    "Benvenuti in RusTorch! Questo notebook dimostra le capacitÃ  principali della nostra libreria di deep learning pronta per la produzione in Rust con API simile a PyTorch.\n",
    "\n",
    "## FunzionalitÃ  Dimostrate:\n",
    "- ðŸ”¥ **Operazioni Tensoriali**: Creare, manipolare e calcolare con i tensori\n",
    "- ðŸ§® **Operazioni Matriciali**: Algebra lineare con prestazioni ottimizzate\n",
    "- ðŸ§  **Strati di Rete Neurale**: Blocchi costitutivi per il deep learning\n",
    "- âš¡ **Prestazioni**: VelocitÃ  potenziata da Rust con accelerazione GPU\n",
    "\n",
    "Iniziamo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importare RusTorch e altre librerie richieste\n",
    "import rustorch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(\"RusTorch importato con successo!\")\n",
    "print(f\"Operazioni disponibili: {dir(rustorch)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-tensors",
   "metadata": {},
   "source": [
    "## 1. Creazione Base dei Tensori\n",
    "\n",
    "RusTorch fornisce molteplici modi per creare tensori, simile a PyTorch ma con i vantaggi prestazionali di Rust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tensor-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creare diversi tipi di tensori\n",
    "tensore_zeri = rustorch.zeros([3, 4])\n",
    "tensore_uni = rustorch.ones([3, 4])\n",
    "tensore_casuale = rustorch.randn([3, 4])\n",
    "tensore_personalizzato = rustorch.PyTensor([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], [2, 3])\n",
    "\n",
    "print(\"Tensore di zeri:\")\n",
    "print(f\"  Forma: {tensore_zeri.shape()}\")\n",
    "print(f\"  Dati: {tensore_zeri.data()}\")\n",
    "\n",
    "print(\"\\nTensore di uni:\")\n",
    "print(f\"  Forma: {tensore_uni.shape()}\")\n",
    "print(f\"  Dati: {tensore_uni.data()}\")\n",
    "\n",
    "print(\"\\nTensore casuale (distribuzione normale):\")\n",
    "print(f\"  Forma: {tensore_casuale.shape()}\")\n",
    "print(f\"  Dati: {tensore_casuale.data()}\")\n",
    "\n",
    "print(\"\\nTensore personalizzato:\")\n",
    "print(f\"  Forma: {tensore_personalizzato.shape()}\")\n",
    "print(f\"  Dati: {tensore_personalizzato.data()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tensor-ops",
   "metadata": {},
   "source": [
    "## 2. Operazioni sui Tensori\n",
    "\n",
    "Eseguire operazioni matematiche sui tensori con backend Rust ottimizzato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operazioni aritmetiche di base\n",
    "a = rustorch.PyTensor([1.0, 2.0, 3.0, 4.0], [2, 2])\n",
    "b = rustorch.PyTensor([5.0, 6.0, 7.0, 8.0], [2, 2])\n",
    "\n",
    "# Addizione\n",
    "addizione = a.add(b)\n",
    "print(\"Addizione di Tensori:\")\n",
    "print(f\"  A: {a.data()}\")\n",
    "print(f\"  B: {b.data()}\")\n",
    "print(f\"  A + B: {addizione.data()}\")\n",
    "\n",
    "# Moltiplicazione elemento per elemento\n",
    "moltiplicazione = a.mul(b)\n",
    "print(\"\\nMoltiplicazione Elemento per Elemento:\")\n",
    "print(f\"  A * B: {moltiplicazione.data()}\")\n",
    "\n",
    "# Moltiplicazione matriciale\n",
    "matmul = a.matmul(b)\n",
    "print(\"\\nMoltiplicazione Matriciale:\")\n",
    "print(f\"  A @ B: {matmul.data()}\")\n",
    "print(f\"  Forma: {matmul.shape()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activations",
   "metadata": {},
   "source": [
    "## 3. Funzioni di Attivazione\n",
    "\n",
    "Funzioni di attivazione essenziali per reti neurali implementate efficientemente in Rust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activation-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creare tensore di input con vari valori\n",
    "valori_input = [-3.0, -1.5, 0.0, 1.5, 3.0]\n",
    "tensore_input = rustorch.PyTensor(valori_input, [5])\n",
    "\n",
    "print(f\"Valori di input: {valori_input}\")\n",
    "print()\n",
    "\n",
    "# Applicare diverse funzioni di attivazione\n",
    "output_relu = tensore_input.relu()\n",
    "output_sigmoid = tensore_input.sigmoid()\n",
    "output_tanh = tensore_input.tanh()\n",
    "\n",
    "print(\"Funzioni di Attivazione:\")\n",
    "print(f\"  ReLU:    {output_relu.data()}\")\n",
    "print(f\"  Sigmoid: {output_sigmoid.data()}\")\n",
    "print(f\"  Tanh:    {output_tanh.data()}\")\n",
    "\n",
    "# Dimostrare le proprietÃ  matematiche\n",
    "print(\"\\nProprietÃ  Matematiche:\")\n",
    "print(f\"  ReLU taglia i valori negativi a zero\")\n",
    "print(f\"  Sigmoid ha output nel range da 0 a 1\")\n",
    "print(f\"  Tanh ha output nel range da -1 a 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-network",
   "metadata": {},
   "source": [
    "## 4. Esempio di Rete Neurale Semplice\n",
    "\n",
    "Costruire una rete neurale di base usando le operazioni tensoriali di RusTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-network-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definire una rete neurale semplice a 2 strati\n",
    "def passaggio_in_avanti_semplice(dati_input, pesi1, bias1, pesi2, bias2):\n",
    "    \"\"\"\n",
    "    Eseguire un passaggio in avanti attraverso una rete neurale a 2 strati.\n",
    "    \"\"\"\n",
    "    # Strato 1: Trasformazione lineare + attivazione ReLU\n",
    "    strato1_lineare = dati_input.matmul(pesi1).add(bias1)\n",
    "    output_strato1 = strato1_lineare.relu()\n",
    "    \n",
    "    # Strato 2: Trasformazione lineare + attivazione Sigmoid\n",
    "    strato2_lineare = output_strato1.matmul(pesi2).add(bias2)\n",
    "    output = strato2_lineare.sigmoid()\n",
    "    \n",
    "    return output, output_strato1\n",
    "\n",
    "# Inizializzare parametri della rete\n",
    "dimensione_input, dimensione_nascosta, dimensione_output = 3, 4, 2\n",
    "\n",
    "# Creare dati di input (dimensione_batch=2, dimensione_input=3)\n",
    "dati_input = rustorch.PyTensor([0.5, -0.2, 1.0, -1.0, 0.8, 0.3], [2, 3])\n",
    "\n",
    "# Inizializzare pesi e bias con piccoli valori casuali\n",
    "pesi1 = rustorch.randn([dimensione_input, dimensione_nascosta]).mul(rustorch.PyTensor([0.1], [1]))\n",
    "bias1 = rustorch.zeros([1, dimensione_nascosta])\n",
    "pesi2 = rustorch.randn([dimensione_nascosta, dimensione_output]).mul(rustorch.PyTensor([0.1], [1]))\n",
    "bias2 = rustorch.zeros([1, dimensione_output])\n",
    "\n",
    "# Passaggio in avanti\n",
    "output, nascosto = passaggio_in_avanti_semplice(dati_input, pesi1, bias1, pesi2, bias2)\n",
    "\n",
    "print(\"Passaggio in Avanti della Rete Neurale:\")\n",
    "print(f\"  Forma input: {dati_input.shape()}\")\n",
    "print(f\"  Dati input: {dati_input.data()}\")\n",
    "print(f\"  Forma strato nascosto: {nascosto.shape()}\")\n",
    "print(f\"  Output strato nascosto: {nascosto.data()}\")\n",
    "print(f\"  Forma output finale: {output.shape()}\")\n",
    "print(f\"  Output finale: {output.data()}\")\n",
    "print(f\"  (Valori output tra 0-1 grazie all'attivazione sigmoid)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "performance",
   "metadata": {},
   "source": [
    "## 5. Confronto delle Prestazioni\n",
    "\n",
    "Confrontare le prestazioni di RusTorch con NumPy per le operazioni matriciali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark delle prestazioni: Moltiplicazione matriciale\n",
    "dimensioni = [100, 500, 1000]\n",
    "\n",
    "print(\"Confronto delle Prestazioni: RusTorch vs NumPy\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for dimensione in dimensioni:\n",
    "    print(f\"\\nDimensione matrice: {dimensione}x{dimensione}\")\n",
    "    \n",
    "    # Benchmark RusTorch\n",
    "    tempo_inizio = time.time()\n",
    "    rust_a = rustorch.randn([dimensione, dimensione])\n",
    "    rust_b = rustorch.randn([dimensione, dimensione])\n",
    "    risultato_rust = rust_a.matmul(rust_b)\n",
    "    tempo_rust = time.time() - tempo_inizio\n",
    "    \n",
    "    # Benchmark NumPy\n",
    "    tempo_inizio = time.time()\n",
    "    numpy_a = np.random.randn(dimensione, dimensione).astype(np.float32)\n",
    "    numpy_b = np.random.randn(dimensione, dimensione).astype(np.float32)\n",
    "    risultato_numpy = np.dot(numpy_a, numpy_b)\n",
    "    tempo_numpy = time.time() - tempo_inizio\n",
    "    \n",
    "    # Calcolare l'accelerazione\n",
    "    accelerazione = tempo_numpy / tempo_rust if tempo_rust > 0 else float('inf')\n",
    "    \n",
    "    print(f\"  RusTorch: {tempo_rust:.4f}s\")\n",
    "    print(f\"  NumPy:    {tempo_numpy:.4f}s\")\n",
    "    print(f\"  Accelerazione: {accelerazione:.2f}x {'(RusTorch piÃ¹ veloce)' if accelerazione > 1 else '(NumPy piÃ¹ veloce)'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Nota: Le prestazioni possono variare in base alla configurazione del sistema e alle ottimizzazioni disponibili.\")\n",
    "print(\"Le prestazioni di RusTorch migliorano significativamente con l'accelerazione GPU abilitata.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Conclusione\n",
    "\n",
    "Questa demo ha mostrato le capacitÃ  principali di RusTorch:\n",
    "\n",
    "âœ… **Creazione e Manipolazione Tensori**: API facile da usare simile a PyTorch  \n",
    "âœ… **Operazioni Matematiche**: Operazioni di algebra lineare ottimizzate  \n",
    "âœ… **Blocchi Costitutivi Rete Neurale**: Funzioni di attivazione e operazioni di strato  \n",
    "âœ… **Prestazioni**: VelocitÃ  potenziata da Rust con potenziale accelerazione GPU  \n",
    "\n",
    "### Prossimi Passi:\n",
    "- Esplorare l'accelerazione GPU con backend CUDA/Metal/OpenCL\n",
    "- Costruire architetture di reti neurali piÃ¹ complesse\n",
    "- Provare modelli transformer e ottimizzatori avanzati\n",
    "- Scoprire il supporto WebGPU per ML basato su browser\n",
    "\n",
    "### Risorse:\n",
    "- ðŸ“š [Documentazione](https://docs.rs/rustorch)\n",
    "- ðŸš€ [Repository GitHub](https://github.com/JunSuzukiJapan/rustorch)\n",
    "- ðŸ““ [Guida Completa Configurazione Jupyter](../../README_JUPYTER.md)\n",
    "\n",
    "Buona programmazione con RusTorch! ðŸ¦€âš¡"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}