{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrazione CoreML di RusTorch - Kernel Rust\n",
    "\n",
    "Questo notebook dimostra come utilizzare CoreML con RusTorch.\n",
    "Viene eseguito sul kernel Rust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificare Dipendenze e Funzionalit√† Richieste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Uso base di RusTorch\n",
    "extern crate rustorch;\n",
    "\n",
    "use rustorch::tensor::Tensor;\n",
    "use rustorch::gpu::DeviceType;\n",
    "\n",
    "println!(\"Versione RusTorch: {}\", env!(\"CARGO_PKG_VERSION\"));\n",
    "println!(\"Versione Rust: {}\", env!(\"RUSTC_VERSION\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificare Disponibilit√† CoreML\n",
    "\n",
    "Verificare se CoreML √® disponibile sul sistema corrente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    use rustorch::backends::DeviceManager;\n",
    "    \n",
    "    let coreml_available = DeviceManager::is_coreml_available();\n",
    "    println!(\"CoreML disponibile: {}\", coreml_available);\n",
    "    \n",
    "    if coreml_available {\n",
    "        println!(\"üéâ CoreML √® disponibile!\");\n",
    "        println!(\"Piattaforma: macOS\");\n",
    "        \n",
    "        // Mostrare informazioni dispositivo\n",
    "        use rustorch::gpu::coreml::device_cache::DeviceCache;\n",
    "        let cache = DeviceCache::global();\n",
    "        cache.warmup();\n",
    "        \n",
    "        let stats = cache.get_stats();\n",
    "        println!(\"Statistiche cache: {:?}\", stats);\n",
    "    } else {\n",
    "        println!(\"‚ö†Ô∏è CoreML non √® disponibile\");\n",
    "        println!(\"Si prega di usare CPU o altri backend GPU\");\n",
    "    }\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"‚ùå Le funzionalit√† CoreML non sono abilitate\");\n",
    "    println!(\"Si prega di compilare con --features coreml\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operazioni Tensore di Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Creare tensori di base\n",
    "let a = Tensor::zeros(&[2, 3]);\n",
    "let b = Tensor::ones(&[3, 2]);\n",
    "\n",
    "println!(\"Forma tensore A: {:?}\", a.shape());\n",
    "println!(\"Forma tensore B: {:?}\", b.shape());\n",
    "\n",
    "// Moltiplicazione matrici di base\n",
    "let result = a.matmul(&b);\n",
    "println!(\"Forma risultato: {:?}\", result.shape());\n",
    "println!(\"Operazioni tensore di base completate\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operazioni con Dispositivo CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    use rustorch::gpu::coreml::{CoreMLDevice, CoreMLBackend};\n",
    "    use rustorch::backends::BackendConfig;\n",
    "    \n",
    "    // Tentare di creare dispositivo CoreML\n",
    "    match CoreMLDevice::new(0) {\n",
    "        Ok(device) => {\n",
    "            println!(\"üñ•Ô∏è Dispositivo CoreML creato con successo\");\n",
    "            println!(\"ID dispositivo: {}\", device.id());\n",
    "            println!(\"Disponibile: {}\", device.is_available());\n",
    "            println!(\"Limite memoria: {} MB\", device.memory_limit() / (1024 * 1024));\n",
    "            \n",
    "            // Creare configurazione backend\n",
    "            let config = BackendConfig::new()\n",
    "                .with_caching(true)\n",
    "                .with_max_cache_size(200)\n",
    "                .with_profiling(true)\n",
    "                .with_auto_fallback(true);\n",
    "            \n",
    "            println!(\"‚öôÔ∏è Configurazione backend: {:?}\", config);\n",
    "            \n",
    "            // Creare backend CoreML\n",
    "            match CoreMLBackend::new(device, config) {\n",
    "                Ok(backend) => {\n",
    "                    println!(\"üöÄ Backend CoreML inizializzato\");\n",
    "                    \n",
    "                    // Ottenere statistiche\n",
    "                    let stats = backend.get_statistics();\n",
    "                    println!(\"üìä Statistiche backend:\");\n",
    "                    println!(\"  Operazioni totali: {}\", stats.total_operations);\n",
    "                    println!(\"  Hit cache: {}\", stats.cache_hits);\n",
    "                    println!(\"  Miss cache: {}\", stats.cache_misses);\n",
    "                    println!(\"  Operazioni fallback: {}\", stats.fallback_operations);\n",
    "                    \n",
    "                    // Creare tensori su CoreML\n",
    "                    let tensor_a = Tensor::randn(&[64, 64]).to_device(&backend);\n",
    "                    let tensor_b = Tensor::randn(&[64, 64]).to_device(&backend);\n",
    "                    \n",
    "                    println!(\"üìê Tensori creati su dispositivo CoreML\");\n",
    "                    \n",
    "                    // Operazione moltiplicazione matrici\n",
    "                    let start = std::time::Instant::now();\n",
    "                    let result = tensor_a.matmul(&tensor_b);\n",
    "                    let duration = start.elapsed();\n",
    "                    \n",
    "                    println!(\"‚úÖ Moltiplicazione matrici completata\");\n",
    "                    println!(\"‚è±Ô∏è Tempo esecuzione: {:?}\", duration);\n",
    "                    println!(\"üéØ Forma risultato: {:?}\", result.shape());\n",
    "                    \n",
    "                    // Pulire cache\n",
    "                    backend.cleanup_cache();\n",
    "                    println!(\"üßπ Cache pulita\");\n",
    "                }\n",
    "                Err(e) => println!(\"‚ùå Errore creazione backend CoreML: {:?}\", e),\n",
    "            }\n",
    "        }\n",
    "        Err(e) => {\n",
    "            println!(\"‚ùå Errore creazione dispositivo CoreML: {:?}\", e);\n",
    "            println!(\"CoreML potrebbe non essere disponibile su questo sistema\");\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"‚ö†Ô∏è Saltando operazioni CoreML - funzionalit√† non abilitate\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confronto Prestazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use std::time::Instant;\n",
    "\n",
    "fn benchmark_operations() {\n",
    "    let sizes = vec![(64, 64), (128, 128), (256, 256), (512, 512)];\n",
    "    \n",
    "    println!(\"üèÅ Benchmarking operazioni:\");\n",
    "    println!(\"Dimensione\\t\\tCPU (ms)\\tDispositivo Preferito\");\n",
    "    println!(\"-\" * 50);\n",
    "    \n",
    "    for (rows, cols) in sizes {\n",
    "        // Creare tensori su CPU\n",
    "        let a = Tensor::randn(&[rows, cols]);\n",
    "        let b = Tensor::randn(&[cols, rows]);\n",
    "        \n",
    "        // Misurare tempo CPU\n",
    "        let start = Instant::now();\n",
    "        let _result = a.matmul(&b);\n",
    "        let cpu_duration = start.elapsed();\n",
    "        \n",
    "        // Determinare dispositivo preferito\n",
    "        let preferred_device = if rows * cols < 1000 {\n",
    "            \"CPU\"\n",
    "        } else if rows * cols < 10000 {\n",
    "            \"Metal GPU\"\n",
    "        } else {\n",
    "            \"CoreML\"\n",
    "        };\n",
    "        \n",
    "        println!(\"{}x{}\\t\\t{:.2}\\t\\t{}\", \n",
    "                rows, cols, \n",
    "                cpu_duration.as_millis() as f64, \n",
    "                preferred_device);\n",
    "    }\n",
    "}\n",
    "\n",
    "benchmark_operations();\n",
    "println!(\"\\nüìù Nota: La selezione dispositivo √® basata su dimensione tensore e disponibilit√†\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selezione Intelligente Dispositivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    use rustorch::backends::{DeviceManager, DeviceSelector};\n",
    "    \n",
    "    fn demonstrate_device_selection() {\n",
    "        println!(\"üéØ Dimostrazione selezione intelligente dispositivo:\");\n",
    "        \n",
    "        let operations = vec![\n",
    "            (\"Moltiplicazione piccola\", vec![16, 16], \"CPU\"),\n",
    "            (\"Convoluzione 2D\", vec![32, 3, 224, 224], \"CoreML\"),\n",
    "            (\"Trasformazione matrice\", vec![128, 128], \"Metal GPU\"),\n",
    "            (\"Operazione batch grande\", vec![512, 512], \"CoreML\"),\n",
    "            (\"Calcolo vettoriale\", vec![1000], \"CPU\"),\n",
    "        ];\n",
    "        \n",
    "        for (name, shape, preferred) in operations {\n",
    "            println!(\"  {:<25} {:?} -> {}\", name, shape, preferred);\n",
    "            \n",
    "            // Simulare selezione basata su regole\n",
    "            let tensor_size: usize = shape.iter().product();\n",
    "            let selected_device = match tensor_size {\n",
    "                size if size < 1000 => DeviceType::Cpu,\n",
    "                size if size < 50000 => DeviceType::MetalGpu,\n",
    "                _ => {\n",
    "                    if DeviceManager::is_coreml_available() {\n",
    "                        DeviceType::CoreML\n",
    "                    } else {\n",
    "                        DeviceType::MetalGpu\n",
    "                    }\n",
    "                }\n",
    "            };\n",
    "            \n",
    "            println!(\"    -> Dispositivo selezionato: {:?}\", selected_device);\n",
    "        }\n",
    "        \n",
    "        println!(\"\\nüìù Logica selezione:\");\n",
    "        println!(\"  ‚Ä¢ < 1K elementi: CPU (overhead minimo)\");\n",
    "        println!(\"  ‚Ä¢ 1K-50K elementi: Metal GPU (bilanciato)\");\n",
    "        println!(\"  ‚Ä¢ > 50K elementi: CoreML (ottimizzato) o Metal GPU (fallback)\");\n",
    "    }\n",
    "    \n",
    "    demonstrate_device_selection();\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"‚ö†Ô∏è Dimostrazione selezione dispositivo saltata - funzionalit√† CoreML non disponibili\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esempio Avanzato: Strato Rete Neurale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn simulate_neural_layer() {\n",
    "    println!(\"üß† Simulazione strato rete neurale:\");\n",
    "    \n",
    "    // Configurazione strato\n",
    "    let batch_size = 32;\n",
    "    let input_dim = 784;   // 28x28 MNIST\n",
    "    let hidden_dim = 256;\n",
    "    let output_dim = 10;   // 10 classi\n",
    "    \n",
    "    println!(\"üìä Configurazione:\");\n",
    "    println!(\"  Dimensione batch: {}\", batch_size);\n",
    "    println!(\"  Dimensione input: {}\", input_dim);\n",
    "    println!(\"  Dimensione nascosta: {}\", hidden_dim);\n",
    "    println!(\"  Dimensione output: {}\", output_dim);\n",
    "    \n",
    "    // Creare tensori\n",
    "    let input = Tensor::randn(&[batch_size, input_dim]);\n",
    "    let weight1 = Tensor::randn(&[input_dim, hidden_dim]);\n",
    "    let weight2 = Tensor::randn(&[hidden_dim, output_dim]);\n",
    "    \n",
    "    println!(\"\\nüîÑ Forward pass:\");\n",
    "    \n",
    "    // Forward pass simulato\n",
    "    let start = Instant::now();\n",
    "    \n",
    "    // Strato 1: input -> nascosto\n",
    "    let hidden = input.matmul(&weight1);\n",
    "    println!(\"  ‚úÖ Input -> Nascosto: {:?}\", hidden.shape());\n",
    "    \n",
    "    // Funzione attivazione ReLU (simulata)\n",
    "    let activated = hidden.relu();\n",
    "    println!(\"  ‚úÖ Attivazione ReLU applicata\");\n",
    "    \n",
    "    // Strato 2: nascosto -> output\n",
    "    let output = activated.matmul(&weight2);\n",
    "    println!(\"  ‚úÖ Nascosto -> Output: {:?}\", output.shape());\n",
    "    \n",
    "    let total_time = start.elapsed();\n",
    "    \n",
    "    println!(\"\\n‚è±Ô∏è Tempo totale forward pass: {:?}\", total_time);\n",
    "    println!(\"üöÄ Prestazioni stimate: {:.0} campioni/secondo\", \n",
    "             (batch_size as f64) / total_time.as_secs_f64());\n",
    "    \n",
    "    println!(\"\\nüìù In un'implementazione reale:\");\n",
    "    println!(\"  ‚Ä¢ Matrici grandi utilizzerebbero CoreML\");\n",
    "    println!(\"  ‚Ä¢ Attivazioni utilizzerebbero Metal GPU\");\n",
    "    println!(\"  ‚Ä¢ Operazioni piccole rimarrebbero su CPU\");\n",
    "}\n",
    "\n",
    "simulate_neural_layer();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestione Errori e Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn demonstrate_fallback_behavior() {\n",
    "    println!(\"üîÑ Dimostrazione comportamento fallback:\");\n",
    "    \n",
    "    // Simulare operazione che potrebbe fallire su CoreML\n",
    "    let complex_tensor = Tensor::randn(&[100, 100]);\n",
    "    \n",
    "    println!(\"üéØ Tentativo operazione CoreML...\");\n",
    "    \n",
    "    // In implementazione reale, questo sarebbe:\n",
    "    // match tensor.to_coreml() {\n",
    "    //     Ok(coreml_tensor) => { /* usare CoreML */ },\n",
    "    //     Err(_) => { /* fallback a Metal/CPU */ }\n",
    "    // }\n",
    "    \n",
    "    let use_coreml = false; // Simulare fallimento CoreML\n",
    "    \n",
    "    if use_coreml {\n",
    "        println!(\"‚úÖ Operazione CoreML riuscita\");\n",
    "    } else {\n",
    "        println!(\"‚ö†Ô∏è CoreML non disponibile, usando fallback\");\n",
    "        \n",
    "        // Fallback a Metal GPU\n",
    "        let start = Instant::now();\n",
    "        let result = complex_tensor.matmul(&complex_tensor);\n",
    "        let fallback_time = start.elapsed();\n",
    "        \n",
    "        println!(\"‚úÖ Operazione fallback completata\");\n",
    "        println!(\"‚è±Ô∏è Tempo fallback: {:?}\", fallback_time);\n",
    "        println!(\"üìê Forma risultato: {:?}\", result.shape());\n",
    "    }\n",
    "    \n",
    "    println!(\"\\nüìù Strategia fallback:\");\n",
    "    println!(\"  1. Tentare CoreML (migliori prestazioni)\");\n",
    "    println!(\"  2. Fallback a Metal GPU (buona compatibilit√†)\");\n",
    "    println!(\"  3. Fallback finale a CPU (massima compatibilit√†)\");\n",
    "}\n",
    "\n",
    "demonstrate_fallback_behavior();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Riepilogo e Prossimi Passi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println!(\"üìã Riepilogo Integrazione CoreML RusTorch (Kernel Rust):\");\n",
    "println!();\n",
    "println!(\"‚úÖ Funzionalit√† dimostrate:\");\n",
    "println!(\"  ‚Ä¢ Verifica disponibilit√† CoreML\");\n",
    "println!(\"  ‚Ä¢ Creazione e gestione dispositivi\");\n",
    "println!(\"  ‚Ä¢ Configurazione backend\");\n",
    "println!(\"  ‚Ä¢ Operazioni tensore di base\");\n",
    "println!(\"  ‚Ä¢ Benchmarking prestazioni\");\n",
    "println!(\"  ‚Ä¢ Selezione intelligente dispositivo\");\n",
    "println!(\"  ‚Ä¢ Comportamento fallback\");\n",
    "println!();\n",
    "println!(\"üöß Area sviluppo:\");\n",
    "println!(\"  ‚Ä¢ Implementazione completa operazioni CoreML\");\n",
    "println!(\"  ‚Ä¢ Ottimizzazione trasferimento memoria\");\n",
    "println!(\"  ‚Ä¢ Supporto esteso tipi tensore\");\n",
    "println!(\"  ‚Ä¢ Profiling prestazioni dettagliato\");\n",
    "println!(\"  ‚Ä¢ Integrazione con pipeline ML\");\n",
    "println!();\n",
    "println!(\"üéØ Prossimi passi raccomandati:\");\n",
    "println!(\"  1. Testare con modelli CoreML preaddestrati\");\n",
    "println!(\"  2. Benchmark comparativo con altri backend\");\n",
    "println!(\"  3. Ottimizzare per casi d'uso specifici\");\n",
    "println!(\"  4. Deployare in applicazioni produzione\");\n",
    "println!();\n",
    "\n",
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    if rustorch::backends::DeviceManager::is_coreml_available() {\n",
    "        println!(\"üéâ Tutte le funzionalit√† CoreML sono disponibili per test!\");\n",
    "    } else {\n",
    "        println!(\"‚ö†Ô∏è CoreML √® abilitato ma non disponibile su questo sistema\");\n",
    "    }\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"‚ö†Ô∏è Compilare con funzionalit√† CoreML per funzionalit√† completa\");\n",
    "}\n",
    "\n",
    "println!(\"\\nüöÄ Pronto per sviluppo avanzato CoreML con RusTorch!\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygments_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}