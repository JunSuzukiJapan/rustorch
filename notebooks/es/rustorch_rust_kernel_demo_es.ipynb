{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🦀 Demo RusTorch con Kernel Rust\n",
    "\n",
    "¡Este notebook demuestra cómo usar RusTorch directamente en Rust dentro de Jupyter!\n",
    "\n",
    "## Características:\n",
    "- 🔥 **Rendimiento Rust Nativo**: Abstracciones de costo cero\n",
    "- 🧮 **Operaciones Tensoriales Directas**: Cálculos matriciales type-safe\n",
    "- 🧠 **Construcción de Redes Neurales**: Deep learning listo para producción\n",
    "- ⚡ **Aceleración GPU**: Soporte CUDA/Metal/OpenCL\n",
    "\n",
    "¡Empecemos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 Configuración de Dependencias\n",
    "\n",
    "Primero, agreguemos RusTorch y ndarray como dependencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ":dep rustorch = \"0.5.11\"\n",
    ":dep ndarray = \"0.16\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Importación de Bibliotecas\n",
    "\n",
    "Importemos RusTorch y ndarray con la macro array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use rustorch::*;\n",
    "use ndarray::prelude::*;\n",
    "use ndarray::array;\n",
    "use std::time::Instant;\n",
    "\n",
    "println!(\"✅ ¡RusTorch y ndarray importados exitosamente!\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔥 Operaciones Tensoriales Básicas\n",
    "\n",
    "Creemos tensores y realicemos operaciones básicas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Crear tensores usando la macro array!\n",
    "let a = Tensor::from_array(array![[1.0, 2.0], [3.0, 4.0]]);\n",
    "let b = Tensor::from_array(array![[5.0, 6.0], [7.0, 8.0]]);\n",
    "\n",
    "println!(\"Tensor a: {:?}\", a);\n",
    "println!(\"Tensor b: {:?}\", b);\n",
    "println!(\"Forma de a: {:?}\", a.shape());\n",
    "println!(\"Forma de b: {:?}\", b.shape());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Multiplicación matricial\n",
    "let matmul_result = a.matmul(&b);\n",
    "println!(\"Multiplicación matricial a @ b: {:?}\", matmul_result);\n",
    "\n",
    "// Operaciones elemento por elemento\n",
    "let sum = &a + &b;\n",
    "println!(\"Suma elemento por elemento a + b: {:?}\", sum);\n",
    "\n",
    "let product = &a * &b;\n",
    "println!(\"Producto elemento por elemento a * b: {:?}\", product);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "// Crear tensores especiales (con anotaciones de tipo explícitas)\nlet zeros: Tensor<f32> = Tensor::zeros(&[3, 3]);\nlet ones: Tensor<f32> = Tensor::ones(&[3, 3]);\nlet random: Tensor<f32> = Tensor::randn(&[3, 3]);\n\nprintln!(\"Tensor ceros: {:?}\", zeros);\nprintln!(\"Tensor unos: {:?}\", ones);\nprintln!(\"Tensor aleatorio: {:?}\", random);"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Crear tensor con valores positivos/negativos mezclados\n",
    "let input = Tensor::from_array(array![[-2.0, -1.0, 0.0, 1.0, 2.0]]);\n",
    "println!(\"Entrada: {:?}\", input);\n",
    "\n",
    "// Aplicar funciones de activación\n",
    "let relu_result = input.relu();\n",
    "let sigmoid_result = input.sigmoid();\n",
    "let tanh_result = input.tanh();\n",
    "\n",
    "println!(\"ReLU: {:?}\", relu_result);\n",
    "println!(\"Sigmoid: {:?}\", sigmoid_result);\n",
    "println!(\"Tanh: {:?}\", tanh_result);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ Benchmark de Rendimiento\n",
    "\n",
    "Comparemos el rendimiento de diferentes operaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "// Benchmark de multiplicación matricial\nlet size = 256;\nlet a: Tensor<f32> = Tensor::randn(&[size, size]);\nlet b: Tensor<f32> = Tensor::randn(&[size, size]);\n\nprintln!(\"🏁 Benchmarking multiplicación matricial {}x{}...\", size, size);\n\nlet start = Instant::now();\nlet result = a.matmul(&b);\nlet duration = start.elapsed();\n\nprintln!(\"✅ Completado en: {:?}\", duration);\nprintln!(\"📊 Forma del resultado: {:?}\", result.shape());\nprintln!(\"📈 Rendimiento: {:.2} GFLOPS\", \n    (2.0 * size as f64 * size as f64 * size as f64) / (duration.as_secs_f64() * 1e9));"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 Conclusión\n",
    "\n",
    "¡Ahora puedes escribir y ejecutar código Rust directamente en Jupyter!\n",
    "\n",
    "**Beneficios:**\n",
    "- 🚀 Rendimiento Rust nativo\n",
    "- 🔧 Acceso directo a bibliotecas\n",
    "- 🎯 Seguridad de tipos\n",
    "- ⚡ Abstracciones de costo cero\n",
    "- 🖥️ Soporte de aceleración GPU\n",
    "\n",
    "**Próximos Pasos:**\n",
    "- Explorar aceleración GPU con backends CUDA/Metal/OpenCL\n",
    "- Construir arquitecturas de redes neurales más complejas\n",
    "- Probar modelos transformer y optimizadores avanzados\n",
    "\n",
    "¡Feliz codificación con RusTorch! 🦀⚡"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygment_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}