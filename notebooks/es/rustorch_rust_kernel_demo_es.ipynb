{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¦€ Demo RusTorch con Kernel Rust\n",
    "\n",
    "Â¡Este notebook demuestra cÃ³mo usar RusTorch directamente en Rust dentro de Jupyter!\n",
    "\n",
    "## CaracterÃ­sticas:\n",
    "- ğŸ”¥ **Rendimiento Rust Nativo**: Abstracciones de costo cero\n",
    "- ğŸ§® **Operaciones Tensoriales Directas**: CÃ¡lculos matriciales type-safe\n",
    "- ğŸ§  **ConstrucciÃ³n de Redes Neurales**: Deep learning listo para producciÃ³n\n",
    "- âš¡ **AceleraciÃ³n GPU**: Soporte CUDA/Metal/OpenCL\n",
    "\n",
    "Â¡Empecemos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ ConfiguraciÃ³n de Dependencias\n",
    "\n",
    "Primero, agreguemos RusTorch y ndarray como dependencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ":dep rustorch = \"0.5.11\"\n",
    ":dep ndarray = \"0.16\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ImportaciÃ³n de Bibliotecas\n",
    "\n",
    "Importemos RusTorch y ndarray con la macro array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use rustorch::*;\n",
    "use ndarray::prelude::*;\n",
    "use ndarray::array;\n",
    "use std::time::Instant;\n",
    "\n",
    "println!(\"âœ… Â¡RusTorch y ndarray importados exitosamente!\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¥ Operaciones Tensoriales BÃ¡sicas\n",
    "\n",
    "Creemos tensores y realicemos operaciones bÃ¡sicas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Crear tensores usando la macro array!\n",
    "let a = Tensor::from_array(array![[1.0, 2.0], [3.0, 4.0]]);\n",
    "let b = Tensor::from_array(array![[5.0, 6.0], [7.0, 8.0]]);\n",
    "\n",
    "println!(\"Tensor a: {:?}\", a);\n",
    "println!(\"Tensor b: {:?}\", b);\n",
    "println!(\"Forma de a: {:?}\", a.shape());\n",
    "println!(\"Forma de b: {:?}\", b.shape());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// MultiplicaciÃ³n matricial\n",
    "let matmul_result = a.matmul(&b);\n",
    "println!(\"MultiplicaciÃ³n matricial a @ b: {:?}\", matmul_result);\n",
    "\n",
    "// Operaciones elemento por elemento\n",
    "let sum = &a + &b;\n",
    "println!(\"Suma elemento por elemento a + b: {:?}\", sum);\n",
    "\n",
    "let product = &a * &b;\n",
    "println!(\"Producto elemento por elemento a * b: {:?}\", product);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "// Crear tensores especiales (con anotaciones de tipo explÃ­citas)\nlet zeros: Tensor<f32> = Tensor::zeros(&[3, 3]);\nlet ones: Tensor<f32> = Tensor::ones(&[3, 3]);\nlet random: Tensor<f32> = Tensor::randn(&[3, 3]);\n\nprintln!(\"Tensor ceros: {:?}\", zeros);\nprintln!(\"Tensor unos: {:?}\", ones);\nprintln!(\"Tensor aleatorio: {:?}\", random);"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Crear tensor con valores positivos/negativos mezclados\n",
    "let input = Tensor::from_array(array![[-2.0, -1.0, 0.0, 1.0, 2.0]]);\n",
    "println!(\"Entrada: {:?}\", input);\n",
    "\n",
    "// Aplicar funciones de activaciÃ³n\n",
    "let relu_result = input.relu();\n",
    "let sigmoid_result = input.sigmoid();\n",
    "let tanh_result = input.tanh();\n",
    "\n",
    "println!(\"ReLU: {:?}\", relu_result);\n",
    "println!(\"Sigmoid: {:?}\", sigmoid_result);\n",
    "println!(\"Tanh: {:?}\", tanh_result);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš¡ Benchmark de Rendimiento\n",
    "\n",
    "Comparemos el rendimiento de diferentes operaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "// Benchmark de multiplicaciÃ³n matricial\nlet size = 256;\nlet a: Tensor<f32> = Tensor::randn(&[size, size]);\nlet b: Tensor<f32> = Tensor::randn(&[size, size]);\n\nprintln!(\"ğŸ Benchmarking multiplicaciÃ³n matricial {}x{}...\", size, size);\n\nlet start = Instant::now();\nlet result = a.matmul(&b);\nlet duration = start.elapsed();\n\nprintln!(\"âœ… Completado en: {:?}\", duration);\nprintln!(\"ğŸ“Š Forma del resultado: {:?}\", result.shape());\nprintln!(\"ğŸ“ˆ Rendimiento: {:.2} GFLOPS\", \n    (2.0 * size as f64 * size as f64 * size as f64) / (duration.as_secs_f64() * 1e9));"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ ConclusiÃ³n\n",
    "\n",
    "Â¡Ahora puedes escribir y ejecutar cÃ³digo Rust directamente en Jupyter!\n",
    "\n",
    "**Beneficios:**\n",
    "- ğŸš€ Rendimiento Rust nativo\n",
    "- ğŸ”§ Acceso directo a bibliotecas\n",
    "- ğŸ¯ Seguridad de tipos\n",
    "- âš¡ Abstracciones de costo cero\n",
    "- ğŸ–¥ï¸ Soporte de aceleraciÃ³n GPU\n",
    "\n",
    "**PrÃ³ximos Pasos:**\n",
    "- Explorar aceleraciÃ³n GPU con backends CUDA/Metal/OpenCL\n",
    "- Construir arquitecturas de redes neurales mÃ¡s complejas\n",
    "- Probar modelos transformer y optimizadores avanzados\n",
    "\n",
    "Â¡Feliz codificaciÃ³n con RusTorch! ğŸ¦€âš¡"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygment_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}