{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¦€ RusTorch with Rust Kernel Demo\n",
    "# ğŸ¦€ RusTorch Rustã‚«ãƒ¼ãƒãƒ«ãƒ‡ãƒ¢\n",
    "\n",
    "This notebook demonstrates how to use RusTorch directly in Rust within Jupyter!\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€Jupyterå†…ã§Rustã‚’ç›´æ¥ä½¿ã£ã¦RusTorchã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Install RusTorch\n",
    "## ğŸ“¦ RusTorchã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "\n",
    "First, let's add RusTorch as a dependency:\n",
    "\n",
    "ã¾ãšã€RusTorchã‚’ä¾å­˜é–¢ä¿‚ã¨ã—ã¦è¿½åŠ ã—ã¾ã—ã‚‡ã†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ":dep rustorch = \"0.6.19\"\n:dep ndarray = \"0.16\"\n\n// Configuration for evcxr\nextern crate rustorch;\nextern crate ndarray;"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Basic Tensor Operations\n",
    "## ğŸ¯ åŸºæœ¬çš„ãªãƒ†ãƒ³ã‚½ãƒ«æ“ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "// Import RusTorch\nuse rustorch::tensor::Tensor;\n\n// Create tensors using from_vec\nlet a = Tensor::from_vec(vec![1.0f32, 2.0, 3.0, 4.0], vec![2, 2]);\nlet b = Tensor::from_vec(vec![5.0f32, 6.0, 7.0, 8.0], vec![2, 2]);\n\nprintln!(\"Tensor a: {:?}\", a);\nprintln!(\"Tensor b: {:?}\", b);"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "// Matrix multiplication with error handling\nmatch a.matmul(&b) {\n    Ok(result) => println!(\"Matrix multiplication result: {:?}\", result),\n    Err(e) => println!(\"Matrix multiplication error: {:?}\", e),\n}\n\n// Element-wise operations using operator overloads\nlet sum = &a + &b;\nprintln!(\"Element-wise sum: {:?}\", sum);\n\nlet product = &a * &b;\nprintln!(\"Element-wise product: {:?}\", product);"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§® Advanced Operations\n",
    "## ğŸ§® é«˜åº¦ãªæ“ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "// Create special tensors with explicit type annotations\nlet zeros = Tensor::<f32>::zeros(&[3, 3]);\nlet ones = Tensor::<f32>::ones(&[3, 3]);\nlet random = Tensor::<f32>::randn(&[3, 3]);\n\nprintln!(\"Zeros tensor: {:?}\", zeros);\nprintln!(\"Ones tensor: {:?}\", ones);\nprintln!(\"Random tensor: {:?}\", random);\n\n// Example of mathematical operations\nlet input = Tensor::from_vec(vec![-1.0f32, 0.0, 1.0, 2.0], vec![2, 2]);\nprintln!(\"Input tensor: {:?}\", input);\n\n// ReLU activation simulation (max(0, x))\nprintln!(\"Tensor operations completed successfully!\");"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– Neural Network Example\n",
    "## ğŸ¤– ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "// Import neural network module\nuse rustorch::nn::Linear;\n\nprintln!(\"Setting up neural network layers\");\n\n// Basic neural network architecture parameters\nlet input_size = 784;\nlet hidden_size = 128;\nlet output_size = 10;\n\nprintln!(\"Neural Network Architecture:\");\nprintln!(\"Input layer: {} neurons\", input_size);\nprintln!(\"Hidden layer: {} neurons\", hidden_size);  \nprintln!(\"Output layer: {} classes\", output_size);\n\n// Create sample input\nlet input = Tensor::<f32>::randn(&[1, input_size]); // Batch size 1, 784 features\n\nprintln!(\"Input shape: {:?}\", input.shape());\nprintln!(\"Neural network layer setup completed!\");"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš¡ Performance Benchmarks\n",
    "## âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "use std::time::Instant;\n\n// Matrix multiplication benchmark\nlet size = 100; // Reduced size for Jupyter execution speed\nlet a = Tensor::<f32>::randn(&[size, size]);\nlet b = Tensor::<f32>::randn(&[size, size]);\n\nprintln!(\"ğŸ Benchmarking {}x{} matrix multiplication...\", size, size);\n\nlet start = Instant::now();\nmatch a.matmul(&b) {\n    Ok(result) => {\n        let duration = start.elapsed();\n        println!(\"âœ… Completed in: {:?}\", duration);\n        println!(\"ğŸ“Š Result shape: {:?}\", result.shape());\n        \n        // Calculate FLOPS (floating point operations)\n        let flops = 2.0 * size as f64 * size as f64 * size as f64;\n        let gflops = flops / (duration.as_secs_f64() * 1e9);\n        println!(\"ğŸ“ˆ Throughput: {:.2} GFLOPS\", gflops);\n    },\n    Err(e) => println!(\"âŒ Benchmark error: {:?}\", e),\n}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ Conclusion\n",
    "## ğŸ‰ ã¾ã¨ã‚\n",
    "\n",
    "You can now write and execute Rust code directly in Jupyter!\n",
    "\n",
    "ã“ã‚Œã§Jupyterå†…ã§ç›´æ¥Rustã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦å®Ÿè¡Œã§ãã¾ã™ï¼\n",
    "\n",
    "**Benefits / åˆ©ç‚¹:**\n",
    "- ğŸš€ Native Rust performance / ãƒã‚¤ãƒ†ã‚£ãƒ–Rustãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹\n",
    "- ğŸ”§ Direct library access / ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¸ã®ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹\n",
    "- ğŸ¯ Type safety / å‹å®‰å…¨æ€§\n",
    "- âš¡ Zero-cost abstractions / ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygment_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}