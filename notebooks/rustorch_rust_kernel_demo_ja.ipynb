{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🦀 RusTorch Rustカーネル デモ\n",
    "\n",
    "このノートブックでは、Jupyter内でRustを直接使ってRusTorchを使用する方法を示します！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 RusTorchをインストール\n",
    "\n",
    "まず、RusTorchを依存関係として追加しましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ":dep rustorch = \"0.6.30\"\n:dep ndarray = \"0.16\"\n\n// evcxr用の設定\nextern crate rustorch;\nextern crate ndarray;"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 基本的なテンソル操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "// RusTorchのimport\nuse rustorch::tensor::Tensor;\n\n// テンソルを作成（ndarray::arrayマクロを使わずに）\nlet a = Tensor::from_vec(vec![1.0f32, 2.0, 3.0, 4.0], vec![2, 2]);\nlet b = Tensor::from_vec(vec![5.0f32, 6.0, 7.0, 8.0], vec![2, 2]);\n\nprintln!(\"テンソル a: {:?}\", a);\nprintln!(\"テンソル b: {:?}\", b);"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "// 行列乗算\nmatch a.matmul(&b) {\n    Ok(result) => println!(\"行列乗算結果: {:?}\", result),\n    Err(e) => println!(\"行列乗算エラー: {:?}\", e),\n}\n\n// 要素ごとの演算（演算子オーバーロード使用）\nlet sum = &a + &b;\nprintln!(\"要素ごとの和: {:?}\", sum);\n\nlet product = &a * &b;  \nprintln!(\"要素ごとの積: {:?}\", product);"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧮 高度な操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "// 特殊なテンソルを作成\nlet zeros = Tensor::<f32>::zeros(&[3, 3]);\nlet ones = Tensor::<f32>::ones(&[3, 3]);\nlet random = Tensor::<f32>::randn(&[3, 3]);\n\nprintln!(\"ゼロテンソル: {:?}\", zeros);\nprintln!(\"ワンテンソル: {:?}\", ones);\nprintln!(\"ランダムテンソル: {:?}\", random);\n\n// 数学関数の適用例\nlet input = Tensor::from_vec(vec![-1.0f32, 0.0, 1.0, 2.0], vec![2, 2]);\nprintln!(\"入力テンソル: {:?}\", input);\n\n// ReLU活性化関数（max(0, x)）をシミュレート\nprintln!(\"テンソル操作が正常に完了しました！\");"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖 ニューラルネットワークの例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "// ニューラルネットワーク用のimport\nuse rustorch::nn::Linear;\n\nprintln!(\"ニューラルネットワーク層の設定を開始します\");\n\n// 基本的なニューラルネットワーク設定パラメータ\nlet input_size = 784;\nlet hidden_size = 128;\nlet output_size = 10;\n\nprintln!(\"ニューラルネットワークアーキテクチャ:\");\nprintln!(\"入力層: {} ニューロン\", input_size);\nprintln!(\"隠れ層: {} ニューロン\", hidden_size);  \nprintln!(\"出力層: {} クラス\", output_size);\n\n// サンプル入力を作成\nlet input = Tensor::<f32>::randn(&[1, input_size]); // バッチサイズ1、784特徴量\n\nprintln!(\"入力の形状: {:?}\", input.shape());\nprintln!(\"ニューラルネットワークの設定が完了しました！\");"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ パフォーマンスベンチマーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "use std::time::Instant;\n\n// 行列乗算のベンチマーク\nlet size = 100; // サイズを小さく調整（Jupyterでの実行速度を考慮）\nlet a = Tensor::<f32>::randn(&[size, size]);\nlet b = Tensor::<f32>::randn(&[size, size]);\n\nprintln!(\"🏁 {}x{}行列乗算をベンチマーク中...\", size, size);\n\nlet start = Instant::now();\nmatch a.matmul(&b) {\n    Ok(result) => {\n        let duration = start.elapsed();\n        println!(\"✅ 完了時間: {:?}\", duration);\n        println!(\"📊 結果の形状: {:?}\", result.shape());\n        \n        // FLOPS計算（浮動小数点演算数）\n        let flops = 2.0 * size as f64 * size as f64 * size as f64;\n        let gflops = flops / (duration.as_secs_f64() * 1e9);\n        println!(\"📈 スループット: {:.2} GFLOPS\", gflops);\n    },\n    Err(e) => println!(\"❌ ベンチマークエラー: {:?}\", e),\n}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 まとめ\n",
    "\n",
    "これでJupyter内で直接Rustコードを書いて実行できます！\n",
    "\n",
    "**利点:**\n",
    "- 🚀 ネイティブRustパフォーマンス\n",
    "- 🔧 ライブラリへの直接アクセス\n",
    "- 🎯 型安全性\n",
    "- ⚡ ゼロコスト抽象化\n",
    "\n",
    "**次のステップ:**\n",
    "- より複雑なニューラルネットワークアーキテクチャを構築\n",
    "- GPU加速バックエンドの使用\n",
    "- カスタム層と活性化関数の実装\n",
    "\n",
    "RusTorchでのコーディングを楽しんでください！🦀⚡"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygment_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}