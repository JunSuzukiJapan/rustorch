{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🦀 RusTorch Rustカーネル デモ\n",
    "\n",
    "このノートブックでは、Jupyter内でRustを直接使ってRusTorchを使用する方法を示します！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 RusTorchをインストール\n",
    "\n",
    "まず、RusTorchを依存関係として追加しましょう："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ":dep rustorch = \"0.5.11\"\n",
    ":dep ndarray = \"0.16\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 基本的なテンソル操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use rustorch::prelude::*;\n",
    "\n",
    "// テンソルを作成\n",
    "let a = Tensor::from_vec(vec![1.0, 2.0, 3.0, 4.0], vec![2, 2]);\n",
    "let b = Tensor::from_vec(vec![5.0, 6.0, 7.0, 8.0], vec![2, 2]);\n",
    "\n",
    "println!(\"テンソル a: {:?}\", a);\n",
    "println!(\"テンソル b: {:?}\", b);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 行列乗算\n",
    "let result = a.matmul(&b).expect(\"Matrix multiplication failed\");\n",
    "println!(\"行列乗算結果: {:?}\", result);\n",
    "\n",
    "// 要素ごとの演算\n",
    "let sum = &a + &b;\n",
    "println!(\"要素ごとの和: {:?}\", sum);\n",
    "\n",
    "let product = &a * &b;\n",
    "println!(\"要素ごとの積: {:?}\", product);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧮 高度な操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 特殊なテンソルを作成（明示的な型注釈付き）\n",
    "let zeros: Tensor<f32> = Tensor::zeros(&[3, 3]);\n",
    "let ones: Tensor<f32> = Tensor::ones(&[3, 3]);\n",
    "let random: Tensor<f32> = Tensor::randn(&[3, 3]);\n",
    "\n",
    "println!(\"ゼロテンソル: {:?}\", zeros);\n",
    "println!(\"ワンテンソル: {:?}\", ones);\n",
    "println!(\"ランダムテンソル: {:?}\", random);\n",
    "\n",
    "// 活性化関数の適用\n",
    "// 注意: nnモジュールの活性化関数を使用\n",
    "println!(\"テンソル操作が正常に完了しました！\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖 ニューラルネットワークの例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use rustorch::nn::*;\n",
    "\n",
    "// 基本的なニューラルネットワーク層を作成（明示的な型注釈付き）\n",
    "let linear1: Linear<f32> = Linear::new(784, 128);\n",
    "let linear2: Linear<f32> = Linear::new(128, 10);\n",
    "\n",
    "println!(\"ニューラルネットワーク層を作成しました\");\n",
    "println!(\"入力層: 784 → 隠れ層: 128 → 出力層: 10\");\n",
    "\n",
    "// サンプル入力を作成\n",
    "let input: Tensor<f32> = Tensor::randn(&[1, 784]); // バッチサイズ1、784特徴量\n",
    "\n",
    "// 層の作成デモ（順伝搬にはより複雑なセットアップが必要）\n",
    "println!(\"入力の形状: {:?}\", input.shape());\n",
    "println!(\"線形層1: 784 → 128 ニューロン\");\n",
    "println!(\"線形層2: 128 → 10 出力クラス\");\n",
    "println!(\"ニューラルネットワーク層の設定が完了しました！\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ パフォーマンスベンチマーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use std::time::Instant;\n",
    "\n",
    "// 行列乗算のベンチマーク\n",
    "let size = 500;\n",
    "let a: Tensor<f32> = Tensor::randn(&[size, size]);\n",
    "let b: Tensor<f32> = Tensor::randn(&[size, size]);\n",
    "\n",
    "println!(\"🏁 {}x{}行列乗算をベンチマーク中...\", size, size);\n",
    "\n",
    "let start = Instant::now();\n",
    "let result = a.matmul(&b).expect(\"Matrix multiplication failed\");\n",
    "let duration = start.elapsed();\n",
    "\n",
    "println!(\"✅ 完了時間: {:?}\", duration);\n",
    "println!(\"📊 結果の形状: {:?}\", result.shape());\n",
    "println!(\"📈 スループット: {:.2} GFLOPS\", \n",
    "    (2.0 * size as f64 * size as f64 * size as f64) / (duration.as_secs_f64() * 1e9));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 まとめ\n",
    "\n",
    "これでJupyter内で直接Rustコードを書いて実行できます！\n",
    "\n",
    "**利点:**\n",
    "- 🚀 ネイティブRustパフォーマンス\n",
    "- 🔧 ライブラリへの直接アクセス\n",
    "- 🎯 型安全性\n",
    "- ⚡ ゼロコスト抽象化\n",
    "\n",
    "**次のステップ:**\n",
    "- より複雑なニューラルネットワークアーキテクチャを構築\n",
    "- GPU加速バックエンドの使用\n",
    "- カスタム層と活性化関数の実装\n",
    "\n",
    "RusTorchでのコーディングを楽しんでください！🦀⚡"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygment_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}