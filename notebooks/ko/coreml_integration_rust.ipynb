{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RusTorch CoreML 통합 - Rust 커널\n",
    "\n",
    "이 노트북은 RusTorch와 CoreML을 사용하는 방법을 보여줍니다.\n",
    "Rust 커널에서 실행됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필수 의존성 및 기능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// RusTorch 기본 사용\n",
    "extern crate rustorch;\n",
    "\n",
    "use rustorch::tensor::Tensor;\n",
    "use rustorch::gpu::DeviceType;\n",
    "\n",
    "println!(\"RusTorch 버전: {}\", env!(\"CARGO_PKG_VERSION\"));\n",
    "println!(\"Rust 버전: {}\", env!(\"RUSTC_VERSION\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreML 가용성 확인\n",
    "\n",
    "현재 시스템에서 CoreML이 사용 가능한지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    use rustorch::backends::DeviceManager;\n",
    "    \n",
    "    let coreml_available = DeviceManager::is_coreml_available();\n",
    "    println!(\"CoreML 사용 가능: {}\", coreml_available);\n",
    "    \n",
    "    if coreml_available {\n",
    "        println!(\"🎉 CoreML을 사용할 수 있습니다!\");\n",
    "        println!(\"플랫폼: macOS\");\n",
    "        \n",
    "        // 디바이스 정보 표시\n",
    "        use rustorch::gpu::coreml::device_cache::DeviceCache;\n",
    "        let cache = DeviceCache::global();\n",
    "        cache.warmup();\n",
    "        \n",
    "        let stats = cache.get_stats();\n",
    "        println!(\"캐시 통계: {:?}\", stats);\n",
    "    } else {\n",
    "        println!(\"⚠️ CoreML을 사용할 수 없습니다\");\n",
    "        println!(\"CPU 또는 다른 GPU 백엔드를 사용해주세요\");\n",
    "    }\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"❌ CoreML 기능이 활성화되지 않았습니다\");\n",
    "    println!(\"--features coreml로 빌드해주세요\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 텐서 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 기본 텐서 생성\n",
    "let a = Tensor::zeros(&[2, 3]);\n",
    "let b = Tensor::ones(&[3, 2]);\n",
    "\n",
    "println!(\"텐서 A 형태: {:?}\", a.shape());\n",
    "println!(\"텐서 B 형태: {:?}\", b.shape());\n",
    "\n",
    "// 기본 행렬 곱셈\n",
    "let result = a.matmul(&b);\n",
    "println!(\"결과 형태: {:?}\", result.shape());\n",
    "println!(\"기본 텐서 연산 완료\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreML 디바이스 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    use rustorch::gpu::coreml::{CoreMLDevice, CoreMLBackend};\n",
    "    use rustorch::backends::BackendConfig;\n",
    "    \n",
    "    // CoreML 디바이스 생성 시도\n",
    "    match CoreMLDevice::new(0) {\n",
    "        Ok(device) => {\n",
    "            println!(\"🖥️ CoreML 디바이스 성공적으로 생성됨\");\n",
    "            println!(\"디바이스 ID: {}\", device.id());\n",
    "            println!(\"사용 가능: {}\", device.is_available());\n",
    "            println!(\"메모리 제한: {} MB\", device.memory_limit() / (1024 * 1024));\n",
    "            \n",
    "            // 백엔드 구성 생성\n",
    "            let config = BackendConfig::new()\n",
    "                .with_caching(true)\n",
    "                .with_max_cache_size(200)\n",
    "                .with_profiling(true)\n",
    "                .with_auto_fallback(true);\n",
    "            \n",
    "            println!(\"⚙️ 백엔드 구성: {:?}\", config);\n",
    "            \n",
    "            // CoreML 백엔드 생성\n",
    "            match CoreMLBackend::new(device, config) {\n",
    "                Ok(backend) => {\n",
    "                    println!(\"🚀 CoreML 백엔드 초기화됨\");\n",
    "                    \n",
    "                    // 통계 가져오기\n",
    "                    let stats = backend.get_statistics();\n",
    "                    println!(\"📊 백엔드 통계:\");\n",
    "                    println!(\"  총 연산 수: {}\", stats.total_operations);\n",
    "                    println!(\"  캐시 히트: {}\", stats.cache_hits);\n",
    "                    println!(\"  캐시 미스: {}\", stats.cache_misses);\n",
    "                    println!(\"  폴백 연산: {}\", stats.fallback_operations);\n",
    "                    \n",
    "                    // CoreML에서 텐서 생성\n",
    "                    let tensor_a = Tensor::randn(&[64, 64]).to_device(&backend);\n",
    "                    let tensor_b = Tensor::randn(&[64, 64]).to_device(&backend);\n",
    "                    \n",
    "                    println!(\"📐 CoreML 디바이스에서 텐서 생성됨\");\n",
    "                    \n",
    "                    // 행렬 곱셈 연산\n",
    "                    let start = std::time::Instant::now();\n",
    "                    let result = tensor_a.matmul(&tensor_b);\n",
    "                    let duration = start.elapsed();\n",
    "                    \n",
    "                    println!(\"✅ 행렬 곱셈 완료\");\n",
    "                    println!(\"⏱️ 실행 시간: {:?}\", duration);\n",
    "                    println!(\"🎯 결과 형태: {:?}\", result.shape());\n",
    "                    \n",
    "                    // 캐시 정리\n",
    "                    backend.cleanup_cache();\n",
    "                    println!(\"🧹 캐시 정리됨\");\n",
    "                }\n",
    "                Err(e) => println!(\"❌ CoreML 백엔드 생성 오류: {:?}\", e),\n",
    "            }\n",
    "        }\n",
    "        Err(e) => {\n",
    "            println!(\"❌ CoreML 디바이스 생성 오류: {:?}\", e);\n",
    "            println!(\"이 시스템에서 CoreML을 사용할 수 없을 수 있습니다\");\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"⚠️ CoreML 연산 건너뜀 - 기능이 활성화되지 않음\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use std::time::Instant;\n",
    "\n",
    "fn benchmark_operations() {\n",
    "    let sizes = vec![(64, 64), (128, 128), (256, 256), (512, 512)];\n",
    "    \n",
    "    println!(\"🏁 연산 벤치마킹:\");\n",
    "    println!(\"크기\\t\\tCPU (ms)\\t선호 디바이스\");\n",
    "    println!(\"-\" * 40);\n",
    "    \n",
    "    for (rows, cols) in sizes {\n",
    "        // CPU에서 텐서 생성\n",
    "        let a = Tensor::randn(&[rows, cols]);\n",
    "        let b = Tensor::randn(&[cols, rows]);\n",
    "        \n",
    "        // CPU 시간 측정\n",
    "        let start = Instant::now();\n",
    "        let _result = a.matmul(&b);\n",
    "        let cpu_duration = start.elapsed();\n",
    "        \n",
    "        // 선호 디바이스 결정\n",
    "        let preferred_device = if rows * cols < 1000 {\n",
    "            \"CPU\"\n",
    "        } else if rows * cols < 10000 {\n",
    "            \"Metal GPU\"\n",
    "        } else {\n",
    "            \"CoreML\"\n",
    "        };\n",
    "        \n",
    "        println!(\"{}x{}\\t\\t{:.2}\\t\\t{}\", \n",
    "                rows, cols, \n",
    "                cpu_duration.as_millis() as f64, \n",
    "                preferred_device);\n",
    "    }\n",
    "}\n",
    "\n",
    "benchmark_operations();\n",
    "println!(\"\\n📝 참고: 디바이스 선택은 텐서 크기와 가용성을 기반으로 합니다\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스마트 디바이스 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    use rustorch::backends::{DeviceManager, DeviceSelector};\n",
    "    \n",
    "    fn demonstrate_device_selection() {\n",
    "        println!(\"🎯 스마트 디바이스 선택 시연:\");\n",
    "        \n",
    "        let operations = vec![\n",
    "            (\"작은 곱셈\", vec![16, 16], \"CPU\"),\n",
    "            (\"2D 컨볼루션\", vec![32, 3, 224, 224], \"CoreML\"),\n",
    "            (\"행렬 변환\", vec![128, 128], \"Metal GPU\"),\n",
    "            (\"큰 배치 연산\", vec![512, 512], \"CoreML\"),\n",
    "            (\"벡터 계산\", vec![1000], \"CPU\"),\n",
    "        ];\n",
    "        \n",
    "        for (name, shape, preferred) in operations {\n",
    "            println!(\"  {:<25} {:?} -> {}\", name, shape, preferred);\n",
    "            \n",
    "            // 규칙 기반 선택 시뮬레이션\n",
    "            let tensor_size: usize = shape.iter().product();\n",
    "            let selected_device = match tensor_size {\n",
    "                size if size < 1000 => DeviceType::Cpu,\n",
    "                size if size < 50000 => DeviceType::MetalGpu,\n",
    "                _ => {\n",
    "                    if DeviceManager::is_coreml_available() {\n",
    "                        DeviceType::CoreML\n",
    "                    } else {\n",
    "                        DeviceType::MetalGpu\n",
    "                    }\n",
    "                }\n",
    "            };\n",
    "            \n",
    "            println!(\"    -> 선택된 디바이스: {:?}\", selected_device);\n",
    "        }\n",
    "        \n",
    "        println!(\"\\n📝 선택 논리:\");\n",
    "        println!(\"  • < 1K 요소: CPU (최소 오버헤드)\");\n",
    "        println!(\"  • 1K-50K 요소: Metal GPU (균형)\");\n",
    "        println!(\"  • > 50K 요소: CoreML (최적화) 또는 Metal GPU (폴백)\");\n",
    "    }\n",
    "    \n",
    "    demonstrate_device_selection();\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"⚠️ 디바이스 선택 시연 건너뜀 - CoreML 기능 사용 불가\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 고급 예제: 신경망 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn simulate_neural_layer() {\n",
    "    println!(\"🧠 신경망 레이어 시뮬레이션:\");\n",
    "    \n",
    "    // 레이어 구성\n",
    "    let batch_size = 32;\n",
    "    let input_dim = 784;   // 28x28 MNIST\n",
    "    let hidden_dim = 256;\n",
    "    let output_dim = 10;   // 10개 클래스\n",
    "    \n",
    "    println!(\"📊 구성:\");\n",
    "    println!(\"  배치 크기: {}\", batch_size);\n",
    "    println!(\"  입력 차원: {}\", input_dim);\n",
    "    println!(\"  은닉 차원: {}\", hidden_dim);\n",
    "    println!(\"  출력 차원: {}\", output_dim);\n",
    "    \n",
    "    // 텐서 생성\n",
    "    let input = Tensor::randn(&[batch_size, input_dim]);\n",
    "    let weight1 = Tensor::randn(&[input_dim, hidden_dim]);\n",
    "    let weight2 = Tensor::randn(&[hidden_dim, output_dim]);\n",
    "    \n",
    "    println!(\"\\n🔄 순전파:\");\n",
    "    \n",
    "    // 순전파 시뮬레이션\n",
    "    let start = Instant::now();\n",
    "    \n",
    "    // 레이어 1: 입력 -> 은닉\n",
    "    let hidden = input.matmul(&weight1);\n",
    "    println!(\"  ✅ 입력 -> 은닉: {:?}\", hidden.shape());\n",
    "    \n",
    "    // ReLU 활성화 함수 (시뮬레이션)\n",
    "    let activated = hidden.relu();\n",
    "    println!(\"  ✅ ReLU 활성화 적용됨\");\n",
    "    \n",
    "    // 레이어 2: 은닉 -> 출력\n",
    "    let output = activated.matmul(&weight2);\n",
    "    println!(\"  ✅ 은닉 -> 출력: {:?}\", output.shape());\n",
    "    \n",
    "    let total_time = start.elapsed();\n",
    "    \n",
    "    println!(\"\\n⏱️ 총 순전파 시간: {:?}\", total_time);\n",
    "    println!(\"🚀 예상 성능: {:.0} 샘플/초\", \n",
    "             (batch_size as f64) / total_time.as_secs_f64());\n",
    "    \n",
    "    println!(\"\\n📝 실제 구현에서는:\");\n",
    "    println!(\"  • 큰 행렬은 CoreML 사용\");\n",
    "    println!(\"  • 활성화는 Metal GPU 사용\");\n",
    "    println!(\"  • 작은 연산은 CPU에 유지\");\n",
    "}\n",
    "\n",
    "simulate_neural_layer();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오류 처리 및 폴백"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn demonstrate_fallback_behavior() {\n",
    "    println!(\"🔄 폴백 동작 시연:\");\n",
    "    \n",
    "    // CoreML에서 실패할 수 있는 연산 시뮬레이션\n",
    "    let complex_tensor = Tensor::randn(&[100, 100]);\n",
    "    \n",
    "    println!(\"🎯 CoreML 연산 시도 중...\");\n",
    "    \n",
    "    // 실제 구현에서는 다음과 같습니다:\n",
    "    // match tensor.to_coreml() {\n",
    "    //     Ok(coreml_tensor) => { /* CoreML 사용 */ },\n",
    "    //     Err(_) => { /* Metal/CPU로 폴백 */ }\n",
    "    // }\n",
    "    \n",
    "    let use_coreml = false; // CoreML 실패 시뮬레이션\n",
    "    \n",
    "    if use_coreml {\n",
    "        println!(\"✅ CoreML 연산 성공\");\n",
    "    } else {\n",
    "        println!(\"⚠️ CoreML 사용 불가, 폴백 사용\");\n",
    "        \n",
    "        // Metal GPU로 폴백\n",
    "        let start = Instant::now();\n",
    "        let result = complex_tensor.matmul(&complex_tensor);\n",
    "        let fallback_time = start.elapsed();\n",
    "        \n",
    "        println!(\"✅ 폴백 연산 완료\");\n",
    "        println!(\"⏱️ 폴백 시간: {:?}\", fallback_time);\n",
    "        println!(\"📐 결과 형태: {:?}\", result.shape());\n",
    "    }\n",
    "    \n",
    "    println!(\"\\n📝 폴백 전략:\");\n",
    "    println!(\"  1. CoreML 시도 (최고 성능)\");\n",
    "    println!(\"  2. Metal GPU로 폴백 (양호한 호환성)\");\n",
    "    println!(\"  3. CPU 최종 폴백 (최대 호환성)\");\n",
    "}\n",
    "\n",
    "demonstrate_fallback_behavior();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약 및 다음 단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println!(\"📋 RusTorch CoreML 통합 요약 (Rust 커널):\");\n",
    "println!();\n",
    "println!(\"✅ 시연된 기능:\");\n",
    "println!(\"  • CoreML 가용성 확인\");\n",
    "println!(\"  • 디바이스 생성 및 관리\");\n",
    "println!(\"  • 백엔드 구성\");\n",
    "println!(\"  • 기본 텐서 연산\");\n",
    "println!(\"  • 성능 벤치마킹\");\n",
    "println!(\"  • 스마트 디바이스 선택\");\n",
    "println!(\"  • 폴백 동작\");\n",
    "println!();\n",
    "println!(\"🚧 개발 영역:\");\n",
    "println!(\"  • 완전한 CoreML 연산 구현\");\n",
    "println!(\"  • 메모리 전송 최적화\");\n",
    "println!(\"  • 확장된 텐서 타입 지원\");\n",
    "println!(\"  • 상세한 성능 프로파일링\");\n",
    "println!(\"  • ML 파이프라인과의 통합\");\n",
    "println!();\n",
    "println!(\"🎯 권장 다음 단계:\");\n",
    "println!(\"  1. 사전 훈련된 CoreML 모델로 테스트\");\n",
    "println!(\"  2. 다른 백엔드와 성능 비교\");\n",
    "println!(\"  3. 특정 사용 사례에 최적화\");\n",
    "println!(\"  4. 프로덕션 애플리케이션에 배포\");\n",
    "println!();\n",
    "\n",
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    if rustorch::backends::DeviceManager::is_coreml_available() {\n",
    "        println!(\"🎉 모든 CoreML 기능을 테스트할 수 있습니다!\");\n",
    "    } else {\n",
    "        println!(\"⚠️ CoreML이 활성화되었지만 이 시스템에서는 사용할 수 없습니다\");\n",
    "    }\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"⚠️ 완전한 기능을 위해 CoreML 기능으로 빌드하세요\");\n",
    "}\n",
    "\n",
    "println!(\"\\n🚀 RusTorch로 고급 CoreML 개발 준비 완료!\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygments_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}