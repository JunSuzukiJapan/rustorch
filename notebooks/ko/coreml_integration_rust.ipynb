{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RusTorch CoreML í†µí•© - Rust ì»¤ë„\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ RusTorchì™€ CoreMLì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "Rust ì»¤ë„ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í•„ìˆ˜ ì˜ì¡´ì„± ë° ê¸°ëŠ¥ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// RusTorch ê¸°ë³¸ ì‚¬ìš©\n",
    "extern crate rustorch;\n",
    "\n",
    "use rustorch::tensor::Tensor;\n",
    "use rustorch::gpu::DeviceType;\n",
    "\n",
    "println!(\"RusTorch ë²„ì „: {}\", env!(\"CARGO_PKG_VERSION\"));\n",
    "println!(\"Rust ë²„ì „: {}\", env!(\"RUSTC_VERSION\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreML ê°€ìš©ì„± í™•ì¸\n",
    "\n",
    "í˜„ì¬ ì‹œìŠ¤í…œì—ì„œ CoreMLì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    use rustorch::backends::DeviceManager;\n",
    "    \n",
    "    let coreml_available = DeviceManager::is_coreml_available();\n",
    "    println!(\"CoreML ì‚¬ìš© ê°€ëŠ¥: {}\", coreml_available);\n",
    "    \n",
    "    if coreml_available {\n",
    "        println!(\"ğŸ‰ CoreMLì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\");\n",
    "        println!(\"í”Œë«í¼: macOS\");\n",
    "        \n",
    "        // ë””ë°”ì´ìŠ¤ ì •ë³´ í‘œì‹œ\n",
    "        use rustorch::gpu::coreml::device_cache::DeviceCache;\n",
    "        let cache = DeviceCache::global();\n",
    "        cache.warmup();\n",
    "        \n",
    "        let stats = cache.get_stats();\n",
    "        println!(\"ìºì‹œ í†µê³„: {:?}\", stats);\n",
    "    } else {\n",
    "        println!(\"âš ï¸ CoreMLì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\");\n",
    "        println!(\"CPU ë˜ëŠ” ë‹¤ë¥¸ GPU ë°±ì—”ë“œë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”\");\n",
    "    }\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"âŒ CoreML ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤\");\n",
    "    println!(\"--features coremlë¡œ ë¹Œë“œí•´ì£¼ì„¸ìš”\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê¸°ë³¸ í…ì„œ ì—°ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// ê¸°ë³¸ í…ì„œ ìƒì„±\n",
    "let a = Tensor::zeros(&[2, 3]);\n",
    "let b = Tensor::ones(&[3, 2]);\n",
    "\n",
    "println!(\"í…ì„œ A í˜•íƒœ: {:?}\", a.shape());\n",
    "println!(\"í…ì„œ B í˜•íƒœ: {:?}\", b.shape());\n",
    "\n",
    "// ê¸°ë³¸ í–‰ë ¬ ê³±ì…ˆ\n",
    "let result = a.matmul(&b);\n",
    "println!(\"ê²°ê³¼ í˜•íƒœ: {:?}\", result.shape());\n",
    "println!(\"ê¸°ë³¸ í…ì„œ ì—°ì‚° ì™„ë£Œ\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreML ë””ë°”ì´ìŠ¤ ì—°ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    use rustorch::gpu::coreml::{CoreMLDevice, CoreMLBackend};\n",
    "    use rustorch::backends::BackendConfig;\n",
    "    \n",
    "    // CoreML ë””ë°”ì´ìŠ¤ ìƒì„± ì‹œë„\n",
    "    match CoreMLDevice::new(0) {\n",
    "        Ok(device) => {\n",
    "            println!(\"ğŸ–¥ï¸ CoreML ë””ë°”ì´ìŠ¤ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë¨\");\n",
    "            println!(\"ë””ë°”ì´ìŠ¤ ID: {}\", device.id());\n",
    "            println!(\"ì‚¬ìš© ê°€ëŠ¥: {}\", device.is_available());\n",
    "            println!(\"ë©”ëª¨ë¦¬ ì œí•œ: {} MB\", device.memory_limit() / (1024 * 1024));\n",
    "            \n",
    "            // ë°±ì—”ë“œ êµ¬ì„± ìƒì„±\n",
    "            let config = BackendConfig::new()\n",
    "                .with_caching(true)\n",
    "                .with_max_cache_size(200)\n",
    "                .with_profiling(true)\n",
    "                .with_auto_fallback(true);\n",
    "            \n",
    "            println!(\"âš™ï¸ ë°±ì—”ë“œ êµ¬ì„±: {:?}\", config);\n",
    "            \n",
    "            // CoreML ë°±ì—”ë“œ ìƒì„±\n",
    "            match CoreMLBackend::new(device, config) {\n",
    "                Ok(backend) => {\n",
    "                    println!(\"ğŸš€ CoreML ë°±ì—”ë“œ ì´ˆê¸°í™”ë¨\");\n",
    "                    \n",
    "                    // í†µê³„ ê°€ì ¸ì˜¤ê¸°\n",
    "                    let stats = backend.get_statistics();\n",
    "                    println!(\"ğŸ“Š ë°±ì—”ë“œ í†µê³„:\");\n",
    "                    println!(\"  ì´ ì—°ì‚° ìˆ˜: {}\", stats.total_operations);\n",
    "                    println!(\"  ìºì‹œ íˆíŠ¸: {}\", stats.cache_hits);\n",
    "                    println!(\"  ìºì‹œ ë¯¸ìŠ¤: {}\", stats.cache_misses);\n",
    "                    println!(\"  í´ë°± ì—°ì‚°: {}\", stats.fallback_operations);\n",
    "                    \n",
    "                    // CoreMLì—ì„œ í…ì„œ ìƒì„±\n",
    "                    let tensor_a = Tensor::randn(&[64, 64]).to_device(&backend);\n",
    "                    let tensor_b = Tensor::randn(&[64, 64]).to_device(&backend);\n",
    "                    \n",
    "                    println!(\"ğŸ“ CoreML ë””ë°”ì´ìŠ¤ì—ì„œ í…ì„œ ìƒì„±ë¨\");\n",
    "                    \n",
    "                    // í–‰ë ¬ ê³±ì…ˆ ì—°ì‚°\n",
    "                    let start = std::time::Instant::now();\n",
    "                    let result = tensor_a.matmul(&tensor_b);\n",
    "                    let duration = start.elapsed();\n",
    "                    \n",
    "                    println!(\"âœ… í–‰ë ¬ ê³±ì…ˆ ì™„ë£Œ\");\n",
    "                    println!(\"â±ï¸ ì‹¤í–‰ ì‹œê°„: {:?}\", duration);\n",
    "                    println!(\"ğŸ¯ ê²°ê³¼ í˜•íƒœ: {:?}\", result.shape());\n",
    "                    \n",
    "                    // ìºì‹œ ì •ë¦¬\n",
    "                    backend.cleanup_cache();\n",
    "                    println!(\"ğŸ§¹ ìºì‹œ ì •ë¦¬ë¨\");\n",
    "                }\n",
    "                Err(e) => println!(\"âŒ CoreML ë°±ì—”ë“œ ìƒì„± ì˜¤ë¥˜: {:?}\", e),\n",
    "            }\n",
    "        }\n",
    "        Err(e) => {\n",
    "            println!(\"âŒ CoreML ë””ë°”ì´ìŠ¤ ìƒì„± ì˜¤ë¥˜: {:?}\", e);\n",
    "            println!(\"ì´ ì‹œìŠ¤í…œì—ì„œ CoreMLì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤\");\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"âš ï¸ CoreML ì—°ì‚° ê±´ë„ˆëœ€ - ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì§€ ì•ŠìŒ\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„±ëŠ¥ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use std::time::Instant;\n",
    "\n",
    "fn benchmark_operations() {\n",
    "    let sizes = vec![(64, 64), (128, 128), (256, 256), (512, 512)];\n",
    "    \n",
    "    println!(\"ğŸ ì—°ì‚° ë²¤ì¹˜ë§ˆí‚¹:\");\n",
    "    println!(\"í¬ê¸°\\t\\tCPU (ms)\\tì„ í˜¸ ë””ë°”ì´ìŠ¤\");\n",
    "    println!(\"-\" * 40);\n",
    "    \n",
    "    for (rows, cols) in sizes {\n",
    "        // CPUì—ì„œ í…ì„œ ìƒì„±\n",
    "        let a = Tensor::randn(&[rows, cols]);\n",
    "        let b = Tensor::randn(&[cols, rows]);\n",
    "        \n",
    "        // CPU ì‹œê°„ ì¸¡ì •\n",
    "        let start = Instant::now();\n",
    "        let _result = a.matmul(&b);\n",
    "        let cpu_duration = start.elapsed();\n",
    "        \n",
    "        // ì„ í˜¸ ë””ë°”ì´ìŠ¤ ê²°ì •\n",
    "        let preferred_device = if rows * cols < 1000 {\n",
    "            \"CPU\"\n",
    "        } else if rows * cols < 10000 {\n",
    "            \"Metal GPU\"\n",
    "        } else {\n",
    "            \"CoreML\"\n",
    "        };\n",
    "        \n",
    "        println!(\"{}x{}\\t\\t{:.2}\\t\\t{}\", \n",
    "                rows, cols, \n",
    "                cpu_duration.as_millis() as f64, \n",
    "                preferred_device);\n",
    "    }\n",
    "}\n",
    "\n",
    "benchmark_operations();\n",
    "println!(\"\\nğŸ“ ì°¸ê³ : ë””ë°”ì´ìŠ¤ ì„ íƒì€ í…ì„œ í¬ê¸°ì™€ ê°€ìš©ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ìŠ¤ë§ˆíŠ¸ ë””ë°”ì´ìŠ¤ ì„ íƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    use rustorch::backends::{DeviceManager, DeviceSelector};\n",
    "    \n",
    "    fn demonstrate_device_selection() {\n",
    "        println!(\"ğŸ¯ ìŠ¤ë§ˆíŠ¸ ë””ë°”ì´ìŠ¤ ì„ íƒ ì‹œì—°:\");\n",
    "        \n",
    "        let operations = vec![\n",
    "            (\"ì‘ì€ ê³±ì…ˆ\", vec![16, 16], \"CPU\"),\n",
    "            (\"2D ì»¨ë³¼ë£¨ì…˜\", vec![32, 3, 224, 224], \"CoreML\"),\n",
    "            (\"í–‰ë ¬ ë³€í™˜\", vec![128, 128], \"Metal GPU\"),\n",
    "            (\"í° ë°°ì¹˜ ì—°ì‚°\", vec![512, 512], \"CoreML\"),\n",
    "            (\"ë²¡í„° ê³„ì‚°\", vec![1000], \"CPU\"),\n",
    "        ];\n",
    "        \n",
    "        for (name, shape, preferred) in operations {\n",
    "            println!(\"  {:<25} {:?} -> {}\", name, shape, preferred);\n",
    "            \n",
    "            // ê·œì¹™ ê¸°ë°˜ ì„ íƒ ì‹œë®¬ë ˆì´ì…˜\n",
    "            let tensor_size: usize = shape.iter().product();\n",
    "            let selected_device = match tensor_size {\n",
    "                size if size < 1000 => DeviceType::Cpu,\n",
    "                size if size < 50000 => DeviceType::MetalGpu,\n",
    "                _ => {\n",
    "                    if DeviceManager::is_coreml_available() {\n",
    "                        DeviceType::CoreML\n",
    "                    } else {\n",
    "                        DeviceType::MetalGpu\n",
    "                    }\n",
    "                }\n",
    "            };\n",
    "            \n",
    "            println!(\"    -> ì„ íƒëœ ë””ë°”ì´ìŠ¤: {:?}\", selected_device);\n",
    "        }\n",
    "        \n",
    "        println!(\"\\nğŸ“ ì„ íƒ ë…¼ë¦¬:\");\n",
    "        println!(\"  â€¢ < 1K ìš”ì†Œ: CPU (ìµœì†Œ ì˜¤ë²„í—¤ë“œ)\");\n",
    "        println!(\"  â€¢ 1K-50K ìš”ì†Œ: Metal GPU (ê· í˜•)\");\n",
    "        println!(\"  â€¢ > 50K ìš”ì†Œ: CoreML (ìµœì í™”) ë˜ëŠ” Metal GPU (í´ë°±)\");\n",
    "    }\n",
    "    \n",
    "    demonstrate_device_selection();\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"âš ï¸ ë””ë°”ì´ìŠ¤ ì„ íƒ ì‹œì—° ê±´ë„ˆëœ€ - CoreML ê¸°ëŠ¥ ì‚¬ìš© ë¶ˆê°€\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê³ ê¸‰ ì˜ˆì œ: ì‹ ê²½ë§ ë ˆì´ì–´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn simulate_neural_layer() {\n",
    "    println!(\"ğŸ§  ì‹ ê²½ë§ ë ˆì´ì–´ ì‹œë®¬ë ˆì´ì…˜:\");\n",
    "    \n",
    "    // ë ˆì´ì–´ êµ¬ì„±\n",
    "    let batch_size = 32;\n",
    "    let input_dim = 784;   // 28x28 MNIST\n",
    "    let hidden_dim = 256;\n",
    "    let output_dim = 10;   // 10ê°œ í´ë˜ìŠ¤\n",
    "    \n",
    "    println!(\"ğŸ“Š êµ¬ì„±:\");\n",
    "    println!(\"  ë°°ì¹˜ í¬ê¸°: {}\", batch_size);\n",
    "    println!(\"  ì…ë ¥ ì°¨ì›: {}\", input_dim);\n",
    "    println!(\"  ì€ë‹‰ ì°¨ì›: {}\", hidden_dim);\n",
    "    println!(\"  ì¶œë ¥ ì°¨ì›: {}\", output_dim);\n",
    "    \n",
    "    // í…ì„œ ìƒì„±\n",
    "    let input = Tensor::randn(&[batch_size, input_dim]);\n",
    "    let weight1 = Tensor::randn(&[input_dim, hidden_dim]);\n",
    "    let weight2 = Tensor::randn(&[hidden_dim, output_dim]);\n",
    "    \n",
    "    println!(\"\\nğŸ”„ ìˆœì „íŒŒ:\");\n",
    "    \n",
    "    // ìˆœì „íŒŒ ì‹œë®¬ë ˆì´ì…˜\n",
    "    let start = Instant::now();\n",
    "    \n",
    "    // ë ˆì´ì–´ 1: ì…ë ¥ -> ì€ë‹‰\n",
    "    let hidden = input.matmul(&weight1);\n",
    "    println!(\"  âœ… ì…ë ¥ -> ì€ë‹‰: {:?}\", hidden.shape());\n",
    "    \n",
    "    // ReLU í™œì„±í™” í•¨ìˆ˜ (ì‹œë®¬ë ˆì´ì…˜)\n",
    "    let activated = hidden.relu();\n",
    "    println!(\"  âœ… ReLU í™œì„±í™” ì ìš©ë¨\");\n",
    "    \n",
    "    // ë ˆì´ì–´ 2: ì€ë‹‰ -> ì¶œë ¥\n",
    "    let output = activated.matmul(&weight2);\n",
    "    println!(\"  âœ… ì€ë‹‰ -> ì¶œë ¥: {:?}\", output.shape());\n",
    "    \n",
    "    let total_time = start.elapsed();\n",
    "    \n",
    "    println!(\"\\nâ±ï¸ ì´ ìˆœì „íŒŒ ì‹œê°„: {:?}\", total_time);\n",
    "    println!(\"ğŸš€ ì˜ˆìƒ ì„±ëŠ¥: {:.0} ìƒ˜í”Œ/ì´ˆ\", \n",
    "             (batch_size as f64) / total_time.as_secs_f64());\n",
    "    \n",
    "    println!(\"\\nğŸ“ ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ”:\");\n",
    "    println!(\"  â€¢ í° í–‰ë ¬ì€ CoreML ì‚¬ìš©\");\n",
    "    println!(\"  â€¢ í™œì„±í™”ëŠ” Metal GPU ì‚¬ìš©\");\n",
    "    println!(\"  â€¢ ì‘ì€ ì—°ì‚°ì€ CPUì— ìœ ì§€\");\n",
    "}\n",
    "\n",
    "simulate_neural_layer();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì˜¤ë¥˜ ì²˜ë¦¬ ë° í´ë°±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn demonstrate_fallback_behavior() {\n",
    "    println!(\"ğŸ”„ í´ë°± ë™ì‘ ì‹œì—°:\");\n",
    "    \n",
    "    // CoreMLì—ì„œ ì‹¤íŒ¨í•  ìˆ˜ ìˆëŠ” ì—°ì‚° ì‹œë®¬ë ˆì´ì…˜\n",
    "    let complex_tensor = Tensor::randn(&[100, 100]);\n",
    "    \n",
    "    println!(\"ğŸ¯ CoreML ì—°ì‚° ì‹œë„ ì¤‘...\");\n",
    "    \n",
    "    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "    // match tensor.to_coreml() {\n",
    "    //     Ok(coreml_tensor) => { /* CoreML ì‚¬ìš© */ },\n",
    "    //     Err(_) => { /* Metal/CPUë¡œ í´ë°± */ }\n",
    "    // }\n",
    "    \n",
    "    let use_coreml = false; // CoreML ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜\n",
    "    \n",
    "    if use_coreml {\n",
    "        println!(\"âœ… CoreML ì—°ì‚° ì„±ê³µ\");\n",
    "    } else {\n",
    "        println!(\"âš ï¸ CoreML ì‚¬ìš© ë¶ˆê°€, í´ë°± ì‚¬ìš©\");\n",
    "        \n",
    "        // Metal GPUë¡œ í´ë°±\n",
    "        let start = Instant::now();\n",
    "        let result = complex_tensor.matmul(&complex_tensor);\n",
    "        let fallback_time = start.elapsed();\n",
    "        \n",
    "        println!(\"âœ… í´ë°± ì—°ì‚° ì™„ë£Œ\");\n",
    "        println!(\"â±ï¸ í´ë°± ì‹œê°„: {:?}\", fallback_time);\n",
    "        println!(\"ğŸ“ ê²°ê³¼ í˜•íƒœ: {:?}\", result.shape());\n",
    "    }\n",
    "    \n",
    "    println!(\"\\nğŸ“ í´ë°± ì „ëµ:\");\n",
    "    println!(\"  1. CoreML ì‹œë„ (ìµœê³  ì„±ëŠ¥)\");\n",
    "    println!(\"  2. Metal GPUë¡œ í´ë°± (ì–‘í˜¸í•œ í˜¸í™˜ì„±)\");\n",
    "    println!(\"  3. CPU ìµœì¢… í´ë°± (ìµœëŒ€ í˜¸í™˜ì„±)\");\n",
    "}\n",
    "\n",
    "demonstrate_fallback_behavior();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println!(\"ğŸ“‹ RusTorch CoreML í†µí•© ìš”ì•½ (Rust ì»¤ë„):\");\n",
    "println!();\n",
    "println!(\"âœ… ì‹œì—°ëœ ê¸°ëŠ¥:\");\n",
    "println!(\"  â€¢ CoreML ê°€ìš©ì„± í™•ì¸\");\n",
    "println!(\"  â€¢ ë””ë°”ì´ìŠ¤ ìƒì„± ë° ê´€ë¦¬\");\n",
    "println!(\"  â€¢ ë°±ì—”ë“œ êµ¬ì„±\");\n",
    "println!(\"  â€¢ ê¸°ë³¸ í…ì„œ ì—°ì‚°\");\n",
    "println!(\"  â€¢ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹\");\n",
    "println!(\"  â€¢ ìŠ¤ë§ˆíŠ¸ ë””ë°”ì´ìŠ¤ ì„ íƒ\");\n",
    "println!(\"  â€¢ í´ë°± ë™ì‘\");\n",
    "println!();\n",
    "println!(\"ğŸš§ ê°œë°œ ì˜ì—­:\");\n",
    "println!(\"  â€¢ ì™„ì „í•œ CoreML ì—°ì‚° êµ¬í˜„\");\n",
    "println!(\"  â€¢ ë©”ëª¨ë¦¬ ì „ì†¡ ìµœì í™”\");\n",
    "println!(\"  â€¢ í™•ì¥ëœ í…ì„œ íƒ€ì… ì§€ì›\");\n",
    "println!(\"  â€¢ ìƒì„¸í•œ ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§\");\n",
    "println!(\"  â€¢ ML íŒŒì´í”„ë¼ì¸ê³¼ì˜ í†µí•©\");\n",
    "println!();\n",
    "println!(\"ğŸ¯ ê¶Œì¥ ë‹¤ìŒ ë‹¨ê³„:\");\n",
    "println!(\"  1. ì‚¬ì „ í›ˆë ¨ëœ CoreML ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸\");\n",
    "println!(\"  2. ë‹¤ë¥¸ ë°±ì—”ë“œì™€ ì„±ëŠ¥ ë¹„êµ\");\n",
    "println!(\"  3. íŠ¹ì • ì‚¬ìš© ì‚¬ë¡€ì— ìµœì í™”\");\n",
    "println!(\"  4. í”„ë¡œë•ì…˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ë°°í¬\");\n",
    "println!();\n",
    "\n",
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    if rustorch::backends::DeviceManager::is_coreml_available() {\n",
    "        println!(\"ğŸ‰ ëª¨ë“  CoreML ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\");\n",
    "    } else {\n",
    "        println!(\"âš ï¸ CoreMLì´ í™œì„±í™”ë˜ì—ˆì§€ë§Œ ì´ ì‹œìŠ¤í…œì—ì„œëŠ” ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\");\n",
    "    }\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"âš ï¸ ì™„ì „í•œ ê¸°ëŠ¥ì„ ìœ„í•´ CoreML ê¸°ëŠ¥ìœ¼ë¡œ ë¹Œë“œí•˜ì„¸ìš”\");\n",
    "}\n",
    "\n",
    "println!(\"\\nğŸš€ RusTorchë¡œ ê³ ê¸‰ CoreML ê°œë°œ ì¤€ë¹„ ì™„ë£Œ!\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygments_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}