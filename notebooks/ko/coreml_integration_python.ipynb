{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RusTorch CoreML í†µí•© - Python ë°”ì¸ë”©\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ Python ë°”ì¸ë”©ì„ í†µí•´ RusTorchì˜ CoreML ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¤ì • ë° ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RusTorch Python ë°”ì¸ë”© ì„í¬íŠ¸\n",
    "try:\n",
    "    import rustorch\n",
    "    print(f\"âœ… RusTorch ë²„ì „: {rustorch.__version__}\")\n",
    "    print(f\"ğŸ“ ì„¤ëª…: {rustorch.__description__}\")\n",
    "    print(f\"ğŸ‘¥ ì‘ì„±ì: {rustorch.__author__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ RusTorch ì„í¬íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"maturin developë¡œ ë¹Œë“œí•´ì£¼ì„¸ìš”\")\n",
    "    exit(1)\n",
    "\n",
    "import numpy as np\n",
    "import platform\n",
    "\n",
    "print(f\"ğŸ–¥ï¸ í”Œë«í¼: {platform.system()} {platform.release()}\")\n",
    "print(f\"ğŸ Python ë²„ì „: {platform.python_version()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreML ê°€ìš©ì„± í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoreML ê¸°ëŠ¥ í™•ì¸\n",
    "try:\n",
    "    # CoreML ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
    "    coreml_available = rustorch.is_coreml_available()\n",
    "    print(f\"ğŸ CoreML ì‚¬ìš© ê°€ëŠ¥: {coreml_available}\")\n",
    "    \n",
    "    if coreml_available:\n",
    "        print(\"ğŸ‰ CoreMLì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")\n",
    "        \n",
    "        # ë””ë°”ì´ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "        device_info = rustorch.get_coreml_device_info()\n",
    "        print(\"ğŸ“± CoreML ë””ë°”ì´ìŠ¤ ì •ë³´:\")\n",
    "        print(device_info)\n",
    "    else:\n",
    "        print(\"âš ï¸ CoreMLì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "        if platform.system() != \"Darwin\":\n",
    "            print(\"CoreMLì€ macOSì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤\")\n",
    "        else:\n",
    "            print(\"CoreML ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "            \n",
    "except AttributeError:\n",
    "    print(\"âŒ CoreML í•¨ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "    print(\"CoreML ê¸°ëŠ¥ìœ¼ë¡œ ë¹Œë“œë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "    coreml_available = False\n",
    "except Exception as e:\n",
    "    print(f\"âŒ CoreML í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "    coreml_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreML ë””ë°”ì´ìŠ¤ ìƒì„± ë° ì‘ì—…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if coreml_available:\n",
    "    try:\n",
    "        # CoreML ë””ë°”ì´ìŠ¤ ìƒì„±\n",
    "        device = rustorch.CoreMLDevice(device_id=0)\n",
    "        print(f\"ğŸ–¥ï¸ CoreML ë””ë°”ì´ìŠ¤ ìƒì„±ë¨: {device}\")\n",
    "        \n",
    "        # ë””ë°”ì´ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "        print(f\"ğŸ†” ë””ë°”ì´ìŠ¤ ID: {device.device_id()}\")\n",
    "        print(f\"âœ… ì‚¬ìš© ê°€ëŠ¥: {device.is_available()}\")\n",
    "        print(f\"ğŸ’¾ ë©”ëª¨ë¦¬ ì œí•œ: {device.memory_limit()} ë°”ì´íŠ¸\")\n",
    "        print(f\"ğŸ§® ì—°ì‚° ìœ ë‹› ì œí•œ: {device.compute_units_limit()}\")\n",
    "        print(f\"ğŸ“š ëª¨ë¸ ìºì‹œ í¬ê¸°: {device.model_cache_size()}\")\n",
    "        \n",
    "        # ìºì‹œ ì •ë¦¬\n",
    "        device.cleanup_cache()\n",
    "        print(\"ğŸ§¹ ìºì‹œ ì •ë¦¬ë¨\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ CoreML ë””ë°”ì´ìŠ¤ ì‘ì—… ì˜¤ë¥˜: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸ CoreMLì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ë””ë°”ì´ìŠ¤ ì‘ì—…ì„ ê±´ë„ˆëœë‹ˆë‹¤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreML ë°±ì—”ë“œ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if coreml_available:\n",
    "    try:\n",
    "        # CoreML ë°±ì—”ë“œ êµ¬ì„± ìƒì„±\n",
    "        config = rustorch.CoreMLBackendConfig(\n",
    "            enable_caching=True,\n",
    "            max_cache_size=200,\n",
    "            enable_profiling=True,\n",
    "            auto_fallback=True\n",
    "        )\n",
    "        print(f\"âš™ï¸ ë°±ì—”ë“œ êµ¬ì„±: {config}\")\n",
    "        \n",
    "        # êµ¬ì„± ê°’ í™•ì¸ ë° ìˆ˜ì •\n",
    "        print(f\"ğŸ“Š ìºì‹± í™œì„±í™”: {config.enable_caching}\")\n",
    "        print(f\"ğŸ—‚ï¸ ìµœëŒ€ ìºì‹œ í¬ê¸°: {config.max_cache_size}\")\n",
    "        print(f\"ğŸ“ˆ í”„ë¡œíŒŒì¼ë§ í™œì„±í™”: {config.enable_profiling}\")\n",
    "        print(f\"ğŸ”„ ìë™ í´ë°±: {config.auto_fallback}\")\n",
    "        \n",
    "        # êµ¬ì„± ìˆ˜ì •\n",
    "        config.enable_profiling = False\n",
    "        config.max_cache_size = 150\n",
    "        print(f\"\\nğŸ”§ ì—…ë°ì´íŠ¸ëœ êµ¬ì„±: {config}\")\n",
    "        \n",
    "        # CoreML ë°±ì—”ë“œ ìƒì„±\n",
    "        backend = rustorch.CoreMLBackend(config)\n",
    "        print(f\"ğŸš€ CoreML ë°±ì—”ë“œ: {backend}\")\n",
    "        print(f\"âœ… ë°±ì—”ë“œ ì‚¬ìš© ê°€ëŠ¥: {backend.is_available()}\")\n",
    "        \n",
    "        # ë°±ì—”ë“œ í†µê³„ ê°€ì ¸ì˜¤ê¸°\n",
    "        stats = backend.get_stats()\n",
    "        print(f\"ğŸ“Š ë°±ì—”ë“œ í†µê³„: {stats}\")\n",
    "        print(f\"   ì´ ì‘ì—… ìˆ˜: {stats.total_operations}\")\n",
    "        print(f\"   ìºì‹œ íˆíŠ¸: {stats.cache_hits}\")\n",
    "        print(f\"   ìºì‹œ ë¯¸ìŠ¤: {stats.cache_misses}\")\n",
    "        print(f\"   í´ë°± ì‘ì—…: {stats.fallback_operations}\")\n",
    "        print(f\"   ìºì‹œ íˆíŠ¸ìœ¨: {stats.cache_hit_rate():.2%}\")\n",
    "        print(f\"   í´ë°±ìœ¨: {stats.fallback_rate():.2%}\")\n",
    "        print(f\"   í‰ê·  ì‹¤í–‰ ì‹œê°„: {stats.average_execution_time_ms:.2f}ms\")\n",
    "        \n",
    "        # ìºì‹œ ì •ë¦¬\n",
    "        backend.cleanup_cache()\n",
    "        print(\"\\nğŸ§¹ ë°±ì—”ë“œ ìºì‹œ ì •ë¦¬ë¨\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ CoreML ë°±ì—”ë“œ ì‘ì—… ì˜¤ë¥˜: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸ CoreMLì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ë°±ì—”ë“œ ì‘ì—…ì„ ê±´ë„ˆëœë‹ˆë‹¤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê¸°ë³¸ í…ì„œ ì—°ì‚° (CPU)\n",
    "\n",
    "CoreMLê³¼ ë¹„êµí•˜ê¸° ìœ„í•´ ë¨¼ì € CPUì—ì„œ ê¸°ë³¸ ì—°ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # ê¸°ë³¸ í…ì„œ ìƒì„± ë° ì—°ì‚°\n",
    "    print(\"ğŸ§® ê¸°ë³¸ í…ì„œ ì—°ì‚° (CPU)\")\n",
    "    \n",
    "    # NumPy ë°°ì—´ì—ì„œ í…ì„œ ìƒì„± (ë‹¨ìˆœí™”ëœ ì¸í„°í˜ì´ìŠ¤)\n",
    "    data_a = np.random.randn(2, 3).astype(np.float32)\n",
    "    data_b = np.random.randn(3, 2).astype(np.float32)\n",
    "    \n",
    "    print(f\"ğŸ“ í–‰ë ¬ A í˜•íƒœ: {data_a.shape}\")\n",
    "    print(f\"ğŸ“ í–‰ë ¬ B í˜•íƒœ: {data_b.shape}\")\n",
    "    \n",
    "    # NumPyë¡œ í–‰ë ¬ ê³±ì…ˆ (ë¹„êµìš©)\n",
    "    numpy_result = np.matmul(data_a, data_b)\n",
    "    print(f\"âœ… NumPy matmul ê²°ê³¼ í˜•íƒœ: {numpy_result.shape}\")\n",
    "    print(f\"ğŸ“Š ê²°ê³¼ (ì²« ë²ˆì§¸ ìš”ì†Œë“¤): {numpy_result.flatten()[:4]}\")\n",
    "    \n",
    "    print(\"\\nğŸš€ CPU ì—°ì‚° ì™„ë£Œ\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ í…ì„œ ì—°ì‚° ì˜¤ë¥˜: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„±ëŠ¥ ë¹„êµ ì‹œë®¬ë ˆì´ì…˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark_matrix_operations():\n",
    "    \"\"\"ë‹¤ë¥¸ í–‰ë ¬ í¬ê¸°ë¡œ ì„±ëŠ¥ ë¹„êµ\"\"\"\n",
    "    \n",
    "    sizes = [(64, 64), (128, 128), (256, 256), (512, 512)]\n",
    "    \n",
    "    print(\"ğŸ ì„±ëŠ¥ ë¹„êµ:\")\n",
    "    print(\"í¬ê¸°\\t\\tCPU ì‹œê°„ (ms)\\tì˜ˆìƒ CoreML (ms)\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for size in sizes:\n",
    "        # CPU ì‹¤í–‰ ì‹œê°„ ì¸¡ì •\n",
    "        a = np.random.randn(*size).astype(np.float32)\n",
    "        b = np.random.randn(size[1], size[0]).astype(np.float32)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        result = np.matmul(a, b)\n",
    "        cpu_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        # ì˜ˆìƒ CoreML ì‹œê°„ (ê°€ìƒ)\n",
    "        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” CoreML ë°±ì—”ë“œì˜ ì‹¤ì œ ì¸¡ì •ê°’ ì‚¬ìš©\n",
    "        expected_coreml_time = cpu_time * 0.6  # ê°€ì •: CoreMLì´ 40% ë¹ ë¦„\n",
    "        \n",
    "        print(f\"{size[0]}x{size[1]}\\t\\t{cpu_time:.2f}\\t\\t{expected_coreml_time:.2f}\")\n",
    "\n",
    "benchmark_matrix_operations()\n",
    "\n",
    "print(\"\\nğŸ“ ì°¸ê³ : CoreML ì‹œê°„ì€ ê°€ìƒì…ë‹ˆë‹¤. ì‹¤ì œ ê°’ì€ êµ¬ì²´ì ì¸ êµ¬í˜„ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë””ë°”ì´ìŠ¤ ì„ íƒ ì‹œë®¬ë ˆì´ì…˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_device_selection():\n",
    "    \"\"\"ìŠ¤ë§ˆíŠ¸ ë””ë°”ì´ìŠ¤ ì„ íƒ ì‹œë®¬ë ˆì´ì…˜\"\"\"\n",
    "    \n",
    "    operations = [\n",
    "        (\"ì‘ì€ í–‰ë ¬ ê³±ì…ˆ\", (16, 16), \"CPU\"),\n",
    "        (\"ì¤‘ê°„ í–‰ë ¬ ê³±ì…ˆ\", (128, 128), \"Metal GPU\"),\n",
    "        (\"í° í–‰ë ¬ ê³±ì…ˆ\", (512, 512), \"CoreML\" if coreml_available else \"Metal GPU\"),\n",
    "        (\"í™œì„±í™” í•¨ìˆ˜\", (32, 64, 128, 128), \"Metal GPU\"),\n",
    "        (\"ì‘ì€ ì»¨ë³¼ë£¨ì…˜\", (1, 3, 32, 32), \"CPU\"),\n",
    "        (\"í° ì»¨ë³¼ë£¨ì…˜\", (16, 64, 224, 224), \"CoreML\" if coreml_available else \"Metal GPU\"),\n",
    "        (\"ë³µì†Œìˆ˜ ì—°ì‚°\", (128, 128), \"Metal GPU\"),  # CoreML ë¯¸ì§€ì›\n",
    "        (\"í†µê³„ ë¶„í¬\", (1000,), \"CPU\"),  # CoreML ë¯¸ì§€ì›\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ¯ ìŠ¤ë§ˆíŠ¸ ë””ë°”ì´ìŠ¤ ì„ íƒ ì‹œë®¬ë ˆì´ì…˜:\")\n",
    "    print(\"ì—°ì‚°\\t\\t\\tí…ì„œ í˜•íƒœ\\t\\tì„ íƒëœ ë””ë°”ì´ìŠ¤\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for name, shape, device in operations:\n",
    "        shape_str = \"x\".join(map(str, shape))\n",
    "        print(f\"{name:<23}\\t{shape_str:<15}\\t{device}\")\n",
    "    \n",
    "    print(\"\\nğŸ“ ì„ íƒ ë…¼ë¦¬:\")\n",
    "    print(\"  â€¢ ì‘ì€ ì—°ì‚°: CPU (ì˜¤ë²„í—¤ë“œ ë°©ì§€)\")\n",
    "    print(\"  â€¢ ì¤‘ê°„ ì—°ì‚°: Metal GPU (ê· í˜•)\")\n",
    "    print(\"  â€¢ í° ì—°ì‚°: CoreML (ìµœì í™”)\")\n",
    "    print(\"  â€¢ ì§€ì›ë˜ì§€ ì•ŠëŠ” ì—°ì‚°: GPU/CPU í´ë°±\")\n",
    "\n",
    "simulate_device_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì‹¤ìš©ì ì¸ ì˜ˆì œ: ê°„ë‹¨í•œ ì‹ ê²½ë§ ë ˆì´ì–´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_neural_network_layer():\n",
    "    \"\"\"ì‹ ê²½ë§ ë ˆì´ì–´ ì‹œë®¬ë ˆì´ì…˜\"\"\"\n",
    "    \n",
    "    print(\"ğŸ§  ì‹ ê²½ë§ ë ˆì´ì–´ ì‹œë®¬ë ˆì´ì…˜:\")\n",
    "    \n",
    "    # ë°°ì¹˜ í¬ê¸° ë° ë ˆì´ì–´ êµ¬ì„±\n",
    "    batch_size = 32\n",
    "    input_features = 784  # 28x28 MNIST\n",
    "    hidden_features = 256\n",
    "    output_features = 10  # 10ê°œ í´ë˜ìŠ¤\n",
    "    \n",
    "    print(f\"ğŸ“Š ë°°ì¹˜ í¬ê¸°: {batch_size}\")\n",
    "    print(f\"ğŸ”¢ ì…ë ¥ íŠ¹ì„±: {input_features}\")\n",
    "    print(f\"ğŸ§® ì€ë‹‰ íŠ¹ì„±: {hidden_features}\")\n",
    "    print(f\"ğŸ¯ ì¶œë ¥ íŠ¹ì„±: {output_features}\")\n",
    "    \n",
    "    # ìˆœì „íŒŒ ì‹œë®¬ë ˆì´ì…˜\n",
    "    steps = [\n",
    "        (\"ì…ë ¥ â†’ ì€ë‹‰\", f\"({batch_size}, {input_features}) @ ({input_features}, {hidden_features})\", \"CoreML\" if coreml_available else \"Metal\"),\n",
    "        (\"ReLU í™œì„±í™”\", f\"({batch_size}, {hidden_features})\", \"Metal\"),\n",
    "        (\"ì€ë‹‰ â†’ ì¶œë ¥\", f\"({batch_size}, {hidden_features}) @ ({hidden_features}, {output_features})\", \"CoreML\" if coreml_available else \"Metal\"),\n",
    "        (\"Softmax\", f\"({batch_size}, {output_features})\", \"CPU\"),\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nğŸ”„ ìˆœì „íŒŒ ì‹œë®¬ë ˆì´ì…˜:\")\n",
    "    total_time = 0\n",
    "    \n",
    "    for step, shape, device in steps:\n",
    "        # ê°€ìƒ ì‹¤í–‰ ì‹œê°„ (ms)\n",
    "        if device == \"CoreML\":\n",
    "            time_ms = np.random.uniform(0.5, 2.0)\n",
    "        elif device == \"Metal\":\n",
    "            time_ms = np.random.uniform(1.0, 3.0)\n",
    "        else:  # CPU\n",
    "            time_ms = np.random.uniform(0.2, 1.0)\n",
    "        \n",
    "        total_time += time_ms\n",
    "        print(f\"  {step:<15} {shape:<30} {device:<8} {time_ms:.2f}ms\")\n",
    "    \n",
    "    print(f\"\\nâ±ï¸ ì´ ìˆœì „íŒŒ ì‹œê°„: {total_time:.2f}ms\")\n",
    "    print(f\"ğŸš€ ì˜ˆìƒ ì²˜ë¦¬ëŸ‰: {1000/total_time:.0f} ë°°ì¹˜/ì´ˆ\")\n",
    "\n",
    "simulate_neural_network_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“‹ RusTorch CoreML í†µí•© ìš”ì•½:\")\n",
    "print()\n",
    "print(\"âœ… ì™„ë£Œëœ í•­ëª©:\")\n",
    "print(\"  â€¢ Jupyter í™˜ê²½ ì„¤ì •\")\n",
    "print(\"  â€¢ Rust ì»¤ë„ ë° Python ë°”ì¸ë”© ìƒì„±\")\n",
    "print(\"  â€¢ CoreML ê°€ìš©ì„± í™•ì¸\")\n",
    "print(\"  â€¢ ë””ë°”ì´ìŠ¤ ê´€ë¦¬ ë° êµ¬ì„±\")\n",
    "print(\"  â€¢ ë°±ì—”ë“œ í†µê³„ ë° í”„ë¡œíŒŒì¼ë§\")\n",
    "print(\"  â€¢ ìŠ¤ë§ˆíŠ¸ ë””ë°”ì´ìŠ¤ ì„ íƒ\")\n",
    "print()\n",
    "print(\"ğŸš§ í–¥í›„ ê°œë°œ:\")\n",
    "print(\"  â€¢ ì‹¤ì œ CoreML ì—°ì‚° êµ¬í˜„\")\n",
    "print(\"  â€¢ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹\")\n",
    "print(\"  â€¢ ë” ë§ì€ í™œì„±í™” í•¨ìˆ˜ ë° ë ˆì´ì–´ íƒ€ì…\")\n",
    "print(\"  â€¢ ì˜¤ë¥˜ ì²˜ë¦¬ ê°œì„ \")\n",
    "print(\"  â€¢ ë©”ëª¨ë¦¬ ìµœì í™”\")\n",
    "print()\n",
    "print(\"ğŸ¯ ê¶Œì¥ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(\"  1. ì‹¤ì œ CoreML ëª¨ë¸ ë¡œë“œ ë° í…ŒìŠ¤íŠ¸\")\n",
    "print(\"  2. Metalê³¼ CoreML ì„±ëŠ¥ ë¹„êµ\")\n",
    "print(\"  3. ì‹¤ì œ ë”¥ëŸ¬ë‹ ì›Œí¬í”Œë¡œìš°ë¡œ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"  4. í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ í‰ê°€\")\n",
    "\n",
    "if coreml_available:\n",
    "    print(\"\\nğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! CoreMLì„ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©° ëª¨ë“  ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ CoreMLì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì§€ë§Œ ê¸°ë³¸ ê¸°ëŠ¥ì€ ì‘ë™í•©ë‹ˆë‹¤.\")\n",
    "    print(\"   macOSì—ì„œ CoreML ê¸°ëŠ¥ì„ í™œì„±í™”í•˜ì—¬ ë¹Œë“œí•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}