{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🦀 RusTorch Rust 커널 데모\n",
    "\n",
    "이 노트북은 Jupyter에서 Rust로 직접 RusTorch를 사용하는 방법을 보여줍니다!\n",
    "\n",
    "## 특징:\n",
    "- 🔥 **네이티브 Rust 성능**: 제로 오버헤드 추상화\n",
    "- 🧮 **직접 텐서 연산**: 타입 안전한 행렬 계산\n",
    "- 🧠 **신경망 구축**: 프로덕션 준비 딥러닝\n",
    "- ⚡ **GPU 가속**: CUDA/Metal/OpenCL 지원\n",
    "\n",
    "시작해봅시다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 의존성 설정\n",
    "\n",
    "먼저 RusTorch와 ndarray를 의존성으로 추가합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ":dep rustorch = \"0.5.11\"\n",
    ":dep ndarray = \"0.16\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 라이브러리 가져오기\n",
    "\n",
    "array 매크로와 함께 RusTorch와 ndarray를 가져옵니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use rustorch::*;\n",
    "use ndarray::prelude::*;\n",
    "use ndarray::array;\n",
    "use std::time::Instant;\n",
    "\n",
    "println!(\"✅ RusTorch와 ndarray 가져오기 성공!\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔥 기본 텐서 연산\n",
    "\n",
    "텐서를 생성하고 기본 연산을 수행합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// array! 매크로를 사용하여 텐서 생성\n",
    "let a = Tensor::from_array(array![[1.0, 2.0], [3.0, 4.0]]);\n",
    "let b = Tensor::from_array(array![[5.0, 6.0], [7.0, 8.0]]);\n",
    "\n",
    "println!(\"텐서 a: {:?}\", a);\n",
    "println!(\"텐서 b: {:?}\", b);\n",
    "println!(\"a의 모양: {:?}\", a.shape());\n",
    "println!(\"b의 모양: {:?}\", b.shape());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 행렬 곱셈\n",
    "let matmul_result = a.matmul(&b);\n",
    "println!(\"행렬 곱셈 a @ b: {:?}\", matmul_result);\n",
    "\n",
    "// 원소별 연산\n",
    "let sum = &a + &b;\n",
    "println!(\"원소별 덧셈 a + b: {:?}\", sum);\n",
    "\n",
    "let product = &a * &b;\n",
    "println!(\"원소별 곱셈 a * b: {:?}\", product);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 활성화 함수\n",
    "\n",
    "신경망 활성화 함수를 적용합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 양수/음수 값이 혼합된 텐서 생성\n",
    "let input = Tensor::from_array(array![[-2.0, -1.0, 0.0, 1.0, 2.0]]);\n",
    "println!(\"입력: {:?}\", input);\n",
    "\n",
    "// 활성화 함수 적용\n",
    "let relu_result = input.relu();\n",
    "let sigmoid_result = input.sigmoid();\n",
    "let tanh_result = input.tanh();\n",
    "\n",
    "println!(\"ReLU: {:?}\", relu_result);\n",
    "println!(\"Sigmoid: {:?}\", sigmoid_result);\n",
    "println!(\"Tanh: {:?}\", tanh_result);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡ 성능 벤치마크\n",
    "\n",
    "다양한 연산의 성능을 비교합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 행렬 곱셈 벤치마크\n",
    "let size = 256;\n",
    "let a = Tensor::randn(&[size, size]);\n",
    "let b = Tensor::randn(&[size, size]);\n",
    "\n",
    "println!(\"🏁 {}x{} 행렬 곱셈 벤치마크 중...\", size, size);\n",
    "\n",
    "let start = Instant::now();\n",
    "let result = a.matmul(&b);\n",
    "let duration = start.elapsed();\n",
    "\n",
    "println!(\"✅ 완료 시간: {:?}\", duration);\n",
    "println!(\"📊 결과 모양: {:?}\", result.shape());\n",
    "println!(\"📈 처리량: {:.2} GFLOPS\", \n",
    "    (2.0 * size as f64 * size as f64 * size as f64) / (duration.as_secs_f64() * 1e9));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 결론\n",
    "\n",
    "이제 Jupyter에서 직접 Rust 코드를 작성하고 실행할 수 있습니다!\n",
    "\n",
    "**장점:**\n",
    "- 🚀 네이티브 Rust 성능\n",
    "- 🔧 직접 라이브러리 접근\n",
    "- 🎯 타입 안전성\n",
    "- ⚡ 제로 비용 추상화\n",
    "- 🖥️ GPU 가속 지원\n",
    "\n",
    "**다음 단계:**\n",
    "- CUDA/Metal/OpenCL 백엔드로 GPU 가속 탐색\n",
    "- 더 복잡한 신경망 아키텍처 구축\n",
    "- 트랜스포머 모델과 고급 옵티마이저 시도\n",
    "\n",
    "RusTorch와 함께 즐거운 코딩하세요! 🦀⚡"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygment_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}