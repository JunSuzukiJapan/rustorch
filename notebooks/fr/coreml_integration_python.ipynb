{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Int√©gration CoreML de RusTorch - Liaisons Python\n",
    "\n",
    "Ce notebook d√©montre comment utiliser la fonctionnalit√© CoreML de RusTorch via les liaisons Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration et Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les liaisons Python de RusTorch\n",
    "try:\n",
    "    import rustorch\n",
    "    print(f\"‚úÖ Version de RusTorch : {rustorch.__version__}\")\n",
    "    print(f\"üìù Description : {rustorch.__description__}\")\n",
    "    print(f\"üë• Auteur : {rustorch.__author__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå √âchec de l'importation de RusTorch : {e}\")\n",
    "    print(\"Veuillez construire avec maturin develop\")\n",
    "    exit(1)\n",
    "\n",
    "import numpy as np\n",
    "import platform\n",
    "\n",
    "print(f\"üñ•Ô∏è Plateforme : {platform.system()} {platform.release()}\")\n",
    "print(f\"üêç Version Python : {platform.python_version()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V√©rifier la Disponibilit√© de CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier la fonctionnalit√© CoreML\n",
    "try:\n",
    "    # V√©rifier si CoreML est disponible\n",
    "    coreml_available = rustorch.is_coreml_available()\n",
    "    print(f\"üçé CoreML disponible : {coreml_available}\")\n",
    "    \n",
    "    if coreml_available:\n",
    "        print(\"üéâ CoreML est disponible !\")\n",
    "        \n",
    "        # Obtenir les informations du p√©riph√©rique\n",
    "        device_info = rustorch.get_coreml_device_info()\n",
    "        print(\"üì± Informations du p√©riph√©rique CoreML :\")\n",
    "        print(device_info)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è CoreML n'est pas disponible\")\n",
    "        if platform.system() != \"Darwin\":\n",
    "            print(\"CoreML n'est disponible que sur macOS\")\n",
    "        else:\n",
    "            print(\"Les fonctionnalit√©s CoreML peuvent ne pas √™tre activ√©es\")\n",
    "            \n",
    "except AttributeError:\n",
    "    print(\"‚ùå Fonctions CoreML non trouv√©es\")\n",
    "    print(\"Peut ne pas √™tre construit avec les fonctionnalit√©s CoreML\")\n",
    "    coreml_available = False\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur lors de la v√©rification de CoreML : {e}\")\n",
    "    coreml_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cr√©ation de P√©riph√©rique CoreML et Op√©rations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if coreml_available:\n",
    "    try:\n",
    "        # Cr√©er un p√©riph√©rique CoreML\n",
    "        device = rustorch.CoreMLDevice(device_id=0)\n",
    "        print(f\"üñ•Ô∏è P√©riph√©rique CoreML cr√©√© : {device}\")\n",
    "        \n",
    "        # Obtenir les informations du p√©riph√©rique\n",
    "        print(f\"üÜî ID du p√©riph√©rique : {device.device_id()}\")\n",
    "        print(f\"‚úÖ Disponible : {device.is_available()}\")\n",
    "        print(f\"üíæ Limite de m√©moire : {device.memory_limit()} octets\")\n",
    "        print(f\"üßÆ Limite des unit√©s de calcul : {device.compute_units_limit()}\")\n",
    "        print(f\"üìö Taille du cache du mod√®le : {device.model_cache_size()}\")\n",
    "        \n",
    "        # Nettoyage du cache\n",
    "        device.cleanup_cache()\n",
    "        print(\"üßπ Cache nettoy√©\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur d'op√©ration du p√©riph√©rique CoreML : {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Saut des op√©rations du p√©riph√©rique car CoreML n'est pas disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration du Backend CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if coreml_available:\n",
    "    try:\n",
    "        # Cr√©er la configuration du backend CoreML\n",
    "        config = rustorch.CoreMLBackendConfig(\n",
    "            enable_caching=True,\n",
    "            max_cache_size=200,\n",
    "            enable_profiling=True,\n",
    "            auto_fallback=True\n",
    "        )\n",
    "        print(f\"‚öôÔ∏è Configuration du backend : {config}\")\n",
    "        \n",
    "        # V√©rifier et modifier les valeurs de configuration\n",
    "        print(f\"üìä Activer la mise en cache : {config.enable_caching}\")\n",
    "        print(f\"üóÇÔ∏è Taille maximale du cache : {config.max_cache_size}\")\n",
    "        print(f\"üìà Activer le profilage : {config.enable_profiling}\")\n",
    "        print(f\"üîÑ Basculement automatique : {config.auto_fallback}\")\n",
    "        \n",
    "        # Modifier la configuration\n",
    "        config.enable_profiling = False\n",
    "        config.max_cache_size = 150\n",
    "        print(f\"\\nüîß Configuration mise √† jour : {config}\")\n",
    "        \n",
    "        # Cr√©er le backend CoreML\n",
    "        backend = rustorch.CoreMLBackend(config)\n",
    "        print(f\"üöÄ Backend CoreML : {backend}\")\n",
    "        print(f\"‚úÖ Backend disponible : {backend.is_available()}\")\n",
    "        \n",
    "        # Obtenir les statistiques du backend\n",
    "        stats = backend.get_stats()\n",
    "        print(f\"üìä Statistiques du backend : {stats}\")\n",
    "        print(f\"   Op√©rations totales : {stats.total_operations}\")\n",
    "        print(f\"   Succ√®s du cache : {stats.cache_hits}\")\n",
    "        print(f\"   √âchecs du cache : {stats.cache_misses}\")\n",
    "        print(f\"   Op√©rations de basculement : {stats.fallback_operations}\")\n",
    "        print(f\"   Taux de succ√®s du cache : {stats.cache_hit_rate():.2%}\")\n",
    "        print(f\"   Taux de basculement : {stats.fallback_rate():.2%}\")\n",
    "        print(f\"   Temps d'ex√©cution moyen : {stats.average_execution_time_ms:.2f}ms\")\n",
    "        \n",
    "        # Nettoyage du cache\n",
    "        backend.cleanup_cache()\n",
    "        print(\"\\nüßπ Cache du backend nettoy√©\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur d'op√©ration du backend CoreML : {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Saut des op√©rations du backend car CoreML n'est pas disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Op√©rations de Tenseurs de Base (CPU)\n",
    "\n",
    "Pour comparer avec CoreML, effectuons d'abord des op√©rations de base sur CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Cr√©ation et op√©rations de tenseurs de base\n",
    "    print(\"üßÆ Op√©rations de tenseurs de base (CPU)\")\n",
    "    \n",
    "    # Cr√©er des tenseurs √† partir de tableaux NumPy (interface simplifi√©e)\n",
    "    data_a = np.random.randn(2, 3).astype(np.float32)\n",
    "    data_b = np.random.randn(3, 2).astype(np.float32)\n",
    "    \n",
    "    print(f\"üìê Forme de la matrice A : {data_a.shape}\")\n",
    "    print(f\"üìê Forme de la matrice B : {data_b.shape}\")\n",
    "    \n",
    "    # Multiplication de matrices avec NumPy (pour comparaison)\n",
    "    numpy_result = np.matmul(data_a, data_b)\n",
    "    print(f\"‚úÖ Forme du r√©sultat matmul NumPy : {numpy_result.shape}\")\n",
    "    print(f\"üìä R√©sultat (premiers √©l√©ments) : {numpy_result.flatten()[:4]}\")\n",
    "    \n",
    "    print(\"\\nüöÄ Op√©rations CPU termin√©es\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur d'op√©ration de tenseur : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation de Comparaison de Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark_matrix_operations():\n",
    "    \"\"\"Comparer les performances avec diff√©rentes tailles de matrices\"\"\"\n",
    "    \n",
    "    sizes = [(64, 64), (128, 128), (256, 256), (512, 512)]\n",
    "    \n",
    "    print(\"üèÅ Comparaison de performance :\")\n",
    "    print(\"Taille\\t\\tTemps CPU (ms)\\tCoreML Attendu (ms)\")\n",
    "    print(\"-\" * 56)\n",
    "    \n",
    "    for size in sizes:\n",
    "        # Mesurer le temps d'ex√©cution CPU\n",
    "        a = np.random.randn(*size).astype(np.float32)\n",
    "        b = np.random.randn(size[1], size[0]).astype(np.float32)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        result = np.matmul(a, b)\n",
    "        cpu_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        # Temps CoreML attendu (hypoth√©tique)\n",
    "        # Dans l'impl√©mentation r√©elle, utiliser les mesures r√©elles du backend CoreML\n",
    "        expected_coreml_time = cpu_time * 0.6  # Hypoth√®se : CoreML est 40% plus rapide\n",
    "        \n",
    "        print(f\"{size[0]}x{size[1]}\\t\\t{cpu_time:.2f}\\t\\t{expected_coreml_time:.2f}\")\n",
    "\n",
    "benchmark_matrix_operations()\n",
    "\n",
    "print(\"\\nüìù Note : Les temps CoreML sont hypoth√©tiques. Les valeurs r√©elles d√©pendent de l'impl√©mentation sp√©cifique.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation de S√©lection de P√©riph√©rique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_device_selection():\n",
    "    \"\"\"Simuler la s√©lection intelligente de p√©riph√©rique\"\"\"\n",
    "    \n",
    "    operations = [\n",
    "        (\"Multiplication de matrice petite\", (16, 16), \"CPU\"),\n",
    "        (\"Multiplication de matrice moyenne\", (128, 128), \"GPU Metal\"),\n",
    "        (\"Multiplication de matrice grande\", (512, 512), \"CoreML\" if coreml_available else \"GPU Metal\"),\n",
    "        (\"Fonction d'activation\", (32, 64, 128, 128), \"GPU Metal\"),\n",
    "        (\"Petite convolution\", (1, 3, 32, 32), \"CPU\"),\n",
    "        (\"Grande convolution\", (16, 64, 224, 224), \"CoreML\" if coreml_available else \"GPU Metal\"),\n",
    "        (\"Op√©rations de nombres complexes\", (128, 128), \"GPU Metal\"),  # CoreML non support√©\n",
    "        (\"Distribution statistique\", (1000,), \"CPU\"),  # CoreML non support√©\n",
    "    ]\n",
    "    \n",
    "    print(\"üéØ Simulation de s√©lection intelligente de p√©riph√©rique :\")\n",
    "    print(\"Op√©ration\\t\\t\\tForme du Tenseur\\t\\tP√©riph√©rique S√©lectionn√©\")\n",
    "    print(\"-\" * 78)\n",
    "    \n",
    "    for name, shape, device in operations:\n",
    "        shape_str = \"x\".join(map(str, shape))\n",
    "        print(f\"{name:<31}\\t{shape_str:<15}\\t{device}\")\n",
    "    \n",
    "    print(\"\\nüìù Logique de s√©lection :\")\n",
    "    print(\"  ‚Ä¢ Petites op√©rations : CPU (√©viter la surcharge)\")\n",
    "    print(\"  ‚Ä¢ Op√©rations moyennes : GPU Metal (√©quilibr√©)\")\n",
    "    print(\"  ‚Ä¢ Grandes op√©rations : CoreML (optimis√©)\")\n",
    "    print(\"  ‚Ä¢ Op√©rations non support√©es : basculement GPU/CPU\")\n",
    "\n",
    "simulate_device_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple Pratique : Couche Simple de R√©seau Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_neural_network_layer():\n",
    "    \"\"\"Simuler une couche de r√©seau neuronal\"\"\"\n",
    "    \n",
    "    print(\"üß† Simulation de couche de r√©seau neuronal :\")\n",
    "    \n",
    "    # Taille du lot et configuration de la couche\n",
    "    batch_size = 32\n",
    "    input_features = 784  # 28x28 MNIST\n",
    "    hidden_features = 256\n",
    "    output_features = 10  # 10 classes\n",
    "    \n",
    "    print(f\"üìä Taille du lot : {batch_size}\")\n",
    "    print(f\"üî¢ Caract√©ristiques d'entr√©e : {input_features}\")\n",
    "    print(f\"üßÆ Caract√©ristiques cach√©es : {hidden_features}\")\n",
    "    print(f\"üéØ Caract√©ristiques de sortie : {output_features}\")\n",
    "    \n",
    "    # Simulation de passe avant\n",
    "    steps = [\n",
    "        (\"Entr√©e ‚Üí Cach√©e\", f\"({batch_size}, {input_features}) @ ({input_features}, {hidden_features})\", \"CoreML\" if coreml_available else \"Metal\"),\n",
    "        (\"Activation ReLU\", f\"({batch_size}, {hidden_features})\", \"Metal\"),\n",
    "        (\"Cach√©e ‚Üí Sortie\", f\"({batch_size}, {hidden_features}) @ ({hidden_features}, {output_features})\", \"CoreML\" if coreml_available else \"Metal\"),\n",
    "        (\"Softmax\", f\"({batch_size}, {output_features})\", \"CPU\"),\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nüîÑ Simulation de passe avant :\")\n",
    "    total_time = 0\n",
    "    \n",
    "    for step, shape, device in steps:\n",
    "        # Temps d'ex√©cution virtuel (ms)\n",
    "        if device == \"CoreML\":\n",
    "            time_ms = np.random.uniform(0.5, 2.0)\n",
    "        elif device == \"Metal\":\n",
    "            time_ms = np.random.uniform(1.0, 3.0)\n",
    "        else:  # CPU\n",
    "            time_ms = np.random.uniform(0.2, 1.0)\n",
    "        \n",
    "        total_time += time_ms\n",
    "        print(f\"  {step:<15} {shape:<30} {device:<8} {time_ms:.2f}ms\")\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è Temps total de la passe avant : {total_time:.2f}ms\")\n",
    "    print(f\"üöÄ D√©bit estim√© : {1000/total_time:.0f} lots/seconde\")\n",
    "\n",
    "simulate_neural_network_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R√©sum√© et Prochaines √âtapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìã R√©sum√© de l'Int√©gration CoreML RusTorch :\")\n",
    "print()\n",
    "print(\"‚úÖ √âl√©ments termin√©s :\")\n",
    "print(\"  ‚Ä¢ Configuration de l'environnement Jupyter\")\n",
    "print(\"  ‚Ä¢ Cr√©ation du noyau Rust et des liaisons Python\")\n",
    "print(\"  ‚Ä¢ V√©rification de la disponibilit√© CoreML\")\n",
    "print(\"  ‚Ä¢ Gestion des p√©riph√©riques et configuration\")\n",
    "print(\"  ‚Ä¢ Statistiques et profilage du backend\")\n",
    "print(\"  ‚Ä¢ S√©lection intelligente de p√©riph√©rique\")\n",
    "print()\n",
    "print(\"üöß D√©veloppement futur :\")\n",
    "print(\"  ‚Ä¢ Impl√©mentation r√©elle des op√©rations CoreML\")\n",
    "print(\"  ‚Ä¢ √âvaluation comparative des performances\")\n",
    "print(\"  ‚Ä¢ Plus de fonctions d'activation et de types de couches\")\n",
    "print(\"  ‚Ä¢ Am√©liorations de la gestion des erreurs\")\n",
    "print(\"  ‚Ä¢ Optimisation de la m√©moire\")\n",
    "print()\n",
    "print(\"üéØ Prochaines √©tapes recommand√©es :\")\n",
    "print(\"  1. Charger et tester de vrais mod√®les CoreML\")\n",
    "print(\"  2. Comparer les performances Metal et CoreML\")\n",
    "print(\"  3. Tester avec de vrais flux de travail d'apprentissage profond\")\n",
    "print(\"  4. √âvaluer en environnement de production\")\n",
    "\n",
    "if coreml_available:\n",
    "    print(\"\\nüéâ F√©licitations ! CoreML est disponible et toutes les fonctionnalit√©s peuvent √™tre test√©es.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è CoreML n'est pas disponible, mais les fonctionnalit√©s de base fonctionnent.\")\n",
    "    print(\"   Nous recommandons de construire avec les fonctionnalit√©s CoreML activ√©es sur macOS.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}