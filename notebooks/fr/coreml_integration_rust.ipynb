{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Int√©gration CoreML de RusTorch - Noyau Rust\n",
    "\n",
    "Ce notebook d√©montre comment utiliser CoreML avec RusTorch.\n",
    "Il s'ex√©cute sur le noyau Rust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V√©rifier les D√©pendances et Fonctionnalit√©s Requises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Utilisation de base de RusTorch\n",
    "extern crate rustorch;\n",
    "\n",
    "use rustorch::tensor::Tensor;\n",
    "use rustorch::gpu::DeviceType;\n",
    "\n",
    "println!(\"Version de RusTorch : {}\", env!(\"CARGO_PKG_VERSION\"));\n",
    "println!(\"Version de Rust : {}\", env!(\"RUSTC_VERSION\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V√©rifier la Disponibilit√© de CoreML\n",
    "\n",
    "V√©rifier si CoreML est disponible sur le syst√®me actuel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    use rustorch::backends::DeviceManager;\n",
    "    \n",
    "    let coreml_available = DeviceManager::is_coreml_available();\n",
    "    println!(\"CoreML disponible : {}\", coreml_available);\n",
    "    \n",
    "    if coreml_available {\n",
    "        println!(\"üéâ CoreML est disponible !\");\n",
    "        println!(\"Plateforme : macOS\");\n",
    "        \n",
    "        // Afficher les informations du p√©riph√©rique\n",
    "        use rustorch::gpu::coreml::device_cache::DeviceCache;\n",
    "        let cache = DeviceCache::global();\n",
    "        cache.warmup();\n",
    "        \n",
    "        let stats = cache.get_stats();\n",
    "        println!(\"Statistiques du cache : {:?}\", stats);\n",
    "    } else {\n",
    "        println!(\"‚ö†Ô∏è CoreML n'est pas disponible\");\n",
    "        println!(\"Veuillez utiliser le CPU ou d'autres backends GPU\");\n",
    "    }\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"‚ùå Les fonctionnalit√©s CoreML ne sont pas activ√©es\");\n",
    "    println!(\"Veuillez construire avec --features coreml\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Op√©rations de Tenseurs de Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Cr√©er des tenseurs de base\n",
    "let a = Tensor::zeros(&[2, 3]);\n",
    "let b = Tensor::ones(&[3, 2]);\n",
    "\n",
    "println!(\"Forme du tenseur A : {:?}\", a.shape());\n",
    "println!(\"Forme du tenseur B : {:?}\", b.shape());\n",
    "\n",
    "// Multiplication de matrices de base\n",
    "let result = a.matmul(&b);\n",
    "println!(\"Forme du r√©sultat : {:?}\", result.shape());\n",
    "println!(\"Op√©rations de tenseurs de base termin√©es\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Op√©rations avec P√©riph√©rique CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    use rustorch::gpu::coreml::{CoreMLDevice, CoreMLBackend};\n",
    "    use rustorch::backends::BackendConfig;\n",
    "    \n",
    "    // Essayer de cr√©er un p√©riph√©rique CoreML\n",
    "    match CoreMLDevice::new(0) {\n",
    "        Ok(device) => {\n",
    "            println!(\"üñ•Ô∏è P√©riph√©rique CoreML cr√©√© avec succ√®s\");\n",
    "            println!(\"ID du p√©riph√©rique : {}\", device.id());\n",
    "            println!(\"Disponible : {}\", device.is_available());\n",
    "            println!(\"Limite de m√©moire : {} MB\", device.memory_limit() / (1024 * 1024));\n",
    "            \n",
    "            // Cr√©er la configuration du backend\n",
    "            let config = BackendConfig::new()\n",
    "                .with_caching(true)\n",
    "                .with_max_cache_size(200)\n",
    "                .with_profiling(true)\n",
    "                .with_auto_fallback(true);\n",
    "            \n",
    "            println!(\"‚öôÔ∏è Configuration du backend : {:?}\", config);\n",
    "            \n",
    "            // Cr√©er le backend CoreML\n",
    "            match CoreMLBackend::new(device, config) {\n",
    "                Ok(backend) => {\n",
    "                    println!(\"üöÄ Backend CoreML initialis√©\");\n",
    "                    \n",
    "                    // Obtenir les statistiques\n",
    "                    let stats = backend.get_statistics();\n",
    "                    println!(\"üìä Statistiques du backend :\");\n",
    "                    println!(\"  Op√©rations totales : {}\", stats.total_operations);\n",
    "                    println!(\"  Succ√®s du cache : {}\", stats.cache_hits);\n",
    "                    println!(\"  √âchecs du cache : {}\", stats.cache_misses);\n",
    "                    println!(\"  Op√©rations de basculement : {}\", stats.fallback_operations);\n",
    "                    \n",
    "                    // Cr√©er des tenseurs sur CoreML\n",
    "                    let tensor_a = Tensor::randn(&[64, 64]).to_device(&backend);\n",
    "                    let tensor_b = Tensor::randn(&[64, 64]).to_device(&backend);\n",
    "                    \n",
    "                    println!(\"üìê Tenseurs cr√©√©s sur le p√©riph√©rique CoreML\");\n",
    "                    \n",
    "                    // Op√©ration de multiplication de matrices\n",
    "                    let start = std::time::Instant::now();\n",
    "                    let result = tensor_a.matmul(&tensor_b);\n",
    "                    let duration = start.elapsed();\n",
    "                    \n",
    "                    println!(\"‚úÖ Multiplication de matrices termin√©e\");\n",
    "                    println!(\"‚è±Ô∏è Temps d'ex√©cution : {:?}\", duration);\n",
    "                    println!(\"üéØ Forme du r√©sultat : {:?}\", result.shape());\n",
    "                    \n",
    "                    // Nettoyer le cache\n",
    "                    backend.cleanup_cache();\n",
    "                    println!(\"üßπ Cache nettoy√©\");\n",
    "                }\n",
    "                Err(e) => println!(\"‚ùå Erreur lors de la cr√©ation du backend CoreML : {:?}\", e),\n",
    "            }\n",
    "        }\n",
    "        Err(e) => {\n",
    "            println!(\"‚ùå Erreur lors de la cr√©ation du p√©riph√©rique CoreML : {:?}\", e);\n",
    "            println!(\"CoreML peut ne pas √™tre disponible sur ce syst√®me\");\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"‚ö†Ô∏è Saut des op√©rations CoreML - fonctionnalit√©s non activ√©es\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison de Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use std::time::Instant;\n",
    "\n",
    "fn benchmark_operations() {\n",
    "    let sizes = vec![(64, 64), (128, 128), (256, 256), (512, 512)];\n",
    "    \n",
    "    println!(\"üèÅ √âvaluation comparative des op√©rations :\");\n",
    "    println!(\"Taille\\t\\tCPU (ms)\\tP√©riph√©rique Pr√©f√©r√©\");\n",
    "    println!(\"-\" * 48);\n",
    "    \n",
    "    for (rows, cols) in sizes {\n",
    "        // Cr√©er des tenseurs sur CPU\n",
    "        let a = Tensor::randn(&[rows, cols]);\n",
    "        let b = Tensor::randn(&[cols, rows]);\n",
    "        \n",
    "        // Mesurer le temps CPU\n",
    "        let start = Instant::now();\n",
    "        let _result = a.matmul(&b);\n",
    "        let cpu_duration = start.elapsed();\n",
    "        \n",
    "        // D√©terminer le p√©riph√©rique pr√©f√©r√©\n",
    "        let preferred_device = if rows * cols < 1000 {\n",
    "            \"CPU\"\n",
    "        } else if rows * cols < 10000 {\n",
    "            \"GPU Metal\"\n",
    "        } else {\n",
    "            \"CoreML\"\n",
    "        };\n",
    "        \n",
    "        println!(\"{}x{}\\t\\t{:.2}\\t\\t{}\", \n",
    "                rows, cols, \n",
    "                cpu_duration.as_millis() as f64, \n",
    "                preferred_device);\n",
    "    }\n",
    "}\n",
    "\n",
    "benchmark_operations();\n",
    "println!(\"\\nüìù Note : La s√©lection de p√©riph√©rique est bas√©e sur la taille du tenseur et la disponibilit√©\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S√©lection Intelligente de P√©riph√©rique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    use rustorch::backends::{DeviceManager, DeviceSelector};\n",
    "    \n",
    "    fn demonstrate_device_selection() {\n",
    "        println!(\"üéØ D√©monstration de la s√©lection intelligente de p√©riph√©rique :\");\n",
    "        \n",
    "        let operations = vec![\n",
    "            (\"Multiplication petite\", vec![16, 16], \"CPU\"),\n",
    "            (\"Convolution 2D\", vec![32, 3, 224, 224], \"CoreML\"),\n",
    "            (\"Transformation de matrice\", vec![128, 128], \"GPU Metal\"),\n",
    "            (\"Op√©ration de lot importante\", vec![512, 512], \"CoreML\"),\n",
    "            (\"Calcul vectoriel\", vec![1000], \"CPU\"),\n",
    "        ];\n",
    "        \n",
    "        for (name, shape, preferred) in operations {\n",
    "            println!(\"  {:<25} {:?} -> {}\", name, shape, preferred);\n",
    "            \n",
    "            // Simuler la s√©lection bas√©e sur les r√®gles\n",
    "            let tensor_size: usize = shape.iter().product();\n",
    "            let selected_device = match tensor_size {\n",
    "                size if size < 1000 => DeviceType::Cpu,\n",
    "                size if size < 50000 => DeviceType::MetalGpu,\n",
    "                _ => {\n",
    "                    if DeviceManager::is_coreml_available() {\n",
    "                        DeviceType::CoreML\n",
    "                    } else {\n",
    "                        DeviceType::MetalGpu\n",
    "                    }\n",
    "                }\n",
    "            };\n",
    "            \n",
    "            println!(\"    -> P√©riph√©rique s√©lectionn√© : {:?}\", selected_device);\n",
    "        }\n",
    "        \n",
    "        println!(\"\\nüìù Logique de s√©lection :\");\n",
    "        println!(\"  ‚Ä¢ < 1K √©l√©ments : CPU (surcharge minimale)\");\n",
    "        println!(\"  ‚Ä¢ 1K-50K √©l√©ments : GPU Metal (√©quilibr√©)\");\n",
    "        println!(\"  ‚Ä¢ > 50K √©l√©ments : CoreML (optimis√©) ou GPU Metal (basculement)\");\n",
    "    }\n",
    "    \n",
    "    demonstrate_device_selection();\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"‚ö†Ô∏è D√©monstration de s√©lection de p√©riph√©rique saut√©e - fonctionnalit√©s CoreML non disponibles\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple Avanc√© : Couche de R√©seau Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn simulate_neural_layer() {\n",
    "    println!(\"üß† Simulation de couche de r√©seau neuronal :\");\n",
    "    \n",
    "    // Configuration de la couche\n",
    "    let batch_size = 32;\n",
    "    let input_dim = 784;   // 28x28 MNIST\n",
    "    let hidden_dim = 256;\n",
    "    let output_dim = 10;   // 10 classes\n",
    "    \n",
    "    println!(\"üìä Configuration :\");\n",
    "    println!(\"  Taille du lot : {}\", batch_size);\n",
    "    println!(\"  Dimension d'entr√©e : {}\", input_dim);\n",
    "    println!(\"  Dimension cach√©e : {}\", hidden_dim);\n",
    "    println!(\"  Dimension de sortie : {}\", output_dim);\n",
    "    \n",
    "    // Cr√©er des tenseurs\n",
    "    let input = Tensor::randn(&[batch_size, input_dim]);\n",
    "    let weight1 = Tensor::randn(&[input_dim, hidden_dim]);\n",
    "    let weight2 = Tensor::randn(&[hidden_dim, output_dim]);\n",
    "    \n",
    "    println!(\"\\nüîÑ Passe avant :\");\n",
    "    \n",
    "    // Passe avant simul√©e\n",
    "    let start = Instant::now();\n",
    "    \n",
    "    // Couche 1 : entr√©e -> cach√©e\n",
    "    let hidden = input.matmul(&weight1);\n",
    "    println!(\"  ‚úÖ Entr√©e -> Cach√©e : {:?}\", hidden.shape());\n",
    "    \n",
    "    // Fonction d'activation ReLU (simul√©e)\n",
    "    let activated = hidden.relu();\n",
    "    println!(\"  ‚úÖ Activation ReLU appliqu√©e\");\n",
    "    \n",
    "    // Couche 2 : cach√©e -> sortie\n",
    "    let output = activated.matmul(&weight2);\n",
    "    println!(\"  ‚úÖ Cach√©e -> Sortie : {:?}\", output.shape());\n",
    "    \n",
    "    let total_time = start.elapsed();\n",
    "    \n",
    "    println!(\"\\n‚è±Ô∏è Temps total de la passe avant : {:?}\", total_time);\n",
    "    println!(\"üöÄ Performance estim√©e : {:.0} √©chantillons/seconde\", \n",
    "             (batch_size as f64) / total_time.as_secs_f64());\n",
    "    \n",
    "    println!(\"\\nüìù Dans une impl√©mentation r√©elle :\");\n",
    "    println!(\"  ‚Ä¢ Les grandes matrices utiliseraient CoreML\");\n",
    "    println!(\"  ‚Ä¢ Les activations utiliseraient le GPU Metal\");\n",
    "    println!(\"  ‚Ä¢ Les petites op√©rations resteraient sur CPU\");\n",
    "}\n",
    "\n",
    "simulate_neural_layer();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestion d'Erreurs et Basculement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn demonstrate_fallback_behavior() {\n",
    "    println!(\"üîÑ D√©monstration du comportement de basculement :\");\n",
    "    \n",
    "    // Simuler une op√©ration qui pourrait √©chouer sur CoreML\n",
    "    let complex_tensor = Tensor::randn(&[100, 100]);\n",
    "    \n",
    "    println!(\"üéØ Tentative d'op√©ration CoreML...\");\n",
    "    \n",
    "    // Dans l'impl√©mentation r√©elle, ce serait :\n",
    "    // match tensor.to_coreml() {\n",
    "    //     Ok(coreml_tensor) => { /* utiliser CoreML */ },\n",
    "    //     Err(_) => { /* basculer vers Metal/CPU */ }\n",
    "    // }\n",
    "    \n",
    "    let use_coreml = false; // Simuler l'√©chec CoreML\n",
    "    \n",
    "    if use_coreml {\n",
    "        println!(\"‚úÖ Op√©ration CoreML r√©ussie\");\n",
    "    } else {\n",
    "        println!(\"‚ö†Ô∏è CoreML non disponible, utilisation du basculement\");\n",
    "        \n",
    "        // Basculer vers le GPU Metal\n",
    "        let start = Instant::now();\n",
    "        let result = complex_tensor.matmul(&complex_tensor);\n",
    "        let fallback_time = start.elapsed();\n",
    "        \n",
    "        println!(\"‚úÖ Op√©ration de basculement termin√©e\");\n",
    "        println!(\"‚è±Ô∏è Temps de basculement : {:?}\", fallback_time);\n",
    "        println!(\"üìê Forme du r√©sultat : {:?}\", result.shape());\n",
    "    }\n",
    "    \n",
    "    println!(\"\\nüìù Strat√©gie de basculement :\");\n",
    "    println!(\"  1. Essayer CoreML (meilleures performances)\");\n",
    "    println!(\"  2. Basculer vers GPU Metal (bonne compatibilit√©)\");\n",
    "    println!(\"  3. Basculement final vers CPU (compatibilit√© maximale)\");\n",
    "}\n",
    "\n",
    "demonstrate_fallback_behavior();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R√©sum√© et Prochaines √âtapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println!(\"üìã R√©sum√© de l'Int√©gration CoreML RusTorch (Noyau Rust) :\");\n",
    "println!();\n",
    "println!(\"‚úÖ Fonctionnalit√©s d√©montr√©es :\");\n",
    "println!(\"  ‚Ä¢ V√©rification de la disponibilit√© CoreML\");\n",
    "println!(\"  ‚Ä¢ Cr√©ation et gestion de p√©riph√©riques\");\n",
    "println!(\"  ‚Ä¢ Configuration du backend\");\n",
    "println!(\"  ‚Ä¢ Op√©rations de tenseurs de base\");\n",
    "println!(\"  ‚Ä¢ √âvaluation comparative des performances\");\n",
    "println!(\"  ‚Ä¢ S√©lection intelligente de p√©riph√©rique\");\n",
    "println!(\"  ‚Ä¢ Comportement de basculement\");\n",
    "println!();\n",
    "println!(\"üöß Zone de d√©veloppement :\");\n",
    "println!(\"  ‚Ä¢ Impl√©mentation compl√®te des op√©rations CoreML\");\n",
    "println!(\"  ‚Ä¢ Optimisation du transfert de m√©moire\");\n",
    "println!(\"  ‚Ä¢ Support √©tendu pour les types de tenseurs\");\n",
    "println!(\"  ‚Ä¢ Profilage d√©taill√© des performances\");\n",
    "println!(\"  ‚Ä¢ Int√©gration avec les pipelines ML\");\n",
    "println!();\n",
    "println!(\"üéØ Prochaines √©tapes recommand√©es :\");\n",
    "println!(\"  1. Tester avec des mod√®les CoreML pr√©-entra√Æn√©s\");\n",
    "println!(\"  2. √âvaluer comparativement avec d'autres backends\");\n",
    "println!(\"  3. Optimiser pour des cas d'usage sp√©cifiques\");\n",
    "println!(\"  4. D√©ployer dans des applications de production\");\n",
    "println!();\n",
    "\n",
    "#[cfg(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\"))]\n",
    "{\n",
    "    if rustorch::backends::DeviceManager::is_coreml_available() {\n",
    "        println!(\"üéâ Toutes les fonctionnalit√©s CoreML sont disponibles pour les tests !\");\n",
    "    } else {\n",
    "        println!(\"‚ö†Ô∏è CoreML est activ√© mais non disponible sur ce syst√®me\");\n",
    "    }\n",
    "}\n",
    "\n",
    "#[cfg(not(any(feature = \"coreml\", feature = \"coreml-hybrid\", feature = \"coreml-fallback\")))]\n",
    "{\n",
    "    println!(\"‚ö†Ô∏è Construisez avec les fonctionnalit√©s CoreML pour une fonctionnalit√© compl√®te\");\n",
    "}\n",
    "\n",
    "println!(\"\\nüöÄ Pr√™t pour le d√©veloppement avanc√© CoreML avec RusTorch !\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygments_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}