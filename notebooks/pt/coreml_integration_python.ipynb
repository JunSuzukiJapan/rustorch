{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integra√ß√£o CoreML do RusTorch - Bindings Python\n",
    "\n",
    "Este notebook demonstra como usar a funcionalidade CoreML do RusTorch atrav√©s de bindings Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configura√ß√£o e Importa√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bindings Python do RusTorch\n",
    "try:\n",
    "    import rustorch\n",
    "    print(f\"‚úÖ Vers√£o do RusTorch: {rustorch.__version__}\")\n",
    "    print(f\"üìù Descri√ß√£o: {rustorch.__description__}\")\n",
    "    print(f\"üë• Autor: {rustorch.__author__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Falha ao importar RusTorch: {e}\")\n",
    "    print(\"Por favor, compile com maturin develop\")\n",
    "    exit(1)\n",
    "\n",
    "import numpy as np\n",
    "import platform\n",
    "\n",
    "print(f\"üñ•Ô∏è Plataforma: {platform.system()} {platform.release()}\")\n",
    "print(f\"üêç Vers√£o do Python: {platform.python_version()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificar Disponibilidade do CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar funcionalidade CoreML\n",
    "try:\n",
    "    # Verificar se CoreML est√° dispon√≠vel\n",
    "    coreml_available = rustorch.is_coreml_available()\n",
    "    print(f\"üçé CoreML dispon√≠vel: {coreml_available}\")\n",
    "    \n",
    "    if coreml_available:\n",
    "        print(\"üéâ CoreML est√° dispon√≠vel!\")\n",
    "        \n",
    "        # Obter informa√ß√µes do dispositivo\n",
    "        device_info = rustorch.get_coreml_device_info()\n",
    "        print(\"üì± Informa√ß√µes do dispositivo CoreML:\")\n",
    "        print(device_info)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è CoreML n√£o est√° dispon√≠vel\")\n",
    "        if platform.system() != \"Darwin\":\n",
    "            print(\"CoreML est√° dispon√≠vel apenas no macOS\")\n",
    "        else:\n",
    "            print(\"Recursos CoreML podem n√£o estar habilitados\")\n",
    "            \n",
    "except AttributeError:\n",
    "    print(\"‚ùå Fun√ß√µes CoreML n√£o encontradas\")\n",
    "    print(\"Pode n√£o estar compilado com recursos CoreML\")\n",
    "    coreml_available = False\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao verificar CoreML: {e}\")\n",
    "    coreml_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria√ß√£o de Dispositivo CoreML e Opera√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if coreml_available:\n",
    "    try:\n",
    "        # Criar dispositivo CoreML\n",
    "        device = rustorch.CoreMLDevice(device_id=0)\n",
    "        print(f\"üñ•Ô∏è Dispositivo CoreML criado: {device}\")\n",
    "        \n",
    "        # Obter informa√ß√µes do dispositivo\n",
    "        print(f\"üÜî ID do dispositivo: {device.device_id()}\")\n",
    "        print(f\"‚úÖ Dispon√≠vel: {device.is_available()}\")\n",
    "        print(f\"üíæ Limite de mem√≥ria: {device.memory_limit()} bytes\")\n",
    "        print(f\"üßÆ Limite de unidades de computa√ß√£o: {device.compute_units_limit()}\")\n",
    "        print(f\"üìö Tamanho do cache do modelo: {device.model_cache_size()}\")\n",
    "        \n",
    "        # Limpeza do cache\n",
    "        device.cleanup_cache()\n",
    "        print(\"üßπ Cache limpo\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro na opera√ß√£o do dispositivo CoreML: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Pulando opera√ß√µes do dispositivo pois CoreML n√£o est√° dispon√≠vel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configura√ß√£o do Backend CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if coreml_available:\n",
    "    try:\n",
    "        # Criar configura√ß√£o do backend CoreML\n",
    "        config = rustorch.CoreMLBackendConfig(\n",
    "            enable_caching=True,\n",
    "            max_cache_size=200,\n",
    "            enable_profiling=True,\n",
    "            auto_fallback=True\n",
    "        )\n",
    "        print(f\"‚öôÔ∏è Configura√ß√£o do backend: {config}\")\n",
    "        \n",
    "        # Verificar e modificar valores de configura√ß√£o\n",
    "        print(f\"üìä Habilitar cache: {config.enable_caching}\")\n",
    "        print(f\"üóÇÔ∏è Tamanho m√°ximo do cache: {config.max_cache_size}\")\n",
    "        print(f\"üìà Habilitar profiling: {config.enable_profiling}\")\n",
    "        print(f\"üîÑ Fallback autom√°tico: {config.auto_fallback}\")\n",
    "        \n",
    "        # Modificar configura√ß√£o\n",
    "        config.enable_profiling = False\n",
    "        config.max_cache_size = 150\n",
    "        print(f\"\\nüîß Configura√ß√£o atualizada: {config}\")\n",
    "        \n",
    "        # Criar backend CoreML\n",
    "        backend = rustorch.CoreMLBackend(config)\n",
    "        print(f\"üöÄ Backend CoreML: {backend}\")\n",
    "        print(f\"‚úÖ Backend dispon√≠vel: {backend.is_available()}\")\n",
    "        \n",
    "        # Obter estat√≠sticas do backend\n",
    "        stats = backend.get_stats()\n",
    "        print(f\"üìä Estat√≠sticas do backend: {stats}\")\n",
    "        print(f\"   Opera√ß√µes totais: {stats.total_operations}\")\n",
    "        print(f\"   Acertos de cache: {stats.cache_hits}\")\n",
    "        print(f\"   Erros de cache: {stats.cache_misses}\")\n",
    "        print(f\"   Opera√ß√µes de fallback: {stats.fallback_operations}\")\n",
    "        print(f\"   Taxa de acerto de cache: {stats.cache_hit_rate():.2%}\")\n",
    "        print(f\"   Taxa de fallback: {stats.fallback_rate():.2%}\")\n",
    "        print(f\"   Tempo m√©dio de execu√ß√£o: {stats.average_execution_time_ms:.2f}ms\")\n",
    "        \n",
    "        # Limpeza do cache\n",
    "        backend.cleanup_cache()\n",
    "        print(\"\\nüßπ Cache do backend limpo\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro na opera√ß√£o do backend CoreML: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Pulando opera√ß√µes do backend pois CoreML n√£o est√° dispon√≠vel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opera√ß√µes B√°sicas de Tensor (CPU)\n",
    "\n",
    "Para comparar com CoreML, vamos primeiro realizar opera√ß√µes b√°sicas na CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Cria√ß√£o e opera√ß√µes b√°sicas de tensor\n",
    "    print(\"üßÆ Opera√ß√µes b√°sicas de tensor (CPU)\")\n",
    "    \n",
    "    # Criar tensores a partir de arrays NumPy (interface simplificada)\n",
    "    data_a = np.random.randn(2, 3).astype(np.float32)\n",
    "    data_b = np.random.randn(3, 2).astype(np.float32)\n",
    "    \n",
    "    print(f\"üìê Forma da matriz A: {data_a.shape}\")\n",
    "    print(f\"üìê Forma da matriz B: {data_b.shape}\")\n",
    "    \n",
    "    # Multiplica√ß√£o de matrizes com NumPy (para compara√ß√£o)\n",
    "    numpy_result = np.matmul(data_a, data_b)\n",
    "    print(f\"‚úÖ Forma do resultado matmul NumPy: {numpy_result.shape}\")\n",
    "    print(f\"üìä Resultado (primeiros elementos): {numpy_result.flatten()[:4]}\")\n",
    "    \n",
    "    print(\"\\nüöÄ Opera√ß√µes CPU completadas\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro na opera√ß√£o de tensor: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simula√ß√£o de Compara√ß√£o de Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark_matrix_operations():\n",
    "    \"\"\"Comparar performance com diferentes tamanhos de matriz\"\"\"\n",
    "    \n",
    "    sizes = [(64, 64), (128, 128), (256, 256), (512, 512)]\n",
    "    \n",
    "    print(\"üèÅ Compara√ß√£o de performance:\")\n",
    "    print(\"Tamanho\\t\\tTempo CPU (ms)\\tCoreML Esperado (ms)\")\n",
    "    print(\"-\" * 58)\n",
    "    \n",
    "    for size in sizes:\n",
    "        # Medir tempo de execu√ß√£o CPU\n",
    "        a = np.random.randn(*size).astype(np.float32)\n",
    "        b = np.random.randn(size[1], size[0]).astype(np.float32)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        result = np.matmul(a, b)\n",
    "        cpu_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        # Tempo CoreML esperado (hipot√©tico)\n",
    "        # Na implementa√ß√£o real, usar medi√ß√µes reais do backend CoreML\n",
    "        expected_coreml_time = cpu_time * 0.6  # Suposi√ß√£o: CoreML √© 40% mais r√°pido\n",
    "        \n",
    "        print(f\"{size[0]}x{size[1]}\\t\\t{cpu_time:.2f}\\t\\t{expected_coreml_time:.2f}\")\n",
    "\n",
    "benchmark_matrix_operations()\n",
    "\n",
    "print(\"\\nüìù Nota: Os tempos CoreML s√£o hipot√©ticos. Valores reais dependem da implementa√ß√£o espec√≠fica.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simula√ß√£o de Sele√ß√£o de Dispositivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_device_selection():\n",
    "    \"\"\"Simular sele√ß√£o inteligente de dispositivo\"\"\"\n",
    "    \n",
    "    operations = [\n",
    "        (\"Multiplica√ß√£o de matriz pequena\", (16, 16), \"CPU\"),\n",
    "        (\"Multiplica√ß√£o de matriz m√©dia\", (128, 128), \"Metal GPU\"),\n",
    "        (\"Multiplica√ß√£o de matriz grande\", (512, 512), \"CoreML\" if coreml_available else \"Metal GPU\"),\n",
    "        (\"Fun√ß√£o de ativa√ß√£o\", (32, 64, 128, 128), \"Metal GPU\"),\n",
    "        (\"Convolu√ß√£o pequena\", (1, 3, 32, 32), \"CPU\"),\n",
    "        (\"Convolu√ß√£o grande\", (16, 64, 224, 224), \"CoreML\" if coreml_available else \"Metal GPU\"),\n",
    "        (\"Opera√ß√µes de n√∫meros complexos\", (128, 128), \"Metal GPU\"),  # CoreML n√£o suportado\n",
    "        (\"Distribui√ß√£o estat√≠stica\", (1000,), \"CPU\"),  # CoreML n√£o suportado\n",
    "    ]\n",
    "    \n",
    "    print(\"üéØ Simula√ß√£o de sele√ß√£o inteligente de dispositivo:\")\n",
    "    print(\"Opera√ß√£o\\t\\t\\tForma do Tensor\\t\\tDispositivo Selecionado\")\n",
    "    print(\"-\" * 78)\n",
    "    \n",
    "    for name, shape, device in operations:\n",
    "        shape_str = \"x\".join(map(str, shape))\n",
    "        print(f\"{name:<31}\\t{shape_str:<15}\\t{device}\")\n",
    "    \n",
    "    print(\"\\nüìù L√≥gica de sele√ß√£o:\")\n",
    "    print(\"  ‚Ä¢ Opera√ß√µes pequenas: CPU (evitar overhead)\")\n",
    "    print(\"  ‚Ä¢ Opera√ß√µes m√©dias: Metal GPU (balanceado)\")\n",
    "    print(\"  ‚Ä¢ Opera√ß√µes grandes: CoreML (otimizado)\")\n",
    "    print(\"  ‚Ä¢ Opera√ß√µes n√£o suportadas: fallback GPU/CPU\")\n",
    "\n",
    "simulate_device_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo Pr√°tico: Camada Simples de Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_neural_network_layer():\n",
    "    \"\"\"Simular camada de rede neural\"\"\"\n",
    "    \n",
    "    print(\"üß† Simula√ß√£o de camada de rede neural:\")\n",
    "    \n",
    "    # Tamanho do lote e configura√ß√£o da camada\n",
    "    batch_size = 32\n",
    "    input_features = 784  # 28x28 MNIST\n",
    "    hidden_features = 256\n",
    "    output_features = 10  # 10 classes\n",
    "    \n",
    "    print(f\"üìä Tamanho do lote: {batch_size}\")\n",
    "    print(f\"üî¢ Caracter√≠sticas de entrada: {input_features}\")\n",
    "    print(f\"üßÆ Caracter√≠sticas ocultas: {hidden_features}\")\n",
    "    print(f\"üéØ Caracter√≠sticas de sa√≠da: {output_features}\")\n",
    "    \n",
    "    # Simula√ß√£o de forward pass\n",
    "    steps = [\n",
    "        (\"Entrada ‚Üí Oculta\", f\"({batch_size}, {input_features}) @ ({input_features}, {hidden_features})\", \"CoreML\" if coreml_available else \"Metal\"),\n",
    "        (\"Ativa√ß√£o ReLU\", f\"({batch_size}, {hidden_features})\", \"Metal\"),\n",
    "        (\"Oculta ‚Üí Sa√≠da\", f\"({batch_size}, {hidden_features}) @ ({hidden_features}, {output_features})\", \"CoreML\" if coreml_available else \"Metal\"),\n",
    "        (\"Softmax\", f\"({batch_size}, {output_features})\", \"CPU\"),\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nüîÑ Simula√ß√£o de forward pass:\")\n",
    "    total_time = 0\n",
    "    \n",
    "    for step, shape, device in steps:\n",
    "        # Tempo de execu√ß√£o virtual (ms)\n",
    "        if device == \"CoreML\":\n",
    "            time_ms = np.random.uniform(0.5, 2.0)\n",
    "        elif device == \"Metal\":\n",
    "            time_ms = np.random.uniform(1.0, 3.0)\n",
    "        else:  # CPU\n",
    "            time_ms = np.random.uniform(0.2, 1.0)\n",
    "        \n",
    "        total_time += time_ms\n",
    "        print(f\"  {step:<15} {shape:<30} {device:<8} {time_ms:.2f}ms\")\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è Tempo total do forward pass: {total_time:.2f}ms\")\n",
    "    print(f\"üöÄ Throughput estimado: {1000/total_time:.0f} lotes/segundo\")\n",
    "\n",
    "simulate_neural_network_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo e Pr√≥ximos Passos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìã Resumo da Integra√ß√£o CoreML do RusTorch:\")\n",
    "print()\n",
    "print(\"‚úÖ Itens completados:\")\n",
    "print(\"  ‚Ä¢ Configura√ß√£o do ambiente Jupyter\")\n",
    "print(\"  ‚Ä¢ Cria√ß√£o do kernel Rust e bindings Python\")\n",
    "print(\"  ‚Ä¢ Verifica√ß√£o de disponibilidade CoreML\")\n",
    "print(\"  ‚Ä¢ Gerenciamento de dispositivos e configura√ß√£o\")\n",
    "print(\"  ‚Ä¢ Estat√≠sticas e profiling do backend\")\n",
    "print(\"  ‚Ä¢ Sele√ß√£o inteligente de dispositivo\")\n",
    "print()\n",
    "print(\"üöß Desenvolvimento futuro:\")\n",
    "print(\"  ‚Ä¢ Implementa√ß√£o real de opera√ß√µes CoreML\")\n",
    "print(\"  ‚Ä¢ Benchmarking de performance\")\n",
    "print(\"  ‚Ä¢ Mais fun√ß√µes de ativa√ß√£o e tipos de camadas\")\n",
    "print(\"  ‚Ä¢ Melhorias no tratamento de erros\")\n",
    "print(\"  ‚Ä¢ Otimiza√ß√£o de mem√≥ria\")\n",
    "print()\n",
    "print(\"üéØ Pr√≥ximos passos recomendados:\")\n",
    "print(\"  1. Carregar e testar modelos CoreML reais\")\n",
    "print(\"  2. Comparar performance Metal e CoreML\")\n",
    "print(\"  3. Testar com workflows de deep learning reais\")\n",
    "print(\"  4. Avaliar em ambiente de produ√ß√£o\")\n",
    "\n",
    "if coreml_available:\n",
    "    print(\"\\nüéâ Parab√©ns! CoreML est√° dispon√≠vel e todas as funcionalidades podem ser testadas.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è CoreML n√£o est√° dispon√≠vel, mas as funcionalidades b√°sicas est√£o funcionando.\")\n",
    "    print(\"   Recomendamos compilar com funcionalidades CoreML habilitadas no macOS.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}