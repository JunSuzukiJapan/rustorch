# RusTorch API æ–‡æ¡£

## ğŸ“š å®Œæ•´APIå‚è€ƒ

æœ¬æ–‡æ¡£ä¸ºRusTorch v0.5.15æä¾›å…¨é¢çš„APIæ–‡æ¡£ï¼ŒæŒ‰æ¨¡å—å’ŒåŠŸèƒ½ç»„ç»‡ã€‚åŒ…å«ç»Ÿä¸€é”™è¯¯å¤„ç†ï¼Œä½¿ç”¨`RusTorchError`å’Œ`RusTorchResult<T>`åœ¨æ‰€æœ‰1060+æµ‹è¯•ä¸­æä¾›ä¸€è‡´çš„é”™è¯¯ç®¡ç†ã€‚**ç¬¬8é˜¶æ®µå·²å®Œæˆ**æ·»åŠ é«˜çº§å¼ é‡å·¥å…·ï¼ŒåŒ…æ‹¬æ¡ä»¶æ“ä½œã€ç´¢å¼•å’Œç»Ÿè®¡å‡½æ•°ã€‚**ç¬¬9é˜¶æ®µå·²å®Œæˆ**å¼•å…¥å…¨é¢åºåˆ—åŒ–ç³»ç»Ÿï¼ŒåŒ…å«æ¨¡å‹ä¿å­˜/åŠ è½½ã€JITç¼–è¯‘å’Œå¤šæ ¼å¼æ”¯æŒï¼ˆåŒ…æ‹¬PyTorchå…¼å®¹æ€§ï¼‰ã€‚

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„

### æ¨¡å—ç»“æ„

```
rustorch/
â”œâ”€â”€ tensor/              # æ ¸å¿ƒå¼ é‡æ“ä½œå’Œæ•°æ®ç»“æ„
â”œâ”€â”€ nn/                  # ç¥ç»ç½‘ç»œå±‚å’Œå‡½æ•°
â”œâ”€â”€ autograd/            # è‡ªåŠ¨å¾®åˆ†å¼•æ“
â”œâ”€â”€ optim/               # ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨
â”œâ”€â”€ special/             # ç‰¹æ®Šæ•°å­¦å‡½æ•°
â”œâ”€â”€ distributions/       # ç»Ÿè®¡åˆ†å¸ƒ
â”œâ”€â”€ vision/              # è®¡ç®—æœºè§†è§‰å˜æ¢
â”œâ”€â”€ linalg/              # çº¿æ€§ä»£æ•°æ“ä½œ (BLAS/LAPACK)
â”œâ”€â”€ gpu/                 # GPUåŠ é€Ÿ (CUDA/Metal/OpenCL/WebGPU)
â”œâ”€â”€ sparse/              # ç¨€ç–å¼ é‡æ“ä½œå’Œå‰ªæ (ç¬¬12é˜¶æ®µ)
â”œâ”€â”€ serialization/       # æ¨¡å‹åºåˆ—åŒ–å’ŒJITç¼–è¯‘ (ç¬¬9é˜¶æ®µ)
â””â”€â”€ wasm/                # WebAssemblyç»‘å®š (è§ [WASM APIæ–‡æ¡£](WASM_API_DOCUMENTATION.md))
```

## ğŸ“Š å¼ é‡æ¨¡å—

### æ ¸å¿ƒå¼ é‡åˆ›å»º

```rust
use rustorch::tensor::Tensor;

// åŸºç¡€åˆ›å»º
let tensor = Tensor::new(vec![2, 3]);               // åŸºäºå½¢çŠ¶çš„åˆ›å»º
let tensor = Tensor::from_vec(data, vec![2, 3]);    // ä»æ•°æ®å‘é‡åˆ›å»º
let tensor = Tensor::zeros(vec![10, 10]);           // é›¶å¡«å……å¼ é‡
let tensor = Tensor::ones(vec![5, 5]);              // ä¸€å¡«å……å¼ é‡
let tensor = Tensor::randn(vec![3, 3]);             // éšæœºæ­£æ€åˆ†å¸ƒ
let tensor = Tensor::rand(vec![3, 3]);              // éšæœºå‡åŒ€åˆ†å¸ƒ [0,1)
let tensor = Tensor::eye(5);                        // å•ä½çŸ©é˜µ
let tensor = Tensor::full(vec![2, 2], 3.14);       // ç”¨ç‰¹å®šå€¼å¡«å……
let tensor = Tensor::arange(0.0, 10.0, 1.0);       // èŒƒå›´å¼ é‡
let tensor = Tensor::linspace(0.0, 1.0, 100);      // çº¿æ€§é—´è·
```

### å¼ é‡æ“ä½œ

```rust
// ç®—æœ¯è¿ç®—
let result = a.add(&b);                             // é€å…ƒç´ åŠ æ³•
let result = a.sub(&b);                             // é€å…ƒç´ å‡æ³•
let result = a.mul(&b);                             // é€å…ƒç´ ä¹˜æ³•
let result = a.div(&b);                             // é€å…ƒç´ é™¤æ³•
let result = a.pow(&b);                             // é€å…ƒç´ å¹‚è¿ç®—
let result = a.rem(&b);                             // é€å…ƒç´ å–ä½™

// çŸ©é˜µè¿ç®—
let result = a.matmul(&b);                          // çŸ©é˜µä¹˜æ³•
let result = a.transpose();                         // çŸ©é˜µè½¬ç½®
let result = a.dot(&b);                             // ç‚¹ç§¯

// æ•°å­¦å‡½æ•°
let result = tensor.exp();                          // æŒ‡æ•°
let result = tensor.ln();                           // è‡ªç„¶å¯¹æ•°
let result = tensor.log10();                        // ä»¥10ä¸ºåº•å¯¹æ•°
let result = tensor.sqrt();                         // å¹³æ–¹æ ¹
let result = tensor.abs();                          // ç»å¯¹å€¼
let result = tensor.sin();                          // æ­£å¼¦å‡½æ•°
let result = tensor.cos();                          // ä½™å¼¦å‡½æ•°
let result = tensor.tan();                          // æ­£åˆ‡å‡½æ•°
let result = tensor.asin();                         // åæ­£å¼¦
let result = tensor.acos();                         // åä½™å¼¦
let result = tensor.atan();                         // åæ­£åˆ‡
let result = tensor.sinh();                         // åŒæ›²æ­£å¼¦
let result = tensor.cosh();                         // åŒæ›²ä½™å¼¦
let result = tensor.tanh();                         // åŒæ›²æ­£åˆ‡
let result = tensor.floor();                        // å‘ä¸‹å–æ•´
let result = tensor.ceil();                         // å‘ä¸Šå–æ•´
let result = tensor.round();                        // å››èˆäº”å…¥
let result = tensor.sign();                         // ç¬¦å·å‡½æ•°
let result = tensor.max();                          // æœ€å¤§å€¼
let result = tensor.min();                          // æœ€å°å€¼
let result = tensor.sum();                          // æ‰€æœ‰å…ƒç´ æ±‚å’Œ
let result = tensor.mean();                         // å¹³å‡å€¼
let result = tensor.std();                          // æ ‡å‡†å·®
let result = tensor.var();                          // æ–¹å·®

// å½¢çŠ¶æ“ä½œ
let result = tensor.reshape(vec![6, 4]);            // é‡å¡‘å¼ é‡
let result = tensor.squeeze();                      // å»é™¤å¤§å°ä¸º1çš„ç»´åº¦
let result = tensor.unsqueeze(1);                   // åœ¨ç´¢å¼•å¤„æ·»åŠ ç»´åº¦
let result = tensor.permute(vec![1, 0, 2]);         // æ’åˆ—ç»´åº¦
let result = tensor.expand(vec![10, 10, 5]);        // æ‰©å±•å¼ é‡ç»´åº¦
```

## ğŸ§  ç¥ç»ç½‘ç»œ(nn)æ¨¡å—

### åŸºç¡€å±‚

```rust
use rustorch::nn::{Linear, Conv2d, BatchNorm1d, Dropout};

// çº¿æ€§å±‚
let linear = Linear::new(784, 256)?;                // è¾“å…¥784ï¼Œè¾“å‡º256
let output = linear.forward(&input)?;

// å·ç§¯å±‚
let conv = Conv2d::new(3, 64, 3, None, Some(1))?; // in_channels=3, out_channels=64, kernel_size=3
let output = conv.forward(&input)?;

// æ‰¹é‡å½’ä¸€åŒ–
let bn = BatchNorm1d::new(256)?;
let normalized = bn.forward(&input)?;

// Dropout
let dropout = Dropout::new(0.5)?;
let output = dropout.forward(&input, true)?;       // training=true
```

### æ¿€æ´»å‡½æ•°

```rust
use rustorch::nn::{ReLU, Sigmoid, Tanh, LeakyReLU, ELU, GELU};

// åŸºç¡€æ¿€æ´»å‡½æ•°
let relu = ReLU::new();
let sigmoid = Sigmoid::new();
let tanh = Tanh::new();

// å‚æ•°åŒ–æ¿€æ´»å‡½æ•°
let leaky_relu = LeakyReLU::new(0.01)?;
let elu = ELU::new(1.0)?;
let gelu = GELU::new();

// ä½¿ç”¨ç¤ºä¾‹
let activated = relu.forward(&input)?;
```

## ğŸš€ GPUåŠ é€Ÿæ¨¡å—

### è®¾å¤‡ç®¡ç†

```rust
use rustorch::gpu::{Device, get_device_count, set_device};

// æ£€æŸ¥å¯ç”¨è®¾å¤‡
let device_count = get_device_count()?;
let device = Device::best_available()?;            // æœ€ä½³è®¾å¤‡é€‰æ‹©

// è®¾å¤‡é…ç½®
set_device(&device)?;

// å°†å¼ é‡ç§»è‡³GPU
let gpu_tensor = tensor.to_device(&device)?;
```

### CUDAæ“ä½œ

```rust
#[cfg(feature = "cuda")]
use rustorch::gpu::cuda::{CudaDevice, memory_stats};

// CUDAè®¾å¤‡æ“ä½œ
let cuda_device = CudaDevice::new(0)?;              // ä½¿ç”¨GPU 0
let stats = memory_stats(0)?;                      // å†…å­˜ç»Ÿè®¡
println!("å·²ç”¨å†…å­˜: {} MB", stats.used_memory / (1024 * 1024));
```

## ğŸ¯ ä¼˜åŒ–å™¨(Optim)æ¨¡å—

### åŸºç¡€ä¼˜åŒ–å™¨

```rust
use rustorch::optim::{Adam, SGD, RMSprop, AdamW};

// Adamä¼˜åŒ–å™¨
let mut optimizer = Adam::new(vec![x.clone(), y.clone()], 0.001, 0.9, 0.999, 1e-8)?;

// SGDä¼˜åŒ–å™¨
let mut sgd = SGD::new(vec![x.clone()], 0.01, 0.9, 1e-4)?;

// ä¼˜åŒ–æ­¥éª¤
optimizer.zero_grad()?;
// ... å‰å‘è®¡ç®—å’Œåå‘ä¼ æ’­ ...
optimizer.step()?;
```

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

### çº¿æ€§å›å½’

```rust
use rustorch::{tensor::Tensor, nn::Linear, optim::Adam, autograd::Variable};

// æ•°æ®å‡†å¤‡
let x = Variable::new(Tensor::randn(vec![100, 1]), false)?;
let y = Variable::new(Tensor::randn(vec![100, 1]), false)?;

// æ¨¡å‹å®šä¹‰
let mut model = Linear::new(1, 1)?;
let mut optimizer = Adam::new(model.parameters(), 0.001, 0.9, 0.999, 1e-8)?;

// è®­ç»ƒå¾ªç¯
for epoch in 0..1000 {
    optimizer.zero_grad()?;
    let pred = model.forward(&x)?;
    let loss = (pred - &y).pow(&Tensor::from(2.0))?.mean()?;
    backward(&loss, true)?;
    optimizer.step()?;
    
    if epoch % 100 == 0 {
        println!("è½®æ¬¡ {}: æŸå¤± = {:.4}", epoch, loss.item::<f32>()?);
    }
}
```

## âš ï¸ å·²çŸ¥é™åˆ¶

1. **GPUå†…å­˜é™åˆ¶**: å¤§å‹å¼ é‡(>8GB)éœ€è¦æ˜¾å¼å†…å­˜ç®¡ç†
2. **WebAssemblyé™åˆ¶**: æŸäº›BLASæ“ä½œåœ¨WASMç¯å¢ƒä¸­ä¸å¯ç”¨
3. **åˆ†å¸ƒå¼å­¦ä¹ **: NCCLåç«¯ä»…åœ¨Linuxä¸Šæ”¯æŒ
4. **Metalé™åˆ¶**: æŸäº›é«˜çº§æ“ä½œä»…åœ¨CUDAåç«¯å¯ç”¨

## ğŸ”— ç›¸å…³é“¾æ¥

- [ä¸»README](../README.md)
- [WASM APIæ–‡æ¡£](WASM_API_DOCUMENTATION.md)
- [JupyteræŒ‡å—](jupyter-guide.md)
- [GitHubä»“åº“](https://github.com/JunSuzukiJapan/RusTorch)
- [Crates.ioåŒ…](https://crates.io/crates/rustorch)

---

**æœ€åæ›´æ–°**: v0.5.15 | **è®¸å¯è¯**: MIT | **ä½œè€…**: Jun Suzuki