# Documentaci√≥n API RusTorch

## üìö Referencia API Completa

Este documento proporciona documentaci√≥n API completa para RusTorch v0.5.15, organizada por m√≥dulo y funcionalidad. Incluye manejo de errores unificado con `RusTorchError` y `RusTorchResult<T>` para gesti√≥n consistente de errores a trav√©s de todos los 1060+ tests. **Fase 8 COMPLETADA** a√±ade utilidades de tensores avanzadas incluyendo operaciones condicionales, indexaci√≥n y funciones estad√≠sticas. **Fase 9 COMPLETADA** introduce sistema de serializaci√≥n completo con guardado/carga de modelos, compilaci√≥n JIT y soporte de m√∫ltiples formatos incluyendo compatibilidad PyTorch.

## üèóÔ∏è Arquitectura Core

### Estructura de M√≥dulos

```
rustorch/
‚îú‚îÄ‚îÄ tensor/              # Operaciones tensores core y estructuras datos
‚îú‚îÄ‚îÄ nn/                  # Capas redes neurales y funciones
‚îú‚îÄ‚îÄ autograd/            # Motor diferenciaci√≥n autom√°tica
‚îú‚îÄ‚îÄ optim/               # Optimizadores y programadores tasa aprendizaje
‚îú‚îÄ‚îÄ special/             # Funciones matem√°ticas especiales
‚îú‚îÄ‚îÄ distributions/       # Distribuciones estad√≠sticas
‚îú‚îÄ‚îÄ vision/              # Transformaciones computer vision
‚îú‚îÄ‚îÄ linalg/              # Operaciones √°lgebra lineal (BLAS/LAPACK)
‚îú‚îÄ‚îÄ gpu/                 # Aceleraci√≥n GPU (CUDA/Metal/OpenCL/WebGPU)
‚îú‚îÄ‚îÄ sparse/              # Operaciones tensores dispersos y poda (Fase 12)
‚îú‚îÄ‚îÄ serialization/       # Serializaci√≥n modelos y compilaci√≥n JIT (Fase 9)
‚îî‚îÄ‚îÄ wasm/                # Bindings WebAssembly (ver [Documentaci√≥n API WASM](WASM_API_DOCUMENTATION.md))
```

## üìä M√≥dulo Tensor

### Creaci√≥n Tensores Base

```rust
use rustorch::tensor::Tensor;

// Creaci√≥n base
let tensor = Tensor::new(vec![2, 3]);               // Creaci√≥n basada en forma
let tensor = Tensor::from_vec(data, vec![2, 3]);    // Desde vector datos
let tensor = Tensor::zeros(vec![10, 10]);           // Tensor lleno ceros
let tensor = Tensor::ones(vec![5, 5]);              // Tensor lleno unos
let tensor = Tensor::randn(vec![3, 3]);             // Distribuci√≥n normal aleatoria
let tensor = Tensor::rand(vec![3, 3]);              // Distribuci√≥n uniforme aleatoria [0,1)
let tensor = Tensor::eye(5);                        // Matriz identidad
let tensor = Tensor::full(vec![2, 2], 3.14);       // Llenar con valor espec√≠fico
let tensor = Tensor::arange(0.0, 10.0, 1.0);       // Tensor rango
let tensor = Tensor::linspace(0.0, 1.0, 100);      // Espaciado lineal
```

### Operaciones Tensores

```rust
// Operaciones aritm√©ticas
let result = a.add(&b);                             // Suma elemento por elemento
let result = a.sub(&b);                             // Resta elemento por elemento
let result = a.mul(&b);                             // Multiplicaci√≥n elemento por elemento
let result = a.div(&b);                             // Divisi√≥n elemento por elemento
let result = a.pow(&b);                             // Potencia elemento por elemento
let result = a.rem(&b);                             // Resto elemento por elemento

// Operaciones matriciales
let result = a.matmul(&b);                          // Multiplicaci√≥n matricial
let result = a.transpose();                         // Transposici√≥n matricial
let result = a.dot(&b);                             // Producto escalar

// Funciones matem√°ticas
let result = tensor.exp();                          // Exponencial
let result = tensor.ln();                           // Logaritmo natural
let result = tensor.log10();                        // Logaritmo base 10
let result = tensor.sqrt();                         // Ra√≠z cuadrada
let result = tensor.abs();                          // Valor absoluto
let result = tensor.sin();                          // Funci√≥n seno
let result = tensor.cos();                          // Funci√≥n coseno
let result = tensor.tan();                          // Funci√≥n tangente
let result = tensor.asin();                         // Arcoseno
let result = tensor.acos();                         // Arcocoseno
let result = tensor.atan();                         // Arcotangente
let result = tensor.sinh();                         // Seno hiperb√≥lico
let result = tensor.cosh();                         // Coseno hiperb√≥lico
let result = tensor.tanh();                         // Tangente hiperb√≥lica
let result = tensor.floor();                        // Funci√≥n suelo
let result = tensor.ceil();                         // Funci√≥n techo
let result = tensor.round();                        // Funci√≥n redondear
let result = tensor.sign();                         // Funci√≥n signo
let result = tensor.max();                          // Valor m√°ximo
let result = tensor.min();                          // Valor m√≠nimo
let result = tensor.sum();                          // Suma todos elementos
let result = tensor.mean();                         // Valor medio
let result = tensor.std();                          // Desviaci√≥n est√°ndar
let result = tensor.var();                          // Varianza

// Manipulaci√≥n forma
let result = tensor.reshape(vec![6, 4]);            // Redimensionar tensor
let result = tensor.squeeze();                      // Quitar dimensiones tama√±o-1
let result = tensor.unsqueeze(1);                   // A√±adir dimensi√≥n en √≠ndice
let result = tensor.permute(vec![1, 0, 2]);         // Permutar dimensiones
let result = tensor.expand(vec![10, 10, 5]);        // Expandir dimensiones tensor
```

## üß† M√≥dulo Neural Network (nn)

### Capas Base

```rust
use rustorch::nn::{Linear, Conv2d, BatchNorm1d, Dropout};

// Capa lineal
let linear = Linear::new(784, 256)?;                // entrada 784, salida 256
let output = linear.forward(&input)?;

// Capa convolucional
let conv = Conv2d::new(3, 64, 3, None, Some(1))?; // in_channels=3, out_channels=64, kernel_size=3
let output = conv.forward(&input)?;

// Normalizaci√≥n por lotes
let bn = BatchNorm1d::new(256)?;
let normalized = bn.forward(&input)?;

// Dropout
let dropout = Dropout::new(0.5)?;
let output = dropout.forward(&input, true)?;       // training=true
```

### Funciones Activaci√≥n

```rust
use rustorch::nn::{ReLU, Sigmoid, Tanh, LeakyReLU, ELU, GELU};

// Funciones activaci√≥n base
let relu = ReLU::new();
let sigmoid = Sigmoid::new();
let tanh = Tanh::new();

// Funciones activaci√≥n parametrizadas
let leaky_relu = LeakyReLU::new(0.01)?;
let elu = ELU::new(1.0)?;
let gelu = GELU::new();

// Ejemplo uso
let activated = relu.forward(&input)?;
```

## üöÄ M√≥dulo Aceleraci√≥n GPU

### Gesti√≥n Dispositivos

```rust
use rustorch::gpu::{Device, get_device_count, set_device};

// Verificar dispositivos disponibles
let device_count = get_device_count()?;
let device = Device::best_available()?;            // Selecci√≥n mejor dispositivo

// Configuraci√≥n dispositivo
set_device(&device)?;

// Mover tensor a GPU
let gpu_tensor = tensor.to_device(&device)?;
```

### Operaciones CUDA

```rust
#[cfg(feature = "cuda")]
use rustorch::gpu::cuda::{CudaDevice, memory_stats};

// Operaciones dispositivo CUDA
let cuda_device = CudaDevice::new(0)?;              // Usar GPU 0
let stats = memory_stats(0)?;                      // Estad√≠sticas memoria
println!("Memoria usada: {} MB", stats.used_memory / (1024 * 1024));
```

## üéØ M√≥dulo Optimizador (Optim)

### Optimizadores Base

```rust
use rustorch::optim::{Adam, SGD, RMSprop, AdamW};

// Optimizador Adam
let mut optimizer = Adam::new(vec![x.clone(), y.clone()], 0.001, 0.9, 0.999, 1e-8)?;

// Optimizador SGD
let mut sgd = SGD::new(vec![x.clone()], 0.01, 0.9, 1e-4)?;

// Paso optimizaci√≥n
optimizer.zero_grad()?;
// ... c√°lculo hacia adelante y retropropagaci√≥n ...
optimizer.step()?;
```

## üìñ Ejemplo Uso

### Regresi√≥n Lineal

```rust
use rustorch::{tensor::Tensor, nn::Linear, optim::Adam, autograd::Variable};

// Preparaci√≥n datos
let x = Variable::new(Tensor::randn(vec![100, 1]), false)?;
let y = Variable::new(Tensor::randn(vec![100, 1]), false)?;

// Definici√≥n modelo
let mut model = Linear::new(1, 1)?;
let mut optimizer = Adam::new(model.parameters(), 0.001, 0.9, 0.999, 1e-8)?;

// Bucle entrenamiento
for epoch in 0..1000 {
    optimizer.zero_grad()?;
    let pred = model.forward(&x)?;
    let loss = (pred - &y).pow(&Tensor::from(2.0))?.mean()?;
    backward(&loss, true)?;
    optimizer.step()?;
    
    if epoch % 100 == 0 {
        println!("√âpoca {}: P√©rdida = {:.4}", epoch, loss.item::<f32>()?);
    }
}
```

## ‚ö†Ô∏è Limitaciones Conocidas

1. **Limitaci√≥n memoria GPU**: Gesti√≥n expl√≠cita memoria requerida para tensores grandes (>8GB)
2. **Limitaci√≥n WebAssembly**: Algunas operaciones BLAS no disponibles en entorno WASM
3. **Entrenamiento distribuido**: Backend NCCL solo soportado en Linux
4. **Limitaci√≥n Metal**: Algunas operaciones avanzadas solo disponibles con backend CUDA

## üîó Enlaces Relacionados

- [README Principal](../README.md)
- [Documentaci√≥n API WASM](WASM_API_DOCUMENTATION.md)
- [Gu√≠a Jupyter](jupyter-guide.md)
- [Repositorio GitHub](https://github.com/JunSuzukiJapan/RusTorch)
- [Paquete Crates.io](https://crates.io/crates/rustorch)

---

**√öltima Actualizaci√≥n**: v0.5.15 | **Licencia**: MIT | **Autor**: Jun Suzuki