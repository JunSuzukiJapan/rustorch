# Documentation API RusTorch

## üìö R√©f√©rence API Compl√®te

Ce document fournit une documentation API compl√®te pour RusTorch v0.5.15, organis√©e par module et fonctionnalit√©. Il comprend une gestion d'erreurs unifi√©e avec `RusTorchError` et `RusTorchResult<T>` pour une gestion coh√©rente des erreurs sur plus de 1060 tests. **Phase 8 TERMIN√âE** ajoute des utilitaires de tenseurs avanc√©s incluant des op√©rations conditionnelles, l'indexation et les fonctions statistiques. **Phase 9 TERMIN√âE** introduit un syst√®me de s√©rialisation complet avec sauvegarde/chargement de mod√®les, compilation JIT et support de formats multiples incluant la compatibilit√© PyTorch.

## üèóÔ∏è Architecture de Base

### Structure des Modules

```
rustorch/
‚îú‚îÄ‚îÄ tensor/              # Op√©rations de tenseurs de base et structures de donn√©es
‚îú‚îÄ‚îÄ nn/                  # Couches et fonctions de r√©seaux de neurones
‚îú‚îÄ‚îÄ autograd/            # Moteur de diff√©rentiation automatique
‚îú‚îÄ‚îÄ optim/               # Optimiseurs et planificateurs de taux d'apprentissage
‚îú‚îÄ‚îÄ special/             # Fonctions math√©matiques sp√©ciales
‚îú‚îÄ‚îÄ distributions/       # Distributions statistiques
‚îú‚îÄ‚îÄ vision/              # Transformations de vision par ordinateur
‚îú‚îÄ‚îÄ linalg/              # Op√©rations d'alg√®bre lin√©aire (BLAS/LAPACK)
‚îú‚îÄ‚îÄ gpu/                 # Acc√©l√©ration GPU (CUDA/Metal/OpenCL/WebGPU)
‚îú‚îÄ‚îÄ sparse/              # Op√©rations de tenseurs creux et √©lagage (Phase 12)
‚îú‚îÄ‚îÄ serialization/       # S√©rialisation de mod√®les et compilation JIT (Phase 9)
‚îî‚îÄ‚îÄ wasm/                # Liaisons WebAssembly (voir [Documentation API WASM](WASM_API_DOCUMENTATION.md))
```

## üìä Module Tensor

### Cr√©ation de Tenseurs de Base

```rust
use rustorch::tensor::Tensor;

// Cr√©ation de base
let tensor = Tensor::new(vec![2, 3]);               // Cr√©ation bas√©e sur la forme
let tensor = Tensor::from_vec(data, vec![2, 3]);    // √Ä partir d'un vecteur de donn√©es
let tensor = Tensor::zeros(vec![10, 10]);           // Tenseur rempli de z√©ros
let tensor = Tensor::ones(vec![5, 5]);              // Tenseur rempli de uns
let tensor = Tensor::randn(vec![3, 3]);             // Distribution normale al√©atoire
let tensor = Tensor::rand(vec![3, 3]);              // Distribution uniforme al√©atoire [0,1)
let tensor = Tensor::eye(5);                        // Matrice identit√©
let tensor = Tensor::full(vec![2, 2], 3.14);       // Remplit avec une valeur sp√©cifique
let tensor = Tensor::arange(0.0, 10.0, 1.0);       // Tenseur de plage
let tensor = Tensor::linspace(0.0, 1.0, 100);      // Espacement lin√©aire
```

### Op√©rations de Tenseurs

```rust
// Op√©rations arithm√©tiques
let result = a.add(&b);                             // Addition √©l√©ment par √©l√©ment
let result = a.sub(&b);                             // Soustraction √©l√©ment par √©l√©ment
let result = a.mul(&b);                             // Multiplication √©l√©ment par √©l√©ment
let result = a.div(&b);                             // Division √©l√©ment par √©l√©ment
let result = a.pow(&b);                             // Puissance √©l√©ment par √©l√©ment
let result = a.rem(&b);                             // Reste √©l√©ment par √©l√©ment

// Op√©rations matricielles
let result = a.matmul(&b);                          // Multiplication matricielle
let result = a.transpose();                         // Transposition matricielle
let result = a.dot(&b);                             // Produit scalaire

// Fonctions math√©matiques
let result = tensor.exp();                          // Exponentielle
let result = tensor.ln();                           // Logarithme naturel
let result = tensor.log10();                        // Logarithme base 10
let result = tensor.sqrt();                         // Racine carr√©e
let result = tensor.abs();                          // Valeur absolue
let result = tensor.sin();                          // Fonction sinus
let result = tensor.cos();                          // Fonction cosinus
let result = tensor.tan();                          // Fonction tangente
let result = tensor.asin();                         // Arcsinus
let result = tensor.acos();                         // Arccosinus
let result = tensor.atan();                         // Arctangente
let result = tensor.sinh();                         // Sinus hyperbolique
let result = tensor.cosh();                         // Cosinus hyperbolique
let result = tensor.tanh();                         // Tangente hyperbolique
let result = tensor.floor();                        // Fonction plancher
let result = tensor.ceil();                         // Fonction plafond
let result = tensor.round();                        // Fonction arrondir
let result = tensor.sign();                         // Fonction signe
let result = tensor.max();                          // Valeur maximale
let result = tensor.min();                          // Valeur minimale
let result = tensor.sum();                          // Somme de tous les √©l√©ments
let result = tensor.mean();                         // Valeur moyenne
let result = tensor.std();                          // √âcart-type
let result = tensor.var();                          // Variance

// Manipulation de forme
let result = tensor.reshape(vec![6, 4]);            // Redimensionner le tenseur
let result = tensor.squeeze();                      // Supprimer les dimensions de taille 1
let result = tensor.unsqueeze(1);                   // Ajouter une dimension √† l'index
let result = tensor.permute(vec![1, 0, 2]);         // Permuter les dimensions
let result = tensor.expand(vec![10, 10, 5]);        // √âtendre les dimensions du tenseur
```

## üß† Module Neural Network (nn)

### Couches de Base

```rust
use rustorch::nn::{Linear, Conv2d, BatchNorm1d, Dropout};

// Couche lin√©aire
let linear = Linear::new(784, 256)?;                // entr√©e 784, sortie 256
let output = linear.forward(&input)?;

// Couche de convolution
let conv = Conv2d::new(3, 64, 3, None, Some(1))?; // in_channels=3, out_channels=64, kernel_size=3
let output = conv.forward(&input)?;

// Normalisation par lots
let bn = BatchNorm1d::new(256)?;
let normalized = bn.forward(&input)?;

// Dropout
let dropout = Dropout::new(0.5)?;
let output = dropout.forward(&input, true)?;       // training=true
```

### Fonctions d'Activation

```rust
use rustorch::nn::{ReLU, Sigmoid, Tanh, LeakyReLU, ELU, GELU};

// Fonctions d'activation de base
let relu = ReLU::new();
let sigmoid = Sigmoid::new();
let tanh = Tanh::new();

// Fonctions d'activation param√©tr√©es
let leaky_relu = LeakyReLU::new(0.01)?;
let elu = ELU::new(1.0)?;
let gelu = GELU::new();

// Exemple d'utilisation
let activated = relu.forward(&input)?;
```

## üöÄ Module d'Acc√©l√©ration GPU

### Gestion des Dispositifs

```rust
use rustorch::gpu::{Device, get_device_count, set_device};

// V√©rifier les dispositifs disponibles
let device_count = get_device_count()?;
let device = Device::best_available()?;            // S√©lection du meilleur dispositif

// Configuration du dispositif
set_device(&device)?;

// D√©placer le tenseur vers GPU
let gpu_tensor = tensor.to_device(&device)?;
```

### Op√©rations CUDA

```rust
#[cfg(feature = "cuda")]
use rustorch::gpu::cuda::{CudaDevice, memory_stats};

// Op√©rations de dispositif CUDA
let cuda_device = CudaDevice::new(0)?;              // Utiliser GPU 0
let stats = memory_stats(0)?;                      // Statistiques m√©moire
println!("M√©moire utilis√©e: {} MB", stats.used_memory / (1024 * 1024));
```

### Op√©rations Metal (macOS)

```rust
#[cfg(feature = "metal")]
use rustorch::gpu::metal::MetalDevice;

// Op√©rations de dispositif Metal
let metal_device = MetalDevice::new()?;
let gpu_tensor = tensor.to_metal(&metal_device)?;
```

## üéØ Module Optimiseur (Optim)

### Optimiseurs de Base

```rust
use rustorch::optim::{Adam, SGD, RMSprop, AdamW};

// Optimiseur Adam
let mut optimizer = Adam::new(vec![x.clone(), y.clone()], 0.001, 0.9, 0.999, 1e-8)?;

// Optimiseur SGD
let mut sgd = SGD::new(vec![x.clone()], 0.01, 0.9, 1e-4)?;

// √âtape d'optimisation
optimizer.zero_grad()?;
// ... calcul en avant et r√©tropropagation ...
optimizer.step()?;
```

### Planificateurs de Taux d'Apprentissage

```rust
use rustorch::optim::scheduler::{StepLR, CosineAnnealingLR, ReduceLROnPlateau};

// Planificateur √† √©tapes
let step_scheduler = StepLR::new(&mut optimizer, 10, 0.1)?;

// Recuit cosinus
let cosine_scheduler = CosineAnnealingLR::new(&mut optimizer, 100)?;

// R√©duction sur plateau
let plateau_scheduler = ReduceLROnPlateau::new(&mut optimizer, "min", 0.1, 10)?;

// Utilisation du planificateur
step_scheduler.step()?;
plateau_scheduler.step(validation_loss)?;
```

## üíæ Module de S√©rialisation (Phase 9)

### Sauvegarde et Chargement de Mod√®les

```rust
use rustorch::serialization::{save_model, load_model, ModelFormat};

// Sauvegarde de mod√®le
save_model(&model, "model.pt", ModelFormat::PyTorch)?;
save_model(&model, "model.rustorch", ModelFormat::Native)?;

// Chargement de mod√®le
let loaded_model = load_model("model.pt", ModelFormat::PyTorch)?;
let native_model = load_model("model.rustorch", ModelFormat::Native)?;
```

### Compilation JIT

```rust
use rustorch::serialization::jit::{trace, script, JitModule};

// JIT bas√© sur tra√ßage
let traced_module = trace(&model, &example_input)?;
let output = traced_module.forward(&input)?;

// JIT bas√© sur script
let scripted = script(&model)?;
let optimized_output = scripted.forward(&input)?;
```

## üî¢ Module d'Alg√®bre Lin√©aire (Linalg)

### Op√©rations de D√©composition

```rust
use rustorch::linalg::{svd, qr, eig, cholesky, lu};

// D√©composition en valeurs singuli√®res
let (u, s, vt) = svd(&tensor, true)?;              // full_matrices=true

// D√©composition QR
let (q, r) = qr(&tensor, "reduced")?;

// D√©composition en valeurs propres
let (eigenvalues, eigenvectors) = eig(&tensor)?;

// D√©composition de Cholesky
let l = cholesky(&tensor)?;

// D√©composition LU
let (p, l, u) = lu(&tensor)?;
```

## üìñ Exemple d'Utilisation

### R√©gression Lin√©aire

```rust
use rustorch::{tensor::Tensor, nn::Linear, optim::Adam, autograd::Variable};

// Pr√©paration des donn√©es
let x = Variable::new(Tensor::randn(vec![100, 1]), false)?;
let y = Variable::new(Tensor::randn(vec![100, 1]), false)?;

// D√©finition du mod√®le
let mut model = Linear::new(1, 1)?;
let mut optimizer = Adam::new(model.parameters(), 0.001, 0.9, 0.999, 1e-8)?;

// Boucle d'entra√Ænement
for epoch in 0..1000 {
    optimizer.zero_grad()?;
    let pred = model.forward(&x)?;
    let loss = (pred - &y).pow(&Tensor::from(2.0))?.mean()?;
    backward(&loss, true)?;
    optimizer.step()?;
    
    if epoch % 100 == 0 {
        println!("√âpoque {}: Perte = {:.4}", epoch, loss.item::<f32>()?);
    }
}
```

## ‚ö†Ô∏è Limitations Connues

1. **Limitation m√©moire GPU**: La gestion explicite de la m√©moire est requise pour les gros tenseurs (>8GB)
2. **Limitation WebAssembly**: Certaines op√©rations BLAS ne sont pas disponibles dans l'environnement WASM
3. **Apprentissage distribu√©**: Le backend NCCL n'est support√© que sur Linux
4. **Limitation Metal**: Certaines op√©rations avanc√©es ne sont disponibles qu'avec le backend CUDA

## üîó Liens Connexes

- [README Principal](../README.md)
- [Documentation API WASM](WASM_API_DOCUMENTATION.md)
- [Guide Jupyter](jupyter-guide.md)
- [D√©p√¥t GitHub](https://github.com/JunSuzukiJapan/RusTorch)
- [Package Crates.io](https://crates.io/crates/rustorch)

---

**Derni√®re Mise √† Jour**: v0.5.15 | **Licence**: MIT | **Auteur**: Jun Suzuki