# RusTorch API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

## ğŸ“š å®Œå…¨API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€RusTorch v0.5.15ã®åŒ…æ‹¬çš„ãªAPIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã€ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨æ©Ÿèƒ½åˆ¥ã«æ•´ç†ã—ã¦æä¾›ã—ã¦ã„ã¾ã™ã€‚ã™ã¹ã¦ã®1060ä»¥ä¸Šã®ãƒ†ã‚¹ãƒˆã«ã‚ãŸã£ã¦ä¸€è²«ã—ãŸã‚¨ãƒ©ãƒ¼ç®¡ç†ã®ãŸã‚ã«ã€`RusTorchError`ã¨`RusTorchResult<T>`ã«ã‚ˆã‚‹çµ±ä¸€ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æ©Ÿèƒ½ãŒã‚ã‚Šã¾ã™ã€‚**Phase 8å®Œäº†**ã«ã‚ˆã‚Šã€æ¡ä»¶æ¼”ç®—ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ“ä½œã€çµ±è¨ˆé–¢æ•°ã‚’å«ã‚€é«˜åº¦ãªãƒ†ãƒ³ã‚½ãƒ«ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸã€‚**Phase 9å®Œäº†**ã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ä¿å­˜/èª­ã¿è¾¼ã¿ã€JITã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã€PyTorchäº’æ›æ€§ã‚’å«ã‚€è¤‡æ•°å½¢å¼ã‚µãƒãƒ¼ãƒˆã®åŒ…æ‹¬çš„ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ãŒå°å…¥ã•ã‚Œã¾ã—ãŸã€‚

## ğŸ—ï¸ ã‚³ã‚¢ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹æˆ

```
rustorch/
â”œâ”€â”€ tensor/              # ã‚³ã‚¢ãƒ†ãƒ³ã‚½ãƒ«æ“ä½œã¨ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
â”œâ”€â”€ nn/                  # ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨é–¢æ•°
â”œâ”€â”€ autograd/            # è‡ªå‹•å¾®åˆ†ã‚¨ãƒ³ã‚¸ãƒ³
â”œâ”€â”€ optim/               # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã¨å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼
â”œâ”€â”€ special/             # ç‰¹æ®Šæ•°å­¦é–¢æ•°
â”œâ”€â”€ distributions/       # çµ±è¨ˆåˆ†å¸ƒ
â”œâ”€â”€ vision/              # ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³å¤‰æ›
â”œâ”€â”€ linalg/              # ç·šå½¢ä»£æ•°æ¼”ç®— (BLAS/LAPACK)
â”œâ”€â”€ gpu/                 # GPUåŠ é€Ÿ (CUDA/Metal/OpenCL/WebGPU)
â”œâ”€â”€ sparse/              # ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ†ãƒ³ã‚½ãƒ«æ¼”ç®—ã¨ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚° (Phase 12)
â”œâ”€â”€ serialization/       # ãƒ¢ãƒ‡ãƒ«ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã¨JITã‚³ãƒ³ãƒ‘ã‚¤ãƒ« (Phase 9)
â””â”€â”€ wasm/                # WebAssemblyãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚° ([WASM APIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](WASM_API_DOCUMENTATION.md)ã‚’å‚ç…§)
```

## ğŸ“Š Tensorãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### ã‚³ã‚¢ãƒ†ãƒ³ã‚½ãƒ«ä½œæˆ

```rust
use rustorch::tensor::Tensor;

// åŸºæœ¬ä½œæˆ
let tensor = Tensor::new(vec![2, 3]);               // å½¢çŠ¶ãƒ™ãƒ¼ã‚¹ä½œæˆ
let tensor = Tensor::from_vec(data, vec![2, 3]);    // ãƒ‡ãƒ¼ã‚¿ãƒ™ã‚¯ã‚¿ãƒ¼ã‹ã‚‰ä½œæˆ
let tensor = Tensor::zeros(vec![10, 10]);           // ã‚¼ãƒ­åŸ‹ã‚ãƒ†ãƒ³ã‚½ãƒ«
let tensor = Tensor::ones(vec![5, 5]);              // ãƒ¯ãƒ³åŸ‹ã‚ãƒ†ãƒ³ã‚½ãƒ«
let tensor = Tensor::randn(vec![3, 3]);             // ãƒ©ãƒ³ãƒ€ãƒ æ­£è¦åˆ†å¸ƒ
let tensor = Tensor::rand(vec![3, 3]);              // ãƒ©ãƒ³ãƒ€ãƒ ä¸€æ§˜åˆ†å¸ƒ [0,1)
let tensor = Tensor::eye(5);                        // å˜ä½è¡Œåˆ—
let tensor = Tensor::full(vec![2, 2], 3.14);       // ç‰¹å®šå€¤ã§åŸ‹ã‚ã‚‹
let tensor = Tensor::arange(0.0, 10.0, 1.0);       // ç¯„å›²ãƒ†ãƒ³ã‚½ãƒ«
let tensor = Tensor::linspace(0.0, 1.0, 100);      // ç·šå½¢ã‚¹ãƒšãƒ¼ã‚·ãƒ³ã‚°
```

### ãƒ†ãƒ³ã‚½ãƒ«æ¼”ç®—

```rust
// ç®—è¡“æ¼”ç®—
let result = a.add(&b);                             // è¦ç´ ã”ã¨ã®åŠ ç®—
let result = a.sub(&b);                             // è¦ç´ ã”ã¨ã®æ¸›ç®—
let result = a.mul(&b);                             // è¦ç´ ã”ã¨ã®ä¹—ç®—
let result = a.div(&b);                             // è¦ç´ ã”ã¨ã®é™¤ç®—
let result = a.pow(&b);                             // è¦ç´ ã”ã¨ã®ç´¯ä¹—
let result = a.rem(&b);                             // è¦ç´ ã”ã¨ã®ä½™ã‚Š

// è¡Œåˆ—æ¼”ç®—
let result = a.matmul(&b);                          // è¡Œåˆ—ç©
let result = a.transpose();                         // è¡Œåˆ—è»¢ç½®
let result = a.dot(&b);                             // ãƒ‰ãƒƒãƒˆç©

// æ•°å­¦é–¢æ•°
let result = tensor.exp();                          // æŒ‡æ•°
let result = tensor.ln();                           // è‡ªç„¶å¯¾æ•°
let result = tensor.log10();                        // å¸¸ç”¨å¯¾æ•°
let result = tensor.sqrt();                         // å¹³æ–¹æ ¹
let result = tensor.abs();                          // çµ¶å¯¾å€¤
let result = tensor.sin();                          // ã‚µã‚¤ãƒ³é–¢æ•°
let result = tensor.cos();                          // ã‚³ã‚µã‚¤ãƒ³é–¢æ•°
let result = tensor.tan();                          // ã‚¿ãƒ³ã‚¸ã‚§ãƒ³ãƒˆé–¢æ•°
let result = tensor.asin();                         // ã‚¢ãƒ¼ã‚¯ã‚µã‚¤ãƒ³
let result = tensor.acos();                         // ã‚¢ãƒ¼ã‚¯ã‚³ã‚µã‚¤ãƒ³
let result = tensor.atan();                         // ã‚¢ãƒ¼ã‚¯ã‚¿ãƒ³ã‚¸ã‚§ãƒ³ãƒˆ
let result = tensor.sinh();                         // åŒæ›²ç·šã‚µã‚¤ãƒ³
let result = tensor.cosh();                         // åŒæ›²ç·šã‚³ã‚µã‚¤ãƒ³
let result = tensor.tanh();                         // åŒæ›²ç·šã‚¿ãƒ³ã‚¸ã‚§ãƒ³ãƒˆ
let result = tensor.floor();                        // ãƒ•ãƒ­ã‚¢é–¢æ•°
let result = tensor.ceil();                         // ã‚·ãƒ¼ãƒªãƒ³ã‚°é–¢æ•°
let result = tensor.round();                        // ãƒ©ã‚¦ãƒ³ãƒ‰é–¢æ•°
let result = tensor.sign();                         // ç¬¦å·é–¢æ•°
let result = tensor.max();                          // æœ€å¤§å€¤
let result = tensor.min();                          // æœ€å°å€¤
let result = tensor.sum();                          // å…¨è¦ç´ ã®åˆè¨ˆ
let result = tensor.mean();                         // å¹³å‡å€¤
let result = tensor.std();                          // æ¨™æº–åå·®
let result = tensor.var();                          // åˆ†æ•£

// å½¢çŠ¶æ“ä½œ
let result = tensor.reshape(vec![6, 4]);            // ãƒ†ãƒ³ã‚½ãƒ«å†å½¢æˆ
let result = tensor.squeeze();                      // ã‚µã‚¤ã‚º1æ¬¡å…ƒã®é™¤å»
let result = tensor.unsqueeze(1);                   // æŒ‡å®šã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«æ¬¡å…ƒè¿½åŠ 
let result = tensor.permute(vec![1, 0, 2]);         // æ¬¡å…ƒã®é †åˆ—
let result = tensor.expand(vec![10, 10, 5]);        // ãƒ†ãƒ³ã‚½ãƒ«æ¬¡å…ƒã®æ‹¡å¼µ

// é«˜åº¦ãªå½¢çŠ¶æ“ä½œ (Phase 1)
let result = tensor.squeeze_dim(1);                 // ç‰¹å®šã®ã‚µã‚¤ã‚º1æ¬¡å…ƒã®é™¤å»
let result = tensor.flatten_owned();                // 1Dãƒ†ãƒ³ã‚½ãƒ«ã«å¹³å¦åŒ–
let result = tensor.flatten_range(1, Some(3));      // æ¬¡å…ƒ1-3ã®å¹³å¦åŒ–
let result = tensor.unflatten(0, &[2, 3]);         // å¹³å¦åŒ–ã®é€†æ“ä½œ
```

### ãƒ†ãƒ³ã‚½ãƒ«çµåˆæ“ä½œ (Phase 2)

```rust
// ãƒ†ãƒ³ã‚½ãƒ«é€£çµ
let result = Tensor::cat(&[a, b, c], 0)?;           // è»¸0ã§ãƒ†ãƒ³ã‚½ãƒ«é€£çµ
let result = Tensor::stack(&[a, b, c], 1)?;         // è»¸1ã§ãƒ†ãƒ³ã‚½ãƒ«ã‚¹ã‚¿ãƒƒã‚¯
let (a, b) = tensor.chunk(2, 0)?;                  // ãƒ†ãƒ³ã‚½ãƒ«ã‚’2ã¤ã«åˆ†å‰²
let (a, b, c) = tensor.split(&[2, 3, 5], 0)?;     // æŒ‡å®šã‚µã‚¤ã‚ºã§åˆ†å‰²

// é«˜åº¦ãªçµåˆæ“ä½œ
let result = tensor.repeat(&[2, 3]);               // æŒ‡å®šå›æ•°ã§ç¹°ã‚Šè¿”ã—
let result = tensor.tile(&[2, 3]);                 // ã‚¿ã‚¤ãƒ«é…ç½®
```

### é«˜åº¦ãªãƒ†ãƒ³ã‚½ãƒ«æ“ä½œ (Phase 8)

```rust
use rustorch::tensor::{IndexSelect, ConditionOps};

// æ¡ä»¶æ“ä½œ
let result = a.where_condition(&mask, &b)?;        // æ¡ä»¶ãƒ™ãƒ¼ã‚¹é¸æŠ
let mask = tensor.gt(0.5)?;                        // æ¡ä»¶ãƒã‚¹ã‚¯ä½œæˆ
let indices = tensor.nonzero()?;                   // ã‚¼ãƒ­ä»¥å¤–ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
let result = tensor.masked_select(&mask)?;         // ãƒã‚¹ã‚¯ã«ã‚ˆã‚‹é¸æŠ

// ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ“ä½œ
let result = tensor.index_select(0, &indices)?;    // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é¸æŠ
let result = tensor.gather(1, &indices)?;          // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åé›†
let result = tensor.scatter(1, &indices, &values)?; // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•£å¸ƒ

// çµ±è¨ˆé–¢æ•°
let result = tensor.median(0)?;                    // ä¸­å¤®å€¤è¨ˆç®—
let result = tensor.mode(0)?;                      // æœ€é »å€¤è¨ˆç®—
let (values, indices) = tensor.sort(0, false)?;    // ã‚½ãƒ¼ãƒˆæ“ä½œ
let (values, indices) = tensor.topk(3, 0, true)?;  // ãƒˆãƒƒãƒ—Kå€¤
```

## ğŸ§  Neural Network (nn) ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### åŸºæœ¬ãƒ¬ã‚¤ãƒ¤ãƒ¼

```rust
use rustorch::nn::{Linear, Conv2d, BatchNorm1d, Dropout};

// ç·šå½¢ãƒ¬ã‚¤ãƒ¤ãƒ¼
let linear = Linear::new(784, 256)?;                // å…¥åŠ›784ã€å‡ºåŠ›256
let output = linear.forward(&input)?;

// ç•³ã¿è¾¼ã¿ãƒ¬ã‚¤ãƒ¤ãƒ¼
let conv = Conv2d::new(3, 64, 3, None, Some(1))?; // in_channels=3, out_channels=64, kernel_size=3
let output = conv.forward(&input)?;

// ãƒãƒƒãƒæ­£è¦åŒ–
let bn = BatchNorm1d::new(256)?;
let normalized = bn.forward(&input)?;

// ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ
let dropout = Dropout::new(0.5)?;
let output = dropout.forward(&input, true)?;       // training=true
```

### æ´»æ€§åŒ–é–¢æ•°

```rust
use rustorch::nn::{ReLU, Sigmoid, Tanh, LeakyReLU, ELU, GELU};

// åŸºæœ¬æ´»æ€§åŒ–é–¢æ•°
let relu = ReLU::new();
let sigmoid = Sigmoid::new();
let tanh = Tanh::new();

// ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»˜ãæ´»æ€§åŒ–é–¢æ•°
let leaky_relu = LeakyReLU::new(0.01)?;
let elu = ELU::new(1.0)?;
let gelu = GELU::new();

// ä½¿ç”¨ä¾‹
let activated = relu.forward(&input)?;
```

### æå¤±é–¢æ•°

```rust
use rustorch::nn::{CrossEntropyLoss, MSELoss, BCELoss};

// åˆ†é¡ç”¨æå¤±é–¢æ•°
let ce_loss = CrossEntropyLoss::new(None, None)?;
let loss = ce_loss.forward(&predictions, &targets)?;

// å›å¸°ç”¨æå¤±é–¢æ•°
let mse_loss = MSELoss::new("mean")?;
let loss = mse_loss.forward(&predictions, &targets)?;

// ãƒã‚¤ãƒŠãƒªåˆ†é¡ç”¨æå¤±é–¢æ•°
let bce_loss = BCELoss::new(None, "mean")?;
let loss = bce_loss.forward(&predictions, &targets)?;
```

### Transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ (Phase 6)

```rust
use rustorch::nn::{MultiHeadAttention, TransformerBlock, PositionalEncoding};

// ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³
let attention = MultiHeadAttention::new(512, 8, 0.1)?; // d_model=512, num_heads=8
let output = attention.forward(&query, &key, &value, None)?;

// Transformerãƒ–ãƒ­ãƒƒã‚¯
let transformer = TransformerBlock::new(512, 2048, 8, 0.1)?;
let output = transformer.forward(&input, None)?;

// ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
let pos_encoding = PositionalEncoding::new(512, 1000)?;
let encoded = pos_encoding.forward(&input)?;
```

## ğŸ”„ è‡ªå‹•å¾®åˆ† (Autograd) ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### åŸºæœ¬å¾®åˆ†æ“ä½œ

```rust
use rustorch::autograd::{Variable, backward};

// å¤‰æ•°ä½œæˆï¼ˆå‹¾é…è¨ˆç®—ã‚’æœ‰åŠ¹åŒ–ï¼‰
let x = Variable::new(Tensor::randn(vec![5, 5]), true)?;
let y = Variable::new(Tensor::randn(vec![5, 5]), true)?;

// å‰é€²è¨ˆç®—
let z = x.matmul(&y)?;
let loss = z.sum()?;

// é€†ä¼æ’­
backward(&loss, true)?;

// å‹¾é…ã‚¢ã‚¯ã‚»ã‚¹
let x_grad = x.grad()?;
let y_grad = y.grad()?;
```

### å‹¾é…ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½

```rust
use rustorch::autograd::gradcheck;

// æ•°å€¤å‹¾é…ã¨ã®æ¯”è¼ƒã«ã‚ˆã‚‹å‹¾é…ãƒã‚§ãƒƒã‚¯
let inputs = vec![
    Variable::new(Tensor::randn(vec![3, 3]), true)?,
];

let check_passed = gradcheck(
    |inputs| inputs[0].matmul(&inputs[0].transpose()),
    &inputs,
    1e-5,  // ç›¸å¯¾è¨±å®¹èª¤å·®
    1e-4,  // çµ¶å¯¾è¨±å®¹èª¤å·®
)?;
```

## ğŸ¯ ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ (Optim) ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### åŸºæœ¬ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼

```rust
use rustorch::optim::{Adam, SGD, RMSprop, AdamW};

// Adamã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼
let mut optimizer = Adam::new(vec![x.clone(), y.clone()], 0.001, 0.9, 0.999, 1e-8)?;

// SGDã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼  
let mut sgd = SGD::new(vec![x.clone()], 0.01, 0.9, 1e-4)?;

// æœ€é©åŒ–ã‚¹ãƒ†ãƒƒãƒ—
optimizer.zero_grad()?;
// ... å‰é€²è¨ˆç®—ã¨é€†ä¼æ’­ ...
optimizer.step()?;
```

### å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼

```rust
use rustorch::optim::scheduler::{StepLR, CosineAnnealingLR, ReduceLROnPlateau};

// ã‚¹ãƒ†ãƒƒãƒ—å­¦ç¿’ç‡æ¸›è¡°
let step_scheduler = StepLR::new(&mut optimizer, 10, 0.1)?;

// ã‚³ã‚µã‚¤ãƒ³ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°
let cosine_scheduler = CosineAnnealingLR::new(&mut optimizer, 100)?;

// ãƒ—ãƒ©ãƒˆãƒ¼æ™‚å­¦ç¿’ç‡æ¸›å°‘
let plateau_scheduler = ReduceLROnPlateau::new(&mut optimizer, "min", 0.1, 10)?;

// ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ä½¿ç”¨
step_scheduler.step()?;
plateau_scheduler.step(validation_loss)?;
```

## ğŸ”¢ ç‰¹æ®Šæ•°å­¦é–¢æ•° (Special) ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### ã‚¬ãƒ³ãƒé–¢æ•°ã¨ãƒ™ãƒ¼ã‚¿é–¢æ•°

```rust
use rustorch::special::{gamma, lgamma, beta, digamma, polygamma};

let result = gamma(&tensor)?;                       // ã‚¬ãƒ³ãƒé–¢æ•°
let result = lgamma(&tensor)?;                      // å¯¾æ•°ã‚¬ãƒ³ãƒé–¢æ•°
let result = beta(&a, &b)?;                         // ãƒ™ãƒ¼ã‚¿é–¢æ•°
let result = digamma(&tensor)?;                     // ãƒ‡ã‚£ã‚¬ãƒ³ãƒé–¢æ•°
let result = polygamma(2, &tensor)?;                // ãƒãƒªã‚¬ãƒ³ãƒé–¢æ•°
```

### ãƒ™ãƒƒã‚»ãƒ«é–¢æ•°

```rust
use rustorch::special::{i0, i1, j0, j1, y0, y1};

let result = i0(&tensor)?;                          // ç¬¬1ç¨®å¤‰å½¢ãƒ™ãƒƒã‚»ãƒ«é–¢æ•° I0
let result = i1(&tensor)?;                          // ç¬¬1ç¨®å¤‰å½¢ãƒ™ãƒƒã‚»ãƒ«é–¢æ•° I1
let result = j0(&tensor)?;                          // ç¬¬1ç¨®ãƒ™ãƒƒã‚»ãƒ«é–¢æ•° J0
let result = j1(&tensor)?;                          // ç¬¬1ç¨®ãƒ™ãƒƒã‚»ãƒ«é–¢æ•° J1
let result = y0(&tensor)?;                          // ç¬¬2ç¨®ãƒ™ãƒƒã‚»ãƒ«é–¢æ•° Y0
let result = y1(&tensor)?;                          // ç¬¬2ç¨®ãƒ™ãƒƒã‚»ãƒ«é–¢æ•° Y1
```

## ğŸ“Š åˆ†å¸ƒ (Distributions) ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### åŸºæœ¬åˆ†å¸ƒ

```rust
use rustorch::distributions::{Normal, Uniform, Categorical, Bernoulli};

// æ­£è¦åˆ†å¸ƒ
let normal = Normal::new(0.0, 1.0)?;
let sample = normal.sample(&[100])?;
let log_prob = normal.log_prob(&sample)?;

// ä¸€æ§˜åˆ†å¸ƒ
let uniform = Uniform::new(0.0, 1.0)?;
let sample = uniform.sample(&[50])?;

// ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«åˆ†å¸ƒ
let probs = Tensor::new(vec![0.3, 0.4, 0.3])?;
let categorical = Categorical::new_probs(&probs)?;
let sample = categorical.sample(&[10])?;

// ãƒ™ãƒ«ãƒŒãƒ¼ã‚¤åˆ†å¸ƒ
let bernoulli = Bernoulli::new_probs(&Tensor::new(vec![0.7])?)?;
let sample = bernoulli.sample(&[20])?;
```

## ğŸ–¼ï¸ ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ (Vision) ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### ç”»åƒå¤‰æ›

```rust
use rustorch::vision::transforms::{
    Compose, Resize, CenterCrop, RandomCrop, RandomHorizontalFlip,
    Normalize, ToTensor, ColorJitter
};

// å¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
let transform = Compose::new(vec![
    Box::new(Resize::new(256)),
    Box::new(RandomCrop::new(224)),
    Box::new(RandomHorizontalFlip::new(0.5)),
    Box::new(ToTensor::new()),
    Box::new(Normalize::new(
        vec![0.485, 0.456, 0.406],  // mean
        vec![0.229, 0.224, 0.225],  // std
    )),
]);

// å¤‰æ›é©ç”¨
let transformed = transform.forward(&input_tensor)?;
```

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

```rust
use rustorch::vision::datasets::{CIFAR10, MNIST, ImageFolder};

// CIFAR-10ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
let cifar10 = CIFAR10::new("./data", true, Some(transform))?;  // train=true
let (image, label) = cifar10.get_item(0)?;

// MNISTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
let mnist = MNIST::new("./data", false, Some(transform))?;     // train=false

// ã‚«ã‚¹ã‚¿ãƒ ç”»åƒãƒ•ã‚©ãƒ«ãƒ€
let dataset = ImageFolder::new("./custom_data", Some(transform))?;
```

## ğŸ”¢ ç·šå½¢ä»£æ•° (Linalg) ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### åˆ†è§£æ“ä½œ

```rust
use rustorch::linalg::{svd, qr, eig, cholesky, lu};

// ç‰¹ç•°å€¤åˆ†è§£
let (u, s, vt) = svd(&tensor, true)?;              // full_matrices=true

// QRåˆ†è§£
let (q, r) = qr(&tensor, "reduced")?;

// å›ºæœ‰å€¤åˆ†è§£
let (eigenvalues, eigenvectors) = eig(&tensor)?;

// ã‚³ãƒ¬ã‚¹ã‚­ãƒ¼åˆ†è§£
let l = cholesky(&tensor)?;

// LUåˆ†è§£
let (p, l, u) = lu(&tensor)?;
```

### ãƒãƒ«ãƒ ã¨è·é›¢

```rust
use rustorch::linalg::{norm, vector_norm, matrix_norm};

let result = norm(&tensor, None, None, false)?;     // ãƒ•ãƒ­ãƒ™ãƒ‹ã‚¦ã‚¹ãƒãƒ«ãƒ 
let result = vector_norm(&tensor, 2.0, &[0], false)?; // L2ãƒãƒ«ãƒ 
let result = matrix_norm(&tensor, "fro", &[0, 1])?; // è¡Œåˆ—ãƒãƒ«ãƒ 
```

## ğŸš€ GPUåŠ é€Ÿãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### ãƒ‡ãƒã‚¤ã‚¹ç®¡ç†

```rust
use rustorch::gpu::{Device, get_device_count, set_device};

// åˆ©ç”¨å¯èƒ½ãƒ‡ãƒã‚¤ã‚¹ç¢ºèª
let device_count = get_device_count()?;
let device = Device::best_available()?;            // æœ€é©ãƒ‡ãƒã‚¤ã‚¹é¸æŠ

// ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
set_device(&device)?;

// ãƒ†ãƒ³ã‚½ãƒ«ã‚’GPUã«ç§»å‹•
let gpu_tensor = tensor.to_device(&device)?;
```

### CUDAæ“ä½œ

```rust
#[cfg(feature = "cuda")]
use rustorch::gpu::cuda::{CudaDevice, memory_stats};

// CUDAãƒ‡ãƒã‚¤ã‚¹æ“ä½œ
let cuda_device = CudaDevice::new(0)?;              // GPU 0ä½¿ç”¨
let stats = memory_stats(0)?;                      // ãƒ¡ãƒ¢ãƒªçµ±è¨ˆ
println!("ä½¿ç”¨ãƒ¡ãƒ¢ãƒª: {} MB", stats.used_memory / (1024 * 1024));
```

### Metalæ“ä½œ (macOS)

```rust
#[cfg(feature = "metal")]
use rustorch::gpu::metal::MetalDevice;

// Metalãƒ‡ãƒã‚¤ã‚¹æ“ä½œ
let metal_device = MetalDevice::new()?;
let gpu_tensor = tensor.to_metal(&metal_device)?;
```

## ğŸ—œï¸ ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ†ãƒ³ã‚½ãƒ« (Sparse) ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (Phase 12)

### COOã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ†ãƒ³ã‚½ãƒ«

```rust
use rustorch::sparse::{SparseTensor, SparseFormat};

// COOå½¢å¼ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ†ãƒ³ã‚½ãƒ«ä½œæˆ
let indices = Tensor::from_vec(vec![0, 1, 2, 0, 1], vec![5])?;
let values = Tensor::from_vec(vec![1.0, 2.0, 3.0, 4.0, 5.0], vec![5])?;
let sparse = SparseTensor::new_coo(indices, values, vec![3, 4])?;

// å¯†ãƒ†ãƒ³ã‚½ãƒ«ã¨ã®æ¼”ç®—
let dense_result = sparse.to_dense()?;
let sparse_result = dense_tensor.to_sparse(SparseFormat::COO)?;
```

### ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°æ“ä½œ

```rust
use rustorch::sparse::pruning::{magnitude_pruning, structured_pruning};

// å¤§ãã•ãƒ™ãƒ¼ã‚¹ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°
let pruned = magnitude_pruning(&tensor, 0.5)?;     // 50%ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°

// æ§‹é€ åŒ–ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°
let pruned = structured_pruning(&tensor, &[1], 0.25)?; // è»¸1ã§25%ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°
```

## ğŸ’¾ ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ (Serialization) ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (Phase 9)

### ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿

```rust
use rustorch::serialization::{save_model, load_model, ModelFormat};

// ãƒ¢ãƒ‡ãƒ«ä¿å­˜
save_model(&model, "model.pt", ModelFormat::PyTorch)?;
save_model(&model, "model.rustorch", ModelFormat::Native)?;

// ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
let loaded_model = load_model("model.pt", ModelFormat::PyTorch)?;
let native_model = load_model("model.rustorch", ModelFormat::Native)?;
```

### JITã‚³ãƒ³ãƒ‘ã‚¤ãƒ«

```rust
use rustorch::serialization::jit::{trace, script, JitModule};

// ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ãƒ™ãƒ¼ã‚¹JIT
let traced_module = trace(&model, &example_input)?;
let output = traced_module.forward(&input)?;

// ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ™ãƒ¼ã‚¹JIT
let scripted = script(&model)?;
let optimized_output = scripted.forward(&input)?;
```

## ğŸŒ WebAssembly (WASM) ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

WebAssemblyã‚µãƒãƒ¼ãƒˆã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€[WASM API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](WASM_API_DOCUMENTATION.md)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

### åŸºæœ¬WASMä½¿ç”¨æ³•

```rust
use rustorch::wasm::{WasmTensor, wasm_ops};

// WASMç’°å¢ƒã§ã®ãƒ†ãƒ³ã‚½ãƒ«ä½œæˆ
let wasm_tensor = WasmTensor::new(vec![2, 3])?;
let result = wasm_ops::matmul(&a, &b)?;
```

## ğŸ”§ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### ã‚¨ãƒ©ãƒ¼å‹

```rust
use rustorch::error::{RusTorchError, RusTorchResult};

// ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä¾‹
match tensor_operation() {
    Ok(result) => println!("æˆåŠŸ: {:?}", result),
    Err(RusTorchError::InvalidShape(msg)) => eprintln!("å½¢çŠ¶ã‚¨ãƒ©ãƒ¼: {}", msg),
    Err(RusTorchError::IncompatibleDevice(msg)) => eprintln!("ãƒ‡ãƒã‚¤ã‚¹ã‚¨ãƒ©ãƒ¼: {}", msg),
    Err(RusTorchError::ComputationError(msg)) => eprintln!("è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {}", msg),
    Err(e) => eprintln!("ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼: {}", e),
}
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ’ãƒ³ãƒˆ

```rust
// åŠ¹ç‡çš„ãªãƒ†ãƒ³ã‚½ãƒ«æ¼”ç®—
let a = Tensor::zeros(vec![1000, 1000]);
let b = Tensor::ones(vec![1000, 1000]);

// in-placeæ¼”ç®—ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡è‰¯ï¼‰
a.add_(&b)?;                                        // a += b
a.mul_(&scalar_tensor)?;                            // a *= scalar

// GPUä½¿ç”¨æ™‚ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹
let device = Device::best_available()?;
let gpu_a = a.to_device(&device)?;                  // ä¸€åº¦GPUè»¢é€
let gpu_b = b.to_device(&device)?;
let result = gpu_a.matmul(&gpu_b)?;                 // GPUä¸Šã§è¨ˆç®—
let cpu_result = result.to_cpu()?;                  // å¿…è¦æ™‚ã®ã¿CPUè»¢é€
```

## ğŸ“ å®Ÿç”¨ä¾‹ã¨ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«

### ç·šå½¢å›å¸°

```rust
use rustorch::{tensor::Tensor, nn::Linear, optim::Adam, autograd::Variable};

// ãƒ‡ãƒ¼ã‚¿æº–å‚™
let x = Variable::new(Tensor::randn(vec![100, 1]), false)?;
let y = Variable::new(Tensor::randn(vec![100, 1]), false)?;

// ãƒ¢ãƒ‡ãƒ«å®šç¾©
let mut model = Linear::new(1, 1)?;
let mut optimizer = Adam::new(model.parameters(), 0.001, 0.9, 0.999, 1e-8)?;

// è¨“ç·´ãƒ«ãƒ¼ãƒ—
for epoch in 0..1000 {
    optimizer.zero_grad()?;
    let pred = model.forward(&x)?;
    let loss = (pred - &y).pow(&Tensor::from(2.0))?.mean()?;
    backward(&loss, true)?;
    optimizer.step()?;
    
    if epoch % 100 == 0 {
        println!("ã‚¨ãƒãƒƒã‚¯ {}: æå¤± = {:.4}", epoch, loss.item::<f32>()?);
    }
}
```

### ç”»åƒåˆ†é¡CNN

```rust
use rustorch::nn::{Conv2d, MaxPool2d, Linear, ReLU, Dropout};

pub struct SimpleCNN {
    conv1: Conv2d,
    conv2: Conv2d,
    pool: MaxPool2d,
    fc1: Linear,
    fc2: Linear,
    relu: ReLU,
    dropout: Dropout,
}

impl SimpleCNN {
    pub fn new() -> RusTorchResult<Self> {
        Ok(Self {
            conv1: Conv2d::new(3, 32, 3, Some(1), None)?,
            conv2: Conv2d::new(32, 64, 3, Some(1), None)?,
            pool: MaxPool2d::new(2, Some(2))?,
            fc1: Linear::new(64 * 8 * 8, 128)?,
            fc2: Linear::new(128, 10)?,
            relu: ReLU::new(),
            dropout: Dropout::new(0.5)?,
        })
    }
    
    pub fn forward(&self, x: &Variable) -> RusTorchResult<Variable> {
        let x = self.relu.forward(&self.conv1.forward(x)?)?;
        let x = self.pool.forward(&x)?;
        let x = self.relu.forward(&self.conv2.forward(&x)?)?;
        let x = self.pool.forward(&x)?;
        let x = x.reshape(vec![-1, 64 * 8 * 8])?;
        let x = self.relu.forward(&self.fc1.forward(&x)?)?;
        let x = self.dropout.forward(&x, true)?;
        self.fc2.forward(&x)
    }
}
```

## ğŸ”§ é«˜åº¦ãªæ©Ÿèƒ½

### ã‚«ã‚¹ã‚¿ãƒ æ¼”ç®—å­å®šç¾©

```rust
use rustorch::tensor::Tensor;

impl Tensor<f32> {
    pub fn custom_activation(&self) -> RusTorchResult<Self> {
        // ã‚«ã‚¹ã‚¿ãƒ æ´»æ€§åŒ–é–¢æ•°ï¼šSwish (x * sigmoid(x))
        let sigmoid_x = self.sigmoid()?;
        self.mul(&sigmoid_x)
    }
    
    pub fn gelu_precise(&self) -> RusTorchResult<Self> {
        // ç²¾å¯†GELUå®Ÿè£…
        let half = Tensor::from(0.5)?;
        let one = Tensor::from(1.0)?;
        let sqrt_2_pi = Tensor::from((2.0 / std::f32::consts::PI).sqrt())?;
        
        let tanh_input = &sqrt_2_pi * self * (one + Tensor::from(0.044715)? * self.pow(&Tensor::from(3.0)?)?)?;
        half * self * (one + tanh_input.tanh()?)
    }
}
```

### åˆ†æ•£å­¦ç¿’ã‚µãƒãƒ¼ãƒˆ

```rust
use rustorch::distributed::{init_process_group, all_reduce, DistributedMode};

// åˆ†æ•£å­¦ç¿’åˆæœŸåŒ–
init_process_group("nccl", 0, 4)?;                  // rank=0, world_size=4

// AllReduceæ¼”ç®—
let reduced = all_reduce(&gradients, DistributedMode::Sum)?;
let averaged = reduced.div(&Tensor::from(4.0)?)?;   // å‹¾é…å¹³å‡åŒ–
```

## ğŸ¯ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ä½¿ç”¨

```rust
use rustorch::utils::memory::{MemoryPool, set_memory_strategy};

// ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«è¨­å®š
set_memory_strategy(MemoryStrategy::Pool(1024 * 1024 * 1024))?; // 1GB ãƒ—ãƒ¼ãƒ«

// åŠ¹ç‡çš„ãªãƒ¡ãƒ¢ãƒªä½¿ç”¨
let pool = MemoryPool::new(512 * 1024 * 1024)?;    // 512MB ãƒ—ãƒ¼ãƒ«
let tensor = pool.allocate_tensor(vec![1000, 1000])?;
```

### SIMDæœ€é©åŒ–

```rust
use rustorch::simd::{simd_add, simd_mul, enable_simd};

// SIMDæœ‰åŠ¹åŒ–
enable_simd(true);

// SIMDæ¼”ç®—ï¼ˆè‡ªå‹•çš„ã«ä½¿ç”¨ã•ã‚Œã‚‹ï¼‰
let result = a.add(&b)?;                            // å†…éƒ¨ã§SIMDæœ€é©åŒ–
```

## ğŸ“– API ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°

### å®‰å®šAPI vs å®Ÿé¨“çš„API

```rust
// å®‰å®šAPIï¼ˆæ¨å¥¨ï¼‰
use rustorch::tensor::Tensor;                       // v0.1+ã§å®‰å®š
use rustorch::nn::Linear;                          // v0.2+ã§å®‰å®š

// å®Ÿé¨“çš„APIï¼ˆæ³¨æ„ã—ã¦ä½¿ç”¨ï¼‰
use rustorch::experimental::quantization::*;       // å®Ÿé¨“çš„é‡å­åŒ–
use rustorch::experimental::pruning::*;            // å®Ÿé¨“çš„ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°
```

### éæ¨å¥¨API

```rust
// v0.6.0ã§å‰Šé™¤äºˆå®š
// let tensor = Tensor::legacy_create(data);        // éæ¨å¥¨ï¼šTensor::from_vecã‚’ä½¿ç”¨
// let result = tensor.old_matmul(&other);          // éæ¨å¥¨ï¼štensor.matmulã‚’ä½¿ç”¨
```

## ğŸ› ï¸ ãƒ‡ãƒãƒƒã‚°ã¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°

### ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰

```rust
use rustorch::debug::{set_debug_mode, print_tensor_info, check_gradients};

// ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹åŒ–
set_debug_mode(true);

// ãƒ†ãƒ³ã‚½ãƒ«æƒ…å ±å‡ºåŠ›
print_tensor_info(&tensor);

// å‹¾é…ãƒã‚§ãƒƒã‚¯
check_gradients(&model, &input, &target)?;
```

### ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°

```rust
use rustorch::profiler::{start_profiling, stop_profiling, get_profile_report};

// ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°é–‹å§‹
start_profiling("gpu")?;

// æ¸¬å®šå¯¾è±¡ã‚³ãƒ¼ãƒ‰
let result = model.forward(&input)?;
let loss = criterion.forward(&result, &target)?;

// ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°çµ‚äº†ã¨ãƒ¬ãƒãƒ¼ãƒˆå–å¾—
let report = stop_profiling()?;
println!("å®Ÿè¡Œãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«: {}", report);
```

## âš ï¸ æ—¢çŸ¥ã®åˆ¶é™äº‹é …

1. **GPU ãƒ¡ãƒ¢ãƒªåˆ¶é™**: å¤§å‹ãƒ†ãƒ³ã‚½ãƒ«ï¼ˆ>8GBï¼‰ã§ã¯æ˜ç¤ºçš„ãªãƒ¡ãƒ¢ãƒªç®¡ç†ãŒå¿…è¦
2. **WebAssemblyåˆ¶é™**: ä¸€éƒ¨ã®BLASæ¼”ç®—ã¯WASMç’°å¢ƒã§ã¯åˆ©ç”¨ä¸å¯
3. **åˆ†æ•£å­¦ç¿’**: NCCLãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¯Linuxç’°å¢ƒã§ã®ã¿ã‚µãƒãƒ¼ãƒˆ
4. **Metalåˆ¶é™**: ä¸€éƒ¨ã®é«˜åº¦ãªæ¼”ç®—ã¯CUDAãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã§ã®ã¿åˆ©ç”¨å¯èƒ½

## ğŸ”— é–¢é€£ãƒªãƒ³ã‚¯

- [ãƒ¡ã‚¤ãƒ³README](../README.md)
- [WASM API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](WASM_API_DOCUMENTATION.md)
- [Jupyterã‚¬ã‚¤ãƒ‰](jupyter-guide.md)
- [GitHub ãƒªãƒã‚¸ãƒˆãƒª](https://github.com/JunSuzukiJapan/RusTorch)
- [Crates.io ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸](https://crates.io/crates/rustorch)

---

**æœ€çµ‚æ›´æ–°**: v0.5.15 | **ãƒ©ã‚¤ã‚»ãƒ³ã‚¹**: MIT | **ä½œè€…**: Jun Suzuki