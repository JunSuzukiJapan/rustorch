# RusTorch - Biblioteca de Deep Learning em Rust

[![Crates.io](https://img.shields.io/crates/v/rustorch.svg)](https://crates.io/crates/rustorch)
[![DocumentaÃ§Ã£o](https://docs.rs/rustorch/badge.svg)](https://docs.rs/rustorch)
[![LicenÃ§a](https://img.shields.io/badge/license-MIT%20OR%20Apache--2.0-blue.svg)](https://github.com/JunSuzukiJapan/rustorch)

**RusTorch** Ã© uma biblioteca de deep learning pronta para produÃ§Ã£o, compatÃ­vel com PyTorch, implementada em Rust puro com funÃ§Ãµes matemÃ¡ticas especiais, distribuiÃ§Ãµes estatÃ­sticas, transformadas de Fourier (FFT/RFFT), decomposiÃ§Ã£o de matrizes (SVD/QR/LU/autovalores), diferenciaÃ§Ã£o automÃ¡tica, redes neurais, transformaÃ§Ãµes de visÃ£o computacional, aceleraÃ§Ã£o GPU completa (CUDA/Metal/OpenCL), otimizaÃ§Ãµes SIMD, processamento paralelo, suporte para WebAssembly em navegadores, suporte abrangente para aprendizado distribuÃ­do e validaÃ§Ã£o de desempenho.

## âœ¨ Principais Recursos

### ğŸš€ OperaÃ§Ãµes de Tensor de Alta Performance
- **OperaÃ§Ãµes de Tensor N-dimensional** com interface similar ao PyTorch
- **OtimizaÃ§Ãµes SIMD** para mÃ¡xima performance da CPU
- **Processamento Paralelo** usando Rayon para operaÃ§Ãµes em lote
- **Gerenciamento Inteligente de MemÃ³ria** com alocaÃ§Ã£o otimizada

### ğŸ§® MatemÃ¡tica AvanÃ§ada
- **FunÃ§Ãµes Especiais**: Gamma, Bessel, funÃ§Ãµes de erro, integrais elÃ­pticas
- **DistribuiÃ§Ãµes EstatÃ­sticas**: Normal, Exponencial, Gamma, Beta, e mais
- **Transformadas de Fourier**: FFT/RFFT implementadas com algoritmos otimizados
- **DecomposiÃ§Ã£o de Matrizes**: SVD, QR, LU, decomposiÃ§Ã£o de autovalores

### ğŸ¤– Deep Learning Completo
- **DiferenciaÃ§Ã£o AutomÃ¡tica** com grafo de computaÃ§Ã£o dinÃ¢mico
- **Camadas de Redes Neurais**: Linear, Convolucional, LSTM, Attention
- **FunÃ§Ãµes de AtivaÃ§Ã£o**: ReLU, Sigmoid, Tanh, GELU, Swish, e mais
- **Algoritmos de OtimizaÃ§Ã£o**: Adam, SGD, AdaGrad, RMSprop

### ğŸ¨ VisÃ£o Computacional
- **TransformaÃ§Ãµes de Imagem**: Redimensionamento, rotaÃ§Ã£o, normalizaÃ§Ã£o
- **Filtros**: ConvoluÃ§Ã£o, detecÃ§Ã£o de bordas, desfoque
- **Processamento de Pipeline** para fluxos de trabalho de visÃ£o

### âš¡ AceleraÃ§Ã£o GPU
- **CUDA**: Suporte completo para GPUs NVIDIA (CUDA 12.x)
- **Metal**: AceleraÃ§Ã£o nativa para GPUs Apple Silicon
- **OpenCL**: Suporte multiplataforma para vÃ¡rios fornecedores de GPU
- **SeleÃ§Ã£o AutomÃ¡tica de Dispositivo** baseada em disponibilidade

### ğŸŒ Compatibilidade com WebAssembly
- **ExecuÃ§Ã£o em Navegador** com otimizaÃ§Ãµes especÃ­ficas para WASM
- **WebGPU**: AceleraÃ§Ã£o GPU em navegadores Chrome/Edge
- **DetecÃ§Ã£o de Recursos** para capacidades do navegador
- **OtimizaÃ§Ã£o de Tamanho de Bundle** para aplicaÃ§Ãµes web

### ğŸ”— IntegraÃ§Ã£o Python
- **Bindings PyO3** para interoperabilidade perfeita com Python
- **Compatibilidade com NumPy** para troca de arrays
- **API Familiar do PyTorch** para fÃ¡cil migraÃ§Ã£o
- **Sistema de Callbacks** para comunicaÃ§Ã£o Rust â†” Python

### ğŸ“Š Aprendizado DistribuÃ­do
- **Processamento Multi-GPU** com NCCL
- **SincronizaÃ§Ã£o de Gradientes** para treinamento em larga escala
- **EstratÃ©gias de Paralelismo** (dados, modelo, pipeline)
- **TolerÃ¢ncia a Falhas** com checkpointing automÃ¡tico

## ğŸš€ InÃ­cio RÃ¡pido

### InstalaÃ§Ã£o

Adicione ao seu `Cargo.toml`:

```toml
[dependencies]
rustorch = "0.6.7"

# Recursos opcionais
[dependencies.rustorch]
version = "0.6.7"
features = [
    "cuda",           # AceleraÃ§Ã£o CUDA
    "metal",          # AceleraÃ§Ã£o Metal (macOS)
    "linalg",         # Ãlgebra linear avanÃ§ada
    "python",         # Bindings Python
    "wasm",           # Suporte WebAssembly
    "model-hub",      # Download de modelos
]
```

### Uso BÃ¡sico

```rust
use rustorch::prelude::*;

fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Criar tensores
    let x = Tensor::randn(&[2, 3], ScalarType::Float32);
    let y = Tensor::ones(&[3, 4], ScalarType::Float32);
    
    // MultiplicaÃ§Ã£o de matrizes
    let z = x.matmul(&y)?;
    println!("Resultado: {:?}", z);
    
    // Construir uma rede neural simples
    let mut model = Sequential::new()
        .add(Linear::new(784, 256)?)
        .add(ReLU::new())
        .add(Linear::new(256, 10)?);
    
    // Forward pass
    let input = Tensor::randn(&[32, 784], ScalarType::Float32);
    let output = model.forward(&input)?;
    
    Ok(())
}
```

### Treinamento com Autograd

```rust
use rustorch::{nn::*, optim::*, autograd::*};

// Definir modelo
let mut model = Sequential::new()
    .add(Linear::new(784, 128)?)
    .add(ReLU::new())
    .add(Linear::new(128, 10)?);

// Configurar otimizador
let mut optimizer = Adam::new(model.parameters(), 0.001)?;

// Loop de treinamento
for epoch in 0..100 {
    let prediction = model.forward(&input)?;
    let loss = mse_loss(&prediction, &target)?;
    
    // Backpropagation
    loss.backward()?;
    optimizer.step()?;
    optimizer.zero_grad()?;
    
    println!("Epoch {}: Loss = {:.4}", epoch, loss.item::<f32>());
}
```

## ğŸ“š DocumentaÃ§Ã£o

- **[Guia de InÃ­cio RÃ¡pido]**: Tutorial para comeÃ§ar
- **[DocumentaÃ§Ã£o da API]**: ReferÃªncia completa da API
- **[Guia WebAssembly]**: IntegraÃ§Ã£o com navegadores
- **[Guia CUDA]**: AceleraÃ§Ã£o GPU
- **[Exemplos]**: Projetos de exemplo

## ğŸŒŸ Recursos AvanÃ§ados

### Processamento GPU
```rust
// DetecÃ§Ã£o automÃ¡tica de GPU
let device = Device::cuda_if_available();
let tensor = Tensor::randn(&[1024, 1024], ScalarType::Float32).to(device);

// OperaÃ§Ãµes aceleradas por GPU
let result = tensor.matmul(&tensor.t())?;
```

### IntegraÃ§Ã£o Python
```python
import rustorch

# Usar diretamente do Python
tensor = rustorch.tensor([1, 2, 3, 4])
result = tensor.sum()
print(f"Soma: {result}")
```

### Deployment WebAssembly
```javascript
import init, { RusTorchModel } from './pkg/rustorch.js';

async function runModel() {
    await init();
    const model = new RusTorchModel();
    const result = model.forward([1, 2, 3, 4]);
    console.log('Resultado:', result);
}
```

## ğŸ—ï¸ Arquitetura

RusTorch Ã© construÃ­do com arquitetura modular:

```
rustorch/
â”œâ”€â”€ tensor/          # OperaÃ§Ãµes de tensor fundamentais
â”œâ”€â”€ autograd/        # Sistema de diferenciaÃ§Ã£o automÃ¡tica
â”œâ”€â”€ nn/             # Camadas de redes neurais
â”œâ”€â”€ optim/          # Algoritmos de otimizaÃ§Ã£o
â”œâ”€â”€ vision/         # UtilitÃ¡rios de visÃ£o computacional
â”œâ”€â”€ distributed/    # ComputaÃ§Ã£o distribuÃ­da
â”œâ”€â”€ gpu/            # Kernels de aceleraÃ§Ã£o GPU
â””â”€â”€ python/         # Bindings Python
```

## ğŸš€ Performance

Benchmarks mostram performance competitiva:

| OperaÃ§Ã£o | RusTorch | PyTorch | NumPy |
|----------|----------|---------|--------|
| MultiplicaÃ§Ã£o de Matrix (1024Ã—1024) | 1.2ms | 1.8ms | 3.2ms |
| ConvoluÃ§Ã£o 2D | 0.8ms | 1.1ms | 2.4ms |
| Forward Pass (ResNet) | 12ms | 15ms | N/A |

*Medido em Intel i7-12700K com RTX 3080*

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Veja o [GUIA DE CONTRIBUIÃ‡ÃƒO] para detalhes.

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob MIT OU Apache-2.0 - veja os arquivos [LICENSE-MIT] e [LICENSE-APACHE] para detalhes.

## ğŸ™ Agradecimentos

- Inspirado pelo PyTorch e pelo ecossistema Rust
- Agradecimentos especiais aos contribuidores e mantenedores
- ConstruÃ­do com â¤ï¸ para a comunidade de machine learning

---

**RusTorch** - Liberando o poder do deep learning com seguranÃ§a e performance do Rust ğŸ¦€âœ¨