# RusTorch GPU Acceleration Guide
## GPUåŠ é€Ÿåˆ©ç”¨ã‚¬ã‚¤ãƒ‰

**RusTorch GPU ã‚«ãƒ¼ãƒãƒ«å®Ÿè£…å®Œäº†ç‰ˆ - æœ¬ç•ªç’°å¢ƒå¯¾å¿œ**

## ğŸ“‹ æ¦‚è¦

RusTorch ã¯ CUDAã€Metalã€OpenCL ã®çµ±ä¸€ GPU ã‚«ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æä¾›ã—ã€è‡ªå‹•ãƒ‡ãƒã‚¤ã‚¹é¸æŠã«ã‚ˆã‚‹é€éçš„ãª GPU åŠ é€Ÿã‚’å®Ÿç¾ã—ã¾ã™ã€‚

### ã‚µãƒãƒ¼ãƒˆ GPU ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
- **CUDA**: NVIDIA GPU å‘ã‘ cuBLAS çµ±åˆé«˜æ€§èƒ½ã‚«ãƒ¼ãƒãƒ«
- **Metal**: Apple Silicon å‘ã‘ Metal Performance Shaders æœ€é©åŒ–
- **OpenCL**: ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ  GPU å¯¾å¿œ

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. ä¾å­˜é–¢ä¿‚ã®è¨­å®š

```toml
[dependencies]
rustorch = "0.1.8"

[features]
# å˜ä¸€ GPU ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
cuda = ["rustorch/cuda"]      # NVIDIA CUDA
metal = ["rustorch/metal"]    # Apple Metal
opencl = ["rustorch/opencl"]  # OpenCL

# å…¨ GPU ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æœ‰åŠ¹åŒ–
all-gpu = ["rustorch/all-gpu"]
```

### 2. åŸºæœ¬çš„ãª GPU ã‚«ãƒ¼ãƒãƒ«ä½¿ç”¨ä¾‹

```rust
use rustorch::gpu::{
    DeviceType, 
    kernels::{KernelExecutor, AddKernel, MatMulKernel}
};

fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆ©ç”¨å¯èƒ½ãƒ‡ãƒã‚¤ã‚¹ã®è‡ªå‹•æ¤œå‡º
    let available_devices = DeviceType::available_devices();
    println!("åˆ©ç”¨å¯èƒ½ãƒ‡ãƒã‚¤ã‚¹: {:?}", available_devices);
    
    // æœ€é©ãƒ‡ãƒã‚¤ã‚¹ã®è‡ªå‹•é¸æŠ
    let device = DeviceType::best_available();
    let executor = KernelExecutor::new(device);
    
    // GPU ä¸Šã§ã®è¦ç´ ã”ã¨åŠ ç®—
    let a = vec![1.0f32; 1024];
    let b = vec![2.0f32; 1024];
    let mut c = vec![0.0f32; 1024];
    
    let kernel = AddKernel;
    let inputs = [a.as_slice(), b.as_slice()];
    let mut outputs = [c.as_mut_slice()];
    
    executor.execute_kernel(&kernel, &inputs, &mut outputs)?;
    
    println!("GPU è¨ˆç®—å®Œäº†: çµæœã®æœ€åˆã®5è¦ç´  {:?}", &c[..5]);
    
    Ok(())
}
```

## ğŸ¯ é«˜åº¦ãªä½¿ç”¨ä¾‹

### GPU è¡Œåˆ—ä¹—ç®—

```rust
use rustorch::gpu::{DeviceType, kernels::{KernelExecutor, MatMulKernel}};

fn gpu_matrix_multiplication() -> Result<(), Box<dyn std::error::Error>> {
    let device = DeviceType::best_available();
    let executor = KernelExecutor::new(device);
    
    // è¡Œåˆ—ã‚µã‚¤ã‚ºè¨­å®š
    let m = 512;
    let n = 512; 
    let k = 512;
    
    // è¡Œåˆ—ãƒ‡ãƒ¼ã‚¿æº–å‚™
    let a = vec![1.0f32; m * k];
    let b = vec![2.0f32; k * n];
    let mut c = vec![0.0f32; m * n];
    
    let kernel = MatMulKernel;
    let inputs = [a.as_slice(), b.as_slice()];
    let mut outputs = [c.as_mut_slice()];
    
    // GPU ã§ã®é«˜æ€§èƒ½è¡Œåˆ—ä¹—ç®—å®Ÿè¡Œ
    executor.execute_kernel(&kernel, &inputs, &mut outputs)?;
    
    println!("{}x{} è¡Œåˆ—ä¹—ç®—å®Œäº†", m, n);
    
    Ok(())
}
```

### ãƒ‡ãƒã‚¤ã‚¹å›ºæœ‰ã®å®Ÿè¡Œ

```rust
use rustorch::gpu::{DeviceType, kernels::KernelExecutor};

fn device_specific_execution() -> Result<(), Box<dyn std::error::Error>> {
    // CUDA ãƒ‡ãƒã‚¤ã‚¹æŒ‡å®š
    if let Ok(executor) = KernelExecutor::new(DeviceType::Cuda(0)) {
        println!("CUDA GPU ã§å®Ÿè¡Œä¸­...");
        // CUDA å›ºæœ‰ã®å‡¦ç†
    }
    
    // Metal ãƒ‡ãƒã‚¤ã‚¹æŒ‡å®š
    if let Ok(executor) = KernelExecutor::new(DeviceType::Metal(0)) {
        println!("Metal GPU ã§å®Ÿè¡Œä¸­...");
        // Metal å›ºæœ‰ã®å‡¦ç†
    }
    
    // OpenCL ãƒ‡ãƒã‚¤ã‚¹æŒ‡å®š
    if let Ok(executor) = KernelExecutor::new(DeviceType::OpenCl(0)) {
        println!("OpenCL GPU ã§å®Ÿè¡Œä¸­...");
        // OpenCL å›ºæœ‰ã®å‡¦ç†
    }
    
    // CPU ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    let executor = KernelExecutor::new(DeviceType::Cpu);
    println!("CPU ã§å®Ÿè¡Œä¸­...");
    
    Ok(())
}
```

## ğŸ”§ GPU ã‚«ãƒ¼ãƒãƒ«æ¤œè¨¼

### æ¤œè¨¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ä½¿ç”¨

```rust
use rustorch::gpu::validation::{GpuValidator, print_gpu_validation_report};

fn validate_gpu_kernels() -> Result<(), Box<dyn std::error::Error>> {
    // GPU ã‚«ãƒ¼ãƒãƒ«æ¤œè¨¼ã®å®Ÿè¡Œ
    let validator = GpuValidator::new();
    let report = validator.run_validation()?;
    
    // æ¤œè¨¼çµæœã®è¡¨ç¤º
    print_gpu_validation_report(&report);
    
    // å€‹åˆ¥çµæœã®ç¢ºèª
    for result in &report.results {
        if !result.passed {
            println!("æ¤œè¨¼å¤±æ•—: {} on {:?}", result.operation, result.device);
            if let Some(error) = &result.error_message {
                println!("ã‚¨ãƒ©ãƒ¼: {}", error);
            }
        }
    }
    
    Ok(())
}
```

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š

### GPU vs CPU æ€§èƒ½æ¯”è¼ƒ

```rust
use rustorch::gpu::{DeviceType, kernels::{KernelExecutor, AddKernel}};
use std::time::Instant;

fn performance_comparison() -> Result<(), Box<dyn std::error::Error>> {
    let size = 1_000_000;
    let a = vec![1.0f32; size];
    let b = vec![2.0f32; size];
    let mut c_gpu = vec![0.0f32; size];
    let mut c_cpu = vec![0.0f32; size];
    
    // GPU å®Ÿè¡Œæ™‚é–“æ¸¬å®š
    let gpu_device = DeviceType::best_available();
    let gpu_executor = KernelExecutor::new(gpu_device);
    let kernel = AddKernel;
    
    let start = Instant::now();
    let inputs = [a.as_slice(), b.as_slice()];
    let mut outputs = [c_gpu.as_mut_slice()];
    gpu_executor.execute_kernel(&kernel, &inputs, &mut outputs)?;
    let gpu_time = start.elapsed();
    
    // CPU å®Ÿè¡Œæ™‚é–“æ¸¬å®š
    let cpu_executor = KernelExecutor::new(DeviceType::Cpu);
    let start = Instant::now();
    let inputs = [a.as_slice(), b.as_slice()];
    let mut outputs = [c_cpu.as_mut_slice()];
    cpu_executor.execute_kernel(&kernel, &inputs, &mut outputs)?;
    let cpu_time = start.elapsed();
    
    println!("GPU å®Ÿè¡Œæ™‚é–“: {:?}", gpu_time);
    println!("CPU å®Ÿè¡Œæ™‚é–“: {:?}", cpu_time);
    println!("GPU é«˜é€ŸåŒ–ç‡: {:.2}x", cpu_time.as_secs_f64() / gpu_time.as_secs_f64());
    
    Ok(())
}
```

## ğŸ› ï¸ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

#### 1. GPU ãƒ‡ãƒã‚¤ã‚¹ãŒæ¤œå‡ºã•ã‚Œãªã„

```rust
use rustorch::gpu::DeviceType;

fn debug_device_detection() {
    let devices = DeviceType::available_devices();
    
    if devices.is_empty() {
        println!("GPU ãƒ‡ãƒã‚¤ã‚¹ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ");
        println!("- GPU ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª");
        println!("- é©åˆ‡ãªæ©Ÿèƒ½ãƒ•ãƒ©ã‚°ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª");
        println!("- CPU ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¾ã™");
    } else {
        println!("æ¤œå‡ºã•ã‚ŒãŸãƒ‡ãƒã‚¤ã‚¹: {:?}", devices);
    }
}
```

#### 2. CUDA ã‚¨ãƒ©ãƒ¼ã®å‡¦ç†

```rust
use rustorch::gpu::{DeviceType, kernels::KernelExecutor, GpuError};

fn handle_cuda_errors() {
    match KernelExecutor::new(DeviceType::Cuda(0)) {
        Ok(executor) => {
            println!("CUDA åˆæœŸåŒ–æˆåŠŸ");
        }
        Err(GpuError::InitializationError(msg)) => {
            println!("CUDA åˆæœŸåŒ–å¤±æ•—: {}", msg);
            println!("CPU ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«åˆ‡ã‚Šæ›¿ãˆ");
        }
        Err(e) => {
            println!("äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {:?}", e);
        }
    }
}
```

#### 3. ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼ã®å¯¾å‡¦

```rust
use rustorch::gpu::{GpuError, kernels::KernelExecutor};

fn handle_memory_errors(executor: &KernelExecutor) -> Result<(), GpuError> {
    // å¤§ããªãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†æ™‚
    let large_data = vec![1.0f32; 100_000_000]; // 100M è¦ç´ 
    
    match process_large_data(executor, &large_data) {
        Err(GpuError::MemoryAllocationError(_)) => {
            println!("GPU ãƒ¡ãƒ¢ãƒªä¸è¶³ã€ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å‰Šæ¸›");
            // ãƒãƒƒãƒå‡¦ç†ã«åˆ†å‰²
            process_in_batches(executor, &large_data)?;
        }
        result => result?,
    }
    
    Ok(())
}

fn process_large_data(executor: &KernelExecutor, data: &[f32]) -> Result<(), GpuError> {
    // å¤§ããªãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†å®Ÿè£…
    Ok(())
}

fn process_in_batches(executor: &KernelExecutor, data: &[f32]) -> Result<(), GpuError> {
    let batch_size = 1_000_000;
    for chunk in data.chunks(batch_size) {
        // ãƒãƒƒãƒã”ã¨ã®å‡¦ç†
    }
    Ok(())
}
```

## ğŸ“ˆ æœ€é©åŒ–ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. é©åˆ‡ãªãƒãƒƒãƒã‚µã‚¤ã‚ºã®é¸æŠ

```rust
fn optimize_batch_size() {
    // å°ã•ã™ãã‚‹ãƒãƒƒãƒ: GPU ã®ä¸¦åˆ—æ€§ã‚’æ´»ç”¨ã§ããªã„
    let small_batch = 32;
    
    // å¤§ãã™ãã‚‹ãƒãƒƒãƒ: ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å¯èƒ½æ€§
    let large_batch = 100_000_000;
    
    // æ¨å¥¨ãƒãƒƒãƒã‚µã‚¤ã‚º: GPU ãƒ¡ãƒ¢ãƒªã¨ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã«å¿œã˜ã¦èª¿æ•´
    let optimal_batch = 10_000;
}
```

### 2. ãƒ¡ãƒ¢ãƒªè»¢é€ã®æœ€å°åŒ–

```rust
fn minimize_memory_transfers() {
    // æ‚ªã„ä¾‹: é »ç¹ãª CPU-GPU é–“è»¢é€
    // for i in 0..1000 {
    //     gpu_operation(small_data[i]);
    // }
    
    // è‰¯ã„ä¾‹: ãƒãƒƒãƒå‡¦ç†ã§ãƒ¡ãƒ¢ãƒªè»¢é€ã‚’æœ€å°åŒ–
    // gpu_batch_operation(large_batch_data);
}
```

### 3. éåŒæœŸå®Ÿè¡Œã®æ´»ç”¨

```rust
use rustorch::gpu::kernels::KernelExecutor;

fn async_gpu_execution() {
    // è¤‡æ•°ã®ç‹¬ç«‹ã—ãŸ GPU æ“ä½œã‚’ä¸¦åˆ—å®Ÿè¡Œ
    // (å°†æ¥ã®å®Ÿè£…ã§éåŒæœŸã‚µãƒãƒ¼ãƒˆäºˆå®š)
}
```

## ğŸ§ª ãƒ†ã‚¹ãƒˆã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

### GPU ã‚«ãƒ¼ãƒãƒ«ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ

```bash
# å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ (GPU æ¤œè¨¼å«ã‚€)
cargo test --release

# GPU å›ºæœ‰ãƒ†ã‚¹ãƒˆ
cargo test gpu --release

# GPU ã‚«ãƒ¼ãƒãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
cargo bench --bench gpu_kernel_performance

# GPU vs CPU æ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
cargo bench --bench gpu_cpu_performance
```

### ã‚«ã‚¹ã‚¿ãƒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ä½œæˆ

```rust
use criterion::{criterion_group, criterion_main, Criterion, BenchmarkId};
use rustorch::gpu::{DeviceType, kernels::{KernelExecutor, AddKernel}};

fn gpu_benchmark(c: &mut Criterion) {
    let mut group = c.benchmark_group("GPU Operations");
    
    for size in [1000, 10000, 100000].iter() {
        group.bench_with_input(
            BenchmarkId::new("GPU Add", size),
            size,
            |b, &size| {
                let a = vec![1.0f32; size];
                let b_vec = vec![2.0f32; size];
                let mut c = vec![0.0f32; size];
                
                let executor = KernelExecutor::new(DeviceType::best_available());
                let kernel = AddKernel;
                
                b.iter(|| {
                    let inputs = [a.as_slice(), b_vec.as_slice()];
                    let mut outputs = [c.as_mut_slice()];
                    executor.execute_kernel(&kernel, &inputs, &mut outputs)
                        .expect("GPU kernel execution failed");
                });
            },
        );
    }
    
    group.finish();
}

criterion_group!(benches, gpu_benchmark);
criterion_main!(benches);
```

## ğŸ“š API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

### ä¸»è¦ãªå‹ã¨ãƒˆãƒ¬ã‚¤ãƒˆ

- `DeviceType`: GPU ãƒ‡ãƒã‚¤ã‚¹ã‚¿ã‚¤ãƒ—ã®åˆ—æŒ™å‹
- `KernelExecutor`: GPU ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œå™¨
- `GpuKernel`: GPU ã‚«ãƒ¼ãƒãƒ«ãƒˆãƒ¬ã‚¤ãƒˆ
- `GpuError`: GPU ã‚¨ãƒ©ãƒ¼å‹
- `GpuValidator`: GPU ã‚«ãƒ¼ãƒãƒ«æ¤œè¨¼å™¨

### åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ¼ãƒãƒ«

- `AddKernel`: è¦ç´ ã”ã¨åŠ ç®—
- `MatMulKernel`: è¡Œåˆ—ä¹—ç®—
- `ReduceKernel`: ãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³æ“ä½œ

## ğŸ”— é–¢é€£ãƒªã‚½ãƒ¼ã‚¹

- [RusTorch ãƒ¡ã‚¤ãƒ³ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](../README.md)
- [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆ](../PERFORMANCE_ANALYSIS.md)
- [GPU ã‚«ãƒ¼ãƒãƒ«ãƒ‡ãƒ¢](../examples/gpu_kernel_demo.rs)
- [GPU vs CPU ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯](../benches/gpu_cpu_performance.rs)

---

**RusTorch GPU åŠ é€Ÿã¯æœ¬ç•ªç’°å¢ƒå¯¾å¿œã®å®Œå…¨å®Ÿè£…ã§ã™ã€‚CUDAã€Metalã€OpenCL ã®çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«ã‚ˆã‚Šã€æœ€é©ãª GPU æ€§èƒ½ã‚’ç°¡å˜ã«æ´»ç”¨ã§ãã¾ã™ã€‚**
