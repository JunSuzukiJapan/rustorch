# CoreML + GPU ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ è©³ç´°è¨­è¨ˆ

> **ä½œæˆæ—¥**: 2025-09-19
> **ç›®çš„**: CoreMLéå¯¾å¿œæ¼”ç®—ã®GPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½å®Ÿè£…è¨ˆç”»
> **å¯¾è±¡**: Feature flag ã«ã‚ˆã‚‹ãƒ‡ãƒã‚¤ã‚¹å„ªå…ˆé †ä½åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ 

## ğŸ“‹ æ¦‚è¦

CoreMLã§å¯¾å¿œã§ããªã„æ¼”ç®—ã‚’è‡ªå‹•çš„ã«GPU â†’ CPUã®é †ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã™ã‚‹å‹•çš„å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ ã®è¨­è¨ˆã€‚

### ğŸ¯ ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥å®Ÿè¡Œå„ªå…ˆé †ä½

#### **Apple Silicon Mac (M1/M2/M3)**
```
CoreML â†’ Metal â†’ OpenCL â†’ CPU
   â†“       â†“       â†“      â†“
 æœ€é«˜é€Ÿ   é«˜é€ŸåŒ–   æ™®é€š   ç¢ºå®Ÿ
```

#### **Intel/AMD PC with NVIDIA GPU**
```
CUDA â†’ OpenCL â†’ CPU
  â†“      â†“      â†“
é«˜é€ŸåŒ–   æ™®é€š   ç¢ºå®Ÿ
```

#### **Intel/AMD PC without NVIDIA GPU**
```
OpenCL â†’ CPU
   â†“      â†“
 æ™®é€š   ç¢ºå®Ÿ
```

**ğŸ” é‡è¦**: CUDAï¼ˆNVIDIAï¼‰ã¨Metalï¼ˆAppleï¼‰ã¯ç‰©ç†çš„ã«ç•°ãªã‚‹ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãªã®ã§ã€ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æ¤œå‡ºã«ã‚ˆã‚Šé©åˆ‡ãªãƒã‚§ãƒ¼ãƒ³ã‚’å‹•çš„æ§‹ç¯‰ã—ã¾ã™ã€‚

---

## ğŸ—ï¸ 1. Feature Flag æ‹¡å¼µè¨­è¨ˆ

### 1.1 æ–°è¦ Feature Flags

```toml
[features]
# æ—¢å­˜ features...
coreml = ["dep:objc2-core-ml", "dep:metal"]
coreml-hybrid = ["coreml", "metal", "cuda"]  # CoreML + GPU ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰
coreml-fallback = ["coreml-hybrid"]          # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½æœ‰åŠ¹
gpu-priority = ["cuda", "metal", "opencl"]   # GPUå„ªå…ˆå®Ÿè¡Œ
```

### 1.2 æ¡ä»¶ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æˆ¦ç•¥

```rust
// Cargo.toml ã§ã®æ¡ä»¶æœ‰åŠ¹åŒ–
[dependencies]
objc2-core-ml = { version = "0.2", optional = true }

// å®Ÿè¡Œæ™‚ã®æ©Ÿèƒ½æ¤œå‡º
#[cfg(feature = "coreml")]
use objc2_core_ml::*;

#[cfg(any(feature = "cuda", feature = "metal", feature = "opencl"))]
use crate::gpu::*;
```

---

## ğŸ›ï¸ 2. DeviceType æ‹¡å¼µ

### 2.1 æ–°ã—ã„ãƒ‡ãƒã‚¤ã‚¹ã‚¿ã‚¤ãƒ—

```rust
/// æ‹¡å¼µãƒ‡ãƒã‚¤ã‚¹ã‚¿ã‚¤ãƒ— - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œ
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum DeviceType {
    Cpu,
    Cuda(usize),
    Metal(usize),
    OpenCL(usize),

    // ğŸ†• CoreMLè¿½åŠ 
    CoreML(usize),

    // ğŸ†• ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ‡ãƒã‚¤ã‚¹
    CoreMLHybrid {
        coreml_id: usize,
        fallback_gpu: Option<GpuDevice>,
    },

    // ğŸ†• è‡ªå‹•é¸æŠ
    Auto,  // åˆ©ç”¨å¯èƒ½ãªæœ€é«˜æ€§èƒ½ãƒ‡ãƒã‚¤ã‚¹ã‚’è‡ªå‹•é¸æŠ
}

/// GPU ãƒ‡ãƒã‚¤ã‚¹è©³ç´°
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum GpuDevice {
    Cuda(usize),
    Metal(usize),
    OpenCL(usize),
}
```

### 2.2 ãƒ‡ãƒã‚¤ã‚¹èƒ½åŠ›ã®ç®¡ç†

```rust
/// ãƒ‡ãƒã‚¤ã‚¹èƒ½åŠ›ãƒãƒˆãƒªã‚¯ã‚¹
#[derive(Debug)]
pub struct DeviceCapability {
    pub device_type: DeviceType,
    pub supports_f16: bool,
    pub supports_f32: bool,
    pub supports_f64: bool,
    pub supports_complex: bool,
    pub supports_distributed: bool,
    pub max_memory_gb: f32,
    pub supported_operations: HashSet<OpType>,
}

/// æ¼”ç®—ã‚¿ã‚¤ãƒ—åˆ†é¡
#[derive(Debug, Hash, PartialEq, Eq)]
pub enum OpType {
    // CoreMLå®Œå…¨å¯¾å¿œ
    LinearAlgebra,
    Convolution,
    Activation,

    // CoreMLéƒ¨åˆ†å¯¾å¿œ
    Reduction,
    Normalization,

    // CoreMLéå¯¾å¿œ
    ComplexMath,
    Distribution,
    CustomKernel,
    DistributedOps,
}
```

---

## âš™ï¸ 3. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³

### 3.1 å‹•çš„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿæ§‹

```rust
/// ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å®Ÿè¡Œç®¡ç†
pub struct HybridExecutor {
    primary_device: DeviceType,
    fallback_devices: Vec<DeviceType>,
    capability_cache: HashMap<DeviceType, DeviceCapability>,
    operation_routing: HashMap<OpType, Vec<DeviceType>>,
}

impl HybridExecutor {
    /// æ¼”ç®—ã«æœ€é©ãªãƒ‡ãƒã‚¤ã‚¹ã‚’é¸æŠ
    pub fn select_device(&self, op_type: OpType, tensor_info: &TensorInfo) -> DeviceType {
        // 1. CoreMLã§å¯¾å¿œå¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
        if self.is_coreml_supported(op_type, tensor_info) {
            return DeviceType::CoreML(0);
        }

        // 2. GPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if let Some(gpu_device) = self.select_gpu_device(op_type, tensor_info) {
            return gpu_device;
        }

        // 3. CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        DeviceType::Cpu
    }

    /// CoreMLå¯¾å¿œå¯å¦åˆ¤å®š
    fn is_coreml_supported(&self, op_type: OpType, tensor_info: &TensorInfo) -> bool {
        match op_type {
            OpType::LinearAlgebra | OpType::Convolution | OpType::Activation => {
                // ãƒ‡ãƒ¼ã‚¿å‹ãƒã‚§ãƒƒã‚¯
                matches!(tensor_info.dtype, DType::F16 | DType::F32)
                    && tensor_info.shape.len() <= 5  // 5æ¬¡å…ƒã¾ã§å¯¾å¿œ
            },
            OpType::Reduction | OpType::Normalization => {
                // åˆ¶é™ä»˜ãå¯¾å¿œ
                tensor_info.shape.len() <= 4
                    && !tensor_info.requires_custom_kernel
            },
            _ => false,  // ãã®ä»–ã¯éå¯¾å¿œ
        }
    }
}
```

### 3.2 å®Ÿè¡Œæ™‚ãƒ‡ãƒã‚¤ã‚¹åˆ‡ã‚Šæ›¿ãˆ

```rust
/// ãƒ‡ãƒã‚¤ã‚¹é–“ã®å‹•çš„åˆ‡ã‚Šæ›¿ãˆ
impl<T> Tensor<T> {
    /// ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¼”ç®—å®Ÿè¡Œ
    pub fn hybrid_operation<F>(&self, op: F) -> RusTorchResult<Tensor<T>>
    where
        F: Fn(&Self, DeviceType) -> RusTorchResult<Tensor<T>>,
    {
        let executor = HybridExecutor::global();
        let op_type = self.infer_operation_type();

        // ãƒ‡ãƒã‚¤ã‚¹é¸æŠ
        let selected_device = executor.select_device(op_type, &self.tensor_info());

        // å®Ÿè¡Œè©¦è¡Œã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        match self.try_operation(&op, selected_device) {
            Ok(result) => Ok(result),
            Err(e) if e.is_device_error() => {
                // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒã‚¤ã‚¹ã§å†è©¦è¡Œ
                let fallback_device = executor.next_fallback_device(selected_device);
                self.try_operation(&op, fallback_device)
            },
            Err(e) => Err(e),
        }
    }
}
```

---

## ğŸ”„ 4. æ¼”ç®—åˆ¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥

### 4.1 ç·šå½¢ä»£æ•°æ¼”ç®—

```rust
impl<T> GpuLinearAlgebra<T> for Tensor<T> {
    fn gpu_matmul(&self, other: &Self) -> RusTorchResult<Tensor<T>> {
        // ğŸ¯ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å®Ÿè¡Œ
        self.hybrid_operation(|tensor, device| {
            match device {
                DeviceType::CoreML(_) => {
                    // CoreML MLComputeGraphä½¿ç”¨
                    tensor.coreml_matmul(other)
                },
                DeviceType::Cuda(_) => {
                    // CUDA cuBLASä½¿ç”¨
                    tensor.cuda_matmul(other)
                },
                DeviceType::Metal(_) => {
                    // Metal Performance Shadersä½¿ç”¨
                    tensor.metal_matmul(other)
                },
                DeviceType::Cpu => {
                    // BLAS CPUå®Ÿè£…
                    tensor.cpu_matmul(other)
                },
                _ => Err(RusTorchError::UnsupportedDevice),
            }
        })
    }
}
```

### 4.2 è¤‡ç´ æ•°æ¼”ç®—ï¼ˆCoreMLéå¯¾å¿œï¼‰

```rust
impl<T> ComplexOperations<T> for Tensor<Complex<T>> {
    fn complex_multiply(&self, other: &Self) -> RusTorchResult<Self> {
        // CoreMLã‚¹ã‚­ãƒƒãƒ— â†’ GPUç›´è¡Œ
        let executor = HybridExecutor::global();

        if executor.has_gpu_support() {
            // GPUå®Ÿè£…
            self.gpu_complex_multiply(other)
        } else {
            // CPU ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            self.cpu_complex_multiply(other)
        }
    }
}
```

### 4.3 åˆ†æ•£æ¼”ç®—ï¼ˆCoreMLéå¯¾å¿œï¼‰

```rust
impl<T> DistributedOperations<T> for Tensor<T> {
    fn all_reduce(&self, op: ReduceOp) -> RusTorchResult<Self> {
        // CoreMLéå¯¾å¿œ â†’ NCCL/MPIç›´è¡Œ
        #[cfg(feature = "nccl")]
        {
            self.nccl_all_reduce(op)
        }
        #[cfg(not(feature = "nccl"))]
        {
            // ã‚·ãƒ³ã‚°ãƒ«ãƒ—ãƒ­ã‚»ã‚¹ã®å ´åˆã¯no-op
            Ok(self.clone())
        }
    }
}
```

---

## ğŸ“Š 5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 5.1 ãƒ‡ãƒã‚¤ã‚¹é¸æŠãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯

```rust
/// æœ€é©ãƒ‡ãƒã‚¤ã‚¹é¸æŠãƒ«ãƒ¼ãƒ«
impl DeviceSelector {
    fn select_optimal_device(&self, tensor_size: usize, op_complexity: f32) -> DeviceType {
        // å°ã•ãªãƒ†ãƒ³ã‚½ãƒ«ï¼ˆ< 1MBï¼‰â†’ CPU
        if tensor_size < 1_000_000 {
            return DeviceType::Cpu;
        }

        // ä¸­ã‚µã‚¤ã‚ºï¼ˆ1MB - 100MBï¼‰â†’ CoreML
        if tensor_size < 100_000_000 && self.coreml_available() {
            return DeviceType::CoreML(0);
        }

        // å¤§ã‚µã‚¤ã‚ºï¼ˆ> 100MBï¼‰â†’ æœ€é«˜æ€§èƒ½GPU
        self.best_gpu_device().unwrap_or(DeviceType::Cpu)
    }
}
```

### 5.2 ãƒ¡ãƒ¢ãƒªè»¢é€æœ€é©åŒ–

```rust
/// ãƒ‡ãƒã‚¤ã‚¹é–“ãƒ¡ãƒ¢ãƒªè»¢é€ç®¡ç†
pub struct MemoryManager {
    device_pools: HashMap<DeviceType, MemoryPool>,
    transfer_cache: LruCache<(DeviceType, DeviceType), TransferMethod>,
}

impl MemoryManager {
    /// æœ€é©ãªè»¢é€æ–¹æ³•é¸æŠ
    fn optimize_transfer(&self, from: DeviceType, to: DeviceType) -> TransferMethod {
        match (from, to) {
            (DeviceType::Metal(_), DeviceType::CoreML(_)) => {
                // Metal â†” CoreML: ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼
                TransferMethod::ZeroCopy
            },
            (DeviceType::Cuda(_), DeviceType::CoreML(_)) => {
                // CUDA â†’ CoreML: ãƒ›ã‚¹ãƒˆçµŒç”±
                TransferMethod::HostStaging
            },
            _ => TransferMethod::Standard,
        }
    }
}
```

---

## ğŸ§ª 6. ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### 6.1 æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ

```rust
#[cfg(test)]
mod hybrid_tests {
    use super::*;

    #[test]
    fn test_coreml_fallback_to_gpu() {
        // CoreMLéå¯¾å¿œæ¼”ç®—ã®GPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        let tensor = Tensor::randn(&[1000, 1000], DType::Complex64);

        // è¤‡ç´ æ•°æ¼”ç®—ï¼ˆCoreMLéå¯¾å¿œï¼‰
        let result = tensor.complex_conjugate();

        // GPUã¾ãŸã¯CPUã§å®Ÿè¡Œã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert!(matches!(result.device(), DeviceType::Cuda(_) | DeviceType::Cpu));
    }

    #[test]
    fn test_gpu_fallback_to_cpu() {
        // GPUéåˆ©ç”¨æ™‚ã®CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        std::env::set_var("RUSTORCH_DISABLE_GPU", "1");

        let tensor = Tensor::randn(&[100, 100], DType::F32);
        let result = tensor.matmul(&tensor);

        assert_eq!(result.device(), DeviceType::Cpu);
    }
}
```

### 6.2 æ€§èƒ½ãƒ†ã‚¹ãƒˆ

```rust
#[cfg(test)]
mod performance_tests {
    use criterion::{black_box, Criterion};

    fn benchmark_hybrid_execution(c: &mut Criterion) {
        let tensor = Tensor::randn(&[1000, 1000], DType::F32);

        c.bench_function("hybrid_matmul", |b| {
            b.iter(|| {
                black_box(tensor.matmul(&tensor))
            })
        });
    }
}
```

---

## ğŸš€ 7. å®Ÿè£…ãƒ•ã‚§ãƒ¼ã‚º

### Phase 1: åŸºç›¤å®Ÿè£… (2-3é€±é–“)
- [ ] DeviceTypeæ‹¡å¼µ
- [ ] HybridExecutoråŸºæœ¬æ©Ÿèƒ½
- [ ] Feature flagè¨­å®š

### Phase 2: ã‚³ã‚¢æ¼”ç®—å¯¾å¿œ (3-4é€±é–“)
- [ ] ç·šå½¢ä»£æ•°ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å®Ÿè¡Œ
- [ ] ç•³ã¿è¾¼ã¿ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
- [ ] ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³é–¢æ•°å¯¾å¿œ

### Phase 3: é«˜åº¦ãªæ©Ÿèƒ½ (2-3é€±é–“)
- [ ] è¤‡ç´ æ•°æ¼”ç®—GPUå°‚ç”¨å®Ÿè£…
- [ ] åˆ†æ•£æ¼”ç®—ã®æ¡ä»¶åˆ†å²
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

---

## ğŸ¯ æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ

### æ€§èƒ½å‘ä¸Š
- **CoreMLå¯¾å¿œæ¼”ç®—**: 50-80% é«˜é€ŸåŒ–
- **GPU ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯**: 20-40% é«˜é€ŸåŒ–
- **è‡ªå‹•æœ€é©åŒ–**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ä»‹å…¥ä¸è¦

### é–‹ç™ºè€…ä½“é¨“
- **Zero Configuration**: feature flagè¨­å®šã®ã¿
- **Graceful Degradation**: ã‚¨ãƒ©ãƒ¼ã§ã¯ãªãè‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
- **é€æ˜æ€§**: ã©ã®ãƒ‡ãƒã‚¤ã‚¹ã§å®Ÿè¡Œã•ã‚ŒãŸã‹ãƒ­ã‚°ã§ç¢ºèªå¯èƒ½