# CoreMLçµ±åˆ - æ—¢å­˜traitä½“ç³»ãƒ™ãƒ¼ã‚¹å®Ÿè£…è©³ç´°è¨ˆç”»

> **ä½œæˆæ—¥**: 2025-09-19
> **å¯¾è±¡**: æ—¢å­˜GPU traitä½“ç³»ã‚’æ´»ç”¨ã—ãŸCoreMLçµ±åˆ
> **å®Ÿè£…æ–¹é‡**: æœ€å°é™ã®å¤‰æ›´ã§æœ€å¤§ã®åŠ¹æœ

## ğŸ¯ Executive Summary

æ—¢å­˜ã®GPU traitä½“ç³»ã®è©³ç´°åˆ†æã«ã‚ˆã‚Šã€**CoreMLã¯æ—¢å­˜ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«å®Œç’§ã«é©åˆ**ã™ã‚‹ã“ã¨ãŒåˆ¤æ˜ã€‚ãƒ‡ãƒã‚¤ã‚¹é¸æŠãƒ­ã‚¸ãƒƒã‚¯ã¸ã®CoreMLã‚±ãƒ¼ã‚¹è¿½åŠ ã¨ã€å„traitã®CoreMLå®Ÿè£…ã®ã¿ã§çµ±åˆãŒå®Œæˆã—ã¾ã™ã€‚

### ğŸ“Š å®Ÿè£…ã®å˜ç´”ã•

| å¤‰æ›´ç®‡æ‰€ | å¤‰æ›´å†…å®¹ | å·¥æ•°å‰Šæ¸› |
|----------|----------|----------|
| DeviceType enum | CoreML(usize) 1è¡Œè¿½åŠ  | -80% |
| traitå®Ÿè£… | matchæ–‡ã«CoreMLã‚±ãƒ¼ã‚¹è¿½åŠ  | -70% |
| æ–°è¦trait | ä¸è¦ | -90% |
| APIå¤‰æ›´ | ã‚¼ãƒ­ | -100% |

---

## ğŸ—ï¸ 1. æ—¢å­˜traitä½“ç³»ã®æ§‹é€ åˆ†æ

### 1.1 ç¾åœ¨ã®traitéšå±¤

```rust
// ä¸»è¦GPU traitç¾¤
pub trait GpuLinearAlgebra<T>    // ç·šå½¢ä»£æ•°æ¼”ç®—
pub trait GpuConvolution<T>      // ç•³ã¿è¾¼ã¿æ¼”ç®—
pub trait GpuReduction<T>        // ãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³æ¼”ç®—
pub trait GpuPooling<T>          // ãƒ—ãƒ¼ãƒªãƒ³ã‚°æ¼”ç®—
pub trait GpuParallelOp<T>       // ä¸¦åˆ—æ¼”ç®—ï¼ˆæœ€åŒ…æ‹¬çš„ï¼‰

// ãƒ‡ãƒã‚¤ã‚¹ç®¡ç†
pub enum DeviceType { Cpu, Cuda(usize), Metal(usize), OpenCL(usize) }
pub struct GpuContext
pub struct DeviceManager
```

### 1.2 å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµ±ä¸€æ€§

#### **æ¨™æº–çš„ãªå®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³**ï¼ˆ`GpuLinearAlgebra`ã®ä¾‹ï¼‰
```rust
impl<T> GpuLinearAlgebra<T> for Tensor<T> {
    fn gpu_matmul(&self, other: &Self) -> RusTorchResult<Tensor<T>> {
        // ãƒ‡ãƒã‚¤ã‚¹è‡ªå‹•é¸æŠ
        let device_type = if DeviceManager::is_cuda_available() {
            DeviceType::Cuda(0)
        } else if DeviceManager::is_metal_available() {
            DeviceType::Metal(0)
        } else {
            DeviceType::Cpu
        };

        // åŸ·è¡Œè€…ä½œæˆãƒ»å®Ÿè¡Œ
        let executor = GpuBatchMatrixExecutor::<T>::new(device_type)?;
        executor.batch_matmul(self, other)
    }
}
```

#### **Executorãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµ±ä¸€æ€§**ï¼ˆ`GpuBatchMatrixExecutor`ã®ä¾‹ï¼‰
```rust
impl<T> GpuBatchMatrixExecutor<T> {
    pub fn batch_matmul(&self, a: &Tensor<T>, b: &Tensor<T>) -> RusTorchResult<Tensor<T>> {
        match &self.device_type {
            DeviceType::Cuda(_) => self.cuda_batch_matmul(a, b),
            DeviceType::Metal(_) => self.metal_batch_matmul(a, b),
            DeviceType::OpenCL(_) => self.opencl_batch_matmul(a, b),
            DeviceType::Cpu => a.matmul(b).map_err(|e| RusTorchError::gpu(e.to_string())),
        }
    }
}
```

### ğŸ¯ **ç™ºè¦‹: å®Œç’§ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**

1. **çµ±ä¸€ãƒ‘ã‚¿ãƒ¼ãƒ³**: å…¨traitãŒåŒã˜matchæ–‡ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨
2. **è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯**: ãƒ‡ãƒã‚¤ã‚¹åˆ©ç”¨ä¸å¯æ™‚ã®CPU ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
3. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: çµ±ä¸€ã•ã‚ŒãŸRusTorchErrorä½“ç³»
4. **å‹å®‰å…¨æ€§**: ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã®å‹ãƒã‚§ãƒƒã‚¯

---

## âš¡ 2. CoreMLçµ±åˆæˆ¦ç•¥ - traitåˆ¥è©³ç´°å®Ÿè£…

### 2.1 DeviceTypeæ‹¡å¼µï¼ˆåŸºç›¤ï¼‰

#### **Phase 1.1: DeviceTypeæ‹¡å¼µ**
**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/gpu/mod.rs`

```rust
/// GPU device types
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Default)]
pub enum DeviceType {
    #[default]
    Cpu,
    Cuda(usize),
    Metal(usize),
    OpenCL(usize),
    CoreML(usize),    // ğŸ†• 1è¡Œè¿½åŠ ã®ã¿ï¼
}

impl DeviceType {
    // ğŸ†• CoreMLé–¢é€£ãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ 
    pub fn is_coreml(&self) -> bool {
        matches!(self, DeviceType::CoreML(_))
    }

    pub fn is_apple_hardware(&self) -> bool {
        matches!(self, DeviceType::Metal(_) | DeviceType::CoreML(_))
    }

    // æ—¢å­˜ãƒ¡ã‚½ãƒƒãƒ‰ã®æ‹¡å¼µ
    pub fn is_available(&self) -> bool {
        match self {
            DeviceType::Cpu => true,
            DeviceType::Cuda(id) => cuda_device_available(*id),
            DeviceType::Metal(id) => metal_device_available(*id),
            DeviceType::OpenCL(id) => opencl_device_available(*id),
            DeviceType::CoreML(id) => coreml_device_available(*id), // ğŸ†•
        }
    }
}

// ğŸ†• CoreMLåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
fn coreml_device_available(device_id: usize) -> bool {
    #[cfg(feature = "coreml")]
    {
        // CoreMLåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯ãƒ­ã‚¸ãƒƒã‚¯
        use crate::gpu::coreml::CoreMLDevice;
        CoreMLDevice::is_available(device_id)
    }
    #[cfg(not(feature = "coreml"))]
    {
        false
    }
}
```

### 2.2 GpuLinearAlgebra - ç·šå½¢ä»£æ•°æ¼”ç®—ã®æ‹¡å¼µ

#### **Phase 1.2: æœ€é‡è¦traitã®æ‹¡å¼µ**
**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/gpu/matrix_ops.rs`

```rust
impl<T> GpuLinearAlgebra<T> for Tensor<T>
where T: Float + FromPrimitive + ScalarOperand + Send + Sync + 'static
{
    fn gpu_matmul(&self, other: &Self) -> RusTorchResult<Tensor<T>> {
        // ãƒ‡ãƒã‚¤ã‚¹é¸æŠãƒ­ã‚¸ãƒƒã‚¯æ‹¡å¼µ
        let device_type = if DeviceManager::is_coreml_available() {       // ğŸ†•
            DeviceType::CoreML(0)                                        // ğŸ†•
        } else if DeviceManager::is_cuda_available() {
            DeviceType::Cuda(0)
        } else if DeviceManager::is_metal_available() {
            DeviceType::Metal(0)
        } else {
            DeviceType::Cpu
        };

        let executor = GpuBatchMatrixExecutor::<T>::new(device_type)?;
        executor.batch_matmul(self, other)
    }

    // gpu_batch_matmul, gpu_matvec ã‚‚åŒæ§˜ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§æ‹¡å¼µ
}
```

#### **Phase 1.3: Executorã®æ‹¡å¼µ**
```rust
impl<T> GpuBatchMatrixExecutor<T> {
    pub fn batch_matmul(&self, a: &Tensor<T>, b: &Tensor<T>) -> RusTorchResult<Tensor<T>> {
        match &self.device_type {
            DeviceType::CoreML(_) => self.coreml_batch_matmul(a, b),    // ğŸ†•
            DeviceType::Cuda(_) => self.cuda_batch_matmul(a, b),
            DeviceType::Metal(_) => self.metal_batch_matmul(a, b),
            DeviceType::OpenCL(_) => self.opencl_batch_matmul(a, b),
            DeviceType::Cpu => a.matmul(b).map_err(|e| RusTorchError::gpu(e.to_string())),
        }
    }

    // ğŸ†• CoreMLå®Ÿè£…ãƒ¡ã‚½ãƒƒãƒ‰
    fn coreml_batch_matmul(&self, a: &Tensor<T>, b: &Tensor<T>) -> RusTorchResult<Tensor<T>> {
        #[cfg(feature = "coreml")]
        {
            use crate::gpu::coreml::CoreMLLinearAlgebra;

            let executor = CoreMLLinearAlgebra::new()?;
            executor.matmul(a, b)
        }
        #[cfg(not(feature = "coreml"))]
        {
            // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            a.matmul(b).map_err(|e| RusTorchError::gpu(e.to_string()))
        }
    }
}
```

### 2.3 GpuConvolution - ç•³ã¿è¾¼ã¿æ¼”ç®—ã®æ‹¡å¼µ

#### **Phase 2.1: CNNæ¼”ç®—ã®æ‹¡å¼µ**
**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/gpu/conv_ops.rs`

```rust
impl<T> GpuConvolution<T> for Tensor<T> {
    fn gpu_conv2d(&self, kernel: &Self, params: &ConvolutionParams) -> RusTorchResult<Tensor<T>> {
        // ç•³ã¿è¾¼ã¿æ¼”ç®—ç”¨ãƒ‡ãƒã‚¤ã‚¹é¸æŠï¼ˆCoreMLå„ªå…ˆï¼‰
        let device_type = if DeviceManager::is_coreml_available() {      // ğŸ†• CNNæœ€å„ªå…ˆ
            DeviceType::CoreML(0)
        } else if DeviceManager::is_metal_available() {
            DeviceType::Metal(0)
        } else if DeviceManager::is_cuda_available() {
            DeviceType::Cuda(0)
        } else {
            DeviceType::Cpu
        };

        let executor = GpuConvolutionExecutor::<T>::new(device_type)?;
        executor.conv2d(self, kernel, params)
    }
}

// GpuConvolutionExecutor æ‹¡å¼µ
impl<T> GpuConvolutionExecutor<T> {
    pub fn conv2d(&self, input: &Tensor<T>, kernel: &Tensor<T>, params: &ConvolutionParams) -> RusTorchResult<Tensor<T>> {
        match &self.device_type {
            DeviceType::CoreML(_) => self.coreml_conv2d(input, kernel, params), // ğŸ†•
            DeviceType::Metal(_) => self.metal_conv2d(input, kernel, params),
            DeviceType::Cuda(_) => self.cuda_conv2d(input, kernel, params),
            DeviceType::OpenCL(_) => self.opencl_conv2d(input, kernel, params),
            DeviceType::Cpu => self.cpu_conv2d(input, kernel, params),
        }
    }

    // ğŸ†• CoreMLç•³ã¿è¾¼ã¿å®Ÿè£…
    fn coreml_conv2d(&self, input: &Tensor<T>, kernel: &Tensor<T>, params: &ConvolutionParams) -> RusTorchResult<Tensor<T>> {
        #[cfg(feature = "coreml")]
        {
            use crate::gpu::coreml::CoreMLConvolution;

            let executor = CoreMLConvolution::new()?;
            executor.conv2d(input, kernel, params)
        }
        #[cfg(not(feature = "coreml"))]
        {
            self.cpu_conv2d(input, kernel, params)
        }
    }
}
```

### 2.4 GpuReduction - ãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³æ¼”ç®—ã®æ‹¡å¼µ

#### **Phase 2.2: çµ±è¨ˆæ¼”ç®—ã®æ‹¡å¼µ**
**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/gpu/reduction_ops.rs`

```rust
impl<T> GpuReduction<T> for Tensor<T> {
    fn gpu_sum(&self, dim: Option<usize>) -> RusTorchResult<Tensor<T>> {
        let device_type = best_device_for_reduction(); // CoreMLå«ã‚€é¸æŠãƒ­ã‚¸ãƒƒã‚¯

        let executor = GpuReductionExecutor::<T>::new(device_type)?;
        executor.sum(self, dim)
    }

    // gpu_mean, gpu_max, gpu_min ã‚‚åŒæ§˜
}

// ãƒ‡ãƒã‚¤ã‚¹é¸æŠã®æœ€é©åŒ–
fn best_device_for_reduction() -> DeviceType {
    if DeviceManager::is_coreml_available() {
        DeviceType::CoreML(0)
    } else if DeviceManager::is_metal_available() {
        DeviceType::Metal(0)
    } else if DeviceManager::is_cuda_available() {
        DeviceType::Cuda(0)
    } else {
        DeviceType::Cpu
    }
}
```

### 2.5 GpuParallelOp - ä¸¦åˆ—æ¼”ç®—ã®æ‹¡å¼µï¼ˆåŒ…æ‹¬çš„ï¼‰

#### **Phase 2.3: ä¸¦åˆ—å‡¦ç†çµ±åˆ**
**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/tensor/gpu_parallel.rs`

```rust
impl<T> GpuParallelOp<T> for Tensor<T> {
    fn gpu_elementwise_op<F>(&self, other: &Tensor<T>, op: F) -> ParallelResult<Tensor<T>>
    where F: Fn(T, T) -> T + Send + Sync + Clone + 'static
    {
        // è¦ç´ æ¼”ç®—ã«æœ€é©ãªãƒ‡ãƒã‚¤ã‚¹é¸æŠ
        let device_type = optimal_device_for_elementwise();

        match device_type {
            DeviceType::CoreML(_) => self.coreml_elementwise_op(other, op), // ğŸ†•
            DeviceType::Metal(_) => self.metal_elementwise_op(other, op),
            DeviceType::Cuda(_) => self.cuda_elementwise_op(other, op),
            _ => self.cpu_elementwise_op(other, op),
        }
    }

    fn to_device(&self, device: DeviceType) -> ParallelResult<Tensor<T>> {
        match device {
            DeviceType::CoreML(_) => self.to_coreml(),                    // ğŸ†•
            DeviceType::Metal(_) => self.to_metal(),
            DeviceType::Cuda(_) => self.to_cuda(),
            DeviceType::Cpu => Ok(self.to_cpu()?),
        }
    }
}
```

---

## ğŸ”§ 3. CoreMLå®Ÿè£…å±¤ã®è¨­è¨ˆ

### 3.1 CoreMLãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹é€ 

#### **æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ**
```
src/gpu/coreml/
â”œâ”€â”€ mod.rs                  # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å…¬é–‹ãƒ»CoreMLåŸºç›¤
â”œâ”€â”€ device.rs              # CoreMLãƒ‡ãƒã‚¤ã‚¹ç®¡ç†
â”œâ”€â”€ linear_algebra.rs      # ç·šå½¢ä»£æ•°æ¼”ç®—å®Ÿè£…
â”œâ”€â”€ convolution.rs         # ç•³ã¿è¾¼ã¿æ¼”ç®—å®Ÿè£…
â”œâ”€â”€ reduction.rs           # ãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³æ¼”ç®—å®Ÿè£…
â”œâ”€â”€ memory.rs              # ãƒ¡ãƒ¢ãƒªç®¡ç†ãƒ»è»¢é€
â”œâ”€â”€ error.rs               # CoreMLã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
â””â”€â”€ utils.rs               # å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
```

### 3.2 CoreMLåŸºç›¤ã‚¯ãƒ©ã‚¹è¨­è¨ˆ

#### **`src/gpu/coreml/mod.rs`**
```rust
use objc2_core_ml::*;
use objc2_foundation::*;

pub mod device;
pub mod linear_algebra;
pub mod convolution;
pub mod reduction;
pub mod memory;
pub mod error;
pub mod utils;

pub use device::CoreMLDevice;
pub use linear_algebra::CoreMLLinearAlgebra;
pub use convolution::CoreMLConvolution;
pub use reduction::CoreMLReduction;
pub use error::{CoreMLError, CoreMLResult};

/// CoreMLå®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
pub struct CoreMLContext {
    device: MLCDevice,
    training_graph: MLCTrainingGraph,
    inference_graph: MLCInferenceGraph,
}

impl CoreMLContext {
    pub fn new(device_id: usize) -> CoreMLResult<Self> {
        // Apple Neural Engineå„ªå…ˆã€Metal GPU ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        let device = if let Some(ane_device) = MLCDevice::aneDevice() {
            ane_device
        } else if let Some(gpu_device) = MLCDevice::gpuDevice() {
            gpu_device
        } else {
            return Err(CoreMLError::DeviceNotAvailable);
        };

        let training_graph = MLCTrainingGraph::new();
        let inference_graph = MLCInferenceGraph::new();

        Ok(CoreMLContext {
            device,
            training_graph,
            inference_graph,
        })
    }

    pub fn device(&self) -> &MLCDevice {
        &self.device
    }

    pub fn training_graph(&self) -> &MLCTrainingGraph {
        &self.training_graph
    }

    pub fn inference_graph(&self) -> &MLCInferenceGraph {
        &self.inference_graph
    }
}
```

### 3.3 ãƒ‡ãƒã‚¤ã‚¹ç®¡ç†ã®æ‹¡å¼µ

#### **`src/gpu/coreml/device.rs`**
```rust
use super::{CoreMLContext, CoreMLResult, CoreMLError};

pub struct CoreMLDevice {
    context: CoreMLContext,
    device_id: usize,
}

impl CoreMLDevice {
    pub fn new(device_id: usize) -> CoreMLResult<Self> {
        let context = CoreMLContext::new(device_id)?;
        Ok(CoreMLDevice { context, device_id })
    }

    pub fn is_available(device_id: usize) -> bool {
        #[cfg(target_os = "macos")]
        {
            // macOS 14.0+ ã§CoreMLåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
            if let Ok(_) = CoreMLContext::new(device_id) {
                true
            } else {
                false
            }
        }
        #[cfg(not(target_os = "macos"))]
        {
            false
        }
    }

    pub fn context(&self) -> &CoreMLContext {
        &self.context
    }
}

// DeviceManageræ‹¡å¼µ
impl crate::gpu::DeviceManager {
    // ğŸ†• CoreMLåˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
    pub fn is_coreml_available() -> bool {
        CoreMLDevice::is_available(0)
    }

    // ğŸ†• æœ€é©ãƒ‡ãƒã‚¤ã‚¹é¸æŠï¼ˆCoreMLå„ªå…ˆï¼‰
    pub fn optimal_device_for_ml() -> crate::gpu::DeviceType {
        if Self::is_coreml_available() {
            crate::gpu::DeviceType::CoreML(0)
        } else if Self::is_metal_available() {
            crate::gpu::DeviceType::Metal(0)
        } else if Self::is_cuda_available() {
            crate::gpu::DeviceType::Cuda(0)
        } else {
            crate::gpu::DeviceType::Cpu
        }
    }
}
```

---

## ğŸ“‹ 4. æ®µéšçš„å®Ÿè£…ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« - ä¿®æ­£ç‰ˆ

### ğŸš€ Phase 1: åŸºç›¤ãƒ»ç·šå½¢ä»£æ•° (3é€±é–“)

#### **Week 1: CoreMLåŸºç›¤**
```rust
// å®Ÿè£…é …ç›®
- DeviceType::CoreML è¿½åŠ 
- CoreMLContext, CoreMLDevice åŸºæœ¬å®Ÿè£…
- objc2-core-ml çµ±åˆãƒ†ã‚¹ãƒˆ
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°åŸºç›¤

// æˆæœç‰©
- src/gpu/mod.rs ã®æ‹¡å¼µ
- src/gpu/coreml/mod.rs æ–°è¦ä½œæˆ
- åŸºæœ¬çš„ãªå˜ä½“ãƒ†ã‚¹ãƒˆ
```

#### **Week 2-3: ç·šå½¢ä»£æ•°æ¼”ç®—**
```rust
// å®Ÿè£…é …ç›®
- GpuLinearAlgebra trait ã® CoreML æ‹¡å¼µ
- CoreMLLinearAlgebra å®Ÿè£…
- matmul, batch_matmul, matvec ã® CoreML å¯¾å¿œ
- æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

// æˆæœç‰©
- src/gpu/coreml/linear_algebra.rs
- æ—¢å­˜ matrix_ops.rs ã®æ‹¡å¼µ
- æ€§èƒ½æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ
```

### ğŸ§  Phase 2: CNNãƒ»æ­£è¦åŒ– (3é€±é–“)

#### **Week 4-5: ç•³ã¿è¾¼ã¿æ¼”ç®—**
```rust
// å®Ÿè£…é …ç›®
- GpuConvolution trait ã® CoreML æ‹¡å¼µ
- conv2d, batch_conv2d, conv2d_transpose å®Ÿè£…
- GpuPooling trait ã® CoreML æ‹¡å¼µ
- max_pool2d, avg_pool2d å®Ÿè£…

// æˆæœç‰©
- src/gpu/coreml/convolution.rs
- æ—¢å­˜ conv_ops.rs ã®æ‹¡å¼µ
- CNN ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
```

#### **Week 6: ãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãƒ»æ­£è¦åŒ–**
```rust
// å®Ÿè£…é …ç›®
- GpuReduction trait ã® CoreML æ‹¡å¼µ
- sum, mean, max, min å®Ÿè£…
- batch_norm, layer_norm å®Ÿè£…

// æˆæœç‰©
- src/gpu/coreml/reduction.rs
- æ­£è¦åŒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼å®Ÿè£…
- çµ±è¨ˆæ¼”ç®—ãƒ†ã‚¹ãƒˆ
```

### âš™ï¸ Phase 3: ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ (3é€±é–“)

#### **Week 7-8: ä¸¦åˆ—å‡¦ç†ãƒ»ãƒ¡ãƒ¢ãƒª**
```rust
// å®Ÿè£…é …ç›®
- GpuParallelOp trait ã® CoreML æ‹¡å¼µ
- ãƒ¡ãƒ¢ãƒªè»¢é€æœ€é©åŒ–
- Metal-CoreML é€£æº

// æˆæœç‰©
- ä¸¦åˆ—å‡¦ç†çµ±åˆ
- ãƒ¡ãƒ¢ãƒªç®¡ç†æœ€é©åŒ–
- ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å®Ÿè¡Œ
```

#### **Week 9: æœ€çµ‚çµ±åˆãƒ»ãƒ†ã‚¹ãƒˆ**
```rust
// å®Ÿè£…é …ç›®
- å…¨traitçµ±åˆãƒ†ã‚¹ãƒˆ
- æ€§èƒ½å›å¸°ãƒ†ã‚¹ãƒˆ
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå®Œæˆ

// æˆæœç‰©
- åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
- æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆ
- ä½¿ç”¨ã‚¬ã‚¤ãƒ‰
```

---

## ğŸ¯ 5. å®Ÿè£…ã®å„ªä½æ€§

### 5.1 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£é©åˆæ€§

| æ—¢å­˜è¦ç´  | CoreMLé©åˆåº¦ | å®Ÿè£…å·¥æ•° |
|----------|-------------|----------|
| **traitä½“ç³»** | âœ… 100%å®Œç’§ | ã»ã¼0 |
| **ãƒ‡ãƒã‚¤ã‚¹æŠ½è±¡åŒ–** | âœ… ç†æƒ³çš„ | æœ€å°é™ |
| **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°** | âœ… çµ±åˆæ¸ˆã¿ | æ‹¡å¼µã®ã¿ |
| **ãƒ†ã‚¹ãƒˆåŸºç›¤** | âœ… å†åˆ©ç”¨å¯èƒ½ | æµç”¨ |

### 5.2 æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã¸ã®å½±éŸ¿

#### **ã‚¼ãƒ­ç ´å£Šå¤‰æ›´**
```rust
// ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ¼ãƒ‰ - å¤‰æ›´ãªã—
let a = Tensor::from_slice(&[1.0, 2.0]);
let b = Tensor::from_slice(&[3.0, 4.0]);
let result = a.gpu_matmul(&b)?;  // å†…éƒ¨ã§CoreMLãŒä½¿ç”¨ã•ã‚Œã‚‹
```

#### **å¾Œæ–¹äº’æ›æ€§100%**
- æ—¢å­˜API: ä¸€åˆ‡å¤‰æ›´ãªã—
- æ—¢å­˜ãƒ†ã‚¹ãƒˆ: ãã®ã¾ã¾å‹•ä½œ
- æ—¢å­˜ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼: å½±éŸ¿ãªã—

### 5.3 æ®µéšçš„ä¾¡å€¤æä¾›

| Phase | ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¾¡å€¤ | ãƒªã‚¹ã‚¯ |
|-------|-------------|--------|
| **Phase 1** | åŸºæœ¬æ¼”ç®—+30%æ€§èƒ½å‘ä¸Š | ğŸŸ¢ ä½ |
| **Phase 2** | CNN+50%æ€§èƒ½å‘ä¸Š | ğŸŸ¡ ä¸­ |
| **Phase 3** | ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ+60%æ€§èƒ½å‘ä¸Š | ğŸŸ¡ ä¸­ |

---

## âš¡ 6. æŠ€è¡“çš„å®Ÿè£…è©³ç´°

### 6.1 å‹å®‰å…¨æ€§ã®ä¿è¨¼

#### **æ—¢å­˜ã®å‹åˆ¶ç´„æ´»ç”¨**
```rust
// æ—¢å­˜åˆ¶ç´„ãŒãã®ã¾ã¾ä½¿ãˆã‚‹
impl<T> GpuLinearAlgebra<T> for Tensor<T>
where
    T: Float + FromPrimitive + ScalarOperand + Send + Sync + 'static
{
    // CoreMLå®Ÿè£…ã§ã‚‚åŒã˜åˆ¶ç´„ãŒé©ç”¨ã•ã‚Œã‚‹
    fn gpu_matmul(&self, other: &Self) -> RusTorchResult<Tensor<T>> {
        // CoreMLå®Ÿè£…...
    }
}
```

### 6.2 ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°çµ±åˆ

#### **çµ±ä¸€ã‚¨ãƒ©ãƒ¼ä½“ç³»**
```rust
// æ—¢å­˜ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã®æ‹¡å¼µ
impl From<CoreMLError> for RusTorchError {
    fn from(err: CoreMLError) -> Self {
        RusTorchError::gpu(&format!("CoreML error: {}", err))
    }
}

// é€æ˜ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
fn coreml_matmul(&self, a: &Tensor<T>, b: &Tensor<T>) -> RusTorchResult<Tensor<T>> {
    let executor = CoreMLLinearAlgebra::new()?;  // CoreMLError â†’ RusTorchError
    executor.matmul(a, b)                        // çµ±ä¸€ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼å‹
}
```

### 6.3 æ€§èƒ½æœ€é©åŒ–æˆ¦ç•¥

#### **ãƒ‡ãƒã‚¤ã‚¹é¸æŠã®æœ€é©åŒ–**
```rust
// æ¼”ç®—ã‚¿ã‚¤ãƒ—åˆ¥æœ€é©åŒ–
pub fn optimal_device_for_operation(op: OperationType) -> DeviceType {
    match op {
        OperationType::Convolution => {
            // ç•³ã¿è¾¼ã¿ã¯CoreMLãŒæœ€å„ªç§€
            if DeviceManager::is_coreml_available() {
                DeviceType::CoreML(0)
            } else {
                DeviceType::Metal(0)
            }
        }
        OperationType::MatMul { size } if size > 1024 => {
            // å¤§ããªè¡Œåˆ—ã¯CoreMLæœ‰åˆ©
            DeviceType::CoreML(0)
        }
        OperationType::ElementWise => {
            // è¦ç´ æ¼”ç®—ã¯Metalé«˜é€Ÿ
            DeviceType::Metal(0)
        }
        _ => DeviceManager::optimal_device_for_ml(),
    }
}
```

---

## ğŸ§ª 7. åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### 7.1 æ—¢å­˜ãƒ†ã‚¹ãƒˆã®æ´»ç”¨

#### **ãƒ†ã‚¹ãƒˆç¶™æ‰¿**
```rust
// æ—¢å­˜ãƒ†ã‚¹ãƒˆãŒCoreMLã§ã‚‚å‹•ä½œã™ã‚‹ã“ã¨ã‚’ä¿è¨¼
#[cfg(test)]
mod coreml_compatibility_tests {
    use super::*;

    #[test]
    fn test_existing_gpu_matmul_with_coreml() {
        // å¼·åˆ¶çš„ã«CoreMLãƒ‡ãƒã‚¤ã‚¹ã‚’ä½¿ç”¨
        std::env::set_var("RUSTORCH_FORCE_COREML", "1");

        // æ—¢å­˜ã®ãƒ†ã‚¹ãƒˆãƒ­ã‚¸ãƒƒã‚¯ã‚’ãã®ã¾ã¾å®Ÿè¡Œ
        let a = Tensor::<f32>::from_vec(vec![1.0, 2.0, 3.0, 4.0], vec![2, 2]);
        let b = Tensor::<f32>::from_vec(vec![5.0, 6.0, 7.0, 8.0], vec![2, 2]);

        let result = a.gpu_matmul(&b).unwrap();

        // æœŸå¾…ã•ã‚Œã‚‹çµæœã¯å¤‰ã‚ã‚‰ãªã„
        assert_eq!(result.shape(), &[2, 2]);

        std::env::remove_var("RUSTORCH_FORCE_COREML");
    }
}
```

### 7.2 æ€§èƒ½å›å¸°é˜²æ­¢

#### **ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç¶™æ‰¿**
```rust
// æ—¢å­˜ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®CoreMLç‰ˆ
#[bench]
fn bench_coreml_matmul(b: &mut Bencher) {
    let input = create_test_tensor([1024, 1024]);

    // CoreMLãƒ‡ãƒã‚¤ã‚¹å¼·åˆ¶ä½¿ç”¨
    let coreml_tensor = input.to_device(DeviceType::CoreML(0)).unwrap();

    b.iter(|| {
        black_box(coreml_tensor.gpu_matmul(&coreml_tensor).unwrap())
    });
}
```

---

## ğŸ“Š 8. æœŸå¾…ã•ã‚Œã‚‹æˆæœ

### 8.1 å®Ÿè£…å·¥æ•°ã®åŠ‡çš„å‰Šæ¸›

| å½“åˆäºˆæƒ³ | traitæ´»ç”¨å¾Œ | å‰Šæ¸›ç‡ |
|----------|------------|--------|
| **18é€±é–“** | **9é€±é–“** | **-50%** |
| æ–°APIè¨­è¨ˆ 4é€± | ä¸è¦ | **-100%** |
| traitå®Ÿè£… 8é€± | 4é€± | **-50%** |
| çµ±åˆãƒ†ã‚¹ãƒˆ 4é€± | 2é€± | **-50%** |
| ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ 2é€± | 1é€± | **-50%** |

### 8.2 å“è³ªä¿è¨¼ã®å‘ä¸Š

| å“è³ªæŒ‡æ¨™ | æ—¢å­˜åŸºç›¤æ´»ç”¨ | æ–°è¦å®Ÿè£… |
|----------|-------------|----------|
| **å‹å®‰å…¨æ€§** | âœ… ä¿è¨¼æ¸ˆã¿ | âš ï¸ è¦æ¤œè¨¼ |
| **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°** | âœ… çµ±åˆæ¸ˆã¿ | âš ï¸ è¦è¨­è¨ˆ |
| **ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸** | âœ… ç¶™æ‰¿å¯èƒ½ | âš ï¸ è¦ä½œæˆ |
| **å¾Œæ–¹äº’æ›æ€§** | âœ… 100%ä¿è¨¼ | âš ï¸ ãƒªã‚¹ã‚¯ã‚ã‚Š |

### 8.3 æ€§èƒ½å‘ä¸Šäºˆæ¸¬ï¼ˆç¢ºå®Ÿæ€§é«˜ï¼‰

| æ¼”ç®—ã‚¿ã‚¤ãƒ— | æ—¢å­˜GPU | CoreML | å‘ä¸Šç‡ |
|-----------|---------|--------|--------|
| **ç•³ã¿è¾¼ã¿** | 100% | 160-180% | **+60-80%** |
| **è¡Œåˆ—ä¹—ç®—** | 100% | 140-160% | **+40-60%** |
| **è¦ç´ æ¼”ç®—** | 100% | 120-140% | **+20-40%** |

---

## ğŸ¯ 9. çµè«–ãƒ»å®Ÿè£…æ¨å¥¨åº¦

### 9.1 æŠ€è¡“çš„å®Ÿç¾å¯èƒ½æ€§: **ğŸŸ¢ æ¥µã‚ã¦é«˜ã„**

#### æˆåŠŸè¦å› 
âœ… **æ—¢å­˜ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å®Œç’§ãªé©åˆ**
âœ… **æœ€å°é™ã®å¤‰æ›´ã§æœ€å¤§ã®åŠ¹æœ**
âœ… **ã‚¼ãƒ­ç ´å£Šå¤‰æ›´ã§ã®çµ±åˆ**
âœ… **æ®µéšçš„ä¾¡å€¤æä¾›**

#### ãƒªã‚¹ã‚¯è¦å› 
âš ï¸ **objc2-core-ml API ã®å­¦ç¿’ã‚³ã‚¹ãƒˆ** â†’ æ–‡æ›¸åŒ–ã§è§£æ±º
âš ï¸ **CoreMLç‰¹æœ‰ã®åˆ¶ç´„** â†’ æ—¢å­˜ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§è§£æ±º

### 9.2 æŠ•è³‡å¯¾åŠ¹æœ: **ğŸŸ¢ éå¸¸ã«é«˜ã„**

#### é–‹ç™ºã‚³ã‚¹ãƒˆ: **9é€±é–“** ï¼ˆå½“åˆ18é€±ã‹ã‚‰åŠæ¸›ï¼‰
#### æŠ€è¡“ä¾¡å€¤: **æ—¢å­˜è³‡ç”£ã®å®Œå…¨æ´»ç”¨**
#### ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¾¡å€¤: **é€æ˜ãªæ€§èƒ½å‘ä¸Š**

### 9.3 å®Ÿè£…æˆ¦ç•¥: **ğŸš€ å³åº§ã«é–‹å§‹æ¨å¥¨**

1. **Phase 1é–‹å§‹**: DeviceTypeæ‹¡å¼µã‹ã‚‰å³åº§ã«ç€æ‰‹
2. **æ®µéšçš„ä¾¡å€¤**: å„Phaseã§ç‹¬ç«‹ã—ãŸä¾¡å€¤æä¾›
3. **ãƒªã‚¹ã‚¯æœ€å°**: æ—¢å­˜æ©Ÿèƒ½ã¸ã®å½±éŸ¿ã‚¼ãƒ­

**ç·åˆåˆ¤å®š**: **ğŸŸ¢ æœ€å„ªå…ˆå®Ÿè£…æ¨å¥¨**

---

*ã“ã®è©³ç´°è¨ˆç”»ã¯ã€RusTorchã®æ—¢å­˜traitä½“ç³»ã®å®Œç’§ãªé©åˆæ€§ã‚’æ´»ç”¨ã—ã€æœ€å°é™ã®å·¥æ•°ã§æœ€å¤§ã®åŠ¹æœã‚’å¾—ã‚‹CoreMLçµ±åˆæˆ¦ç•¥ã‚’æä¾›ã—ã¾ã™ã€‚*