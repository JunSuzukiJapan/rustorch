# example-cli Refactoring Plan
ç”Ÿæˆæ—¥æ™‚: 2025-10-08

## ğŸ¯ ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã®ç›®çš„

Metal GPUçµ±åˆã®å‰ã«ã€example-cliã®ã‚³ãƒ¼ãƒ‰å“è³ªã‚’æ”¹å–„ã—ã€ä¿å®ˆæ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚

## ğŸ“Š ç¾çŠ¶åˆ†æ

### ã‚³ãƒ¼ãƒ‰çµ±è¨ˆ
- **ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: 57 Rustãƒ•ã‚¡ã‚¤ãƒ«
- **ç·è¡Œæ•°**: 12,057è¡Œ
- **å…¬é–‹å‹**: 77å€‹ï¼ˆstruct/enumï¼‰
- **å…¬é–‹é–¢æ•°**: 268å€‹
- **TODO/FIXME**: 3å€‹ã®ã¿ï¼ˆè‰¯å¥½ï¼‰

### æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«
1. **inference.rs** (932è¡Œ) - æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³
2. **tensor_loader.rs** (653è¡Œ) - ãƒ†ãƒ³ã‚½ãƒ«ãƒ­ãƒ¼ãƒ€ãƒ¼
3. **repl.rs** (522è¡Œ) - REPLã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
4. **gguf.rs** (511è¡Œ) - GGUFãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
5. **main.rs** (505è¡Œ) - ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ

## ğŸ”´ ä¸»è¦ãªå•é¡Œç‚¹

### 1. main.rs ã®è‚¥å¤§åŒ–ï¼ˆ505è¡Œï¼‰

**å•é¡Œç®‡æ‰€**: 32-400è¡Œï¼ˆ`start_cli()`é–¢æ•°ï¼‰

#### 1.1 è¨­å®šãƒãƒ¼ã‚¸ãƒ­ã‚¸ãƒƒã‚¯ã®å†—é•·æ€§ï¼ˆ46-76è¡Œï¼‰
```rust
// æ‚ªã„ä¾‹: æ‰‹å‹•ã§ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã”ã¨ã«ãƒãƒ¼ã‚¸
let max_tokens = if args.max_tokens != 512 {
    args.max_tokens
} else {
    file_config.generation.max_tokens
};

let temperature = if (args.temperature - 0.7).abs() > f32::EPSILON {
    args.temperature
} else {
    file_config.generation.temperature
};
// ... ç¹°ã‚Šè¿”ã—
```

**æ”¹å–„æ¡ˆ**: ConfigBuilderãƒ‘ã‚¿ãƒ¼ãƒ³ã¾ãŸã¯merge()ãƒ¡ã‚½ãƒƒãƒ‰
```rust
// è‰¯ã„ä¾‹
let gen_config = GenerationConfig::builder()
    .with_cli_args(&args)
    .with_file_config(&file_config)
    .build();
```

#### 1.2 ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ­ãƒ¼ãƒ‰  ãƒ­ã‚¸ãƒƒã‚¯ã®é‡è¤‡ï¼ˆ112-300è¡Œï¼‰

**å•é¡Œ**:
- `hybrid-f32`ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰: 112-198è¡Œï¼ˆ87è¡Œï¼‰
- `mac-hybrid`ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰: 202-270è¡Œï¼ˆ69è¡Œï¼‰
- `metal`ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰: 271-340è¡Œï¼ˆ70è¡Œï¼‰
- **ã»ã¼åŒã˜ã‚³ãƒ¼ãƒ‰ãŒ3å›ç¹°ã‚Šè¿”ã•ã‚Œã¦ã„ã‚‹**

**é‡è¤‡ã‚³ãƒ¼ãƒ‰ä¾‹**:
```rust
// hybrid-f32 (120-128è¡Œ)
let model_name_lower = model_path.file_name()
    .and_then(|n| n.to_str())
    .unwrap_or("")
    .to_lowercase();

let is_llama = model_name_lower.contains("llama") ||
              model_name_lower.contains("mistral") ||
              model_name_lower.contains("mixtral");

// mac-hybrid (210-218è¡Œ) - å®Œå…¨ã«åŒã˜
let model_name_lower = model_path.file_name()
    .and_then(|n| n.to_str())
    .unwrap_or("")
    .to_lowercase();

let is_llama = model_name_lower.contains("llama") ||
              model_name_lower.contains("mistral") ||
              model_name_lower.contains("mixtral");

// metal (279-287è¡Œ) - å®Œå…¨ã«åŒã˜
```

**æ”¹å–„æ¡ˆ**: BackendLoaderãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³
```rust
// æ–°ã—ã„æ§‹é€ 
pub struct BackendLoader;

impl BackendLoader {
    pub fn load_model(
        backend: Backend,
        model_path: &Path,
        engine: &mut InferenceEngine
    ) -> Result<()> {
        let architecture = Self::detect_architecture(model_path)?;

        match (backend, architecture) {
            (Backend::HybridF32, Architecture::Llama) => {
                Self::load_f32_llama(model_path, DeviceType::Metal, engine)
            }
            (Backend::MacHybrid, Architecture::Llama) => {
                Self::load_f32_llama(model_path, DeviceType::Hybrid, engine)
            }
            // ...
        }
    }

    fn detect_architecture(model_path: &Path) -> Result<Architecture> {
        let model_name = model_path.file_name()
            .and_then(|n| n.to_str())
            .unwrap_or("")
            .to_lowercase();

        if model_name.contains("llama") ||
           model_name.contains("mistral") ||
           model_name.contains("mixtral") {
            Ok(Architecture::Llama)
        } else {
            Ok(Architecture::GPT)
        }
    }

    fn load_f32_llama(
        model_path: &Path,
        device_type: DeviceType,
        engine: &mut InferenceEngine
    ) -> Result<()> {
        // å…±é€šå®Ÿè£…
    }
}
```

### 2. inference.rs ã®è¤‡é›‘æ€§ï¼ˆ932è¡Œï¼‰

**ç¾çŠ¶**: å˜ä¸€ã®implãƒ–ãƒ­ãƒƒã‚¯ã«28å€‹ã®ãƒ¡ã‚½ãƒƒãƒ‰

**æ”¹å–„æ¡ˆ**:
- æ¨è«–ãƒ­ã‚¸ãƒƒã‚¯ã‚’åˆ†é›¢: `InferenceEngine` + `InferenceBackend` trait
- ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥ã‚’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–

### 3. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ã®è²¬ä»»åˆ†é›¢ä¸è¶³

**ç¾çŠ¶ã®å•é¡Œ**:
- `main.rs`ãŒãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ­ãƒ¼ãƒ‰è©³ç´°ã‚’çŸ¥ã‚Šã™ãã¦ã„ã‚‹
- `InferenceEngine`ãŒè¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«å‹ã‚’ç›´æ¥ä¿æŒï¼ˆf64/f32/Llamaï¼‰

## ğŸ¯ ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°è¨ˆç”»

### Phase 1: è¨­å®šãƒãƒ¼ã‚¸ã®æ”¹å–„ï¼ˆå„ªå…ˆåº¦: é«˜ï¼‰

**å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«**: `src/utils/config.rs`

**å®Ÿè£…**:
```rust
impl GenerationConfig {
    /// Merge CLI args with file config
    /// CLI args take precedence
    pub fn merge(file_config: &GenerationConfig, args: &CliArgs) -> Self {
        Self {
            max_tokens: Self::override_value(
                args.max_tokens,
                512, // default
                file_config.max_tokens
            ),
            temperature: Self::override_f32(
                args.temperature,
                0.7, // default
                file_config.temperature
            ),
            top_p: Self::override_f32(
                args.top_p,
                0.9, // default
                file_config.top_p
            ),
            top_k: Self::override_value(
                args.top_k,
                40, // default
                file_config.top_k as u32
            ) as usize,
        }
    }

    fn override_value<T: PartialEq>(cli: T, default: T, file: T) -> T {
        if cli != default { cli } else { file }
    }

    fn override_f32(cli: f32, default: f32, file: f32) -> f32 {
        if (cli - default).abs() > f32::EPSILON { cli } else { file }
    }
}
```

**å‰Šæ¸›è¡Œæ•°**: main.rs ã‹ã‚‰ç´„30è¡Œå‰Šæ¸›

### Phase 2: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ­ãƒ¼ãƒ€ãƒ¼ã®åˆ†é›¢ï¼ˆå„ªå…ˆåº¦: é«˜ï¼‰

**æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«**: `src/model/backend_loader.rs`

**æ§‹é€ **:
```rust
pub enum Architecture {
    GPT,
    Llama,
}

pub struct BackendLoader;

impl BackendLoader {
    /// Load model with specified backend
    pub fn load_model(
        backend: Backend,
        model_path: &Path,
        engine: &mut InferenceEngine,
    ) -> Result<()> {
        let arch = Self::detect_architecture(model_path)?;

        #[cfg(feature = "hybrid-f32")]
        if backend == Backend::HybridF32 {
            return Self::load_hybrid_f32(model_path, arch, engine);
        }

        #[cfg(feature = "mac-hybrid")]
        if backend == Backend::Hybrid {
            return Self::load_mac_hybrid(model_path, arch, engine);
        }

        #[cfg(feature = "metal")]
        if backend == Backend::Metal {
            return Self::load_metal(model_path, arch, engine);
        }

        // CPU fallback
        Self::load_cpu(model_path, arch, engine)
    }

    fn detect_architecture(path: &Path) -> Result<Architecture>;
    fn load_hybrid_f32(path: &Path, arch: Architecture, engine: &mut InferenceEngine) -> Result<()>;
    fn load_mac_hybrid(path: &Path, arch: Architecture, engine: &mut InferenceEngine) -> Result<()>;
    fn load_metal(path: &Path, arch: Architecture, engine: &mut InferenceEngine) -> Result<()>;
    fn load_cpu(path: &Path, arch: Architecture, engine: &mut InferenceEngine) -> Result<()>;
}
```

**å‰Šæ¸›è¡Œæ•°**: main.rsã‹ã‚‰ç´„200è¡Œå‰Šæ¸›

### Phase 3: InferenceEngineã®ç°¡ç´ åŒ–ï¼ˆå„ªå…ˆåº¦: ä¸­ï¼‰

**ç¾çŠ¶ã®å•é¡Œ**:
```rust
pub struct InferenceEngine {
    model: Option<TransformerModel>,
    gpt_model: Option<GPTModel>,
    #[cfg(feature = "hybrid-f32")]
    f32_gpt_model: Option<F32GPTModel>,
    #[cfg(feature = "hybrid-f32")]
    f32_llama_model: Option<F32LlamaModel>,
    // ...
}
```

**æ”¹å–„æ¡ˆ**: Enum Dispatchãƒ‘ã‚¿ãƒ¼ãƒ³
```rust
pub enum ModelBackend {
    Transformer(TransformerModel),
    GPT(GPTModel),
    #[cfg(feature = "hybrid-f32")]
    F32GPT(F32GPTModel),
    #[cfg(feature = "hybrid-f32")]
    F32Llama(F32LlamaModel),
}

pub struct InferenceEngine {
    backend: Option<ModelBackend>,
    generation_config: GenerationConfig,
    sampling_config: SamplingConfig,
    loader: ModelLoader,
}

impl InferenceEngine {
    pub fn generate(&mut self, prompt: &str) -> Result<String> {
        match &mut self.backend {
            Some(ModelBackend::Transformer(m)) => self.generate_transformer(m, prompt),
            Some(ModelBackend::GPT(m)) => self.generate_gpt(m, prompt),
            #[cfg(feature = "hybrid-f32")]
            Some(ModelBackend::F32GPT(m)) => self.generate_f32_gpt(m, prompt),
            #[cfg(feature = "hybrid-f32")]
            Some(ModelBackend::F32Llama(m)) => self.generate_f32_llama(m, prompt),
            None => Err(anyhow::anyhow!("No model loaded")),
        }
    }
}
```

### Phase 4: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹é€ ã®æ•´ç†ï¼ˆå„ªå…ˆåº¦: ä½ï¼‰

**ææ¡ˆæ§‹é€ **:
```
src/
â”œâ”€â”€ main.rs (ç°¡ç´ åŒ–: 150è¡Œä»¥ä¸‹)
â”œâ”€â”€ lib.rs
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ mod.rs
â”‚   â”œâ”€â”€ cpu.rs
â”‚   â”œâ”€â”€ metal.rs
â”‚   â”œâ”€â”€ cuda.rs
â”‚   â””â”€â”€ hybrid.rs
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ mod.rs
â”‚   â”œâ”€â”€ loader.rs
â”‚   â”œâ”€â”€ backend_loader.rs (æ–°è¦)
â”‚   â”œâ”€â”€ inference.rs (ç°¡ç´ åŒ–)
â”‚   â””â”€â”€ architectures/
â”œâ”€â”€ config/  (æ–°è¦: utils/config.rs ã‹ã‚‰ç§»å‹•)
â”‚   â”œâ”€â”€ mod.rs
â”‚   â”œâ”€â”€ generation.rs
â”‚   â””â”€â”€ merge.rs
â””â”€â”€ ...
```

## ğŸ“‹ å®Ÿè£…é †åº

### Step 1: è¨­å®šãƒãƒ¼ã‚¸ã®æ”¹å–„ âœ…
- [ ] `GenerationConfig::merge()`å®Ÿè£…
- [ ] main.rsã§ä½¿ç”¨
- [ ] ãƒ†ã‚¹ãƒˆè¿½åŠ 

### Step 2: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ­ãƒ¼ãƒ€ãƒ¼åˆ†é›¢ âœ…
- [ ] `src/model/backend_loader.rs`ä½œæˆ
- [ ] `Architecture`enumå®šç¾©
- [ ] `BackendLoader`å®Ÿè£…
- [ ] main.rsã‹ã‚‰ç§»è¡Œ
- [ ] ãƒ†ã‚¹ãƒˆè¿½åŠ 

### Step 3: main.rsã®ç°¡ç´ åŒ–ç¢ºèª âœ…
- [ ] è¡Œæ•°ç¢ºèªï¼ˆç›®æ¨™: 200è¡Œä»¥ä¸‹ï¼‰
- [ ] è¤‡é›‘åº¦ç¢ºèª
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¿½åŠ 

### Step 4: InferenceEngineç°¡ç´ åŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
- [ ] `ModelBackend` enumå®Ÿè£…
- [ ] `InferenceEngine`ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°
- [ ] æ—¢å­˜æ©Ÿèƒ½ã®å‹•ä½œç¢ºèª

## ğŸ“ æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ

### ã‚³ãƒ¼ãƒ‰å“è³ª
- âœ… main.rs: 505è¡Œ â†’ ç´„200è¡Œï¼ˆ60%å‰Šæ¸›ï¼‰
- âœ… é‡è¤‡ã‚³ãƒ¼ãƒ‰å‰Šæ¸›: ç´„200è¡Œ
- âœ… ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è²¬ä»»ã®æ˜ç¢ºåŒ–

### ä¿å®ˆæ€§
- âœ… æ–°ã—ã„ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰è¿½åŠ ãŒå®¹æ˜“
- âœ… è¨­å®šãƒãƒ¼ã‚¸ãƒ­ã‚¸ãƒƒã‚¯ã®ä¸€å…ƒç®¡ç†
- âœ… ãƒ†ã‚¹ãƒˆå®¹æ˜“æ€§ã®å‘ä¸Š

### Metalçµ±åˆã®æº–å‚™
- âœ… ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ­ã‚¸ãƒƒã‚¯ãŒåˆ†é›¢ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€Metalãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰çµ±åˆãŒå®¹æ˜“
- âœ… InferenceEngineã®è¤‡é›‘æ€§ãŒä½æ¸›ã•ã‚Œã€GPUçµ±åˆã®ãƒ†ã‚¹ãƒˆãŒç°¡å˜

## ğŸš€ æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

1. **å³åº§ã«é–‹å§‹**: Step 1ï¼ˆè¨­å®šãƒãƒ¼ã‚¸æ”¹å–„ï¼‰
2. **Phase 1å®Œäº†å¾Œ**: Step 2ï¼ˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ­ãƒ¼ãƒ€ãƒ¼åˆ†é›¢ï¼‰
3. **ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å®Œäº†å¾Œ**: Metal GPUçµ±åˆã«é€²ã‚€

## ğŸ“Š æˆåŠŸåŸºæº–

- [ ] main.rsãŒ200è¡Œä»¥ä¸‹
- [ ] é‡è¤‡ã‚³ãƒ¼ãƒ‰ã‚¼ãƒ­ï¼ˆDRYåŸå‰‡éµå®ˆï¼‰
- [ ] æ—¢å­˜æ©Ÿèƒ½ã™ã¹ã¦å‹•ä½œï¼ˆregressionç„¡ã—ï¼‰
- [ ] æ–°ã—ã„ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ >80%
- [ ] Metalçµ±åˆã®æº–å‚™å®Œäº†
