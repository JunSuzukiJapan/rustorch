# トークナイザー修正の進捗レポート

**日付**: 2025-10-08
**ステータス**: 🔧 部分的に修正、さらなる改善が必要

## 実装した修正

### 修正内容
`LlamaSpmTokenizer::tokenize()`にSentencePiece前処理を追加：

```rust
// Before (間違い):
let chars: Vec<char> = text.chars().collect();

// After (部分的に正しい):
let preprocessed = format!("▁{}", text.replace(' ', "▁"));
let chars: Vec<char> = preprocessed.chars().collect();
```

### 動作確認

テスト入力:  `"Hello"`（チャットテンプレート付き）
```
formatted='<|user|>\nHello</s>\n<|assistant|>\n'
tokens=[1, 529, 29989, 1792, 29989, 29958, 13, 10994, 829, 29879, 29958, 13, 29966, 29989, 465, 22137, 29989, 29958, 13, 2]
```

## 発見した問題

### 問題1: 改行の扱いが不完全

**現象**:
- トークンID `10994` = `"Hello"` (スペースプレフィックスなし)
- 期待値: トークンID `15043` = `"▁Hello"` (スペースプレフィックス付き)

**原因**:
チャットテンプレートの`\n`（改行）の後の単語が、正しくトークン化されていない。
- 入力: `"<|user|>\nHello</s>"`
- `\n`の後の`"Hello"`は`"▁Hello"`としてトークン化されるべき
- しかし現在の実装は`text.replace(' ', '▁')`のみで、改行を考慮していない

### 問題2: SentencePieceの単語境界定義

SentencePieceでは、以下が単語境界とみなされる：
- スペース (` `)
- 改行 (`\n`, `\r`)
- タブ (`\t`)
- その他の空白文字

現在の実装はスペースのみを処理。

## 必要な追加修正

### 修正案1: 全ての空白文字を処理

```rust
// Better approach:
let preprocessed = text
    .chars()
    .map(|c| {
        if c.is_whitespace() {
            '▁'
        } else {
            c
        }
    })
    .collect::<String>();
let preprocessed = format!("▁{}", preprocessed);
```

### 修正案2: llama.cpp互換の実装

llama.cppの正確な動作を確認し、それに合わせる必要があります。
- どの文字が単語境界として扱われるか
- 特殊トークン（`<s>`, `</s>`等）の扱い
- 改行とスペースの違い（両方とも`▁`に変換？別々に処理？）

## テスト結果

### 語彙確認 ✅
```
"Hello" -> ID 10994 (スペースなし)
"▁Hello" -> ID 15043 (スペースプレフィックス付き)
"What" -> ID 5618
"▁What" -> ID 1724
```

### マージルール確認 ✅
```
[0] "▁" + "t" = "▁t" (ID 260)
[6] "▁t" + "h" = "▁th" (ID 266)
[18] "▁t" + "he" = "▁the" (ID 278)
```

語彙とマージルールは正しく抽出されている。

### トークン化テスト ❌
```
Input: "<|user|>\nHello</s>"
Current:  [529, 29989, 1792, 29989, 29958, 13, 10994, 829, 29879, 29958]
                                              ^^^^^ 間違い
Expected: [529, 29989, 1792, 29989, 29958, 13, 15043, 829, 29879, 29958]
                                              ^^^^^ 正しい
```

## 次のステップ

### 優先度1: 空白文字の完全な処理
1. 全ての空白文字（スペース、改行、タブ等）を`▁`に変換
2. テストして動作確認
3. llama.cppと出力を比較

### 優先度2: llama.cppとの詳細比較
1. llama.cppのソースコードを参照
2. トークナイザーの前処理ロジックを完全に理解
3. 同じロジックをRustで実装

### 優先度3: エッジケースのテスト
1. 複数の連続したスペース/改行
2. 特殊文字との組み合わせ
3. 空文字列、非ASCII文字

## 関連ファイル

- `example-cli/src/tokenizer/llama_spm.rs` (lines 86-95) - 修正箇所
- `examples/test_llama_spm_tokenizer.rs` - 語彙テスト
- `docs/core/SESSION_2025_10_08_SUMMARY.md` - セッションサマリー

## 結論

**部分的な進歩** ✅:
- スペース処理の基本実装
- 語彙・マージルール抽出の確認
- 問題の特定（改行の扱い）

**残りの作業** ⚠️:
- 全ての空白文字の処理
- llama.cpp互換性の完全な確保
- 包括的なテスト

トークナイザーの完全な修正により、RusTorchはllama.cppと同じ出力を生成できるようになります。
