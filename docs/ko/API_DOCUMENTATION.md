# RusTorch API ë¬¸ì„œ

## ğŸ“š ì™„ì „í•œ API ì°¸ì¡°

ì´ ë¬¸ì„œëŠ” RusTorch v0.5.15ì˜ í¬ê´„ì ì¸ API ë¬¸ì„œë¥¼ ëª¨ë“ˆê³¼ ê¸°ëŠ¥ë³„ë¡œ ì •ë¦¬í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤. ëª¨ë“  1060+ í…ŒìŠ¤íŠ¸ì— ê±¸ì³ ì¼ê´€ëœ ì˜¤ë¥˜ ê´€ë¦¬ë¥¼ ìœ„í•´ `RusTorchError`ì™€ `RusTorchResult<T>`ë¥¼ ì‚¬ìš©í•œ í†µí•© ì˜¤ë¥˜ ì²˜ë¦¬ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. **8ë‹¨ê³„ ì™„ë£Œ**ë¡œ ì¡°ê±´ ì—°ì‚°, ì¸ë±ì‹±, í†µê³„ í•¨ìˆ˜ë¥¼ í¬í•¨í•œ ê³ ê¸‰ í…ì„œ ìœ í‹¸ë¦¬í‹°ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. **9ë‹¨ê³„ ì™„ë£Œ**ë¡œ ëª¨ë¸ ì €ì¥/ë¡œë“œ, JIT ì»´íŒŒì¼, PyTorch í˜¸í™˜ì„±ì„ í¬í•¨í•œ ë‹¤ì¤‘ í˜•ì‹ ì§€ì›ì˜ í¬ê´„ì ì¸ ì§ë ¬í™” ì‹œìŠ¤í…œì´ ë„ì…ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ—ï¸ í•µì‹¬ ì•„í‚¤í…ì²˜

### ëª¨ë“ˆ êµ¬ì¡°

```
rustorch/
â”œâ”€â”€ tensor/              # í•µì‹¬ í…ì„œ ì—°ì‚°ê³¼ ë°ì´í„° êµ¬ì¡°
â”œâ”€â”€ nn/                  # ì‹ ê²½ë§ ë ˆì´ì–´ì™€ í•¨ìˆ˜
â”œâ”€â”€ autograd/            # ìë™ ë¯¸ë¶„ ì—”ì§„
â”œâ”€â”€ optim/               # ì˜µí‹°ë§ˆì´ì €ì™€ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
â”œâ”€â”€ special/             # íŠ¹ìˆ˜ ìˆ˜í•™ í•¨ìˆ˜
â”œâ”€â”€ distributions/       # í†µê³„ ë¶„í¬
â”œâ”€â”€ vision/              # ì»´í“¨í„° ë¹„ì „ ë³€í™˜
â”œâ”€â”€ linalg/              # ì„ í˜• ëŒ€ìˆ˜ ì—°ì‚° (BLAS/LAPACK)
â”œâ”€â”€ gpu/                 # GPU ê°€ì† (CUDA/Metal/OpenCL/WebGPU)
â”œâ”€â”€ sparse/              # í¬ì†Œ í…ì„œ ì—°ì‚°ê³¼ ê°€ì§€ì¹˜ê¸° (12ë‹¨ê³„)
â”œâ”€â”€ serialization/       # ëª¨ë¸ ì§ë ¬í™”ì™€ JIT ì»´íŒŒì¼ (9ë‹¨ê³„)
â””â”€â”€ wasm/                # WebAssembly ë°”ì¸ë”© ([WASM API ë¬¸ì„œ](WASM_API_DOCUMENTATION.md) ì°¸ì¡°)
```

## ğŸ“Š í…ì„œ ëª¨ë“ˆ

### ê¸°ë³¸ í…ì„œ ìƒì„±

```rust
use rustorch::tensor::Tensor;

// ê¸°ë³¸ ìƒì„±
let tensor = Tensor::new(vec![2, 3]);               // í˜•íƒœ ê¸°ë°˜ ìƒì„±
let tensor = Tensor::from_vec(data, vec![2, 3]);    // ë°ì´í„° ë²¡í„°ë¡œë¶€í„° ìƒì„±
let tensor = Tensor::zeros(vec![10, 10]);           // ì˜ìœ¼ë¡œ ì±„ìš´ í…ì„œ
let tensor = Tensor::ones(vec![5, 5]);              // ì¼ë¡œ ì±„ìš´ í…ì„œ
let tensor = Tensor::randn(vec![3, 3]);             // ë¬´ì‘ìœ„ ì •ê·œ ë¶„í¬
let tensor = Tensor::rand(vec![3, 3]);              // ë¬´ì‘ìœ„ ê· ë“± ë¶„í¬ [0,1)
let tensor = Tensor::eye(5);                        // ë‹¨ìœ„ í–‰ë ¬
let tensor = Tensor::full(vec![2, 2], 3.14);       // íŠ¹ì • ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
let tensor = Tensor::arange(0.0, 10.0, 1.0);       // ë²”ìœ„ í…ì„œ
let tensor = Tensor::linspace(0.0, 1.0, 100);      // ì„ í˜• ê°„ê²©
```

### í…ì„œ ì—°ì‚°

```rust
// ì‚°ìˆ  ì—°ì‚°
let result = a.add(&b);                             // ì›ì†Œë³„ ë§ì…ˆ
let result = a.sub(&b);                             // ì›ì†Œë³„ ëº„ì…ˆ
let result = a.mul(&b);                             // ì›ì†Œë³„ ê³±ì…ˆ
let result = a.div(&b);                             // ì›ì†Œë³„ ë‚˜ëˆ—ì…ˆ
let result = a.pow(&b);                             // ì›ì†Œë³„ ê±°ë“­ì œê³±
let result = a.rem(&b);                             // ì›ì†Œë³„ ë‚˜ë¨¸ì§€

// í–‰ë ¬ ì—°ì‚°
let result = a.matmul(&b);                          // í–‰ë ¬ ê³±ì…ˆ
let result = a.transpose();                         // í–‰ë ¬ ì „ì¹˜
let result = a.dot(&b);                             // ë‚´ì 

// ìˆ˜í•™ í•¨ìˆ˜
let result = tensor.exp();                          // ì§€ìˆ˜
let result = tensor.ln();                           // ìì—° ë¡œê·¸
let result = tensor.log10();                        // ìƒìš© ë¡œê·¸
let result = tensor.sqrt();                         // ì œê³±ê·¼
let result = tensor.abs();                          // ì ˆëŒ“ê°’
let result = tensor.sin();                          // ì‚¬ì¸ í•¨ìˆ˜
let result = tensor.cos();                          // ì½”ì‚¬ì¸ í•¨ìˆ˜
let result = tensor.tan();                          // íƒ„ì  íŠ¸ í•¨ìˆ˜
let result = tensor.asin();                         // ì•„í¬ì‚¬ì¸
let result = tensor.acos();                         // ì•„í¬ì½”ì‚¬ì¸
let result = tensor.atan();                         // ì•„í¬íƒ„ì  íŠ¸
let result = tensor.sinh();                         // ìŒê³¡ ì‚¬ì¸
let result = tensor.cosh();                         // ìŒê³¡ ì½”ì‚¬ì¸
let result = tensor.tanh();                         // ìŒê³¡ íƒ„ì  íŠ¸
let result = tensor.floor();                        // ë°”ë‹¥ í•¨ìˆ˜
let result = tensor.ceil();                         // ì²œì¥ í•¨ìˆ˜
let result = tensor.round();                        // ë°˜ì˜¬ë¦¼ í•¨ìˆ˜
let result = tensor.sign();                         // ë¶€í˜¸ í•¨ìˆ˜
let result = tensor.max();                          // ìµœëŒ“ê°’
let result = tensor.min();                          // ìµœì†Ÿê°’
let result = tensor.sum();                          // ëª¨ë“  ì›ì†Œ í•©
let result = tensor.mean();                         // í‰ê· ê°’
let result = tensor.std();                          // í‘œì¤€í¸ì°¨
let result = tensor.var();                          // ë¶„ì‚°

// í˜•íƒœ ì¡°ì‘
let result = tensor.reshape(vec![6, 4]);            // í…ì„œ ì¬í˜•ì„±
let result = tensor.squeeze();                      // í¬ê¸°-1 ì°¨ì› ì œê±°
let result = tensor.unsqueeze(1);                   // ì¸ë±ìŠ¤ì— ì°¨ì› ì¶”ê°€
let result = tensor.permute(vec![1, 0, 2]);         // ì°¨ì› ìˆœì—´
let result = tensor.expand(vec![10, 10, 5]);        // í…ì„œ ì°¨ì› í™•ì¥
```

## ğŸ§  ì‹ ê²½ë§(nn) ëª¨ë“ˆ

### ê¸°ë³¸ ë ˆì´ì–´

```rust
use rustorch::nn::{Linear, Conv2d, BatchNorm1d, Dropout};

// ì„ í˜• ë ˆì´ì–´
let linear = Linear::new(784, 256)?;                // ì…ë ¥ 784, ì¶œë ¥ 256
let output = linear.forward(&input)?;

// í•©ì„±ê³± ë ˆì´ì–´
let conv = Conv2d::new(3, 64, 3, None, Some(1))?; // in_channels=3, out_channels=64, kernel_size=3
let output = conv.forward(&input)?;

// ë°°ì¹˜ ì •ê·œí™”
let bn = BatchNorm1d::new(256)?;
let normalized = bn.forward(&input)?;

// ë“œë¡­ì•„ì›ƒ
let dropout = Dropout::new(0.5)?;
let output = dropout.forward(&input, true)?;       // training=true
```

### í™œì„±í™” í•¨ìˆ˜

```rust
use rustorch::nn::{ReLU, Sigmoid, Tanh, LeakyReLU, ELU, GELU};

// ê¸°ë³¸ í™œì„±í™” í•¨ìˆ˜
let relu = ReLU::new();
let sigmoid = Sigmoid::new();
let tanh = Tanh::new();

// ë§¤ê°œë³€ìˆ˜í™”ëœ í™œì„±í™” í•¨ìˆ˜
let leaky_relu = LeakyReLU::new(0.01)?;
let elu = ELU::new(1.0)?;
let gelu = GELU::new();

// ì‚¬ìš© ì˜ˆì œ
let activated = relu.forward(&input)?;
```

## ğŸš€ GPU ê°€ì† ëª¨ë“ˆ

### ë””ë°”ì´ìŠ¤ ê´€ë¦¬

```rust
use rustorch::gpu::{Device, get_device_count, set_device};

// ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤ í™•ì¸
let device_count = get_device_count()?;
let device = Device::best_available()?;            // ìµœì  ë””ë°”ì´ìŠ¤ ì„ íƒ

// ë””ë°”ì´ìŠ¤ ì„¤ì •
set_device(&device)?;

// í…ì„œë¥¼ GPUë¡œ ì´ë™
let gpu_tensor = tensor.to_device(&device)?;
```

### CUDA ì—°ì‚°

```rust
#[cfg(feature = "cuda")]
use rustorch::gpu::cuda::{CudaDevice, memory_stats};

// CUDA ë””ë°”ì´ìŠ¤ ì—°ì‚°
let cuda_device = CudaDevice::new(0)?;              // GPU 0 ì‚¬ìš©
let stats = memory_stats(0)?;                      // ë©”ëª¨ë¦¬ í†µê³„
println!("ì‚¬ìš©ëœ ë©”ëª¨ë¦¬: {} MB", stats.used_memory / (1024 * 1024));
```

## ğŸ¯ ìµœì í™”ê¸°(Optim) ëª¨ë“ˆ

### ê¸°ë³¸ ìµœì í™”ê¸°

```rust
use rustorch::optim::{Adam, SGD, RMSprop, AdamW};

// Adam ìµœì í™”ê¸°
let mut optimizer = Adam::new(vec![x.clone(), y.clone()], 0.001, 0.9, 0.999, 1e-8)?;

// SGD ìµœì í™”ê¸°
let mut sgd = SGD::new(vec![x.clone()], 0.01, 0.9, 1e-4)?;

// ìµœì í™” ë‹¨ê³„
optimizer.zero_grad()?;
// ... ìˆœì „íŒŒì™€ ì—­ì „íŒŒ ...
optimizer.step()?;
```

## ğŸ“– ì‚¬ìš© ì˜ˆì œ

### ì„ í˜• íšŒê·€

```rust
use rustorch::{tensor::Tensor, nn::Linear, optim::Adam, autograd::Variable};

// ë°ì´í„° ì¤€ë¹„
let x = Variable::new(Tensor::randn(vec![100, 1]), false)?;
let y = Variable::new(Tensor::randn(vec![100, 1]), false)?;

// ëª¨ë¸ ì •ì˜
let mut model = Linear::new(1, 1)?;
let mut optimizer = Adam::new(model.parameters(), 0.001, 0.9, 0.999, 1e-8)?;

// í›ˆë ¨ ë£¨í”„
for epoch in 0..1000 {
    optimizer.zero_grad()?;
    let pred = model.forward(&x)?;
    let loss = (pred - &y).pow(&Tensor::from(2.0))?.mean()?;
    backward(&loss, true)?;
    optimizer.step()?;
    
    if epoch % 100 == 0 {
        println!("ì—í¬í¬ {}: ì†ì‹¤ = {:.4}", epoch, loss.item::<f32>()?);
    }
}
```

## âš ï¸ ì•Œë ¤ì§„ ì œí•œì‚¬í•­

1. **GPU ë©”ëª¨ë¦¬ ì œí•œ**: í° í…ì„œ(>8GB)ì˜ ê²½ìš° ëª…ì‹œì  ë©”ëª¨ë¦¬ ê´€ë¦¬ í•„ìš”
2. **WebAssembly ì œí•œ**: ì¼ë¶€ BLAS ì—°ì‚°ì´ WASM í™˜ê²½ì—ì„œ ì‚¬ìš© ë¶ˆê°€
3. **ë¶„ì‚° í•™ìŠµ**: NCCL ë°±ì—”ë“œëŠ” Linuxì—ì„œë§Œ ì§€ì›
4. **Metal ì œí•œ**: ì¼ë¶€ ê³ ê¸‰ ì—°ì‚°ì€ CUDA ë°±ì—”ë“œì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥

## ğŸ”— ê´€ë ¨ ë§í¬

- [ë©”ì¸ README](../README.md)
- [WASM API ë¬¸ì„œ](WASM_API_DOCUMENTATION.md)
- [Jupyter ê°€ì´ë“œ](jupyter-guide.md)
- [GitHub ì €ì¥ì†Œ](https://github.com/JunSuzukiJapan/RusTorch)
- [Crates.io íŒ¨í‚¤ì§€](https://crates.io/crates/rustorch)

---

**ìµœê·¼ ì—…ë°ì´íŠ¸**: v0.5.15 | **ë¼ì´ì„ ìŠ¤**: MIT | **ì‘ì„±ì**: Jun Suzuki