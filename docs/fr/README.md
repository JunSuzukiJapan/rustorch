# RusTorch ğŸš€

[![Crates.io](https://img.shields.io/crates/v/rustorch)](https://crates.io/crates/rustorch)
[![Documentation](https://docs.rs/rustorch/badge.svg)](https://docs.rs/rustorch)
[![License](https://img.shields.io/badge/license-MIT%2FApache--2.0-blue.svg)](https://github.com/JunSuzukiJapan/rustorch)
[![Tests](https://img.shields.io/badge/tests-968%20passing-brightgreen.svg)](#testing)
[![Build](https://img.shields.io/badge/build-passing-brightgreen.svg)](#testing)

**Une bibliothÃ¨que d'apprentissage profond prÃªte pour la production en Rust avec une API similaire Ã  PyTorch, l'accÃ©lÃ©ration GPU et des performances de niveau entreprise**

RusTorch est une bibliothÃ¨que d'apprentissage profond entiÃ¨rement fonctionnelle qui exploite la sÃ©curitÃ© et les performances de Rust, fournissant des opÃ©rations tensorielles complÃ¨tes, la diffÃ©renciation automatique, des couches de rÃ©seau de neurones, des architectures de transformateur, l'accÃ©lÃ©ration GPU multi-backend (CUDA/Metal/OpenCL), des optimisations SIMD avancÃ©es, la gestion de mÃ©moire de niveau entreprise, la validation de donnÃ©es et l'assurance qualitÃ©, ainsi que des systÃ¨mes de dÃ©bogage et de journalisation complets.

## âœ¨ FonctionnalitÃ©s

- ğŸ”¥ **OpÃ©rations Tensorielles ComplÃ¨tes** : OpÃ©rations mathÃ©matiques, diffusion, indexation et statistiques
- ğŸ¤– **Architecture Transformer** : ImplÃ©mentation complÃ¨te de transformer avec attention multi-tÃªtes
- ğŸ§® **DÃ©composition Matricielle** : SVD, QR, dÃ©composition en valeurs propres avec compatibilitÃ© PyTorch
- ğŸ§  **DiffÃ©renciation Automatique** : Graphe computationnel basÃ© sur bande pour le calcul de gradient
- ğŸš€ **Moteur d'ExÃ©cution Dynamique** : Compilation JIT et optimisation Ã  l'exÃ©cution
- ğŸ—ï¸ **Couches de RÃ©seaux de Neurones** : Linear, Conv1d/2d/3d, ConvTranspose, RNN/LSTM/GRU, BatchNorm, Dropout, et plus
- âš¡ **Optimisations Multi-Plateformes** : SIMD (AVX2/SSE/NEON), spÃ©cifiques Ã  la plateforme et optimisations conscientes du matÃ©riel
- ğŸ® **IntÃ©gration GPU** : Support CUDA/Metal/OpenCL avec sÃ©lection automatique de pÃ©riphÃ©rique
- ğŸŒ **Support WebAssembly** : ML complet dans le navigateur avec couches de rÃ©seau de neurones, vision par ordinateur et infÃ©rence en temps rÃ©el
- ğŸ® **IntÃ©gration WebGPU** : AccÃ©lÃ©ration GPU optimisÃ©e Chrome avec repli CPU pour la compatibilitÃ© multi-navigateurs
- ğŸ“ **Support de Formats de ModÃ¨les** : Safetensors, infÃ©rence ONNX, compatibilitÃ© state dict PyTorch
- âœ… **PrÃªt pour la Production** : 968 tests rÃ©ussis, systÃ¨me de gestion d'erreurs unifiÃ©
- ğŸ“ **Fonctions MathÃ©matiques AmÃ©liorÃ©es** : Ensemble complet de fonctions mathÃ©matiques (exp, ln, sin, cos, tan, sqrt, abs, pow)
- ğŸ”§ **Surcharges d'OpÃ©rateurs AvancÃ©es** : Support complet d'opÃ©rateurs pour tenseurs avec opÃ©rations scalaires et affectations en place
- ğŸ“ˆ **Optimiseurs AvancÃ©s** : SGD, Adam, AdamW, RMSprop, AdaGrad avec planificateurs de taux d'apprentissage
- ğŸ” **Validation de DonnÃ©es et Assurance QualitÃ©** : Analyse statistique, dÃ©tection d'anomalies, vÃ©rification de cohÃ©rence, surveillance en temps rÃ©el
- ğŸ› **DÃ©bogage et Journalisation Complets** : Journalisation structurÃ©e, profilage des performances, suivi de mÃ©moire, alertes automatisÃ©es

## ğŸš€ DÃ©marrage Rapide

**ğŸ““ Pour le guide complet de configuration Jupyter, voir [README_JUPYTER.md](../../README_JUPYTER.md)**

### DÃ©mo Python Jupyter Lab

ğŸ““ **[Guide Complet Jupyter](../../README_JUPYTER.md)** | **[Guide Jupyter](jupyter-guide.md)**

#### DÃ©mo CPU Standard
Lancez RusTorch avec Jupyter Lab en une commande :

```bash
./start_jupyter.sh
```

#### DÃ©mo AccÃ©lÃ©rÃ©e WebGPU
Lancez RusTorch avec support WebGPU pour l'accÃ©lÃ©ration GPU basÃ©e sur navigateur :

```bash
./start_jupyter_webgpu.sh
```

Les deux scripts vont :
- ğŸ“¦ CrÃ©er l'environnement virtuel automatiquement
- ğŸ”§ Construire les bindings Python RusTorch
- ğŸš€ Lancer Jupyter Lab avec le notebook de dÃ©monstration
- ğŸ“ Ouvrir le notebook de dÃ©monstration prÃªt Ã  exÃ©cuter

**FonctionnalitÃ©s WebGPU :**
- ğŸŒ AccÃ©lÃ©ration GPU basÃ©e sur navigateur
- âš¡ OpÃ©rations matricielles haute performance dans le navigateur
- ğŸ”„ Repli automatique vers CPU quand GPU indisponible
- ğŸ¯ OptimisÃ© Chrome/Edge (navigateurs recommandÃ©s)

#### Noyau Rust pour Jupyter
Lancez le noyau Rust natif dans Jupyter (evcxr_jupyter) :

```bash
./quick_start_rust_kernel.sh
```

Cela va :
- ğŸ¦€ Installer le noyau Rust evcxr_jupyter
- ğŸ““ CrÃ©er un notebook de dÃ©mo Rust kernel
- ğŸš€ Lancer Jupyter avec support Rust natif
- ğŸ“ OpÃ©rations tensorielles directes en Rust

### Installation

Ajoutez ceci Ã  votre `Cargo.toml` :

```toml
[dependencies]
rustorch = "0.5.10"

# FonctionnalitÃ©s optionnelles
[features]
default = ["linalg"]
linalg = ["rustorch/linalg"]           # OpÃ©rations d'algÃ¨bre linÃ©aire (SVD, QR, valeurs propres)
cuda = ["rustorch/cuda"]
metal = ["rustorch/metal"] 
opencl = ["rustorch/opencl"]
safetensors = ["rustorch/safetensors"]
onnx = ["rustorch/onnx"]
wasm = ["rustorch/wasm"]                # Support WebAssembly pour ML navigateur
webgpu = ["rustorch/webgpu"]            # AccÃ©lÃ©ration WebGPU optimisÃ©e Chrome

# Pour dÃ©sactiver les fonctionnalitÃ©s linalg (Ã©viter les dÃ©pendances OpenBLAS/LAPACK) :
rustorch = { version = "0.5.10", default-features = false }
```

### Utilisation de Base

```rust
use rustorch::tensor::Tensor;
use rustorch::optim::{SGD, WarmupScheduler, OneCycleLR, AnnealStrategy};

fn main() {
    // CrÃ©er des tenseurs
    let a = Tensor::from_vec(vec![1.0f32, 2.0, 3.0, 4.0], vec![2, 2]);
    let b = Tensor::from_vec(vec![5.0f32, 6.0, 7.0, 8.0], vec![2, 2]);
    
    // OpÃ©rations de base avec surcharges d'opÃ©rateurs
    let c = &a + &b;  // Addition Ã©lÃ©ment par Ã©lÃ©ment
    let d = &a - &b;  // Soustraction Ã©lÃ©ment par Ã©lÃ©ment
    let e = &a * &b;  // Multiplication Ã©lÃ©ment par Ã©lÃ©ment
    let f = &a / &b;  // Division Ã©lÃ©ment par Ã©lÃ©ment
    
    // OpÃ©rations scalaires
    let g = &a + 10.0;  // Ajouter scalaire Ã  tous les Ã©lÃ©ments
    let h = &a * 2.0;   // Multiplier par scalaire
    
    // Fonctions mathÃ©matiques
    let exp_result = a.exp();   // Fonction exponentielle
    let ln_result = a.ln();     // Logarithme naturel
    let sin_result = a.sin();   // Fonction sinus
    let sqrt_result = a.sqrt(); // Racine carrÃ©e
    
    // OpÃ©rations matricielles
    let matmul_result = a.matmul(&b);  // Multiplication matricielle
    
    // OpÃ©rations d'algÃ¨bre linÃ©aire (nÃ©cessite la fonctionnalitÃ© linalg)
    #[cfg(feature = "linalg")]
    {
        let svd_result = a.svd();       // DÃ©composition SVD
        let qr_result = a.qr();         // DÃ©composition QR
        let eig_result = a.eigh();      // DÃ©composition en valeurs propres
    }
    
    // Optimiseurs avancÃ©s avec planification de taux d'apprentissage
    let optimizer = SGD::new(0.01);
    let mut scheduler = WarmupScheduler::new(optimizer, 0.1, 5); // Ã‰chauffement Ã  0.1 sur 5 Ã©poques
    
    println!("Forme : {:?}", c.shape());
    println!("RÃ©sultat : {:?}", c.as_slice());
}
```

### Utilisation WebAssembly

Pour les applications ML basÃ©es sur navigateur :

```javascript
import init, * as rustorch from './pkg/rustorch.js';

async function browserML() {
    await init();
    
    // Couches de rÃ©seau de neurones
    const linear = new rustorch.WasmLinear(784, 10, true);
    const conv = new rustorch.WasmConv2d(3, 32, 3, 1, 1, true);
    
    // Fonctions mathÃ©matiques amÃ©liorÃ©es
    const gamma_result = rustorch.WasmSpecial.gamma_batch([1.5, 2.0, 2.5]);
    const bessel_result = rustorch.WasmSpecial.bessel_i_batch(0, [0.5, 1.0, 1.5]);
    
    // Distributions statistiques
    const normal_dist = new rustorch.WasmDistributions();
    const samples = normal_dist.normal_sample_batch(100, 0.0, 1.0);
    
    // Optimiseurs pour l'entraÃ®nement
    const sgd = new rustorch.WasmOptimizer();
    sgd.sgd_init(0.01, 0.9); // taux_apprentissage, momentum
    
    // Traitement d'image
    const resized = rustorch.WasmVision.resize(image, 256, 256, 224, 224, 3);
    const normalized = rustorch.WasmVision.normalize(resized, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225], 3);
    
    // Passage avant
    const predictions = conv.forward(normalized, 1, 224, 224);
    console.log('PrÃ©dictions ML navigateur :', predictions);
}
```

## ğŸ“š Documentation

- **[Guide de DÃ©marrage](../getting-started.md)** - Utilisation de base et exemples
- **[FonctionnalitÃ©s](../features.md)** - Liste complÃ¨te des fonctionnalitÃ©s et spÃ©cifications
- **[Performance](../performance.md)** - Benchmarks et dÃ©tails d'optimisation
- **[Guide Jupyter WASM](jupyter-guide.md)** - Configuration pas Ã  pas de Jupyter Notebook

### WebAssembly et ML Navigateur
- **[Guide WebAssembly](../WASM_GUIDE.md)** - IntÃ©gration WASM complÃ¨te et rÃ©fÃ©rence API
- **[IntÃ©gration WebGPU](../WEBGPU_INTEGRATION.md)** - AccÃ©lÃ©ration GPU optimisÃ©e Chrome

### Production et OpÃ©rations
- **[Guide d'AccÃ©lÃ©ration GPU](../GPU_ACCELERATION_GUIDE.md)** - Configuration et utilisation GPU
- **[Guide de Production](../PRODUCTION_GUIDE.md)** - DÃ©ploiement et mise Ã  l'Ã©chelle

## ğŸ“Š Performance

**RÃ©sultats de benchmarks rÃ©cents :**

| OpÃ©ration | Performance | DÃ©tails |
|-----------|-------------|---------|
| **DÃ©composition SVD** | ~1ms (matrice 8x8) | âœ… BasÃ© sur LAPACK |
| **DÃ©composition QR** | ~24Î¼s (matrice 8x8) | âœ… DÃ©composition rapide |
| **Valeurs Propres** | ~165Î¼s (matrice 8x8) | âœ… Matrices symÃ©triques |
| **FFT Complexe** | 10-312Î¼s (8-64 Ã©chantillons) | âœ… OptimisÃ© Cooley-Tukey |
| **RÃ©seau de Neurones** | 1-7s entraÃ®nement | âœ… DÃ©mo Boston housing |
| **Fonctions d'Activation** | <1Î¼s | âœ… ReLU, Sigmoid, Tanh |

## ğŸ§ª Tests

**968 tests rÃ©ussis** - Assurance qualitÃ© prÃªte pour la production avec systÃ¨me de gestion d'erreurs unifiÃ©.

```bash
# ExÃ©cuter tous les tests
cargo test --no-default-features

# ExÃ©cuter tests avec fonctionnalitÃ©s d'algÃ¨bre linÃ©aire
cargo test --features linalg
```

## ğŸ¤ Contribution

Nous accueillons les contributions ! Voyez les domaines oÃ¹ l'aide est particuliÃ¨rement nÃ©cessaire :

- **ğŸ¯ PrÃ©cision des Fonctions SpÃ©ciales** : AmÃ©liorer la prÃ©cision numÃ©rique
- **âš¡ Optimisation des Performances** : AmÃ©liorations SIMD, optimisation GPU
- **ğŸ§ª Tests** : Cas de test plus complets
- **ğŸ“š Documentation** : Exemples, tutoriels, amÃ©liorations
- **ğŸŒ Support de Plateformes** : WebAssembly, plateformes mobiles

## Licence

Sous licence soit :

 * Licence Apache, Version 2.0 ([LICENSE-APACHE](../../LICENSE-APACHE) ou http://www.apache.org/licenses/LICENSE-2.0)
 * Licence MIT ([LICENSE-MIT](../../LICENSE-MIT) ou http://opensource.org/licenses/MIT)

Ã  votre choix.