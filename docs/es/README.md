# RusTorch üöÄ

[![Crates.io](https://img.shields.io/crates/v/rustorch)](https://crates.io/crates/rustorch)
[![Documentation](https://docs.rs/rustorch/badge.svg)](https://docs.rs/rustorch)
[![License](https://img.shields.io/badge/license-MIT%2FApache--2.0-blue.svg)](https://github.com/JunSuzukiJapan/rustorch)
[![Tests](https://img.shields.io/badge/tests-968%20passing-brightgreen.svg)](#testing)
[![Build](https://img.shields.io/badge/build-passing-brightgreen.svg)](#testing)

**Una biblioteca de deep learning lista para producci√≥n en Rust con API similar a PyTorch, aceleraci√≥n GPU y rendimiento de nivel empresarial**

RusTorch es una biblioteca de deep learning completamente funcional que aprovecha la seguridad y el rendimiento de Rust, proporcionando operaciones tensoriales completas, diferenciaci√≥n autom√°tica, capas de redes neuronales, arquitecturas transformer, aceleraci√≥n GPU multi-backend (CUDA/Metal/OpenCL), optimizaciones SIMD avanzadas, gesti√≥n de memoria de nivel empresarial, validaci√≥n de datos y aseguramiento de calidad, y sistemas completos de depuraci√≥n y logging.

## ‚ú® Caracter√≠sticas

- üî• **Operaciones Tensoriales Completas**: Operaciones matem√°ticas, broadcasting, indexaci√≥n y estad√≠sticas
- ü§ñ **Arquitectura Transformer**: Implementaci√≥n completa de transformer con atenci√≥n multi-head
- üßÆ **Descomposici√≥n Matricial**: SVD, QR, descomposici√≥n de autovalores con compatibilidad PyTorch
- üß† **Diferenciaci√≥n Autom√°tica**: Grafo computacional basado en cinta para c√°lculo de gradientes
- üöÄ **Motor de Ejecuci√≥n Din√°mico**: Compilaci√≥n JIT y optimizaci√≥n en tiempo de ejecuci√≥n
- üèóÔ∏è **Capas de Red Neuronal**: Linear, Conv1d/2d/3d, ConvTranspose, RNN/LSTM/GRU, BatchNorm, Dropout, y m√°s
- ‚ö° **Optimizaciones Multi-Plataforma**: SIMD (AVX2/SSE/NEON), espec√≠ficas de plataforma y optimizaciones hardware-aware
- üéÆ **Integraci√≥n GPU**: Soporte CUDA/Metal/OpenCL con selecci√≥n autom√°tica de dispositivo
- üåê **Soporte WebAssembly**: ML completo en navegador con capas de red neuronal, visi√≥n computacional e inferencia en tiempo real
- üéÆ **Integraci√≥n WebGPU**: Aceleraci√≥n GPU optimizada para Chrome con fallback CPU para compatibilidad cross-browser
- üìÅ **Soporte Formatos de Modelo**: Safetensors, inferencia ONNX, compatibilidad state dict PyTorch
- ‚úÖ **Listo para Producci√≥n**: 968 tests aprobados, sistema de manejo de errores unificado
- üìê **Funciones Matem√°ticas Mejoradas**: Conjunto completo de funciones matem√°ticas (exp, ln, sin, cos, tan, sqrt, abs, pow)
- üîß **Sobrecarga de Operadores Avanzada**: Soporte completo de operadores para tensores con operaciones escalares y asignaciones in-place
- üìà **Optimizadores Avanzados**: SGD, Adam, AdamW, RMSprop, AdaGrad con programadores de tasa de aprendizaje
- üîç **Validaci√≥n de Datos y Aseguramiento de Calidad**: An√°lisis estad√≠stico, detecci√≥n de anomal√≠as, verificaci√≥n de consistencia, monitoreo en tiempo real
- üêõ **Depuraci√≥n y Logging Completos**: Logging estructurado, profiling de rendimiento, seguimiento de memoria, alertas automatizadas

## üöÄ Inicio R√°pido

### Demo Python Jupyter Lab

#### Demo CPU Est√°ndar
Lanza RusTorch con Jupyter Lab en un comando:

```bash
./start_jupyter.sh
```

#### Demo Acelerada WebGPU
Lanza RusTorch con soporte WebGPU para aceleraci√≥n GPU basada en navegador:

```bash
./start_jupyter_webgpu.sh
```

Ambos scripts har√°n:
- üì¶ Crear entorno virtual autom√°ticamente
- üîß Construir bindings Python de RusTorch
- üöÄ Lanzar Jupyter Lab con notebook demo
- üìç Abrir notebook demo listo para ejecutar

**Caracter√≠sticas WebGPU:**
- üåê Aceleraci√≥n GPU basada en navegador
- ‚ö° Operaciones matriciales de alto rendimiento en navegador
- üîÑ Fallback autom√°tico a CPU cuando GPU no disponible
- üéØ Optimizado Chrome/Edge (navegadores recomendados)

### Instalaci√≥n

A√±ade esto a tu `Cargo.toml`:

```toml
[dependencies]
rustorch = "0.5.10"

# Caracter√≠sticas opcionales
[features]
default = ["linalg"]
linalg = ["rustorch/linalg"]           # Operaciones √°lgebra lineal (SVD, QR, autovalores)
cuda = ["rustorch/cuda"]
metal = ["rustorch/metal"] 
opencl = ["rustorch/opencl"]
safetensors = ["rustorch/safetensors"]
onnx = ["rustorch/onnx"]
wasm = ["rustorch/wasm"]                # Soporte WebAssembly para ML navegador
webgpu = ["rustorch/webgpu"]            # Aceleraci√≥n WebGPU optimizada Chrome

# Para desactivar caracter√≠sticas linalg (evitar dependencias OpenBLAS/LAPACK):
rustorch = { version = "0.5.10", default-features = false }
```

### Uso B√°sico

```rust
use rustorch::tensor::Tensor;
use rustorch::optim::{SGD, WarmupScheduler, OneCycleLR, AnnealStrategy};

fn main() {
    // Crear tensores
    let a = Tensor::from_vec(vec![1.0f32, 2.0, 3.0, 4.0], vec![2, 2]);
    let b = Tensor::from_vec(vec![5.0f32, 6.0, 7.0, 8.0], vec![2, 2]);
    
    // Operaciones b√°sicas con sobrecarga de operadores
    let c = &a + &b;  // Suma elemento por elemento
    let d = &a - &b;  // Resta elemento por elemento
    let e = &a * &b;  // Multiplicaci√≥n elemento por elemento
    let f = &a / &b;  // Divisi√≥n elemento por elemento
    
    // Operaciones escalares
    let g = &a + 10.0;  // A√±adir escalar a todos los elementos
    let h = &a * 2.0;   // Multiplicar por escalar
    
    // Funciones matem√°ticas
    let exp_result = a.exp();   // Funci√≥n exponencial
    let ln_result = a.ln();     // Logaritmo natural
    let sin_result = a.sin();   // Funci√≥n seno
    let sqrt_result = a.sqrt(); // Ra√≠z cuadrada
    
    // Operaciones matriciales
    let matmul_result = a.matmul(&b);  // Multiplicaci√≥n matricial
    
    // Operaciones √°lgebra lineal (requiere caracter√≠stica linalg)
    #[cfg(feature = "linalg")]
    {
        let svd_result = a.svd();       // Descomposici√≥n SVD
        let qr_result = a.qr();         // Descomposici√≥n QR
        let eig_result = a.eigh();      // Descomposici√≥n autovalores
    }
    
    // Optimizadores avanzados con programaci√≥n tasa de aprendizaje
    let optimizer = SGD::new(0.01);
    let mut scheduler = WarmupScheduler::new(optimizer, 0.1, 5); // Warmup a 0.1 sobre 5 √©pocas
    
    println!("Forma: {:?}", c.shape());
    println!("Resultado: {:?}", c.as_slice());
}
```

### Uso WebAssembly

Para aplicaciones ML basadas en navegador:

```javascript
import init, * as rustorch from './pkg/rustorch.js';

async function browserML() {
    await init();
    
    // Capas red neuronal
    const linear = new rustorch.WasmLinear(784, 10, true);
    const conv = new rustorch.WasmConv2d(3, 32, 3, 1, 1, true);
    
    // Funciones matem√°ticas mejoradas
    const gamma_result = rustorch.WasmSpecial.gamma_batch([1.5, 2.0, 2.5]);
    const bessel_result = rustorch.WasmSpecial.bessel_i_batch(0, [0.5, 1.0, 1.5]);
    
    // Distribuciones estad√≠sticas
    const normal_dist = new rustorch.WasmDistributions();
    const samples = normal_dist.normal_sample_batch(100, 0.0, 1.0);
    
    // Optimizadores para entrenamiento
    const sgd = new rustorch.WasmOptimizer();
    sgd.sgd_init(0.01, 0.9); // tasa_aprendizaje, momento
    
    // Procesamiento de im√°genes
    const resized = rustorch.WasmVision.resize(image, 256, 256, 224, 224, 3);
    const normalized = rustorch.WasmVision.normalize(resized, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225], 3);
    
    // Forward pass
    const predictions = conv.forward(normalized, 1, 224, 224);
    console.log('Predicciones ML navegador:', predictions);
}
```

## üìö Documentaci√≥n

- **[Gu√≠a de Inicio](../getting-started.md)** - Uso b√°sico y ejemplos
- **[Caracter√≠sticas](../features.md)** - Lista completa de caracter√≠sticas y especificaciones
- **[Rendimiento](../performance.md)** - Benchmarks y detalles de optimizaci√≥n
- **[Gu√≠a Jupyter WASM](jupyter-guide.md)** - Configuraci√≥n paso a paso de Jupyter Notebook

### WebAssembly y ML Navegador
- **[Gu√≠a WebAssembly](../WASM_GUIDE.md)** - Integraci√≥n WASM completa y referencia API
- **[Integraci√≥n WebGPU](../WEBGPU_INTEGRATION.md)** - Aceleraci√≥n GPU optimizada Chrome

### Producci√≥n y Operaciones
- **[Gu√≠a Aceleraci√≥n GPU](../GPU_ACCELERATION_GUIDE.md)** - Configuraci√≥n y uso GPU
- **[Gu√≠a Producci√≥n](../PRODUCTION_GUIDE.md)** - Despliegue y escalado

## üìä Rendimiento

**Resultados de benchmarks recientes:**

| Operaci√≥n | Rendimiento | Detalles |
|-----------|-------------|----------|
| **Descomposici√≥n SVD** | ~1ms (matriz 8x8) | ‚úÖ Basado en LAPACK |
| **Descomposici√≥n QR** | ~24Œºs (matriz 8x8) | ‚úÖ Descomposici√≥n r√°pida |
| **Autovalores** | ~165Œºs (matriz 8x8) | ‚úÖ Matrices sim√©tricas |
| **FFT Compleja** | 10-312Œºs (8-64 muestras) | ‚úÖ Optimizada Cooley-Tukey |
| **Red Neuronal** | 1-7s entrenamiento | ‚úÖ Demo Boston housing |
| **Funciones Activaci√≥n** | <1Œºs | ‚úÖ ReLU, Sigmoid, Tanh |

## üß™ Testing

**968 tests aprobados** - Aseguramiento de calidad listo para producci√≥n con sistema de manejo de errores unificado.

```bash
# Ejecutar todos los tests
cargo test --no-default-features

# Ejecutar tests con caracter√≠sticas √°lgebra lineal
cargo test --features linalg
```

## ü§ù Contribuir

¬°Damos la bienvenida a contribuciones! Ve √°reas donde se necesita especialmente ayuda:

- **üéØ Precisi√≥n Funciones Especiales**: Mejorar precisi√≥n num√©rica
- **‚ö° Optimizaci√≥n Rendimiento**: Mejoras SIMD, optimizaci√≥n GPU
- **üß™ Testing**: Casos de test m√°s completos
- **üìö Documentaci√≥n**: Ejemplos, tutoriales, mejoras
- **üåê Soporte Plataformas**: WebAssembly, plataformas m√≥viles

## Licencia

Licenciado bajo cualquiera de:

 * Licencia Apache, Versi√≥n 2.0 ([LICENSE-APACHE](../../LICENSE-APACHE) o http://www.apache.org/licenses/LICENSE-2.0)
 * Licencia MIT ([LICENSE-MIT](../../LICENSE-MIT) o http://opensource.org/licenses/MIT)

a tu elecci√≥n.