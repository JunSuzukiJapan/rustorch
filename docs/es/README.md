# RusTorch ğŸš€

[![Crates.io](https://img.shields.io/crates/v/rustorch)](https://crates.io/crates/rustorch)
[![Documentation](https://docs.rs/rustorch/badge.svg)](https://docs.rs/rustorch)
[![License](https://img.shields.io/badge/license-MIT%2FApache--2.0-blue.svg)](https://github.com/JunSuzukiJapan/rustorch)
[![Tests](https://img.shields.io/badge/tests-968%20passing-brightgreen.svg)](#testing)
[![Build](https://img.shields.io/badge/build-passing-brightgreen.svg)](#testing)

**Una biblioteca de deep learning lista para producciÃ³n en Rust con API similar a PyTorch, aceleraciÃ³n GPU y rendimiento de nivel empresarial**

RusTorch es una biblioteca de deep learning completamente funcional que aprovecha la seguridad y el rendimiento de Rust, proporcionando operaciones tensoriales completas, diferenciaciÃ³n automÃ¡tica, capas de redes neuronales, arquitecturas transformer, aceleraciÃ³n GPU multi-backend (CUDA/Metal/OpenCL), optimizaciones SIMD avanzadas, gestiÃ³n de memoria de nivel empresarial, validaciÃ³n de datos y aseguramiento de calidad, y sistemas completos de depuraciÃ³n y logging.

## âœ¨ CaracterÃ­sticas

- ğŸ”¥ **Operaciones Tensoriales Completas**: Operaciones matemÃ¡ticas, broadcasting, indexaciÃ³n y estadÃ­sticas, utilidades avanzadas Phase 8
- ğŸ¤– **Arquitectura Transformer**: ImplementaciÃ³n completa de transformer con atenciÃ³n multi-head
- ğŸ§® **DescomposiciÃ³n Matricial**: SVD, QR, descomposiciÃ³n de autovalores con compatibilidad PyTorch
- ğŸ§  **DiferenciaciÃ³n AutomÃ¡tica**: Grafo computacional basado en cinta para cÃ¡lculo de gradientes
- ğŸš€ **Motor de EjecuciÃ³n DinÃ¡mico**: CompilaciÃ³n JIT y optimizaciÃ³n en tiempo de ejecuciÃ³n
- ğŸ—ï¸ **Capas de Red Neuronal**: Linear, Conv1d/2d/3d, ConvTranspose, RNN/LSTM/GRU, BatchNorm, Dropout, y mÃ¡s
- âš¡ **Optimizaciones Multi-Plataforma**: SIMD (AVX2/SSE/NEON), especÃ­ficas de plataforma y optimizaciones hardware-aware
- ğŸ® **IntegraciÃ³n GPU**: Soporte CUDA/Metal/OpenCL con selecciÃ³n automÃ¡tica de dispositivo
- ğŸŒ **Soporte WebAssembly**: ML completo en navegador con capas de red neuronal, visiÃ³n computacional e inferencia en tiempo real
- ğŸ® **IntegraciÃ³n WebGPU**: AceleraciÃ³n GPU optimizada para Chrome con fallback CPU para compatibilidad cross-browser
- ğŸ“ **Soporte Formatos de Modelo**: Safetensors, inferencia ONNX, compatibilidad state dict PyTorch
- âœ… **Listo para ProducciÃ³n**: 968 tests aprobados, sistema de manejo de errores unificado
- ğŸ“ **Funciones MatemÃ¡ticas Mejoradas**: Conjunto completo de funciones matemÃ¡ticas (exp, ln, sin, cos, tan, sqrt, abs, pow)
- ğŸ”§ **Sobrecarga de Operadores Avanzada**: Soporte completo de operadores para tensores con operaciones escalares y asignaciones in-place
- ğŸ“ˆ **Optimizadores Avanzados**: SGD, Adam, AdamW, RMSprop, AdaGrad con programadores de tasa de aprendizaje
- ğŸ” **ValidaciÃ³n de Datos y Aseguramiento de Calidad**: AnÃ¡lisis estadÃ­stico, detecciÃ³n de anomalÃ­as, verificaciÃ³n de consistencia, monitoreo en tiempo real
- ğŸ› **DepuraciÃ³n y Logging Completos**: Logging estructurado, profiling de rendimiento, seguimiento de memoria, alertas automatizadas
- ğŸ¯ **Utilidades de Tensor Phase 8**: Operaciones condicionales (where, masked_select, masked_fill), operaciones de indexaciÃ³n (gather, scatter, index_select), operaciones estadÃ­sticas (topk, kthvalue), y utilidades avanzadas (unique, histogram)

## ğŸš€ Inicio RÃ¡pido

**ğŸ““ Para la guÃ­a completa de configuraciÃ³n de Jupyter, ver [README_JUPYTER.md](../../README_JUPYTER.md)**

### Demo Python Jupyter Lab

ğŸ““ **[GuÃ­a Completa Jupyter](../../README_JUPYTER.md)** | **[GuÃ­a Jupyter](jupyter-guide.md)**

#### Demo CPU EstÃ¡ndar
Lanza RusTorch con Jupyter Lab en un comando:

```bash
./start_jupyter.sh
```

#### Demo Acelerada WebGPU
Lanza RusTorch con soporte WebGPU para aceleraciÃ³n GPU basada en navegador:

```bash
./start_jupyter_webgpu.sh
```

Ambos scripts harÃ¡n:
- ğŸ“¦ Crear entorno virtual automÃ¡ticamente
- ğŸ”§ Construir bindings Python de RusTorch
- ğŸš€ Lanzar Jupyter Lab con notebook demo
- ğŸ“ Abrir notebook demo listo para ejecutar

**CaracterÃ­sticas WebGPU:**
- ğŸŒ AceleraciÃ³n GPU basada en navegador
- âš¡ Operaciones matriciales de alto rendimiento en navegador
- ğŸ”„ Fallback automÃ¡tico a CPU cuando GPU no disponible
- ğŸ¯ Optimizado Chrome/Edge (navegadores recomendados)

#### Kernel Rust para Jupyter
Lanza el kernel Rust nativo en Jupyter (evcxr_jupyter):

```bash
./quick_start_rust_kernel.sh
```

Esto:
- ğŸ¦€ Instala el kernel Rust evcxr_jupyter
- ğŸ““ Crea notebook demo del kernel Rust
- ğŸš€ Lanza Jupyter con soporte Rust nativo
- ğŸ“ Operaciones tensoriales directas en Rust

### InstalaciÃ³n

AÃ±ade esto a tu `Cargo.toml`:

```toml
[dependencies]
rustorch = "0.5.10"

# CaracterÃ­sticas opcionales
[features]
default = ["linalg"]
linalg = ["rustorch/linalg"]           # Operaciones Ã¡lgebra lineal (SVD, QR, autovalores)
cuda = ["rustorch/cuda"]
metal = ["rustorch/metal"] 
opencl = ["rustorch/opencl"]
safetensors = ["rustorch/safetensors"]
onnx = ["rustorch/onnx"]
wasm = ["rustorch/wasm"]                # Soporte WebAssembly para ML navegador
webgpu = ["rustorch/webgpu"]            # AceleraciÃ³n WebGPU optimizada Chrome

# Para desactivar caracterÃ­sticas linalg (evitar dependencias OpenBLAS/LAPACK):
rustorch = { version = "0.5.10", default-features = false }
```

### Uso BÃ¡sico

```rust
use rustorch::tensor::Tensor;
use rustorch::optim::{SGD, WarmupScheduler, OneCycleLR, AnnealStrategy};

fn main() {
    // Crear tensores
    let a = Tensor::from_vec(vec![1.0f32, 2.0, 3.0, 4.0], vec![2, 2]);
    let b = Tensor::from_vec(vec![5.0f32, 6.0, 7.0, 8.0], vec![2, 2]);
    
    // Operaciones bÃ¡sicas con sobrecarga de operadores
    let c = &a + &b;  // Suma elemento por elemento
    let d = &a - &b;  // Resta elemento por elemento
    let e = &a * &b;  // MultiplicaciÃ³n elemento por elemento
    let f = &a / &b;  // DivisiÃ³n elemento por elemento
    
    // Operaciones escalares
    let g = &a + 10.0;  // AÃ±adir escalar a todos los elementos
    let h = &a * 2.0;   // Multiplicar por escalar
    
    // Funciones matemÃ¡ticas
    let exp_result = a.exp();   // FunciÃ³n exponencial
    let ln_result = a.ln();     // Logaritmo natural
    let sin_result = a.sin();   // FunciÃ³n seno
    let sqrt_result = a.sqrt(); // RaÃ­z cuadrada
    
    // Operaciones matriciales
    let matmul_result = a.matmul(&b);  // MultiplicaciÃ³n matricial
    
    // Operaciones Ã¡lgebra lineal (requiere caracterÃ­stica linalg)
    #[cfg(feature = "linalg")]
    {
        let svd_result = a.svd();       // DescomposiciÃ³n SVD
        let qr_result = a.qr();         // DescomposiciÃ³n QR
        let eig_result = a.eigh();      // DescomposiciÃ³n autovalores
    }
    
    // Optimizadores avanzados con programaciÃ³n tasa de aprendizaje
    let optimizer = SGD::new(0.01);
    let mut scheduler = WarmupScheduler::new(optimizer, 0.1, 5); // Warmup a 0.1 sobre 5 Ã©pocas
    
    println!("Forma: {:?}", c.shape());
    println!("Resultado: {:?}", c.as_slice());
}
```

### Uso WebAssembly

Para aplicaciones ML basadas en navegador:

```javascript
import init, * as rustorch from './pkg/rustorch.js';

async function browserML() {
    await init();
    
    // Capas red neuronal
    const linear = new rustorch.WasmLinear(784, 10, true);
    const conv = new rustorch.WasmConv2d(3, 32, 3, 1, 1, true);
    
    // Funciones matemÃ¡ticas mejoradas
    const gamma_result = rustorch.WasmSpecial.gamma_batch([1.5, 2.0, 2.5]);
    const bessel_result = rustorch.WasmSpecial.bessel_i_batch(0, [0.5, 1.0, 1.5]);
    
    // Distribuciones estadÃ­sticas
    const normal_dist = new rustorch.WasmDistributions();
    const samples = normal_dist.normal_sample_batch(100, 0.0, 1.0);
    
    // Optimizadores para entrenamiento
    const sgd = new rustorch.WasmOptimizer();
    sgd.sgd_init(0.01, 0.9); // tasa_aprendizaje, momento
    
    // Procesamiento de imÃ¡genes
    const resized = rustorch.WasmVision.resize(image, 256, 256, 224, 224, 3);
    const normalized = rustorch.WasmVision.normalize(resized, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225], 3);
    
    // Forward pass
    const predictions = conv.forward(normalized, 1, 224, 224);
    console.log('Predicciones ML navegador:', predictions);
}
```

## ğŸ“š DocumentaciÃ³n

- **[GuÃ­a de Inicio](../getting-started.md)** - Uso bÃ¡sico y ejemplos
- **[CaracterÃ­sticas](../features.md)** - Lista completa de caracterÃ­sticas y especificaciones
- **[Rendimiento](../performance.md)** - Benchmarks y detalles de optimizaciÃ³n
- **[GuÃ­a Jupyter WASM](jupyter-guide.md)** - ConfiguraciÃ³n paso a paso de Jupyter Notebook

### WebAssembly y ML Navegador
- **[GuÃ­a WebAssembly](../WASM_GUIDE.md)** - IntegraciÃ³n WASM completa y referencia API
- **[IntegraciÃ³n WebGPU](../WEBGPU_INTEGRATION.md)** - AceleraciÃ³n GPU optimizada Chrome

### ProducciÃ³n y Operaciones
- **[GuÃ­a AceleraciÃ³n GPU](../GPU_ACCELERATION_GUIDE.md)** - ConfiguraciÃ³n y uso GPU
- **[GuÃ­a ProducciÃ³n](../PRODUCTION_GUIDE.md)** - Despliegue y escalado

## ğŸ“Š Rendimiento

**Resultados de benchmarks recientes:**

| OperaciÃ³n | Rendimiento | Detalles |
|-----------|-------------|----------|
| **DescomposiciÃ³n SVD** | ~1ms (matriz 8x8) | âœ… Basado en LAPACK |
| **DescomposiciÃ³n QR** | ~24Î¼s (matriz 8x8) | âœ… DescomposiciÃ³n rÃ¡pida |
| **Autovalores** | ~165Î¼s (matriz 8x8) | âœ… Matrices simÃ©tricas |
| **FFT Compleja** | 10-312Î¼s (8-64 muestras) | âœ… Optimizada Cooley-Tukey |
| **Red Neuronal** | 1-7s entrenamiento | âœ… Demo Boston housing |
| **Funciones ActivaciÃ³n** | <1Î¼s | âœ… ReLU, Sigmoid, Tanh |

## ğŸ§ª Testing

**968 tests aprobados** - Aseguramiento de calidad listo para producciÃ³n con sistema de manejo de errores unificado.

```bash
# Ejecutar todos los tests
cargo test --no-default-features

# Ejecutar tests con caracterÃ­sticas Ã¡lgebra lineal
cargo test --features linalg
```

## ğŸ¤ Contribuir

Â¡Damos la bienvenida a contribuciones! Ve Ã¡reas donde se necesita especialmente ayuda:

- **ğŸ¯ PrecisiÃ³n Funciones Especiales**: Mejorar precisiÃ³n numÃ©rica
- **âš¡ OptimizaciÃ³n Rendimiento**: Mejoras SIMD, optimizaciÃ³n GPU
- **ğŸ§ª Testing**: Casos de test mÃ¡s completos
- **ğŸ“š DocumentaciÃ³n**: Ejemplos, tutoriales, mejoras
- **ğŸŒ Soporte Plataformas**: WebAssembly, plataformas mÃ³viles

## Licencia

Licenciado bajo cualquiera de:

 * Licencia Apache, VersiÃ³n 2.0 ([LICENSE-APACHE](../../LICENSE-APACHE) o http://www.apache.org/licenses/LICENSE-2.0)
 * Licencia MIT ([LICENSE-MIT](../../LICENSE-MIT) o http://opensource.org/licenses/MIT)

a tu elecciÃ³n.