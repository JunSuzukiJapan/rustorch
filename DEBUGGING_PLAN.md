# RusTorch GGUF Llama Debugging Plan

## ç¾çŠ¶ã¾ã¨ã‚ (2025-10-06 æ›´æ–°)

### âœ… æ¤œè¨¼æ¸ˆã¿ãƒ»æ­£å¸¸å‹•ä½œ
1. **GGUF Weight Format** - è»¢ç½®ä¸è¦ã€å…¨ã¦ã®weightsãŒæ­£ã—ãèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹
2. **Matrix Multiplication** - æ¬¡å…ƒãŒé©åˆã€ã‚¨ãƒ©ãƒ¼ãªã—
3. **Transformer Layers** - ä¸­é–“å€¤ã¯æ­£å¸¸ç¯„å›²
4. **Logits Computation** - ã‚¼ãƒ­ã§ã¯ãªãã€é©åˆ‡ãªå€¤(9.5-9.6ç¯„å›²)
5. **Reference Implementation** - llama.cpp ã¯åŒã˜ãƒ¢ãƒ‡ãƒ«ã§æ­£ã—ã "Paris" ã‚’å‡ºåŠ›
6. **âœ… Embedding Extraction** - Row extractionã¸ã®ä¿®æ­£ã§æ­£å¸¸å‹•ä½œ
7. **âœ… RoPE Implementation** - Position 0ã§ cos=1, sin=0ã‚’æ­£ã—ãé©ç”¨
8. **âœ… Q/K/V Projections** - å…¨ã¦éã‚¼ãƒ­ã®æ­£å¸¸å€¤ã‚’å‡ºåŠ›
9. **âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹** - ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãªã—ã§5ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆå®Œäº†

### âŒ å•é¡Œ
**å‡ºåŠ›å“è³ª**: ç„¡æ„å‘³ãªãƒˆãƒ¼ã‚¯ãƒ³åˆ—ãŒç”Ÿæˆã•ã‚Œã‚‹
- Input: "What is the capital of France?"
- Our output: "ruction werk werk werk werk" (ãƒˆãƒ¼ã‚¯ãƒ³ [13210, 9888, 9888, 9888, 9888])
- Expected (llama.cpp): "Paris" ã¾ãŸã¯å¦¥å½“ãªå¿œç­”

### ğŸ”¬ èª¿æŸ»çµæœ

#### Position 12-14 ã§ã®è¦³æ¸¬
- Logitsæ­£å¸¸: top5=[(19388, 9.60), (15965, 9.58), ...]
- Last layerå‡ºåŠ›æ­£å¸¸: [-0.72, -0.77, -0.18, 1.27, ...]
- RMSNormå‡ºåŠ›æ­£å¸¸: [-1.27, -1.29, -0.32, 2.31, ...]

#### Weight Shapesç¢ºèª
- `token_embd.weight`: [2048, 32000]
- `output.weight`: [2048, 32000]
- Linear layers: [2048, 256] ãªã© - å…¨ã¦æ­£å¸¸

### ğŸ¯ æœªè§£æ±ºã®ç–‘å•ç‚¹

1. **Embedding Extraction**
   - Column extractionä½¿ç”¨ä¸­: `idx = i * vocab_size + token_id`
   - å½¢çŠ¶ [2048, 32000] ã§ã®ãƒ¡ãƒ¢ãƒªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãŒæ­£ã—ã„ã‹?
   - llama.cppã¨åŒã˜å€¤ã‚’æŠ½å‡ºã—ã¦ã„ã‚‹ã‹æœªç¢ºèª

2. **Performance Issue**
   - é•·ã„å…¥åŠ›ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç™ºç”Ÿ
   - ãƒ­ã‚°ç„¡åŠ¹åŒ–ã—ã¦ã‚‚æ”¹å–„ã›ãš
   - ç„¡é™ãƒ«ãƒ¼ãƒ—ã¾ãŸã¯deadlockã®å¯èƒ½æ€§

3. **Sampling Strategy**
   - Temperature/top-k/top-pã®è¨­å®šç¢ºèªå¿…è¦
   - åŒã˜logitå€¤ã‚’æŒã¤è¤‡æ•°ãƒˆãƒ¼ã‚¯ãƒ³ã®é¸æŠãƒ­ã‚¸ãƒƒã‚¯

## æˆ¦ç•¥çš„ãƒ‡ãƒãƒƒã‚°è¨ˆç”»

### Phase 1: Embeddingæ¤œè¨¼ (æœ€å„ªå…ˆ)

**ä»®èª¬**: Column extractionãŒèª¤ã£ãŸå€¤ã‚’æŠ½å‡ºã—ã¦ã„ã‚‹

**æ¤œè¨¼æ–¹æ³•**:
1. Token ID 1 (BOS) ã®embeddingã‚’æ‰‹å‹•è¨ˆç®—
2. llama.cppã¨æ¯”è¼ƒ (--log-disable false ã§å†…éƒ¨å€¤ç¢ºèª)
3. å¿…è¦ãªã‚‰ row extraction ã«å¤‰æ›´ã—ã¦ãƒ†ã‚¹ãƒˆ

**ã‚³ãƒ¼ãƒ‰å¤‰æ›´ç®‡æ‰€**: `src/hybrid_f32/models/llama.rs:467-481`

### Phase 2: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œè§£æ±º

**ä»®èª¬**: KV cacheã¾ãŸã¯ãƒ¡ãƒ¢ãƒªç®¡ç†ã«å•é¡Œ

**æ¤œè¨¼æ–¹æ³•**:
1. æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’åˆ¶é™ (--max-tokens 5)
2. KV cacheæ›´æ–°ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¢ºèª
3. Metal GPUãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãƒã‚§ãƒƒã‚¯

### Phase 3: Samplingæˆ¦ç•¥ç¢ºèª

**æ¤œè¨¼æ–¹æ³•**:
1. Temperature=0.0 (greedy sampling) ã§ãƒ†ã‚¹ãƒˆ
2. Top token IDã‚’ç›´æ¥ç¢ºèª
3. llama.cppã®samplingè¨­å®šã¨æ¯”è¼ƒ

## æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

### å³åº§ã«å®Ÿè¡Œ
1. Embedding extractionã‚’ row extraction ã«å¤‰æ›´ã—ã¦ãƒ†ã‚¹ãƒˆ
2. æœ€å°é™ã®å…¥åŠ› ("Hi") ã§å‹•ä½œç¢ºèª
3. KV cacheã‚µã‚¤ã‚ºåˆ¶é™è¿½åŠ 

### æ¯”è¼ƒæ¤œè¨¼
1. llama.cpp --log-enable ã§å†…éƒ¨å€¤å–å¾—
2. åŒã˜token IDã§ã®embeddingå€¤æ¯”è¼ƒ
3. æœ€åˆã®logitså€¤ã‚’æ¯”è¼ƒ

## ã‚³ãƒ¼ãƒ‰ä¿®æ­£æ¡ˆ

### ä¿®æ­£1: Row Extractionå¼·åˆ¶
```rust
// get_embedding() å†…
// å¸¸ã«row extractionã‚’ä½¿ç”¨
let start = token_id * hidden_size;
let end = start + hidden_size;
Ok(embed_data[start..end].to_vec())
```

### ä¿®æ­£2: Max Tokensåˆ¶é™
```rust
// CLIå¼•æ•°ã«--max-tokensè¿½åŠ æ¸ˆã¿
// ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’5ã«å¤‰æ›´ã—ã¦ãƒ†ã‚¹ãƒˆ
```

### ä¿®æ­£3: ãƒ‡ãƒãƒƒã‚°æœ€å°åŒ–
```rust
// å…¨ã¦ã®eprintln!ã‚’æ¡ä»¶ä»˜ãã«
const DEBUG: bool = false;
if DEBUG { eprintln!(...); }
```

## æˆåŠŸåŸºæº–

âœ… "What is the capital of France?" â†’ "Paris" ã‚’å«ã‚€é©åˆ‡ãªå¿œç­”
âœ… ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãªã— (< 10ç§’)
âœ… llama.cppã¨åŒç­‰ã®å“è³ª

---
Last updated: 2025-10-06
Status: Embedding extractionæ¤œè¨¼ãŒæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
