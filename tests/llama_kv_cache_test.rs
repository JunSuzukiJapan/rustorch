/// KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å‹•ä½œã‚’æ¤œè¨¼ã™ã‚‹ãƒ†ã‚¹ãƒˆ
///
/// ãƒ†ã‚¹ãƒˆå†…å®¹ï¼š
/// 1. KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®åˆæœŸåŒ–ã¨ã‚¯ãƒªã‚¢
/// 2. ãƒˆãƒ¼ã‚¯ãƒ³è¿½åŠ æ™‚ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºå¢—åŠ 
/// 3. è¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã§ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨
/// 4. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢å¾Œã®å†åˆæœŸåŒ–

use rustorch::models::llama::KVCache;

#[test]
fn test_kv_cache_initialization() {
    println!("ğŸ§ª Test 1: KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®åˆæœŸåŒ–");

    let num_layers = 22;
    let batch_size = 1;
    let max_cache_size = 2048;
    let kv_dim = 256; // TinyLlama: 4 KV heads Ã— 64 head_dim

    let cache = KVCache::new(num_layers, batch_size, max_cache_size, kv_dim);

    // åˆæœŸçŠ¶æ…‹ã®æ¤œè¨¼
    assert_eq!(cache.batch_size, batch_size, "ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒä¸€è‡´ã™ã‚‹ã“ã¨");
    assert_eq!(cache.max_cache_size, max_cache_size, "æœ€å¤§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºãŒä¸€è‡´ã™ã‚‹ã“ã¨");
    assert_eq!(cache.k_cache.len(), num_layers, "ãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°ãŒä¸€è‡´ã™ã‚‹ã“ã¨");
    assert_eq!(cache.v_cache.len(), num_layers, "ãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°ãŒä¸€è‡´ã™ã‚‹ã“ã¨");
    assert_eq!(cache.cached_tokens[0], 0, "åˆæœŸã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã¯0ã§ã‚ã‚‹ã“ã¨");

    println!("âœ… KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæ­£ã—ãåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ");
}

#[test]
fn test_kv_cache_clear() {
    println!("ğŸ§ª Test 2: KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚¯ãƒªã‚¢");

    let num_layers = 22;
    let batch_size = 1;
    let max_cache_size = 2048;
    let kv_dim = 256;

    let mut cache = KVCache::new(num_layers, batch_size, max_cache_size, kv_dim);

    // ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨­å®š
    cache.cached_tokens[0] = 100;
    assert_eq!(cache.cached_tokens[0], 100, "ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒè¨­å®šã•ã‚Œã‚‹ã“ã¨");

    // ã‚¯ãƒªã‚¢
    cache.clear();
    assert_eq!(cache.cached_tokens[0], 0, "ã‚¯ãƒªã‚¢å¾Œã¯ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒ0ã«ãªã‚‹ã“ã¨");

    println!("âœ… KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæ­£ã—ãã‚¯ãƒªã‚¢ã•ã‚Œã¾ã—ãŸ");
}

#[test]
fn test_kv_cache_token_accumulation() {
    println!("ğŸ§ª Test 3: ãƒˆãƒ¼ã‚¯ãƒ³ã®ç´¯ç©");

    let num_layers = 22;
    let batch_size = 1;
    let max_cache_size = 2048;
    let kv_dim = 256;

    let mut cache = KVCache::new(num_layers, batch_size, max_cache_size, kv_dim);

    // ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: è¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã§ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¿½åŠ 
    println!("Step 0: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‡¦ç† (14ãƒˆãƒ¼ã‚¯ãƒ³)");
    cache.cached_tokens[0] += 14;
    assert_eq!(cache.cached_tokens[0], 14, "Step 0å¾Œ: 14ãƒˆãƒ¼ã‚¯ãƒ³");

    println!("Step 1: 1ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆ");
    cache.cached_tokens[0] += 1;
    assert_eq!(cache.cached_tokens[0], 15, "Step 1å¾Œ: 15ãƒˆãƒ¼ã‚¯ãƒ³");

    println!("Step 2: 1ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆ");
    cache.cached_tokens[0] += 1;
    assert_eq!(cache.cached_tokens[0], 16, "Step 2å¾Œ: 16ãƒˆãƒ¼ã‚¯ãƒ³");

    println!("Step 3: 1ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆ");
    cache.cached_tokens[0] += 1;
    assert_eq!(cache.cached_tokens[0], 17, "Step 3å¾Œ: 17ãƒˆãƒ¼ã‚¯ãƒ³");

    println!("âœ… ãƒˆãƒ¼ã‚¯ãƒ³ãŒæ­£ã—ãç´¯ç©ã•ã‚Œã¾ã—ãŸ");
}

#[test]
fn test_kv_cache_size_calculation() {
    println!("ğŸ§ª Test 4: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºã®è¨ˆç®—");

    let num_layers = 22;
    let batch_size = 1;
    let max_cache_size = 2048;
    let kv_dim = 256;

    let cache = KVCache::new(num_layers, batch_size, max_cache_size, kv_dim);

    // å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºã‚’æ¤œè¨¼
    for layer_idx in 0..num_layers {
        let k_cache_size = cache.k_cache[layer_idx][0].len();
        let v_cache_size = cache.v_cache[layer_idx][0].len();

        let expected_size = max_cache_size * kv_dim;

        assert_eq!(k_cache_size, expected_size,
            "Layer {}: Kã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºãŒæ­£ã—ã„ã“ã¨", layer_idx);
        assert_eq!(v_cache_size, expected_size,
            "Layer {}: Vã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºãŒæ­£ã—ã„ã“ã¨", layer_idx);
    }

    println!("âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºãŒæ­£ã—ãè¨ˆç®—ã•ã‚Œã¾ã—ãŸ");
}

#[test]
fn test_kv_cache_overflow_detection() {
    println!("ğŸ§ª Test 5: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼æ¤œå‡º");

    let num_layers = 2;
    let batch_size = 1;
    let max_cache_size = 100; // å°ã•ã„å€¤ã§ãƒ†ã‚¹ãƒˆ
    let kv_dim = 256;

    let mut cache = KVCache::new(num_layers, batch_size, max_cache_size, kv_dim);

    // æœ€å¤§ã‚µã‚¤ã‚ºã¾ã§è¿½åŠ 
    cache.cached_tokens[0] = max_cache_size;

    // ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼æ¤œå‡ºã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    let would_overflow = cache.cached_tokens[0] + 1 > max_cache_size;
    assert!(would_overflow, "æœ€å¤§ã‚µã‚¤ã‚ºè¶…éã‚’æ¤œå‡ºã§ãã‚‹ã“ã¨");

    println!("âœ… ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼æ¤œå‡ºãŒæ­£ã—ãå‹•ä½œã—ã¾ã™");
}

#[test]
fn test_kv_cache_multi_batch() {
    println!("ğŸ§ª Test 6: ãƒãƒ«ãƒãƒãƒƒãƒã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥");

    let num_layers = 22;
    let batch_size = 4;
    let max_cache_size = 2048;
    let kv_dim = 256;

    let mut cache = KVCache::new(num_layers, batch_size, max_cache_size, kv_dim);

    // å„ãƒãƒƒãƒã‚¢ã‚¤ãƒ†ãƒ ã«ç•°ãªã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨­å®š
    cache.cached_tokens[0] = 10;
    cache.cached_tokens[1] = 20;
    cache.cached_tokens[2] = 30;
    cache.cached_tokens[3] = 40;

    assert_eq!(cache.cached_tokens[0], 10, "ãƒãƒƒãƒ0: 10ãƒˆãƒ¼ã‚¯ãƒ³");
    assert_eq!(cache.cached_tokens[1], 20, "ãƒãƒƒãƒ1: 20ãƒˆãƒ¼ã‚¯ãƒ³");
    assert_eq!(cache.cached_tokens[2], 30, "ãƒãƒƒãƒ2: 30ãƒˆãƒ¼ã‚¯ãƒ³");
    assert_eq!(cache.cached_tokens[3], 40, "ãƒãƒƒãƒ3: 40ãƒˆãƒ¼ã‚¯ãƒ³");

    // ã‚¯ãƒªã‚¢å¾Œã¯ã™ã¹ã¦0
    cache.clear();
    for i in 0..batch_size {
        assert_eq!(cache.cached_tokens[i], 0, "ãƒãƒƒãƒ{}: ã‚¯ãƒªã‚¢å¾Œã¯0", i);
    }

    println!("âœ… ãƒãƒ«ãƒãƒãƒƒãƒã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæ­£ã—ãå‹•ä½œã—ã¾ã™");
}

#[test]
fn test_kv_cache_gqa_dimensions() {
    println!("ğŸ§ª Test 7: GQA (Grouped Query Attention) ç”¨ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¬¡å…ƒ");

    // TinyLlamaã®è¨­å®š
    let num_layers = 22;
    let batch_size = 1;
    let max_cache_size = 2048;
    let num_heads = 32;
    let num_kv_heads = 4; // GQA: 4 KV heads
    let head_dim = 64;
    let kv_dim = num_kv_heads * head_dim; // 4 Ã— 64 = 256

    let cache = KVCache::new(num_layers, batch_size, max_cache_size, kv_dim);

    // GQAã®æ¬¡å…ƒæ¤œè¨¼
    let heads_per_kv = num_heads / num_kv_heads; // 32 / 4 = 8
    println!("  GQAè¨­å®š:");
    println!("    - num_heads (Q): {}", num_heads);
    println!("    - num_kv_heads (K/V): {}", num_kv_heads);
    println!("    - heads_per_kv: {}", heads_per_kv);
    println!("    - head_dim: {}", head_dim);
    println!("    - kv_dim: {}", kv_dim);

    assert_eq!(kv_dim, 256, "TinyLlama GQAã®kv_dimã¯256ã§ã‚ã‚‹ã“ã¨");
    assert_eq!(heads_per_kv, 8, "å„KVãƒ˜ãƒƒãƒ‰ã¯8å€‹ã®Qãƒ˜ãƒƒãƒ‰ã§å…±æœ‰ã•ã‚Œã‚‹ã“ã¨");

    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºã®æ¤œè¨¼
    for layer_idx in 0..num_layers {
        let k_cache_size = cache.k_cache[layer_idx][0].len();
        let expected_size = max_cache_size * kv_dim; // 2048 Ã— 256 = 524288
        assert_eq!(k_cache_size, expected_size,
            "Layer {}: Kã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºãŒæ­£ã—ã„ã“ã¨", layer_idx);
    }

    println!("âœ… GQAç”¨ã®KVã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¬¡å…ƒãŒæ­£ã—ãè¨­å®šã•ã‚Œã¾ã—ãŸ");
}

#[test]
fn test_kv_cache_position_tracking() {
    println!("ğŸ§ª Test 8: Position tracking (è‡ªå·±å›å¸°ç”Ÿæˆã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³)");

    let num_layers = 22;
    let batch_size = 1;
    let max_cache_size = 2048;
    let kv_dim = 256;

    let mut cache = KVCache::new(num_layers, batch_size, max_cache_size, kv_dim);

    // è‡ªå·±å›å¸°ç”Ÿæˆã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    println!("\nğŸ“ è‡ªå·±å›å¸°ç”Ÿæˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³:");

    // Step 0: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨ä½“ã‚’å‡¦ç†
    let prompt_len = 14;
    let cache_start = cache.cached_tokens[0];
    let cache_end = cache_start + prompt_len;

    println!("  Step 0: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå‡¦ç†");
    println!("    - seq_len: {}", prompt_len);
    println!("    - cache_start: {}", cache_start);
    println!("    - cache_end: {}", cache_end);

    cache.cached_tokens[0] += prompt_len;
    assert_eq!(cache.cached_tokens[0], 14, "Step 0å¾Œ: 14ãƒˆãƒ¼ã‚¯ãƒ³");

    // Step 1: 1ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆ
    let gen_len = 1;
    let cache_start = cache.cached_tokens[0];
    let cache_end = cache_start + gen_len;
    let total_seq_len = cache.cached_tokens[0] + gen_len;

    println!("\n  Step 1: 1ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆ");
    println!("    - seq_len: {}", gen_len);
    println!("    - cache_start: {}", cache_start);
    println!("    - cache_end: {}", cache_end);
    println!("    - total_seq_len (for attention): {}", total_seq_len);

    cache.cached_tokens[0] += gen_len;
    assert_eq!(cache.cached_tokens[0], 15, "Step 1å¾Œ: 15ãƒˆãƒ¼ã‚¯ãƒ³");
    assert_eq!(total_seq_len, 15, "Attentionç”¨ã®total_seq_lenãŒæ­£ã—ã„ã“ã¨");

    // Step 2: 1ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆ
    let gen_len = 1;
    let cache_start = cache.cached_tokens[0];
    let cache_end = cache_start + gen_len;
    let total_seq_len = cache.cached_tokens[0] + gen_len;

    println!("\n  Step 2: 1ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆ");
    println!("    - seq_len: {}", gen_len);
    println!("    - cache_start: {}", cache_start);
    println!("    - cache_end: {}", cache_end);
    println!("    - total_seq_len (for attention): {}", total_seq_len);

    cache.cached_tokens[0] += gen_len;
    assert_eq!(cache.cached_tokens[0], 16, "Step 2å¾Œ: 16ãƒˆãƒ¼ã‚¯ãƒ³");
    assert_eq!(total_seq_len, 16, "Attentionç”¨ã®total_seq_lenãŒæ­£ã—ã„ã“ã¨");

    println!("\nâœ… Position trackingãŒæ­£ã—ãå‹•ä½œã—ã¾ã™");
}
