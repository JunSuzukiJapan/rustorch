{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced ML Training with RusTorch WASM\n",
    "# RusTorch WASM È´òÂ∫¶„Å™MLÂ≠¶Áøí\n",
    "\n",
    "This notebook demonstrates advanced machine learning training capabilities using RusTorch WASM, including optimizers, autograd, and neural network training.\n",
    "\n",
    "„Åì„ÅÆ„Éé„Éº„Éà„Éñ„ÉÉ„ÇØ„Åß„ÅØ„ÄÅ„Ç™„Éó„ÉÜ„Ç£„Éû„Ç§„Ç∂„ÄÅËá™ÂãïÂæÆÂàÜ„ÄÅ„Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÂ≠¶Áøí„ÇíÂê´„ÇÄ„ÄÅRusTorch WASM„Çí‰ΩøÁî®„Åó„ÅüÈ´òÂ∫¶„Å™Ê©üÊ¢∞Â≠¶ÁøíÂ≠¶ÁøíÊ©üËÉΩ„ÇíÂÆüÊºî„Åó„Åæ„Åô„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Load RusTorch Jupyter integration\n",
    "const script = document.createElement('script');\n",
    "script.src = '../rustorch_jupyter.js';\n",
    "document.head.appendChild(script);\n",
    "await new Promise(resolve => { script.onload = resolve; });\n",
    "\n",
    "// Initialize\n",
    "const rustorch = new RusTorchJupyter();\n",
    "await rustorch.initialize();\n",
    "console.log('üöÄ Advanced ML training environment ready');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generation / „Éá„Éº„Çø„Çª„ÉÉ„ÉàÁîüÊàê\n",
    "\n",
    "Generate synthetic datasets for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Generate synthetic classification dataset\n",
    "const dist = await rustorch.distributions();\n",
    "const utils = await rustorch.utils();\n",
    "\n",
    "// Generate features (2D Gaussian clusters)\n",
    "const n_samples = 1000;\n",
    "const n_features = 2;\n",
    "\n",
    "// Class 0: centered at (-1, -1)\n",
    "const class0_x = dist.normal(n_samples/2, -1.0, 0.5);\n",
    "const class0_y = dist.normal(n_samples/2, -1.0, 0.5);\n",
    "\n",
    "// Class 1: centered at (1, 1)\n",
    "const class1_x = dist.normal(n_samples/2, 1.0, 0.5);\n",
    "const class1_y = dist.normal(n_samples/2, 1.0, 0.5);\n",
    "\n",
    "// Combine features\n",
    "const features = [...class0_x, ...class1_x, ...class0_y, ...class1_y];\n",
    "const labels = [...new Array(n_samples/2).fill(0), ...new Array(n_samples/2).fill(1)];\n",
    "\n",
    "console.log('üìä Generated synthetic dataset:');\n",
    "console.log(`Features shape: [${n_samples}, ${n_features}]`);\n",
    "console.log(`Labels: ${n_samples/2} samples per class`);\n",
    "console.log('Sample features:', features.slice(0, 10));\n",
    "console.log('Sample labels:', labels.slice(0, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Architecture / „Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£\n",
    "\n",
    "Define a simple binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create neural network\n",
    "const nn = await rustorch.neuralNetwork();\n",
    "\n",
    "// Simple 2-layer MLP for binary classification\n",
    "const layer1 = nn.createLinear(2, 8, true);   // 2 features ‚Üí 8 hidden\n",
    "const layer2 = nn.createLinear(8, 1, true);   // 8 hidden ‚Üí 1 output\n",
    "\n",
    "console.log('üß† Neural network architecture:');\n",
    "console.log('Layer 1: Linear(2 ‚Üí 8) with bias');\n",
    "console.log('Layer 2: Linear(8 ‚Üí 1) with bias');\n",
    "console.log('Activation: ReLU (built-in)');\n",
    "console.log('Output: Sigmoid for binary classification');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop / Â≠¶Áøí„É´„Éº„Éó\n",
    "\n",
    "Implement a simple training loop with SGD optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Initialize optimizer\n",
    "const optimizers = await rustorch.optimizers();\n",
    "const sgd = optimizers.sgd(0.01, 0.9); // learning_rate=0.01, momentum=0.9\n",
    "\n",
    "// Training parameters\n",
    "const epochs = 10;\n",
    "const batch_size = 32;\n",
    "const n_batches = Math.floor(n_samples / batch_size);\n",
    "\n",
    "console.log('üéØ Training configuration:');\n",
    "console.log(`Epochs: ${epochs}`);\n",
    "console.log(`Batch size: ${batch_size}`);\n",
    "console.log(`Batches per epoch: ${n_batches}`);\n",
    "console.log('Optimizer: SGD with momentum');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Simple training simulation (pseudo-code for demonstration)\n",
    "// Note: Full backpropagation requires the simplified autograd system\n",
    "\n",
    "console.log('üîÑ Training simulation:');\n",
    "\n",
    "for (let epoch = 0; epoch < epochs; epoch++) {\n",
    "    let total_loss = 0;\n",
    "    \n",
    "    for (let batch = 0; batch < Math.min(n_batches, 5); batch++) { // Limit for demo\n",
    "        // Get batch data\n",
    "        const start_idx = batch * batch_size;\n",
    "        const end_idx = Math.min(start_idx + batch_size, n_samples);\n",
    "        const batch_size_actual = end_idx - start_idx;\n",
    "        \n",
    "        // Extract batch features\n",
    "        const batch_features = [];\n",
    "        for (let i = start_idx; i < end_idx; i++) {\n",
    "            batch_features.push(features[i], features[i + n_samples]); // x, y coordinates\n",
    "        }\n",
    "        \n",
    "        // Forward pass\n",
    "        const hidden_output = layer1.forward(batch_features, batch_size_actual, 2);\n",
    "        const predictions = layer2.forward(hidden_output, batch_size_actual, 8);\n",
    "        \n",
    "        // Compute simple loss (mean squared error for demo)\n",
    "        let batch_loss = 0;\n",
    "        for (let i = 0; i < batch_size_actual; i++) {\n",
    "            const target = labels[start_idx + i];\n",
    "            const pred = 1 / (1 + Math.exp(-predictions[i])); // sigmoid\n",
    "            batch_loss += (pred - target) ** 2;\n",
    "        }\n",
    "        batch_loss /= batch_size_actual;\n",
    "        total_loss += batch_loss;\n",
    "        \n",
    "        // Simulate optimizer step\n",
    "        // sgd.step(params, grads); // Would use actual gradients here\n",
    "    }\n",
    "    \n",
    "    const avg_loss = total_loss / Math.min(n_batches, 5);\n",
    "    console.log(`Epoch ${epoch + 1}/${epochs}: Loss = ${avg_loss.toFixed(4)}`);\n",
    "}\n",
    "\n",
    "console.log('‚úÖ Training simulation completed');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis / „Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÂàÜÊûê\n",
    "\n",
    "Analyze the performance characteristics in Jupyter environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Comprehensive performance analysis\n",
    "console.log('üîç Performance Analysis in Jupyter Lab:');\n",
    "\n",
    "// Test different tensor sizes\n",
    "const sizes = [100, 1000, 10000];\n",
    "const results = [];\n",
    "\n",
    "for (const size of sizes) {\n",
    "    const test_data = new Array(size).fill(0).map(() => Math.random());\n",
    "    const test_tensor = await rustorch.createTensor(test_data, [Math.sqrt(size), Math.sqrt(size)]);\n",
    "    \n",
    "    const add_time = await utils.benchmark(async () => {\n",
    "        test_tensor.add(test_tensor);\n",
    "    }, 50);\n",
    "    \n",
    "    const sum_time = await utils.benchmark(async () => {\n",
    "        test_tensor.sum();\n",
    "    }, 50);\n",
    "    \n",
    "    results.push({ size, add_time, sum_time });\n",
    "    console.log(`Size ${size}: Add=${add_time.toFixed(2)}ms, Sum=${sum_time.toFixed(2)}ms`);\n",
    "}\n",
    "\n",
    "console.log('\\nüìä Performance Summary:');\n",
    "console.log('- Small tensors (100): Fast operations suitable for interactive development');\n",
    "console.log('- Medium tensors (1000): Good performance for notebook experiments');\n",
    "console.log('- Large tensors (10000): Consider WebGPU acceleration for better performance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup / „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó\n",
    "\n",
    "Properly cleanup resources when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Cleanup (if needed for memory management)\n",
    "console.log('üßπ Cleaning up resources...');\n",
    "\n",
    "// Free tensors if memory management is critical\n",
    "// Note: WASM garbage collection usually handles this automatically\n",
    "\n",
    "console.log('‚úÖ Jupyter Lab session cleanup completed');\n",
    "console.log('üí° Tip: Use \"Kernel ‚Üí Restart\" to fully reset the WASM environment');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JavaScript",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "name": "javascript",
   "version": "ES2020"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}