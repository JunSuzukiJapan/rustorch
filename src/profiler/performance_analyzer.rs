//! Performance Analysis & Optimization Engine
//! ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ»æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³

use crate::error::{RusTorchError, RusTorchResult};
use crate::profiler::benchmark_suite::{BenchmarkResult, BenchmarkStatistics};
use crate::profiler::core::{PerformanceStatistics, SessionSnapshot};
use std::collections::HashMap;
use std::time::{Duration, Instant};

/// Performance trend direction
/// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‚¾å‘æ–¹å‘
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum TrendDirection {
    /// Performance is improving
    /// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šä¸­
    Improving,
    /// Performance is degrading
    /// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ£åŒ–ä¸­
    Degrading,
    /// Performance is stable
    /// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å®‰å®š
    Stable,
    /// Not enough data
    /// ãƒ‡ãƒ¼ã‚¿ä¸è¶³
    Unknown,
}

/// Performance trend analysis
/// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‚¾å‘åˆ†æ
#[derive(Debug, Clone)]
pub struct PerformanceTrend {
    /// Operation name
    /// æ“ä½œå
    pub operation_name: String,
    /// Trend direction
    /// å‚¾å‘æ–¹å‘
    pub direction: TrendDirection,
    /// Rate of change (% per measurement)
    /// å¤‰åŒ–ç‡ï¼ˆæ¸¬å®šã”ã¨ã®%ï¼‰
    pub change_rate_percent: f64,
    /// Confidence level (0.0 to 1.0)
    /// ä¿¡é ¼åº¦ï¼ˆ0.0ã‹ã‚‰1.0ï¼‰
    pub confidence: f64,
    /// Historical measurements
    /// éå»ã®æ¸¬å®šå€¤
    pub measurements: Vec<TrendMeasurement>,
    /// Projected performance
    /// äºˆæ¸¬ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
    pub projection: Option<PerformanceProjection>,
}

/// Individual trend measurement
/// å€‹åˆ¥å‚¾å‘æ¸¬å®š
#[derive(Debug, Clone)]
pub struct TrendMeasurement {
    /// Measurement timestamp
    /// æ¸¬å®šã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    pub timestamp: Instant,
    /// Performance value (e.g., execution time in ms)
    /// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å€¤ï¼ˆä¾‹ï¼šå®Ÿè¡Œæ™‚é–“ã®msï¼‰
    pub value: f64,
    /// Measurement context
    /// æ¸¬å®šã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    pub context: MeasurementContext,
}

/// Context for performance measurements
/// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
#[derive(Debug, Clone)]
pub struct MeasurementContext {
    /// System load at measurement time
    /// æ¸¬å®šæ™‚ã‚·ã‚¹ãƒ†ãƒ è² è·
    pub system_load: Option<f64>,
    /// Memory pressure
    /// ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼
    pub memory_pressure: Option<f64>,
    /// GPU utilization
    /// GPUä½¿ç”¨ç‡
    pub gpu_utilization: Option<f64>,
    /// Temperature factors
    /// æ¸©åº¦è¦å› 
    pub temperature_celsius: Option<f32>,
    /// Additional metadata
    /// è¿½åŠ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    pub metadata: HashMap<String, String>,
}

/// Performance projection
/// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬
#[derive(Debug, Clone)]
pub struct PerformanceProjection {
    /// Predicted value at next measurement
    /// æ¬¡ã®æ¸¬å®šã§ã®äºˆæ¸¬å€¤
    pub next_value: f64,
    /// Prediction confidence (0.0 to 1.0)
    /// äºˆæ¸¬ä¿¡é ¼åº¦ï¼ˆ0.0ã‹ã‚‰1.0ï¼‰
    pub confidence: f64,
    /// Time horizon for prediction
    /// äºˆæ¸¬ã®æ™‚é–“è»¸
    pub time_horizon: Duration,
    /// Potential performance range
    /// æ½œåœ¨çš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç¯„å›²
    pub value_range: (f64, f64),
}

/// Optimization recommendation
/// æœ€é©åŒ–æ¨å¥¨äº‹é …
#[derive(Debug, Clone)]
pub struct OptimizationRecommendation {
    /// Recommendation ID
    /// æ¨å¥¨äº‹é …ID
    pub id: String,
    /// Target operation or system component
    /// å¯¾è±¡æ“ä½œã¾ãŸã¯ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
    pub target: String,
    /// Recommendation type
    /// æ¨å¥¨äº‹é …ã‚¿ã‚¤ãƒ—
    pub recommendation_type: RecommendationType,
    /// Priority level
    /// å„ªå…ˆåº¦ãƒ¬ãƒ™ãƒ«
    pub priority: RecommendationPriority,
    /// Description of the issue
    /// å•é¡Œã®èª¬æ˜
    pub description: String,
    /// Recommended action
    /// æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    pub action: String,
    /// Expected improvement
    /// æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„
    pub expected_improvement: ExpectedImprovement,
    /// Implementation complexity
    /// å®Ÿè£…è¤‡é›‘åº¦
    pub complexity: ImplementationComplexity,
    /// Supporting evidence
    /// è£ä»˜ã‘è¨¼æ‹ 
    pub evidence: Vec<String>,
    /// Recommendation timestamp
    /// æ¨å¥¨äº‹é …ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    pub timestamp: Instant,
}

/// Type of optimization recommendation
/// æœ€é©åŒ–æ¨å¥¨äº‹é …ã®ã‚¿ã‚¤ãƒ—
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum RecommendationType {
    /// Algorithm optimization
    /// ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æœ€é©åŒ–
    Algorithm,
    /// Memory optimization
    /// ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
    Memory,
    /// GPU optimization
    /// GPUæœ€é©åŒ–
    Gpu,
    /// Caching strategy
    /// ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥
    Caching,
    /// Parallelization
    /// ä¸¦åˆ—åŒ–
    Parallelization,
    /// Data structure optimization
    /// ãƒ‡ãƒ¼ã‚¿æ§‹é€ æœ€é©åŒ–
    DataStructure,
    /// System configuration
    /// ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
    SystemConfig,
    /// Hardware upgrade
    /// ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰
    Hardware,
}

/// Recommendation priority
/// æ¨å¥¨äº‹é …å„ªå…ˆåº¦
#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
pub enum RecommendationPriority {
    /// Critical performance issue
    /// é‡è¦ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œ
    Critical,
    /// High impact optimization
    /// é«˜å½±éŸ¿æœ€é©åŒ–
    High,
    /// Medium impact optimization
    /// ä¸­å½±éŸ¿æœ€é©åŒ–
    Medium,
    /// Low impact optimization
    /// ä½å½±éŸ¿æœ€é©åŒ–
    Low,
    /// Optional improvement
    /// ã‚ªãƒ—ã‚·ãƒ§ãƒ³æ”¹å–„
    Optional,
}

/// Expected improvement from recommendation
/// æ¨å¥¨äº‹é …ã«ã‚ˆã‚‹æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„
#[derive(Debug, Clone)]
pub struct ExpectedImprovement {
    /// Performance improvement percentage
    /// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ç‡
    pub performance_gain_percent: f64,
    /// Memory reduction percentage
    /// ãƒ¡ãƒ¢ãƒªå‰Šæ¸›ç‡
    pub memory_reduction_percent: Option<f64>,
    /// Energy efficiency improvement
    /// ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡æ”¹å–„
    pub energy_efficiency_gain_percent: Option<f64>,
    /// Confidence in estimate (0.0 to 1.0)
    /// è¦‹ç©ã‚‚ã‚Šã®ä¿¡é ¼åº¦ï¼ˆ0.0ã‹ã‚‰1.0ï¼‰
    pub confidence: f64,
}

/// Implementation complexity
/// å®Ÿè£…è¤‡é›‘åº¦
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ImplementationComplexity {
    /// Simple configuration change
    /// ã‚·ãƒ³ãƒ—ãƒ«ãªè¨­å®šå¤‰æ›´
    Trivial,
    /// Minor code changes
    /// è»½å¾®ãªã‚³ãƒ¼ãƒ‰å¤‰æ›´
    Simple,
    /// Moderate refactoring required
    /// ä¸­ç¨‹åº¦ã®ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¿…è¦
    Moderate,
    /// Significant architectural changes
    /// é‡è¦ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¤‰æ›´
    Complex,
    /// Major system redesign
    /// ä¸»è¦ã‚·ã‚¹ãƒ†ãƒ å†è¨­è¨ˆ
    Expert,
}

/// Trend analysis configuration
/// å‚¾å‘åˆ†æè¨­å®š
#[derive(Debug, Clone)]
pub struct TrendAnalysisConfig {
    /// Minimum measurements for trend analysis
    /// å‚¾å‘åˆ†æã®æœ€å°æ¸¬å®šæ•°
    pub min_measurements: usize,
    /// Lookback window for trend analysis
    /// å‚¾å‘åˆ†æã®æŒ¯ã‚Šè¿”ã‚ŠæœŸé–“
    pub lookback_window: Duration,
    /// Significance threshold for trend detection
    /// å‚¾å‘æ¤œå‡ºã®æœ‰æ„æ€§é–¾å€¤
    pub significance_threshold: f64,
    /// Minimum confidence for recommendations
    /// æ¨å¥¨äº‹é …ã®æœ€å°ä¿¡é ¼åº¦
    pub min_recommendation_confidence: f64,
}

impl Default for TrendAnalysisConfig {
    fn default() -> Self {
        Self {
            min_measurements: 5,
            lookback_window: Duration::from_secs(3600), // 1 hour
            significance_threshold: 0.05,               // 5% change
            min_recommendation_confidence: 0.7,
        }
    }
}

/// Performance analyzer engine
/// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚¨ãƒ³ã‚¸ãƒ³
#[derive(Debug)]
pub struct PerformanceAnalyzer {
    /// Analysis configuration
    /// åˆ†æè¨­å®š
    config: TrendAnalysisConfig,
    /// Historical performance data
    /// éå»ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿
    performance_history: HashMap<String, Vec<TrendMeasurement>>,
    /// Cached trend analysis results
    /// ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸå‚¾å‘åˆ†æçµæœ
    trend_cache: HashMap<String, PerformanceTrend>,
    /// Generated recommendations
    /// ç”Ÿæˆã•ã‚ŒãŸæ¨å¥¨äº‹é …
    recommendations: Vec<OptimizationRecommendation>,
    /// Baseline performance metrics
    /// ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    baselines: HashMap<String, f64>,
    /// Analysis timestamp
    /// åˆ†æã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    last_analysis: Option<Instant>,
}

impl PerformanceAnalyzer {
    /// Create new performance analyzer
    /// æ–°ã—ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æå™¨ã‚’ä½œæˆ
    pub fn new() -> Self {
        Self {
            config: TrendAnalysisConfig::default(),
            performance_history: HashMap::new(),
            trend_cache: HashMap::new(),
            recommendations: Vec::new(),
            baselines: HashMap::new(),
            last_analysis: None,
        }
    }

    /// Create analyzer with custom configuration
    /// ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã§åˆ†æå™¨ã‚’ä½œæˆ
    pub fn with_config(config: TrendAnalysisConfig) -> Self {
        Self {
            config,
            performance_history: HashMap::new(),
            trend_cache: HashMap::new(),
            recommendations: Vec::new(),
            baselines: HashMap::new(),
            last_analysis: None,
        }
    }

    /// Add performance measurement
    /// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šã‚’è¿½åŠ 
    pub fn add_measurement(
        &mut self,
        operation_name: String,
        value: f64,
        context: MeasurementContext,
    ) {
        let measurement = TrendMeasurement {
            timestamp: Instant::now(),
            value,
            context,
        };

        self.performance_history
            .entry(operation_name.clone())
            .or_default()
            .push(measurement);

        // Invalidate cache for this operation
        self.trend_cache.remove(&operation_name);

        // Maintain history size (keep last 1000 measurements)
        if let Some(history) = self.performance_history.get_mut(&operation_name) {
            if history.len() > 1000 {
                history.drain(0..500);
            }
        }
    }

    /// Analyze session performance
    /// ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åˆ†æ
    pub fn analyze_session(&mut self, session: &SessionSnapshot) -> RusTorchResult<TrendAnalysis> {
        println!("ğŸ” Analyzing session: {}", session.session_name);

        let mut trends = HashMap::new();

        for operation in &session.operations {
            let stats = operation.get_statistics();

            // Add measurement from session
            let context = MeasurementContext {
                system_load: None,
                memory_pressure: None,
                gpu_utilization: None,
                temperature_celsius: None,
                metadata: HashMap::new(),
            };

            self.add_measurement(operation.name.clone(), stats.avg_time_ms, context);

            // Analyze trend for this operation
            if let Ok(trend) = self.analyze_operation_trend(&operation.name) {
                trends.insert(operation.name.clone(), trend);
            }
        }

        // Generate recommendations based on analysis
        self.generate_recommendations(&trends)?;

        self.last_analysis = Some(Instant::now());

        Ok(TrendAnalysis {
            session_id: session.session_id.clone(),
            session_name: session.session_name.clone(),
            analysis_timestamp: Instant::now(),
            operation_trends: trends.clone(),
            overall_performance_score: self.calculate_overall_score(&session.operations)?,
            recommendations: self.recommendations.clone(),
            summary: self.generate_analysis_summary(&trends),
        })
    }

    /// Analyze benchmark results
    /// ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚’åˆ†æ
    pub fn analyze_benchmark_results(
        &mut self,
        results: &HashMap<String, BenchmarkResult>,
    ) -> RusTorchResult<BenchmarkAnalysis> {
        println!(
            "ğŸ“Š Analyzing benchmark results ({} benchmarks)",
            results.len()
        );

        let mut analysis_results = HashMap::new();
        let mut performance_insights = Vec::new();

        for (name, result) in results {
            if result.error.is_none() {
                // Add benchmark data to history
                let context = MeasurementContext {
                    system_load: result
                        .system_metrics
                        .as_ref()
                        .map(|s| s.cpu_utilization_percent),
                    memory_pressure: result
                        .memory_metrics
                        .as_ref()
                        .map(|m| m.fragmentation_score),
                    gpu_utilization: result
                        .gpu_metrics
                        .as_ref()
                        .map(|g| g.gpu_utilization_percent),
                    temperature_celsius: result
                        .gpu_metrics
                        .as_ref()
                        .and_then(|g| g.gpu_temperature_celsius),
                    metadata: HashMap::new(),
                };

                self.add_measurement(name.clone(), result.statistics.mean_ms, context);

                // Analyze benchmark performance
                let analysis = self.analyze_benchmark_performance(result)?;
                analysis_results.insert(name.clone(), analysis);

                // Generate performance insights
                if let Some(insights) = self.generate_benchmark_insights(result) {
                    performance_insights.extend(insights);
                }
            }
        }

        Ok(BenchmarkAnalysis {
            analysis_timestamp: Instant::now(),
            benchmark_results: analysis_results,
            performance_insights,
            comparative_analysis: self.generate_comparative_analysis(results)?,
            optimization_opportunities: self.identify_optimization_opportunities(results)?,
        })
    }

    /// Set baseline for operation
    /// æ“ä½œã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’è¨­å®š
    pub fn set_baseline(&mut self, operation_name: String, baseline_value: f64) {
        self.baselines.insert(operation_name, baseline_value);
    }

    /// Get performance trend for operation
    /// æ“ä½œã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‚¾å‘ã‚’å–å¾—
    pub fn get_trend(&mut self, operation_name: &str) -> RusTorchResult<PerformanceTrend> {
        if let Some(cached_trend) = self.trend_cache.get(operation_name) {
            return Ok(cached_trend.clone());
        }

        let trend = self.analyze_operation_trend(operation_name)?;
        self.trend_cache
            .insert(operation_name.to_string(), trend.clone());
        Ok(trend)
    }

    /// Get all current recommendations
    /// ç¾åœ¨ã®å…¨æ¨å¥¨äº‹é …ã‚’å–å¾—
    pub fn get_recommendations(&self) -> &[OptimizationRecommendation] {
        &self.recommendations
    }

    /// Get recommendations by priority
    /// å„ªå…ˆåº¦åˆ¥æ¨å¥¨äº‹é …ã‚’å–å¾—
    pub fn get_recommendations_by_priority(
        &self,
        priority: RecommendationPriority,
    ) -> Vec<&OptimizationRecommendation> {
        self.recommendations
            .iter()
            .filter(|r| r.priority == priority)
            .collect()
    }

    /// Clear analysis data
    /// åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
    pub fn clear(&mut self) {
        self.performance_history.clear();
        self.trend_cache.clear();
        self.recommendations.clear();
        self.baselines.clear();
        self.last_analysis = None;
    }

    // Private analysis methods

    fn analyze_operation_trend(&self, operation_name: &str) -> RusTorchResult<PerformanceTrend> {
        let measurements = self
            .performance_history
            .get(operation_name)
            .ok_or_else(|| RusTorchError::Profiling {
                message: format!("No measurements for operation: {}", operation_name),
            })?;

        if measurements.len() < self.config.min_measurements {
            return Ok(PerformanceTrend {
                operation_name: operation_name.to_string(),
                direction: TrendDirection::Unknown,
                change_rate_percent: 0.0,
                confidence: 0.0,
                measurements: measurements.clone(),
                projection: None,
            });
        }

        // Calculate trend using linear regression
        let (slope, confidence) = self.calculate_linear_trend(measurements)?;

        let direction = if slope.abs() < self.config.significance_threshold {
            TrendDirection::Stable
        } else if slope < 0.0 {
            TrendDirection::Improving // Negative slope = decreasing time = better performance
        } else {
            TrendDirection::Degrading
        };

        let change_rate_percent = slope * 100.0;

        // Generate projection if trend is significant
        let projection = if confidence > 0.5 {
            Some(self.generate_projection(measurements, slope, confidence)?)
        } else {
            None
        };

        Ok(PerformanceTrend {
            operation_name: operation_name.to_string(),
            direction,
            change_rate_percent,
            confidence,
            measurements: measurements.clone(),
            projection,
        })
    }

    fn calculate_linear_trend(
        &self,
        measurements: &[TrendMeasurement],
    ) -> RusTorchResult<(f64, f64)> {
        if measurements.len() < 2 {
            return Ok((0.0, 0.0));
        }

        // Convert timestamps to seconds from first measurement
        let first_time = measurements[0].timestamp;
        let x_values: Vec<f64> = measurements
            .iter()
            .map(|m| m.timestamp.duration_since(first_time).as_secs_f64())
            .collect();

        let y_values: Vec<f64> = measurements.iter().map(|m| m.value).collect();

        // Calculate linear regression
        let n = measurements.len() as f64;
        let sum_x: f64 = x_values.iter().sum();
        let sum_y: f64 = y_values.iter().sum();
        let sum_xy: f64 = x_values.iter().zip(&y_values).map(|(x, y)| x * y).sum();
        let sum_x2: f64 = x_values.iter().map(|x| x * x).sum();

        let slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x * sum_x);

        // Calculate R-squared for confidence
        let mean_y = sum_y / n;
        let ss_tot: f64 = y_values.iter().map(|y| (y - mean_y).powi(2)).sum();
        let intercept = (sum_y - slope * sum_x) / n;
        let ss_res: f64 = x_values
            .iter()
            .zip(&y_values)
            .map(|(x, y)| (y - (slope * x + intercept)).powi(2))
            .sum();

        let r_squared = if ss_tot > 0.0 {
            1.0 - (ss_res / ss_tot)
        } else {
            0.0
        };
        let confidence = r_squared.max(0.0).min(1.0);

        Ok((slope, confidence))
    }

    fn generate_projection(
        &self,
        measurements: &[TrendMeasurement],
        slope: f64,
        confidence: f64,
    ) -> RusTorchResult<PerformanceProjection> {
        let last_measurement = &measurements[measurements.len() - 1];
        let time_horizon = Duration::from_secs(3600); // 1 hour projection

        let next_value = last_measurement.value + slope * time_horizon.as_secs_f64();

        // Calculate uncertainty range based on confidence
        let uncertainty_factor = (1.0 - confidence) * 0.2; // Max 20% uncertainty
        let range_width = next_value * uncertainty_factor;

        Ok(PerformanceProjection {
            next_value,
            confidence,
            time_horizon,
            value_range: (next_value - range_width, next_value + range_width),
        })
    }

    fn generate_recommendations(
        &mut self,
        trends: &HashMap<String, PerformanceTrend>,
    ) -> RusTorchResult<()> {
        self.recommendations.clear();

        for (operation_name, trend) in trends {
            match trend.direction {
                TrendDirection::Degrading
                    if trend.confidence > self.config.min_recommendation_confidence =>
                {
                    let recommendation =
                        self.create_degradation_recommendation(operation_name, trend)?;
                    self.recommendations.push(recommendation);
                }
                TrendDirection::Stable => {
                    // Look for optimization opportunities even in stable performance
                    if let Some(recommendation) =
                        self.create_optimization_recommendation(operation_name, trend)?
                    {
                        self.recommendations.push(recommendation);
                    }
                }
                _ => {}
            }
        }

        // Sort recommendations by priority
        self.recommendations
            .sort_by(|a, b| a.priority.cmp(&b.priority));

        Ok(())
    }

    fn create_degradation_recommendation(
        &self,
        operation_name: &str,
        trend: &PerformanceTrend,
    ) -> RusTorchResult<OptimizationRecommendation> {
        let priority = if trend.change_rate_percent > 20.0 {
            RecommendationPriority::Critical
        } else if trend.change_rate_percent > 10.0 {
            RecommendationPriority::High
        } else {
            RecommendationPriority::Medium
        };

        Ok(OptimizationRecommendation {
            id: format!("degradation_{}", operation_name),
            target: operation_name.to_string(),
            recommendation_type: RecommendationType::Algorithm,
            priority,
            description: format!(
                "Performance degradation detected: {:.1}% slower over recent measurements",
                trend.change_rate_percent
            ),
            action: "Investigate recent changes and profile operation for bottlenecks".to_string(),
            expected_improvement: ExpectedImprovement {
                performance_gain_percent: trend.change_rate_percent,
                memory_reduction_percent: None,
                energy_efficiency_gain_percent: None,
                confidence: trend.confidence,
            },
            complexity: ImplementationComplexity::Moderate,
            evidence: vec![
                format!("Trend confidence: {:.1}%", trend.confidence * 100.0),
                format!("Change rate: {:.1}%", trend.change_rate_percent),
            ],
            timestamp: Instant::now(),
        })
    }

    fn create_optimization_recommendation(
        &self,
        _operation_name: &str,
        _trend: &PerformanceTrend,
    ) -> RusTorchResult<Option<OptimizationRecommendation>> {
        // Placeholder for optimization opportunity detection
        Ok(None)
    }

    fn analyze_benchmark_performance(
        &self,
        _result: &BenchmarkResult,
    ) -> RusTorchResult<BenchmarkPerformanceAnalysis> {
        // Placeholder implementation
        Ok(BenchmarkPerformanceAnalysis {
            stability_score: 0.9,
            efficiency_score: 0.8,
            comparison_to_baseline: None,
            bottleneck_indicators: Vec::new(),
        })
    }

    fn generate_benchmark_insights(
        &self,
        _result: &BenchmarkResult,
    ) -> Option<Vec<PerformanceInsight>> {
        // Placeholder implementation
        None
    }

    fn generate_comparative_analysis(
        &self,
        _results: &HashMap<String, BenchmarkResult>,
    ) -> RusTorchResult<ComparativeAnalysis> {
        // Placeholder implementation
        Ok(ComparativeAnalysis {
            performance_ranking: Vec::new(),
            relative_performance: HashMap::new(),
            category_analysis: HashMap::new(),
        })
    }

    fn identify_optimization_opportunities(
        &self,
        _results: &HashMap<String, BenchmarkResult>,
    ) -> RusTorchResult<Vec<OptimizationOpportunity>> {
        // Placeholder implementation
        Ok(Vec::new())
    }

    fn calculate_overall_score(
        &self,
        _operations: &[crate::profiler::core::OperationMetrics],
    ) -> RusTorchResult<f64> {
        // Simplified overall score calculation
        Ok(0.85) // Placeholder
    }

    fn generate_analysis_summary(
        &self,
        trends: &HashMap<String, PerformanceTrend>,
    ) -> AnalysisSummary {
        let total_operations = trends.len();
        let improving_count = trends
            .values()
            .filter(|t| t.direction == TrendDirection::Improving)
            .count();
        let degrading_count = trends
            .values()
            .filter(|t| t.direction == TrendDirection::Degrading)
            .count();
        let stable_count = trends
            .values()
            .filter(|t| t.direction == TrendDirection::Stable)
            .count();

        AnalysisSummary {
            total_operations,
            improving_count,
            degrading_count,
            stable_count,
            critical_recommendations: self
                .get_recommendations_by_priority(RecommendationPriority::Critical)
                .len(),
            high_recommendations: self
                .get_recommendations_by_priority(RecommendationPriority::High)
                .len(),
        }
    }
}

/// Overall trend analysis results
/// å…¨ä½“å‚¾å‘åˆ†æçµæœ
#[derive(Debug, Clone)]
pub struct TrendAnalysis {
    /// Source session ID
    /// ã‚½ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
    pub session_id: String,
    /// Source session name
    /// ã‚½ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³å
    pub session_name: String,
    /// Analysis timestamp
    /// åˆ†æã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    pub analysis_timestamp: Instant,
    /// Trends for individual operations
    /// å€‹åˆ¥æ“ä½œã®å‚¾å‘
    pub operation_trends: HashMap<String, PerformanceTrend>,
    /// Overall performance score (0.0 to 1.0)
    /// å…¨ä½“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢ï¼ˆ0.0ã‹ã‚‰1.0ï¼‰
    pub overall_performance_score: f64,
    /// Generated recommendations
    /// ç”Ÿæˆã•ã‚ŒãŸæ¨å¥¨äº‹é …
    pub recommendations: Vec<OptimizationRecommendation>,
    /// Analysis summary
    /// åˆ†æã‚µãƒãƒªãƒ¼
    pub summary: AnalysisSummary,
}

/// Analysis summary
/// åˆ†æã‚µãƒãƒªãƒ¼
#[derive(Debug, Clone)]
pub struct AnalysisSummary {
    /// Total operations analyzed
    /// åˆ†æã—ãŸç·æ“ä½œæ•°
    pub total_operations: usize,
    /// Operations with improving performance
    /// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šä¸­ã®æ“ä½œæ•°
    pub improving_count: usize,
    /// Operations with degrading performance
    /// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ£åŒ–ä¸­ã®æ“ä½œæ•°
    pub degrading_count: usize,
    /// Operations with stable performance
    /// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å®‰å®šã®æ“ä½œæ•°
    pub stable_count: usize,
    /// Number of critical recommendations
    /// é‡è¦æ¨å¥¨äº‹é …æ•°
    pub critical_recommendations: usize,
    /// Number of high priority recommendations
    /// é«˜å„ªå…ˆåº¦æ¨å¥¨äº‹é …æ•°
    pub high_recommendations: usize,
}

/// Benchmark analysis results
/// ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯åˆ†æçµæœ
#[derive(Debug, Clone)]
pub struct BenchmarkAnalysis {
    /// Analysis timestamp
    /// åˆ†æã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    pub analysis_timestamp: Instant,
    /// Results for individual benchmarks
    /// å€‹åˆ¥ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®çµæœ
    pub benchmark_results: HashMap<String, BenchmarkPerformanceAnalysis>,
    /// Performance insights
    /// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ´å¯Ÿ
    pub performance_insights: Vec<PerformanceInsight>,
    /// Comparative analysis
    /// æ¯”è¼ƒåˆ†æ
    pub comparative_analysis: ComparativeAnalysis,
    /// Optimization opportunities
    /// æœ€é©åŒ–æ©Ÿä¼š
    pub optimization_opportunities: Vec<OptimizationOpportunity>,
}

// Supporting data structures (placeholders for full implementation)

/// Benchmark performance analysis results
/// ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æçµæœ
#[derive(Debug, Clone)]
pub struct BenchmarkPerformanceAnalysis {
    /// Stability score (0.0 - 1.0)
    /// å®‰å®šæ€§ã‚¹ã‚³ã‚¢ï¼ˆ0.0 - 1.0ï¼‰
    pub stability_score: f64,
    /// Efficiency score (0.0 - 1.0)
    /// åŠ¹ç‡æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0.0 - 1.0ï¼‰
    pub efficiency_score: f64,
    /// Comparison to baseline performance
    /// ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã®æ¯”è¼ƒ
    pub comparison_to_baseline: Option<f64>,
    /// Identified bottleneck indicators
    /// ç‰¹å®šã•ã‚ŒãŸãƒœãƒˆãƒ«ãƒãƒƒã‚¯æŒ‡æ¨™
    pub bottleneck_indicators: Vec<String>,
}

#[derive(Debug, Clone)]
pub struct PerformanceInsight {
    pub category: String,
    pub description: String,
    pub impact_level: RecommendationPriority,
}

#[derive(Debug, Clone)]
pub struct ComparativeAnalysis {
    pub performance_ranking: Vec<String>,
    pub relative_performance: HashMap<String, f64>,
    pub category_analysis: HashMap<String, f64>,
}

#[derive(Debug, Clone)]
pub struct OptimizationOpportunity {
    pub operation: String,
    pub opportunity_type: RecommendationType,
    pub potential_gain: f64,
    pub implementation_effort: ImplementationComplexity,
}

impl Default for PerformanceAnalyzer {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_analyzer_creation() {
        let analyzer = PerformanceAnalyzer::new();
        assert_eq!(analyzer.recommendations.len(), 0);
        assert_eq!(analyzer.performance_history.len(), 0);
    }

    #[test]
    fn test_measurement_addition() {
        let mut analyzer = PerformanceAnalyzer::new();

        let context = MeasurementContext {
            system_load: Some(0.5),
            memory_pressure: None,
            gpu_utilization: None,
            temperature_celsius: None,
            metadata: HashMap::new(),
        };

        analyzer.add_measurement("test_op".to_string(), 100.0, context);

        assert_eq!(analyzer.performance_history.len(), 1);
        assert!(analyzer.performance_history.contains_key("test_op"));
        assert_eq!(analyzer.performance_history["test_op"].len(), 1);
    }

    #[test]
    fn test_trend_analysis_insufficient_data() {
        let analyzer = PerformanceAnalyzer::new();
        let result = analyzer.analyze_operation_trend("nonexistent_op");
        assert!(result.is_err());
    }

    #[test]
    fn test_baseline_setting() {
        let mut analyzer = PerformanceAnalyzer::new();
        analyzer.set_baseline("test_op".to_string(), 50.0);

        assert!(analyzer.baselines.contains_key("test_op"));
        assert_eq!(analyzer.baselines["test_op"], 50.0);
    }

    #[test]
    fn test_linear_trend_calculation() {
        let analyzer = PerformanceAnalyzer::new();
        let start_time = Instant::now();

        let measurements = vec![
            TrendMeasurement {
                timestamp: start_time,
                value: 100.0,
                context: MeasurementContext {
                    system_load: None,
                    memory_pressure: None,
                    gpu_utilization: None,
                    temperature_celsius: None,
                    metadata: HashMap::new(),
                },
            },
            TrendMeasurement {
                timestamp: start_time + Duration::from_secs(60),
                value: 110.0,
                context: MeasurementContext {
                    system_load: None,
                    memory_pressure: None,
                    gpu_utilization: None,
                    temperature_celsius: None,
                    metadata: HashMap::new(),
                },
            },
        ];

        let result = analyzer.calculate_linear_trend(&measurements);
        assert!(result.is_ok());
        let (slope, confidence) = result.unwrap();
        assert!(slope > 0.0); // Increasing trend
        assert!(confidence >= 0.0 && confidence <= 1.0);
    }
}
