//! # RusTorch ğŸš€
//!
//! **A production-ready deep learning library in Rust with PyTorch-like API, unified error handling, and 100% test success**
//!
//! RusTorch v0.4.0 is a fully functional deep learning library that leverages Rust's safety and performance,
//! providing comprehensive tensor operations, automatic differentiation, neural network layers,
//! transformer architectures, GPU acceleration, unified error handling system, and advanced memory optimization features.
//!
//! ## âœ¨ Key Features
//!
//! - **ğŸ”¥ Comprehensive Tensor Operations**: Math operations, broadcasting, indexing, and statistics
//! - **ğŸ¤– Transformer Architecture**: Complete transformer implementation with multi-head attention
//! - **âš¡ SIMD Optimizations**: AVX2/SSE4.1 vectorized operations for high performance
//! - **ğŸ”„ Unified Parallel Operations**: Trait-based parallel tensor operations with intelligent scheduling
//! - **ğŸ® GPU Integration**: CUDA/Metal/OpenCL support with automatic device selection
//! - **ğŸ’¾ Advanced Memory Management**: Zero-copy operations, SIMD-aligned allocation, and memory pools
//! - **ğŸ§  Automatic Differentiation**: Tape-based computational graph for gradient computation
//! - **ğŸ—ï¸ Neural Network Layers**: Linear, Conv1d/2d/3d, ConvTranspose, RNN/LSTM/GRU, BatchNorm, Dropout, and more
//! - **ğŸ›¡ï¸ Unified Error Handling**: Single `RusTorchError` type with 61+ specialized helper functions and `RusTorchResult<T>` for cleaner APIs
//! - **ğŸ”§ Safe Operations**: Type-safe tensor operations with comprehensive error handling and ReLU activation
//! - **âš™ï¸ Shared Base Traits**: Reusable convolution and pooling base implementations for code efficiency
//! - **ğŸŒ WebAssembly Support**: Browser-compatible WASM bindings with optimized performance
//!
//! ## ğŸš€ Quick Start
//!
//! ```rust
//! use rustorch::prelude::*;
//!
//! // Create tensors
//! let a = Tensor::from_vec(vec![1.0f32, 2.0, 3.0, 4.0], vec![2, 2]);
//! let b = Tensor::from_vec(vec![5.0f32, 6.0, 7.0, 8.0], vec![2, 2]);
//!
//! // Basic operations
//! let c = &a + &b;  // Addition
//! let d = a.matmul(&b);  // Matrix multiplication
//!
//! // Mathematical functions
//! let e = a.sin();  // Sine function
//! let f = a.exp();  // Exponential function
//!
//! println!("Shape: {:?}", c.shape());
//! println!("Result: {:?}", c.as_slice());
//! ```
//!
//! ## ğŸ”§ Safe Operations with Error Handling
//!
//! ```rust
//! use rustorch::nn::safe_ops::SafeOps;
//!
//! // Create variables safely with validation
//! let var = SafeOps::create_variable(vec![-1.0, 0.0, 1.0], vec![3], false).unwrap();
//!
//! // Apply ReLU activation function
//! let relu_result = SafeOps::relu(&var).unwrap();
//! println!("ReLU: {:?}", relu_result.data().read().unwrap().as_array()); // [0.0, 0.0, 1.0]
//!
//! // Get tensor statistics
//! let stats = SafeOps::get_stats(&var).unwrap();
//! println!("Mean: {:.2}, Std: {:.2}", stats.mean, stats.std_dev());
//! ```
//!
//! ## ğŸ—ï¸ Architecture Overview
//!
//! The library is organized into several key modules:
//!
//! - [`tensor`]: Core tensor operations with parallel and GPU acceleration
//! - [`nn`]: Neural network layers and building blocks
//!   - [`nn::safe_ops`]: Safe tensor operations with error handling and ReLU activation
//!   - [`nn::conv_base`]: Shared base traits for convolution and pooling layers
//! - [`autograd`]: Automatic differentiation system
//! - [`vision`]: Computer vision utilities including transforms and datasets
//! - [`optim`]: Optimization algorithms (SGD, Adam, etc.)
//! - [`gpu`]: GPU acceleration support (CUDA, Metal, OpenCL)
//! - [`simd`]: SIMD vectorized operations
//! - `wasm`: WebAssembly bindings for browser deployment
//! - [`memory`]: Advanced memory management and pooling
//! - [`data`]: Data loading and processing utilities
//!
//! ## ğŸ”„ Parallel Operations
//!
//! RusTorch provides a unified trait-based system for parallel tensor operations:
//!
//! ```rust
//! use rustorch::tensor::{Tensor, parallel_traits::*};
//!
//! let tensor1 = Tensor::<f32>::ones(&[4, 4]);  // 2D matrices for simplicity
//! let tensor2 = Tensor::<f32>::ones(&[4, 4]);
//!
//! // Basic tensor operations
//! let result = &tensor1 + &tensor2; // Element-wise addition
//!
//! // Matrix multiplication
//! let matmul_result = tensor1.matmul(&tensor2);
//!
//! // Basic reduction operations
//! let sum = tensor1.sum();
//! # assert_eq!(result.shape(), &[4, 4]);
//! # assert_eq!(matmul_result.unwrap().shape(), &[4, 4]);
//! ```
//!
//! ## ğŸ® GPU Integration
//!
//! Seamless GPU acceleration with automatic device selection:
//!
//! ```no_run
//! use rustorch::tensor::Tensor;
//!
//! let tensor1 = Tensor::<f32>::ones(&[4, 4]);
//! let tensor2 = Tensor::<f32>::ones(&[4, 4]);
//!
//! // GPU-accelerated operations (when available)
//! let result = &tensor1 + &tensor2;  // Basic tensor operations
//! ```
//!
//! ## ğŸ’¾ Memory Optimization
//!
//! Advanced memory management for optimal performance:
//!
//! ```rust
//! use rustorch::tensor::Tensor;
//!
//! let tensor = Tensor::<f32>::ones(&[4, 4]);
//!
//! // Basic tensor operations
//! let result = &tensor * &tensor; // Element-wise multiplication
//! # assert_eq!(result.shape(), &[4, 4]);
//! ```
//!
//! ## ğŸŒ WebAssembly Integration
//!
//! Run neural networks directly in browsers with optimized WASM bindings:
//!
//! ```javascript
//! // Browser usage (JavaScript)
//! import init, * as rustorch from './pkg/rustorch.js';
//!
//! await init();
//!
//! // Create and manipulate tensors
//! const tensor1 = rustorch.WasmTensor.ones([2, 3]);
//! const tensor2 = rustorch.WasmTensor.random([2, 3]);
//! const sum = tensor1.add(tensor2);
//!
//! // Neural network inference
//! const model = new rustorch.WasmModel();
//! model.add_linear(10, 5, true);
//! model.add_relu();
//!
//! const input = rustorch.WasmTensor.random([1, 10]);
//! const output = model.forward(input);
//!
//! console.log('Output:', output.data());
//! ```

#![warn(missing_docs)]
#![warn(rustdoc::missing_crate_level_docs)]

/// Unified error handling system
/// çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 
pub mod error;

/// Automatic Mixed Precision (AMP) training support
/// è‡ªå‹•æ··åˆç²¾åº¦(AMP)å­¦ç¿’ã‚µãƒãƒ¼ãƒˆ
pub mod amp;
/// Automatic differentiation module
/// è‡ªå‹•å¾®åˆ†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
pub mod autograd;
/// Unified compute backend abstraction layer  
/// çµ±ä¸€è¨ˆç®—ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æŠ½è±¡åŒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼
pub mod backends;
/// Common utilities and shared functionality
/// å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã¨å…±æœ‰æ©Ÿèƒ½
pub mod common;
/// PyTorch to RusTorch conversion system
/// PyTorchã‹ã‚‰RusTorchå¤‰æ›ã‚·ã‚¹ãƒ†ãƒ 
pub mod convert;
/// Data loading and processing utilities
/// ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å‡¦ç†ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
pub mod data;
/// Distributed training support for multi-GPU and multi-machine training
/// ãƒãƒ«ãƒGPUãŠã‚ˆã³ãƒãƒ«ãƒãƒã‚·ãƒ³å­¦ç¿’ç”¨åˆ†æ•£å­¦ç¿’ã‚µãƒãƒ¼ãƒˆ
#[cfg(not(target_arch = "wasm32"))]
pub mod distributed;
/// Statistical distributions module providing PyTorch-compatible probability distributions
/// PyTorchäº’æ›ã®ç¢ºç‡åˆ†å¸ƒã‚’æä¾›ã™ã‚‹çµ±è¨ˆåˆ†å¸ƒãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
pub mod distributions;
/// Data types for tensors
/// ãƒ†ãƒ³ã‚½ãƒ«ç”¨ãƒ‡ãƒ¼ã‚¿å‹
pub mod dtype;
/// Model format support and conversion utilities
/// ãƒ¢ãƒ‡ãƒ«å½¢å¼ã‚µãƒãƒ¼ãƒˆã¨å¤‰æ›ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
pub mod formats;
/// GPU acceleration support (CUDA, Metal, OpenCL)
/// GPUåŠ é€Ÿã‚µãƒãƒ¼ãƒˆï¼ˆCUDAã€Metalã€OpenCLï¼‰
#[cfg(not(target_arch = "wasm32"))]
pub mod gpu;
/// Memory management and pooling utilities
/// ãƒ¡ãƒ¢ãƒªç®¡ç†ã¨ãƒ—ãƒ¼ãƒªãƒ³ã‚°ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
#[cfg(not(target_arch = "wasm32"))]
pub mod memory;
/// Model import functionality for PyTorch and ONNX models
/// PyTorchã¨ONNXãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ©Ÿèƒ½
pub mod model_import;
/// Pre-built models and architectures
/// äº‹å‰æ§‹ç¯‰ãƒ¢ãƒ‡ãƒ«ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
pub mod models;
/// Neural network layers and building blocks
/// ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨æ§‹æˆè¦ç´ 
pub mod nn;
/// Optimization algorithms
/// æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
pub mod optim;
/// Parallel processing utilities
/// ä¸¦åˆ—å‡¦ç†ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
pub mod parallel;
/// Performance profiler
/// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼
pub mod profiler;
/// SIMD vectorized operations for performance optimization
/// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã®ãŸã‚ã®SIMDãƒ™ã‚¯ãƒˆãƒ«åŒ–æ“ä½œ
#[cfg(not(target_arch = "wasm32"))]
pub mod simd;
/// Special mathematical functions (gamma, Bessel, error functions)
/// ç‰¹æ®Šæ•°å­¦é–¢æ•°ï¼ˆã‚¬ãƒ³ãƒã€ãƒ™ãƒƒã‚»ãƒ«ã€èª¤å·®é–¢æ•°ï¼‰
pub mod special;
/// Tensor operations and data structures
/// ãƒ†ãƒ³ã‚½ãƒ«æ“ä½œã¨ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
pub mod tensor;
/// TensorBoard integration
/// TensorBoardçµ±åˆ
pub mod tensorboard;
/// Testing utilities and helpers
/// ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã¨ãƒ˜ãƒ«ãƒ‘ãƒ¼
#[cfg(test)]
pub mod test_utils;
/// Training loop abstractions and utilities
/// å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã®æŠ½è±¡åŒ–ã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
pub mod training;
/// Utility functions
/// ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
pub mod utils;
/// Computer vision module providing image transforms, data augmentation, and built-in datasets
/// ç”»åƒå¤‰æ›ã€ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã€çµ„ã¿è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æä¾›ã™ã‚‹ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
pub mod vision;
/// Visualization tools for plots, graphs, and data analysis
/// ãƒ—ãƒ­ãƒƒãƒˆã€ã‚°ãƒ©ãƒ•ã€ãƒ‡ãƒ¼ã‚¿è§£æç”¨ã®å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«
pub mod visualization;

/// WebAssembly support and bindings
/// WebAssemblyã‚µãƒãƒ¼ãƒˆã¨ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°
#[cfg(feature = "wasm")]
pub mod wasm;

/// Simple WebAssembly support for basic operations
/// åŸºæœ¬æ“ä½œã®ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ãªWebAssemblyã‚µãƒãƒ¼ãƒˆ
// Removed redundant wasm_simple module - functionality integrated into wasm module

/// Re-exports of commonly used items
pub mod prelude {
    pub use crate::autograd::Variable;
    pub use crate::convert::{LayerInfo, LayerType, ModelGraph, ModelParser};
    pub use crate::convert::{
        SimpleConversionError, SimplePyTorchConverter, SimplifiedPyTorchModel,
    };
    pub use crate::data::{DataLoader, Dataset, TensorDataset};
    pub use crate::distributions::{
        Bernoulli, Beta, Categorical, Exponential, Gamma, Normal, Uniform,
    };
    pub use crate::distributions::{Distribution, DistributionError, DistributionTrait};
    pub use crate::models::{BERTBuilder, TransformerModel, TransformerModelBuilder, BERT};
    pub use crate::models::{
        CNNBuilder, Model, ModelBuilder, ModelMode, ResNet, ResNetBuilder, CNN,
    };
    pub use crate::models::{InferenceEngine, Metrics, Trainer, TrainingConfig, TrainingResult};
    pub use crate::models::{LSTMModel, LSTMModelBuilder, RNNModel, RNNModelBuilder};
    pub use crate::models::{ModelLoader, ModelSaver, SerializationFormat};
    pub use crate::nn::activation::{
        elu, gelu, hardswish, leaky_relu, mish, relu, selu, sigmoid, softmax, swish, tanh,
    };
    pub use crate::nn::loss::{
        binary_cross_entropy, cross_entropy, huber_loss, mse_loss, nll_loss,
    };
    pub use crate::nn::{
        dropout, AlphaDropout, AvgPool2d, BatchNorm1d, BatchNorm2d, Conv2d, Dropout, GRUCell,
        LSTMCell, Linear, MaxPool2d, Module, RNNCell, GRU, LSTM, RNN,
    };
    pub use crate::optim::{AdaGrad, Adam, Optimizer, RMSprop, SGD};
    pub use crate::special::SpecialFunctions;
    pub use crate::special::{bessel_i, bessel_j, bessel_k, bessel_y};
    pub use crate::special::{beta, digamma, gamma, lbeta, lgamma};
    pub use crate::special::{erf, erfc, erfcinv, erfinv};
    pub use crate::tensor::Tensor;
    pub use crate::vision::{
        datasets::*, pipeline::*, presets::*, transforms::*, Image, ImageFormat,
    };
    pub use crate::visualization::{ChartType, ColorMap, PlotConfig, PlotStyle, TensorPlotConfig};
    pub use crate::visualization::{GraphVisualizer, TensorVisualizer, TrainingPlotter};
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_tensor_creation() {
        let t = tensor::Tensor::from_vec(vec![1.0, 2.0, 3.0], vec![3]);
        assert_eq!(t.size(), vec![3]);
    }
}
