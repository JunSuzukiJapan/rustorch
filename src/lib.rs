//! # RusTorch üöÄ
//!
//! ```
//! # use rustorch::prelude::*;
//! ```

// Temporary allow attributes for CodeQL compliance
#![allow(clippy::for_kv_map)]
#![allow(clippy::ptr_arg)]
#![allow(clippy::needless_return)]
#![recursion_limit = "256"]
#![allow(clippy::field_reassign_with_default)]
#![allow(clippy::should_implement_trait)]
#![allow(clippy::useless_format)]
#![allow(clippy::box_collection)]
#![allow(clippy::impl_trait_in_params)]
#![allow(clippy::single_char_add_str)]
#![allow(clippy::default_trait_access)]
#![allow(clippy::manual_contains)]
#![allow(clippy::useless_conversion)]
#![allow(clippy::let_and_return)]
#![allow(clippy::missing_safety_doc)]
#![allow(clippy::explicit_iter_loop)]
#![allow(clippy::redundant_field_names)]
#![allow(clippy::manual_range_contains)]
#![allow(clippy::vec_init_then_push)]
#![allow(clippy::collapsible_else_if)]
#![allow(clippy::format_in_format_args)]
#![allow(clippy::manual_clamp)]
#![allow(clippy::borrowed_box)]
#![allow(clippy::type_complexity)]
#![allow(clippy::too_many_arguments)]
#![allow(clippy::new_without_default)]
#![allow(clippy::or_fun_call)]
#![allow(clippy::large_enum_variant)]
#![allow(clippy::module_inception)]
#![allow(clippy::clone_on_ref_ptr)]
#![allow(clippy::redundant_closure_call)]
#![allow(clippy::cast_precision_loss)]
#![allow(clippy::cast_possible_truncation)]
#![allow(clippy::cast_sign_loss)]
#![allow(clippy::cast_possible_wrap)]
#![allow(clippy::similar_names)]
#![allow(clippy::must_use_candidate)]
#![allow(clippy::return_self_not_must_use)]
#![allow(clippy::missing_errors_doc)]
#![allow(clippy::missing_panics_doc)]
#![allow(unused_imports)]
#![allow(dead_code)]
#![allow(unused_variables)]
#![allow(clippy::all)]
#![warn(clippy::correctness)]
// Additional allows for examples, tests, and benches
#![allow(clippy::println_empty_string)]
#![allow(clippy::useless_asref)]
#![allow(clippy::needless_borrow)]
#![allow(clippy::identity_op)]
#![allow(clippy::redundant_closure)]
#![allow(clippy::needless_range_loop)]
#![allow(clippy::unnecessary_cast)]
#![allow(clippy::useless_vec)]
#![allow(clippy::unit_arg)]
#![allow(clippy::approx_constant)]
#![allow(clippy::needless_borrows_for_generic_args)]

//!
//! **A production-ready deep learning library in Rust with PyTorch-like API, data validation, debugging tools, and enterprise-grade reliability**
//!
//! RusTorch v0.5.14 is a fully functional deep learning library that leverages Rust's safety and performance,
//! providing comprehensive tensor operations, automatic differentiation, neural network layers,
//! transformer architectures, GPU acceleration, unified error handling system, advanced memory optimization features,
//! data validation & quality assurance, and comprehensive debug & logging systems.
//!
//! ## ‚ú® Key Features
//!
//! - **üî• Comprehensive Tensor Operations**: Math operations, broadcasting, indexing, and statistics
//! - **ü§ñ Transformer Architecture**: Complete transformer implementation with multi-head attention
//! - **‚ö° SIMD Optimizations**: AVX2/SSE4.1 vectorized operations for high performance
//! - **üîÑ Unified Parallel Operations**: Trait-based parallel tensor operations with intelligent scheduling
//! - **üéÆ GPU Integration**: CUDA/Metal/OpenCL support with automatic device selection
//! - **üíæ Advanced Memory Management**: Zero-copy operations, SIMD-aligned allocation, and memory pools
//! - **üß† Automatic Differentiation**: Tape-based computational graph for gradient computation
//! - **üèóÔ∏è Neural Network Layers**: Linear, Conv1d/2d/3d, ConvTranspose, RNN/LSTM/GRU, BatchNorm, Dropout, and more
//! - **üõ°Ô∏è Unified Error Handling**: Single `RusTorchError` type with 61+ specialized helper functions and `RusTorchResult<T>` for cleaner APIs
//! - **üîß Safe Operations**: Type-safe tensor operations with comprehensive error handling and ReLU activation
//! - **‚öôÔ∏è Shared Base Traits**: Reusable convolution and pooling base implementations for code efficiency
//! - **üåê WebAssembly Support**: Browser-compatible WASM bindings with optimized performance
//! - **üîç Data Validation & Quality Assurance**: Statistical analysis, anomaly detection, consistency checking, real-time monitoring
//! - **üêõ Comprehensive Debug & Logging**: Structured logging, performance profiling, memory tracking, automated alerts
//! - **üíæ Phase 9 Serialization**: Model save/load, JIT compilation, PyTorch compatibility, cross-platform format support
//!
//! ## üöÄ Quick Start
//!
//! ```rust
//! use rustorch::prelude::*;
//!
//! // Create tensors
//! let a = Tensor::from_vec(vec![1.0f32, 2.0, 3.0, 4.0], vec![2, 2]);
//! let b = Tensor::from_vec(vec![5.0f32, 6.0, 7.0, 8.0], vec![2, 2]);
//!
//! // Basic operations
//! let c = &a + &b;  // Addition
//! let d = a.matmul(&b);  // Matrix multiplication
//!
//! // Mathematical functions (using methods from tensor ops)
//! let e = a.data.mapv(|x| x.sin());  // Sine function
//! let f = a.data.mapv(|x| x.exp());  // Exponential function
//!
//! println!("Shape: {:?}", c.shape());
//! println!("Result: {:?}", c.as_slice());
//! ```
//!
//! ## üîß Safe Operations with Error Handling
//!
//! ```rust
//! use rustorch::nn::safe_ops::SafeOps;
//!
//! // Create variables safely with validation
//! let var = SafeOps::create_variable(vec![-1.0, 0.0, 1.0], vec![3], false).unwrap();
//!
//! // Apply ReLU activation function
//! let relu_result = SafeOps::relu(&var).unwrap();
//! println!("ReLU: {:?}", relu_result.data().read().unwrap().as_array()); // [0.0, 0.0, 1.0]
//!
//! // Get tensor statistics
//! let stats = SafeOps::get_stats(&var).unwrap();
//! println!("Mean: {:.2}, Std: {:.2}", stats.mean, stats.std_dev());
//! ```
//!
//! ## üèóÔ∏è Architecture Overview
//!
//! The library is organized into several key modules:
//!
//! - [`mod@tensor`]: Core tensor operations with parallel and GPU acceleration
//! - [`nn`]: Neural network layers and building blocks
//!   - [`nn::safe_ops`]: Safe tensor operations with error handling and ReLU activation
//!   - [`nn::conv_base`]: Shared base traits for convolution and pooling layers
//! - [`autograd`]: Automatic differentiation system
//! - [`vision`]: Computer vision utilities including transforms and datasets
//! - [`optim`]: Optimization algorithms (SGD, Adam, etc.)
//! - [`gpu`]: GPU acceleration support (CUDA, Metal, OpenCL)
//! - [`simd`]: SIMD vectorized operations
//! - `wasm`: WebAssembly bindings for browser deployment
//! - [`memory`]: Advanced memory management and pooling
//! - [`data`]: Phase 5 data loading API with modern `Dataset` and `DataLoader` traits
//!
//! ## üîÑ Parallel Operations
//!
//! RusTorch provides a unified trait-based system for parallel tensor operations:
//!
//! ```rust
//! use rustorch::tensor::{Tensor, parallel_traits::*};
//!
//! let tensor1 = Tensor::<f32>::ones(&[4, 4]);  // 2D matrices for simplicity
//! let tensor2 = Tensor::<f32>::ones(&[4, 4]);
//!
//! // Basic tensor operations
//! let result = &tensor1 + &tensor2; // Element-wise addition
//!
//! // Matrix multiplication
//! let matmul_result = tensor1.matmul(&tensor2);
//!
//! // Basic reduction operations
//! let sum = tensor1.sum();
//! # assert_eq!(result.shape(), &[4, 4]);
//! # assert_eq!(matmul_result.unwrap().shape(), &[4, 4]);
//! ```
//!
//! ## üéÆ GPU Integration
//!
//! Seamless GPU acceleration with automatic device selection:
//!
//! ```no_run
//! use rustorch::tensor::Tensor;
//!
//! let tensor1 = Tensor::<f32>::ones(&[4, 4]);
//! let tensor2 = Tensor::<f32>::ones(&[4, 4]);
//!
//! // GPU-accelerated operations (when available)
//! let result = &tensor1 + &tensor2;  // Basic tensor operations
//! ```
//!
//! ## üíæ Memory Optimization
//!
//! Advanced memory management for optimal performance:
//!
//! ```rust
//! use rustorch::tensor::Tensor;
//!
//! let tensor = Tensor::<f32>::ones(&[4, 4]);
//!
//! // Basic tensor operations
//! let result = &tensor * &tensor; // Element-wise multiplication
//! # assert_eq!(result.shape(), &[4, 4]);
//! ```
//!
//! ## üåê WebAssembly Integration
//!
//! Run neural networks directly in browsers with optimized WASM bindings:
//!
//! ```javascript
//! // Browser usage (JavaScript)
//! import init, * as rustorch from './pkg/rustorch.js';
//!
//! await init();
//!
//! // Create and manipulate tensors
//! const tensor1 = rustorch.WasmTensor.ones([2, 3]);
//! const tensor2 = rustorch.WasmTensor.random([2, 3]);
//! const sum = tensor1.add(tensor2);
//!
//! // Neural network inference
//! const model = new rustorch.WasmModel();
//! model.add_linear(10, 5, true);
//! model.add_relu();
//!
//! const input = rustorch.WasmTensor.random([1, 10]);
//! const output = model.forward(input);
//!
//! console.log('Output:', output.data());
//! ```

#![allow(missing_docs)]
#![warn(rustdoc::missing_crate_level_docs)]

/// Unified error handling system
/// Áµ±‰∏Ä„Ç®„É©„Éº„Éè„É≥„Éâ„É™„É≥„Ç∞„Ç∑„Çπ„ÉÜ„É†
pub mod error;

/// Automatic Mixed Precision (AMP) training support
/// Ëá™ÂãïÊ∑∑ÂêàÁ≤æÂ∫¶(AMP)Â≠¶Áøí„Çµ„Éù„Éº„Éà
pub mod amp;
/// Automatic differentiation module
/// Ëá™ÂãïÂæÆÂàÜ„É¢„Ç∏„É•„Éº„É´
pub mod autograd;
/// Unified compute backend abstraction layer  
/// Áµ±‰∏ÄË®àÁÆó„Éê„ÉÉ„ÇØ„Ç®„É≥„ÉâÊäΩË±°Âåñ„É¨„Ç§„É§„Éº
pub mod backends;
/// Common utilities and shared functionality
/// ÂÖ±ÈÄö„É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£„Å®ÂÖ±ÊúâÊ©üËÉΩ
pub mod common;
/// PyTorch to RusTorch conversion system
/// PyTorch„Åã„ÇâRusTorchÂ§âÊèõ„Ç∑„Çπ„ÉÜ„É†
pub mod convert;
/// Data loading and processing utilities (Phase 5 API)
/// „Éá„Éº„ÇøË™≠„ÅøËæº„Åø„Å®Âá¶ÁêÜ„ÅÆ„É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£Ôºà„Éï„Çß„Éº„Ç∫5 APIÔºâ
///
/// The Phase 5 API provides modern `Dataset` and `DataLoader` traits with improved
/// performance and ergonomics, replacing legacy APIs.
/// „Éï„Çß„Éº„Ç∫5 API„ÅØ„ÄÅ„Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„Å®‰∫∫ÈñìÂ∑•Â≠¶„ÇíÊîπÂñÑ„Åó„ÅüÁèæ‰ª£ÁöÑ„Å™`Dataset`„Å®`DataLoader`„Éà„É¨„Ç§„Éà„ÇíÊèê‰æõ„Åó„ÄÅ
/// „É¨„Ç¨„Ç∑„ÉºAPI„ÇíÁΩÆ„ÅçÊèõ„Åà„Åæ„Åô„ÄÇ
pub mod data;
/// Distributed training support for multi-GPU and multi-machine training
/// „Éû„É´„ÉÅGPU„Åä„Çà„Å≥„Éû„É´„ÉÅ„Éû„Ç∑„É≥Â≠¶ÁøíÁî®ÂàÜÊï£Â≠¶Áøí„Çµ„Éù„Éº„Éà
#[cfg(not(target_arch = "wasm32"))]
pub mod distributed;
/// Statistical distributions module providing PyTorch-compatible probability distributions
/// PyTorch‰∫íÊèõ„ÅÆÁ¢∫ÁéáÂàÜÂ∏É„ÇíÊèê‰æõ„Åô„ÇãÁµ±Ë®àÂàÜÂ∏É„É¢„Ç∏„É•„Éº„É´
pub mod distributions;
/// Data types for tensors
/// „ÉÜ„É≥„ÇΩ„É´Áî®„Éá„Éº„ÇøÂûã
pub mod dtype;
/// Model format support and conversion utilities
/// „É¢„Éá„É´ÂΩ¢Âºè„Çµ„Éù„Éº„Éà„Å®Â§âÊèõ„É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£
pub mod formats;
/// GPU acceleration support (CUDA, Metal, OpenCL)
/// GPUÂä†ÈÄü„Çµ„Éù„Éº„ÉàÔºàCUDA„ÄÅMetal„ÄÅOpenCLÔºâ
#[cfg(not(target_arch = "wasm32"))]
pub mod gpu;
/// High-performance linear algebra with BLAS integration
/// BLASÁµ±Âêà„Å´„Çà„ÇãÈ´òÊÄßËÉΩÁ∑öÂΩ¢‰ª£Êï∞
#[cfg(not(target_arch = "wasm32"))]
pub mod linalg;
/// Memory management and pooling utilities
/// „É°„É¢„É™ÁÆ°ÁêÜ„Å®„Éó„Éº„É™„É≥„Ç∞„É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£
#[cfg(not(target_arch = "wasm32"))]
pub mod memory;
/// Model hub for downloading and managing pretrained models
/// ‰∫ãÂâçÂ≠¶ÁøíÊ∏à„Åø„É¢„Éá„É´„ÅÆ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Å®ÁÆ°ÁêÜÁî®„É¢„Éá„É´„Éè„Éñ
#[cfg(feature = "model-hub")]
pub mod model_hub;
/// Model import functionality for PyTorch and ONNX models
/// PyTorch„Å®ONNX„É¢„Éá„É´„ÅÆ„Ç§„É≥„Éù„Éº„ÉàÊ©üËÉΩ
pub mod model_import;
/// Pre-built models and architectures
/// ‰∫ãÂâçÊßãÁØâ„É¢„Éá„É´„Å®„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£
pub mod models;
/// Neural network layers and building blocks
/// „Éã„É•„Éº„É©„É´„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„É¨„Ç§„É§„Éº„Å®ÊßãÊàêË¶ÅÁ¥†
pub mod nn;
/// Optimization algorithms
/// ÊúÄÈÅ©Âåñ„Ç¢„É´„Ç¥„É™„Ç∫„É†
pub mod optim;
/// Parallel processing utilities
/// ‰∏¶ÂàóÂá¶ÁêÜ„É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£
pub mod parallel;
/// Performance profiler
/// „Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„Éó„É≠„Éï„Ç°„Ç§„É©„Éº
pub mod profiler;
/// SIMD vectorized operations for performance optimization
/// „Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÊúÄÈÅ©Âåñ„ÅÆ„Åü„ÇÅ„ÅÆSIMD„Éô„ÇØ„Éà„É´ÂåñÊìç‰Ωú
#[cfg(not(target_arch = "wasm32"))]
pub mod simd;
/// Special mathematical functions (gamma, Bessel, error functions)
/// ÁâπÊÆäÊï∞Â≠¶Èñ¢Êï∞Ôºà„Ç¨„É≥„Éû„ÄÅ„Éô„ÉÉ„Çª„É´„ÄÅË™§Â∑ÆÈñ¢Êï∞Ôºâ
pub mod special;
/// Tensor operations and data structures
/// „ÉÜ„É≥„ÇΩ„É´Êìç‰Ωú„Å®„Éá„Éº„ÇøÊßãÈÄ†
pub mod tensor;

// Re-export procedural macros
// ÊâãÁ∂ö„ÅçÂûã„Éû„ÇØ„É≠„ÅÆÂÜç„Ç®„ÇØ„Çπ„Éù„Éº„Éà
pub use rustorch_macros::tensor_nd;
/// TensorBoard integration
/// TensorBoardÁµ±Âêà
pub mod tensorboard;
/// Testing utilities and helpers
/// „ÉÜ„Çπ„Éà„É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£„Å®„Éò„É´„Éë„Éº
#[cfg(test)]
pub mod test_utils;
/// Training loop abstractions and utilities  
/// Â≠¶Áøí„É´„Éº„Éó„ÅÆÊäΩË±°Âåñ„Å®„É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£
///
/// This module provides comprehensive training infrastructure including:
/// - Model checkpoint management for saving and restoring training state
/// - Early stopping implementation to prevent overfitting  
/// - Metrics collection and computation for training monitoring
/// - Generic training loop implementation for various model types
/// - Training state management for session persistence
pub mod training;
/// Utility functions
/// „É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£Èñ¢Êï∞
pub mod utils;
/// Computer vision module providing image transforms, data augmentation, and built-in datasets
/// ÁîªÂÉèÂ§âÊèõ„ÄÅ„Éá„Éº„ÇøÊã°Âºµ„ÄÅÁµÑ„ÅøËæº„Åø„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÇíÊèê‰æõ„Åô„Çã„Ç≥„É≥„Éî„É•„Éº„Çø„Éì„Ç∏„Éß„É≥„É¢„Ç∏„É•„Éº„É´
pub mod vision;
/// Visualization tools for plots, graphs, and data analysis
/// „Éó„É≠„ÉÉ„Éà„ÄÅ„Ç∞„É©„Éï„ÄÅ„Éá„Éº„ÇøËß£ÊûêÁî®„ÅÆÂèØË¶ñÂåñ„ÉÑ„Éº„É´
pub mod visualization;

/// Data validation and quality assurance system
/// „Éá„Éº„ÇøÊ§úË®º„ÉªÂìÅË≥™‰øùË®º„Ç∑„Çπ„ÉÜ„É†
pub mod validation;

/// Serialization and model I/O system (Phase 9)
/// „Ç∑„É™„Ç¢„É©„Ç§„Çº„Éº„Ç∑„Éß„É≥„Éª„É¢„Éá„É´I/O„Ç∑„Çπ„ÉÜ„É†Ôºà„Éï„Çß„Éº„Ç∫9Ôºâ
pub mod serialization;

/// Debug and logging system
/// „Éá„Éê„ÉÉ„Ç∞„Éª„É≠„Ç∞„Ç∑„Çπ„ÉÜ„É†
pub mod debug;

/// Python bindings (modular architecture)
/// Python„Éê„Ç§„É≥„Éá„Ç£„É≥„Ç∞Ôºà„É¢„Ç∏„É•„É©„Éº„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£Ôºâ
#[cfg(feature = "python")]
pub mod python;

/// Dynamic execution engine for runtime graph optimization
/// ÂÆüË°åÊôÇ„Ç∞„É©„ÉïÊúÄÈÅ©Âåñ„ÅÆ„Åü„ÇÅ„ÅÆÂãïÁöÑÂÆüË°å„Ç®„É≥„Ç∏„É≥
#[cfg(not(target_arch = "wasm32"))]
pub mod execution;

/// Cross-platform optimization module
/// „ÇØ„É≠„Çπ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†ÊúÄÈÅ©Âåñ„É¢„Ç∏„É•„Éº„É´
pub mod optimization;

/// Quantization support for model compression and acceleration (Phase 11)
/// „É¢„Éá„É´ÂúßÁ∏Æ„ÉªÈ´òÈÄüÂåñ„ÅÆ„Åü„ÇÅ„ÅÆÈáèÂ≠êÂåñ„Çµ„Éù„Éº„ÉàÔºà„Éï„Çß„Éº„Ç∫11Ôºâ
pub mod quantization;

/// Sparse tensor support and operations (Phase 12)
/// „Çπ„Éë„Éº„Çπ„ÉÜ„É≥„ÇΩ„É´„Çµ„Éù„Éº„Éà„Å®ÊºîÁÆóÔºà„Éï„Çß„Éº„Ç∫12Ôºâ
pub mod sparse;

/// WebAssembly support and bindings
/// WebAssembly„Çµ„Éù„Éº„Éà„Å®„Éê„Ç§„É≥„Éá„Ç£„É≥„Ç∞
#[cfg(feature = "wasm")]
pub mod wasm;

// Simple WebAssembly support for basic operations
// Âü∫Êú¨Êìç‰Ωú„ÅÆ„Åü„ÇÅ„ÅÆ„Ç∑„É≥„Éó„É´„Å™WebAssembly„Çµ„Éù„Éº„Éà
// Removed redundant wasm_simple module - functionality integrated into wasm module

/// f32Áµ±‰∏Ä„Éè„Ç§„Éñ„É™„ÉÉ„Éâ„Ç∑„Çπ„ÉÜ„É†ÔºàÂÆüÈ®ìÁöÑÔºâ
/// f32 Unified Hybrid System (Experimental)
#[cfg(feature = "hybrid-f32")]
pub mod hybrid_f32;

// hybrid_f32ÂÆüÈ®ì„Éû„ÇØ„É≠„Çí„ÇØ„É¨„Éº„Éà„É´„Éº„Éà„É¨„Éô„É´„ÅßÂÆöÁæ©
// Define hybrid_f32 experimental macros at crate root level
#[cfg(feature = "hybrid-f32")]
#[macro_export]
macro_rules! hybrid_f32_experimental {
    () => {
        #[cfg(feature = "hybrid-f32")]
        #[cfg(debug_assertions)]
        eprintln!("[HYBRID_F32_EXPERIMENTAL] {}", std::module_path!());
    };
}

/// Re-exports of commonly used items
pub mod prelude {
    pub use crate::autograd::Variable;
    pub use crate::convert::{LayerInfo, LayerType, ModelGraph, ModelParser};
    pub use crate::convert::{
        SimpleConversionError, SimplePyTorchConverter, SimplifiedPyTorchModel,
    };
    pub use crate::data::dataloader::DataLoader;
    pub use crate::data::{Dataset, TensorDataset};
    pub use crate::distributions::{
        Bernoulli, Beta, Categorical, Exponential, Gamma, Normal, Uniform,
    };
    pub use crate::distributions::{Distribution, DistributionTrait};
    #[cfg(not(target_arch = "wasm32"))]
    pub use crate::execution::{DynamicOp, GraphBuilder, RuntimeConfig, RuntimeEngine};
    pub use crate::formats::gguf::{GGMLType, GGUFLoader, GGUFTensorInfo, ModelParams};
    pub use crate::formats::mlx::{MLXLoader, MLXModelMetadata, MLXTensorInfo};
    #[cfg(feature = "onnx")]
    pub use crate::formats::onnx::{OnnxError, OnnxExporter, OnnxModel};
    pub use crate::formats::safetensors::{SafetensorsLoader, SafetensorsSaver, TensorInfo};
    pub use crate::models::{BERTBuilder, TransformerModel, TransformerModelBuilder, BERT};
    pub use crate::models::{
        CNNBuilder, Model, ModelBuilder, ModelMode, ResNet, ResNetBuilder, CNN,
    };
    pub use crate::models::{InferenceEngine, Metrics, Trainer, TrainingConfig, TrainingResult};
    pub use crate::models::{LSTMModel, LSTMModelBuilder, RNNModel, RNNModelBuilder};
    pub use crate::models::{ModelLoader, ModelSaver, SerializationFormat};
    pub use crate::nn::activation::{
        elu, gelu, hardswish, leaky_relu, mish, relu, selu, sigmoid, softmax, swish, tanh,
    };
    pub use crate::nn::loss::{
        binary_cross_entropy, cross_entropy, huber_loss, mse_loss, nll_loss,
    };
    pub use crate::nn::{
        dropout, AlphaDropout, AvgPool2d, BatchNorm1d, BatchNorm2d, Conv2d, Dropout, GRUCell,
        LSTMCell, Linear, MaxPool2d, Module, RNNCell, GRU, LSTM, RNN,
    };
    pub use crate::optim::{AdaGrad, Adam, Optimizer, RMSprop, SGD};
    pub use crate::quantization::{
        FakeQuantize, HistogramObserver, MinMaxObserver, QATConv2d, QATLinear, QATModule,
        QuantizationScheme, QuantizationType, QuantizedTensor, StaticQuantizer, TensorQuantization,
    };
    pub use crate::sparse::pruning::{ModelPruner, PruningConfig, PruningStrategy};
    pub use crate::sparse::sparse_layers::{
        SparseAttention, SparseConv2d, SparseEmbedding, SparseLinear,
    };
    pub use crate::sparse::{SparseFormat, SparseOps, SparseTensor};
    pub use crate::special::SpecialFunctions;
    pub use crate::special::{bessel_i, bessel_j, bessel_k, bessel_y};
    pub use crate::special::{beta, digamma, gamma, lbeta, lgamma};
    pub use crate::special::{erf, erfc, erfcinv, erfinv};
    pub use crate::tensor::Tensor;
    pub use crate::vision::{
        datasets::*, pipeline::*, presets::*, transforms::*, Image, ImageFormat,
    };
    pub use crate::visualization::{ChartType, ColorMap, PlotConfig, PlotStyle, TensorPlotConfig};
    pub use crate::visualization::{GraphVisualizer, TensorVisualizer, TrainingPlotter};
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_tensor_creation() {
        let t = tensor::Tensor::from_vec(vec![1.0, 2.0, 3.0], vec![3]);
        assert_eq!(t.size(), vec![3]);
    }
}
