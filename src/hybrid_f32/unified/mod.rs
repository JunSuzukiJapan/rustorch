//! f32Áµ±‰∏Ä„Éè„Ç§„Éñ„É™„ÉÉ„ÉâÂÆüË°å„Ç∑„Çπ„ÉÜ„É†
//! f32 Unified Hybrid Execution System

#[cfg(target_os = "macos")]
use crate::hybrid_f32::gpu::{
    F32CoreMLExecutor, F32MetalExecutor, F32UnifiedGPUContext, GPUDevice,
};

use crate::error::RusTorchResult;
#[cfg(not(target_os = "macos"))]
use crate::hybrid_f32::gpu::{F32UnifiedGPUContext, GPUDevice};
use crate::hybrid_f32::tensor::core::F32Tensor;
use crate::hybrid_f32::ExperimentResults;
use std::time::Instant;

/// f32Áµ±‰∏Ä„Éè„Ç§„Éñ„É™„ÉÉ„ÉâÂÆüË°å„Ç®„É≥„Ç∏„É≥
/// f32 Unified Hybrid Execution Engine
#[derive(Debug)]
pub struct F32HybridExecutor {
    gpu_context: F32UnifiedGPUContext,
    device_selector: F32DeviceSelector,
    performance_monitor: PerformanceMonitor,
}

impl F32HybridExecutor {
    /// Êñ∞„Åó„ÅÑ„Éè„Ç§„Éñ„É™„ÉÉ„ÉâÂÆüË°å„Ç®„É≥„Ç∏„É≥„Çí‰ΩúÊàê
    /// Create new hybrid execution engine
    pub fn new() -> RusTorchResult<Self> {
        crate::hybrid_f32_experimental!();

        let gpu_context = F32UnifiedGPUContext::new();
        let device_selector = F32DeviceSelector::new();
        let performance_monitor = PerformanceMonitor::new();

        println!("üöÄ F32 Unified Hybrid Executor initialized");
        println!("  üîç Detecting available devices...");

        Ok(Self {
            gpu_context,
            device_selector,
            performance_monitor,
        })
    }

    /// „Ç∑„Çπ„ÉÜ„É†ÂàùÊúüÂåñ
    /// Initialize system
    pub fn initialize(&mut self) -> RusTorchResult<()> {
        let available_devices = self.gpu_context.detect_available_devices();

        println!("üìä Available devices:");
        for (device, info) in &available_devices {
            println!(
                "  {:?}: {} ({:.1} TFLOPS f32)",
                device, info.device_name, info.estimated_tflops_f32
            );
        }

        self.device_selector
            .update_device_capabilities(available_devices);

        println!("‚úÖ F32 Hybrid system initialized successfully");
        Ok(())
    }

    /// Áµ±‰∏ÄÂÆüË°åÔºàÂ§âÊèõ„Ç≥„Çπ„Éà„Å™„ÅóÔºâ
    /// Unified execution (no conversion cost)
    pub fn execute_matmul(
        &mut self,
        a: &F32Tensor,
        b: &F32Tensor,
    ) -> RusTorchResult<(F32Tensor, ExperimentResults)> {
        crate::hybrid_f32_experimental!();

        let start_time = Instant::now();

        // ÊúÄÈÅ©„Éá„Éê„Ç§„ÇπÈÅ∏Êäû
        let operation = F32Operation::MatMul {
            size_a: a.shape().to_vec(),
            size_b: b.shape().to_vec(),
        };
        let optimal_device = self.device_selector.select_optimal_device(&operation)?;

        println!("üéØ Selected device: {:?}", optimal_device);

        // „Éá„Éê„Ç§„ÇπÂàùÊúüÂåñÔºàÂøÖË¶Å„Å´Âøú„Åò„Å¶Ôºâ
        self.gpu_context.initialize_device(optimal_device.clone())?;

        // Áµ±‰∏ÄÂÆüË°å
        let result = match optimal_device {
            GPUDevice::Metal(device_id) => {
                println!("‚ö° Executing on Metal GPU {} (f32 direct)", device_id);
                self.execute_metal_f32(a, b)?
            }
            GPUDevice::CoreML(device_id) => {
                println!("üß† Executing on Neural Engine {} (f32 direct)", device_id);
                self.execute_coreml_f32(a, b)?
            }
            GPUDevice::CPU => {
                println!("üíª Executing on CPU (f32 direct)");
                self.execute_cpu_f32(a, b)?
            }
        };

        let execution_time = start_time.elapsed();

        // ÂÆüÈ®ìÁµêÊûú„ÇíË®òÈå≤
        let mut experiment_results = ExperimentResults::new();
        experiment_results.total_execution_time = execution_time;
        experiment_results.conversion_cost_reduction = 100.0; // Â§âÊèõ„Ç≥„Çπ„ÉàÂÆåÂÖ®ÂâäÈô§

        self.performance_monitor
            .record_execution(&operation, execution_time, &optimal_device);

        println!("‚úÖ Execution completed in {:?}", execution_time);
        println!("üìä Conversion cost reduction: 100% (zero conversion overhead)");

        Ok((result, experiment_results))
    }

    /// Metal f32ÂÆüË°å
    /// Metal f32 execution
    fn execute_metal_f32(&self, a: &F32Tensor, b: &F32Tensor) -> RusTorchResult<F32Tensor> {
        self.gpu_context.execute_matmul(a, b)
    }

    /// CoreML f32ÂÆüË°å
    /// CoreML f32 execution
    fn execute_coreml_f32(&self, a: &F32Tensor, b: &F32Tensor) -> RusTorchResult<F32Tensor> {
        self.gpu_context.execute_matmul(a, b)
    }

    /// CPU f32ÂÆüË°å
    /// CPU f32 execution
    fn execute_cpu_f32(&self, a: &F32Tensor, b: &F32Tensor) -> RusTorchResult<F32Tensor> {
        a.matmul(b)
    }

    /// „Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÁµ±Ë®à„ÇíÂèñÂæó
    /// Get performance statistics
    pub fn get_performance_stats(&self) -> PerformanceStats {
        self.performance_monitor.get_stats()
    }
}

/// f32Â∞ÇÁî®„Éá„Éê„Ç§„ÇπÈÅ∏ÊäûÂô®
/// f32-specific device selector
#[derive(Debug)]
pub struct F32DeviceSelector {
    device_capabilities: Vec<(GPUDevice, super::gpu::DevicePerformanceInfo)>,
    selection_strategy: SelectionStrategy,
}

#[derive(Debug, Clone)]
pub enum SelectionStrategy {
    Performance,     // ÊúÄÈ´òÊÄßËÉΩÂÑ™ÂÖà
    PowerEfficiency, // ÈõªÂäõÂäπÁéáÂÑ™ÂÖà
    Adaptive,        // ÈÅ©ÂøúÁöÑÈÅ∏Êäû
}

impl F32DeviceSelector {
    pub fn new() -> Self {
        Self {
            device_capabilities: Vec::new(),
            selection_strategy: SelectionStrategy::Adaptive,
        }
    }

    pub fn update_device_capabilities(
        &mut self,
        capabilities: Vec<(GPUDevice, super::gpu::DevicePerformanceInfo)>,
    ) {
        self.device_capabilities = capabilities;
    }

    /// ÊúÄÈÅ©„Éá„Éê„Ç§„ÇπÈÅ∏ÊäûÔºàf32Â∞ÇÁî®Ôºâ
    /// Select optimal device (f32-specific)
    pub fn select_optimal_device(&self, operation: &F32Operation) -> RusTorchResult<GPUDevice> {
        match operation {
            F32Operation::MatMul { size_a, size_b } => {
                let total_elements =
                    size_a.iter().product::<usize>() + size_b.iter().product::<usize>();

                match total_elements {
                    // Â§ßË¶èÊ®°Á∑öÂΩ¢‰ª£Êï∞ ‚Üí Metal GPU
                    size if size > 50000 => Ok(GPUDevice::Metal(0)),
                    // ‰∏≠Ë¶èÊ®° ‚Üí Neural EngineÔºàf32„Åß„ÇÇÂäπÁéáÁöÑÔºâ
                    size if size > 1000 => Ok(GPUDevice::CoreML(0)),
                    // Â∞èË¶èÊ®° ‚Üí CPU
                    _ => Ok(GPUDevice::CPU),
                }
            }
            F32Operation::Conv2D { .. } => {
                // Áï≥„ÅøËæº„ÅøÊºîÁÆó„ÅØNeural EngineÂÑ™ÂÖà
                Ok(GPUDevice::CoreML(0))
            }
            F32Operation::Activation { .. } => {
                // Ê¥ªÊÄßÂåñÈñ¢Êï∞„ÅØNeural EngineÊúÄÈÅ©
                Ok(GPUDevice::CoreML(0))
            }
        }
    }
}

/// f32Êìç‰Ωú„Çø„Ç§„Éó
/// f32 operation types
#[derive(Debug, Clone)]
pub enum F32Operation {
    MatMul {
        size_a: Vec<usize>,
        size_b: Vec<usize>,
    },
    Conv2D {
        input_shape: Vec<usize>,
        kernel_shape: Vec<usize>,
    },
    Activation {
        input_shape: Vec<usize>,
    },
}

/// „Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÁõ£Ë¶ñ
/// Performance monitoring
#[derive(Debug)]
pub struct PerformanceMonitor {
    execution_history: Vec<ExecutionRecord>,
    total_operations: usize,
    total_conversion_cost_saved: std::time::Duration,
}

#[derive(Debug, Clone)]
pub struct ExecutionRecord {
    pub operation: String,
    pub device: GPUDevice,
    pub execution_time: std::time::Duration,
    pub timestamp: Instant,
}

#[derive(Debug, Clone)]
pub struct PerformanceStats {
    pub total_operations: usize,
    pub average_execution_time: std::time::Duration,
    pub conversion_cost_savings: std::time::Duration,
    pub device_usage: std::collections::HashMap<String, usize>,
}

impl PerformanceMonitor {
    pub fn new() -> Self {
        Self {
            execution_history: Vec::new(),
            total_operations: 0,
            total_conversion_cost_saved: std::time::Duration::from_secs(0),
        }
    }

    pub fn record_execution(
        &mut self,
        operation: &F32Operation,
        execution_time: std::time::Duration,
        device: &GPUDevice,
    ) {
        let operation_name = match operation {
            F32Operation::MatMul { .. } => "matmul",
            F32Operation::Conv2D { .. } => "conv2d",
            F32Operation::Activation { .. } => "activation",
        };

        let record = ExecutionRecord {
            operation: operation_name.to_string(),
            device: device.clone(),
            execution_time,
            timestamp: Instant::now(),
        };

        self.execution_history.push(record);
        self.total_operations += 1;

        // Êé®ÂÆöÂ§âÊèõ„Ç≥„Çπ„ÉàÁØÄÁ¥ÑÔºà10-30%„ÅÆÂÆüË°åÊôÇÈñìÁõ∏ÂΩìÔºâ
        let estimated_conversion_cost = execution_time.mul_f64(0.2); // 20%Êé®ÂÆö
        self.total_conversion_cost_saved += estimated_conversion_cost;
    }

    pub fn get_stats(&self) -> PerformanceStats {
        let mut device_usage = std::collections::HashMap::new();
        let total_time: std::time::Duration = self
            .execution_history
            .iter()
            .map(|record| {
                let device_name = match &record.device {
                    GPUDevice::CPU => "CPU".to_string(),
                    GPUDevice::Metal(id) => format!("Metal({})", id),
                    GPUDevice::CoreML(id) => format!("CoreML({})", id),
                };
                *device_usage.entry(device_name).or_insert(0) += 1;
                record.execution_time
            })
            .sum();

        let average_time = if self.total_operations > 0 {
            total_time / self.total_operations as u32
        } else {
            std::time::Duration::from_secs(0)
        };

        PerformanceStats {
            total_operations: self.total_operations,
            average_execution_time: average_time,
            conversion_cost_savings: self.total_conversion_cost_saved,
            device_usage,
        }
    }
}

impl Default for F32HybridExecutor {
    fn default() -> Self {
        Self::new().expect("Failed to create F32HybridExecutor")
    }
}

impl Default for F32DeviceSelector {
    fn default() -> Self {
        Self::new()
    }
}

impl Default for PerformanceMonitor {
    fn default() -> Self {
        Self::new()
    }
}
