//! F32Tensor - f32å°‚ç”¨ãƒ†ãƒ³ã‚½ãƒ«å®Ÿè£…
//! F32Tensor - f32-specific tensor implementation
//!
//! å¤‰æ›ã‚³ã‚¹ãƒˆå®Œå…¨å‰Šé™¤ã‚’ç›®çš„ã¨ã—ãŸf32å°‚ç”¨ãƒ†ãƒ³ã‚½ãƒ«
//! f32-specific tensor aimed at complete conversion cost elimination

use crate::error::RusTorchResult;
use ndarray::{Array, IxDyn};
use std::sync::Arc;

/// ãƒ‡ãƒã‚¤ã‚¹æœ€é©åŒ–çŠ¶æ…‹
/// Device optimization state
#[derive(Debug, Clone)]
pub enum DeviceState {
    CPU,
    Metal { device_id: usize },
    CoreML { device_id: usize },
    Synchronized, // å…¨ãƒ‡ãƒã‚¤ã‚¹åŒæœŸæ¸ˆã¿
}

/// Metalå…±æœ‰ãƒãƒƒãƒ•ã‚¡ï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ï¼‰
/// Metal shared buffer (placeholder)
#[derive(Debug)]
pub struct MetalBuffer {
    _device_id: usize,
    _size: usize,
}

impl MetalBuffer {
    pub fn new(device_id: usize, size: usize) -> Self {
        Self {
            _device_id: device_id,
            _size: size,
        }
    }
}

/// CoreMLå…±æœ‰ãƒãƒƒãƒ•ã‚¡ï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ï¼‰
/// CoreML shared buffer (placeholder)
#[derive(Debug)]
pub struct CoreMLBuffer {
    _device_id: usize,
    _shape: Vec<usize>,
}

impl CoreMLBuffer {
    pub fn new(device_id: usize, shape: Vec<usize>) -> Self {
        Self {
            _device_id: device_id,
            _shape: shape,
        }
    }
}

/// f32å°‚ç”¨ãƒ†ãƒ³ã‚½ãƒ«ï¼ˆå¤‰æ›ã‚³ã‚¹ãƒˆæœ€å°åŒ–ï¼‰
/// f32-specific tensor (conversion cost minimization)
#[derive(Debug)]
pub struct F32Tensor {
    /// CPUå´ãƒ‡ãƒ¼ã‚¿
    /// CPU-side data
    pub data: Array<f32, IxDyn>,

    /// GPUå…±æœ‰ãƒãƒƒãƒ•ã‚¡ï¼ˆMetalç”¨ï¼‰
    /// GPU shared buffer (for Metal)
    pub metal_buffer: Option<Arc<MetalBuffer>>,

    /// Neural Engineå…±æœ‰ãƒãƒƒãƒ•ã‚¡ï¼ˆCoreMLç”¨ï¼‰
    /// Neural Engine shared buffer (for CoreML)
    pub coreml_buffer: Option<Arc<CoreMLBuffer>>,

    /// ãƒ‡ãƒã‚¤ã‚¹æœ€é©åŒ–çŠ¶æ…‹
    /// Device optimization state
    pub device_state: DeviceState,

    /// å‹¾é…è¿½è·¡
    /// Gradient tracking
    pub requires_grad: bool,

    /// ãƒ†ãƒ³ã‚½ãƒ«å½¢çŠ¶
    /// Tensor shape
    shape: Vec<usize>,
}

impl F32Tensor {
    /// æ–°ã—ã„F32Tensorã‚’ä½œæˆ
    /// Create new F32Tensor
    pub fn new(data: Vec<f32>, shape: Vec<usize>) -> RusTorchResult<Self> {
        let total_elements: usize = shape.iter().product();

        if data.len() != total_elements {
            return Err(crate::error::RusTorchError::InvalidParameters {
                operation: "F32Tensor::new".to_string(),
                message: format!(
                    "Data length {} doesn't match shape elements {}",
                    data.len(),
                    total_elements
                ),
            });
        }

        let ndarray_data = Array::from_shape_vec(IxDyn(&shape), data)
            .map_err(|e| crate::error::RusTorchError::TensorOp {
                message: format!("Failed to create ndarray: {}", e),
                source: None,
            })?;

        Ok(Self {
            data: ndarray_data,
            metal_buffer: None,
            coreml_buffer: None,
            device_state: DeviceState::CPU,
            requires_grad: false,
            shape,
        })
    }

    /// ã‚¼ãƒ­ãƒ†ãƒ³ã‚½ãƒ«ã‚’ä½œæˆ
    /// Create zero tensor
    pub fn zeros(shape: &[usize]) -> Self {
        let total_elements: usize = shape.iter().product();
        let data = vec![0.0f32; total_elements];

        Self::new(data, shape.to_vec()).expect("Failed to create zero tensor")
    }

    /// ãƒ©ãƒ³ãƒ€ãƒ ãƒ†ãƒ³ã‚½ãƒ«ã‚’ä½œæˆ
    /// Create random tensor
    pub fn randn(shape: &[usize]) -> Self {
        use rand::Rng;
        let mut rng = rand::thread_rng();
        let total_elements: usize = shape.iter().product();
        let data: Vec<f32> = (0..total_elements)
            .map(|_| rng.gen_range(-1.0..1.0))
            .collect();

        Self::new(data, shape.to_vec()).expect("Failed to create random tensor")
    }

    /// 1åŸ‹ã‚ãƒ†ãƒ³ã‚½ãƒ«ã‚’ä½œæˆ
    /// Create ones tensor
    pub fn ones(shape: &[usize]) -> Self {
        let total_elements: usize = shape.iter().product();
        let data = vec![1.0f32; total_elements];

        Self::new(data, shape.to_vec()).expect("Failed to create ones tensor")
    }

    /// ä¸€æ§˜åˆ†å¸ƒ[0,1)ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ãƒ†ãƒ³ã‚½ãƒ«ã‚’ä½œæˆ
    /// Create random tensor from uniform distribution [0,1)
    pub fn rand(shape: &[usize]) -> Self {
        use rand::Rng;
        let mut rng = rand::thread_rng();
        let total_elements: usize = shape.iter().product();
        let data: Vec<f32> = (0..total_elements)
            .map(|_| rng.gen::<f32>())
            .collect();

        Self::new(data, shape.to_vec()).expect("Failed to create random tensor")
    }

    /// ä¸€æ§˜åˆ†å¸ƒ[low,high)ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ãƒ†ãƒ³ã‚½ãƒ«ã‚’ä½œæˆ
    /// Create random tensor from uniform distribution [low,high)
    pub fn uniform(shape: &[usize], low: f32, high: f32) -> Self {
        use rand::Rng;
        let mut rng = rand::thread_rng();
        let total_elements: usize = shape.iter().product();
        let data: Vec<f32> = (0..total_elements)
            .map(|_| rng.gen_range(low..high))
            .collect();

        Self::new(data, shape.to_vec()).expect("Failed to create uniform tensor")
    }

    /// é€£ç¶šå€¤ãƒ†ãƒ³ã‚½ãƒ«ã‚’ä½œæˆ
    /// Create arange tensor
    pub fn arange(start: f32, end: f32, step: f32) -> Self {
        let mut data = Vec::new();
        let mut current = start;

        while current < end {
            data.push(current);
            current += step;
        }

        let len = data.len();
        Self::new(data, vec![len]).expect("Failed to create arange tensor")
    }

    /// ç­‰é–“éš”å€¤ãƒ†ãƒ³ã‚½ãƒ«ã‚’ä½œæˆ
    /// Create linspace tensor
    pub fn linspace(start: f32, end: f32, steps: usize) -> Self {
        if steps <= 1 {
            return Self::new(vec![start], vec![1]).expect("Failed to create linspace tensor");
        }

        let step_size = (end - start) / (steps - 1) as f32;
        let data: Vec<f32> = (0..steps)
            .map(|i| start + i as f32 * step_size)
            .collect();

        Self::new(data, vec![steps]).expect("Failed to create linspace tensor")
    }

    /// å˜ä½è¡Œåˆ—ã‚’ä½œæˆ
    /// Create identity matrix
    pub fn eye(n: usize) -> Self {
        let mut data = vec![0.0f32; n * n];
        for i in 0..n {
            data[i * n + i] = 1.0f32;
        }

        Self::new(data, vec![n, n]).expect("Failed to create identity matrix")
    }

    /// ãƒ™ã‚¯ã‚¿ãƒ¼ã‹ã‚‰ãƒ†ãƒ³ã‚½ãƒ«ã‚’ä½œæˆ
    /// Create tensor from vector
    pub fn from_vec(data: Vec<f32>, shape: Vec<usize>) -> RusTorchResult<Self> {
        Self::new(data, shape)
    }

    /// ãƒ†ãƒ³ã‚½ãƒ«å½¢çŠ¶ã‚’å–å¾—
    /// Get tensor shape
    pub fn shape(&self) -> &[usize] {
        &self.shape
    }

    /// ãƒ‡ãƒã‚¤ã‚¹çŠ¶æ…‹ã‚’å–å¾—
    /// Get device state
    pub fn device_state(&self) -> &DeviceState {
        &self.device_state
    }


    /// ãƒ†ãƒ³ã‚½ãƒ«åŠ ç®—ï¼ˆf32å°‚ç”¨ï¼‰
    /// Tensor addition (f32-specific)
    pub fn add(&self, other: &F32Tensor) -> RusTorchResult<F32Tensor> {
        if self.shape != other.shape {
            return Err(crate::error::RusTorchError::InvalidParameters {
                operation: "F32Tensor::add".to_string(),
                message: format!(
                    "Shape mismatch: {:?} vs {:?}",
                    self.shape, other.shape
                ),
            });
        }

        let result_data: Vec<f32> = self.data.iter()
            .zip(other.data.iter())
            .map(|(a, b)| a + b)
            .collect();

        F32Tensor::new(result_data, self.shape.clone())
    }

    /// ãƒ†ãƒ³ã‚½ãƒ«æ¸›ç®—ï¼ˆf32å°‚ç”¨ï¼‰
    /// Tensor subtraction (f32-specific)
    pub fn sub(&self, other: &F32Tensor) -> RusTorchResult<F32Tensor> {
        if self.shape != other.shape {
            return Err(crate::error::RusTorchError::InvalidParameters {
                operation: "F32Tensor::sub".to_string(),
                message: format!(
                    "Shape mismatch: {:?} vs {:?}",
                    self.shape, other.shape
                ),
            });
        }

        let result_data: Vec<f32> = self.data.iter()
            .zip(other.data.iter())
            .map(|(a, b)| a - b)
            .collect();

        F32Tensor::new(result_data, self.shape.clone())
    }

    /// ãƒ†ãƒ³ã‚½ãƒ«ä¹—ç®—ï¼ˆf32å°‚ç”¨ï¼‰
    /// Tensor multiplication (f32-specific)
    pub fn mul(&self, other: &F32Tensor) -> RusTorchResult<F32Tensor> {
        if self.shape != other.shape {
            return Err(crate::error::RusTorchError::InvalidParameters {
                operation: "F32Tensor::mul".to_string(),
                message: format!(
                    "Shape mismatch: {:?} vs {:?}",
                    self.shape, other.shape
                ),
            });
        }

        let result_data: Vec<f32> = self.data.iter()
            .zip(other.data.iter())
            .map(|(a, b)| a * b)
            .collect();

        F32Tensor::new(result_data, self.shape.clone())
    }

    /// ãƒ†ãƒ³ã‚½ãƒ«é™¤ç®—ï¼ˆf32å°‚ç”¨ï¼‰
    /// Tensor division (f32-specific)
    pub fn div(&self, other: &F32Tensor) -> RusTorchResult<F32Tensor> {
        if self.shape != other.shape {
            return Err(crate::error::RusTorchError::InvalidParameters {
                operation: "F32Tensor::div".to_string(),
                message: format!(
                    "Shape mismatch: {:?} vs {:?}",
                    self.shape, other.shape
                ),
            });
        }

        let result_data: Vec<f32> = self.data.iter()
            .zip(other.data.iter())
            .map(|(a, b)| a / b)
            .collect();

        F32Tensor::new(result_data, self.shape.clone())
    }

    /// ã‚¹ã‚«ãƒ©ãƒ¼åŠ ç®—ï¼ˆf32å°‚ç”¨ï¼‰
    /// Scalar addition (f32-specific)
    pub fn add_scalar(&self, scalar: f32) -> RusTorchResult<F32Tensor> {
        let result_data: Vec<f32> = self.data.iter()
            .map(|&a| a + scalar)
            .collect();

        F32Tensor::new(result_data, self.shape.clone())
    }

    /// ã‚¹ã‚«ãƒ©ãƒ¼æ¸›ç®—ï¼ˆf32å°‚ç”¨ï¼‰
    /// Scalar subtraction (f32-specific)
    pub fn sub_scalar(&self, scalar: f32) -> RusTorchResult<F32Tensor> {
        let result_data: Vec<f32> = self.data.iter()
            .map(|&a| a - scalar)
            .collect();

        F32Tensor::new(result_data, self.shape.clone())
    }

    /// ã‚¹ã‚«ãƒ©ãƒ¼ä¹—ç®—ï¼ˆf32å°‚ç”¨ï¼‰
    /// Scalar multiplication (f32-specific)
    pub fn mul_scalar(&self, scalar: f32) -> RusTorchResult<F32Tensor> {
        let result_data: Vec<f32> = self.data.iter()
            .map(|&a| a * scalar)
            .collect();

        F32Tensor::new(result_data, self.shape.clone())
    }

    /// ã‚¹ã‚«ãƒ©ãƒ¼é™¤ç®—ï¼ˆf32å°‚ç”¨ï¼‰
    /// Scalar division (f32-specific)
    pub fn div_scalar(&self, scalar: f32) -> RusTorchResult<F32Tensor> {
        let result_data: Vec<f32> = self.data.iter()
            .map(|&a| a / scalar)
            .collect();

        F32Tensor::new(result_data, self.shape.clone())
    }

    /// ç¬¦å·åè»¢ï¼ˆf32å°‚ç”¨ï¼‰
    /// Negation (f32-specific)
    pub fn neg(&self) -> RusTorchResult<F32Tensor> {
        let result_data: Vec<f32> = self.data.iter()
            .map(|&a| -a)
            .collect();

        F32Tensor::new(result_data, self.shape.clone())
    }

    /// çµ¶å¯¾å€¤ï¼ˆf32å°‚ç”¨ï¼‰
    /// Absolute value (f32-specific)
    pub fn abs(&self) -> RusTorchResult<F32Tensor> {
        let result_data: Vec<f32> = self.data.iter()
            .map(|&a| a.abs())
            .collect();

        F32Tensor::new(result_data, self.shape.clone())
    }

    /// ã¹ãä¹—ï¼ˆf32å°‚ç”¨ï¼‰
    /// Power (f32-specific)
    pub fn pow(&self, exponent: f32) -> RusTorchResult<F32Tensor> {
        let result_data: Vec<f32> = self.data.iter()
            .map(|&a| a.powf(exponent))
            .collect();

        F32Tensor::new(result_data, self.shape.clone())
    }

    /// å¹³æ–¹æ ¹ï¼ˆf32å°‚ç”¨ï¼‰
    /// Square root (f32-specific)
    pub fn sqrt(&self) -> RusTorchResult<F32Tensor> {
        let result_data: Vec<f32> = self.data.iter()
            .map(|&a| a.sqrt())
            .collect();

        F32Tensor::new(result_data, self.shape.clone())
    }

    /// ãƒ†ãƒ³ã‚½ãƒ«åˆè¨ˆï¼ˆf32å°‚ç”¨ï¼‰
    /// Tensor sum (f32-specific)
    pub fn sum(&self) -> RusTorchResult<f32> {
        Ok(self.data.iter().sum::<f32>())
    }

    /// ãƒ†ãƒ³ã‚½ãƒ«å¹³å‡ï¼ˆf32å°‚ç”¨ï¼‰
    /// Tensor mean (f32-specific)
    pub fn mean(&self) -> RusTorchResult<f32> {
        if self.data.is_empty() {
            return Err(crate::error::RusTorchError::InvalidParameters {
                operation: "F32Tensor::mean".to_string(),
                message: "Cannot compute mean of empty tensor".to_string(),
            });
        }
        Ok(self.data.iter().sum::<f32>() / self.data.len() as f32)
    }

    /// ãƒ†ãƒ³ã‚½ãƒ«æœ€å¤§å€¤ï¼ˆf32å°‚ç”¨ï¼‰
    /// Tensor maximum (f32-specific)
    pub fn max(&self) -> RusTorchResult<f32> {
        self.data.iter().max_by(|a, b| a.partial_cmp(b).unwrap())
            .copied()
            .ok_or_else(|| crate::error::RusTorchError::InvalidParameters {
                operation: "F32Tensor::max".to_string(),
                message: "Cannot compute max of empty tensor".to_string(),
            })
    }

    /// ãƒ†ãƒ³ã‚½ãƒ«æœ€å°å€¤ï¼ˆf32å°‚ç”¨ï¼‰
    /// Tensor minimum (f32-specific)
    pub fn min(&self) -> RusTorchResult<f32> {
        self.data.iter().min_by(|a, b| a.partial_cmp(b).unwrap())
            .copied()
            .ok_or_else(|| crate::error::RusTorchError::InvalidParameters {
                operation: "F32Tensor::min".to_string(),
                message: "Cannot compute min of empty tensor".to_string(),
            })
    }

    /// ãƒ†ãƒ³ã‚½ãƒ«æ¨™æº–åå·®ï¼ˆf32å°‚ç”¨ï¼‰
    /// Tensor standard deviation (f32-specific)
    pub fn std(&self) -> RusTorchResult<f32> {
        if self.data.is_empty() {
            return Err(crate::error::RusTorchError::InvalidParameters {
                operation: "F32Tensor::std".to_string(),
                message: "Cannot compute std of empty tensor".to_string(),
            });
        }

        let mean = self.mean()?;
        let variance = self.data.iter()
            .map(|&x| (x - mean).powi(2))
            .sum::<f32>() / self.data.len() as f32;

        Ok(variance.sqrt())
    }

    /// ãƒ†ãƒ³ã‚½ãƒ«åˆ†æ•£ï¼ˆf32å°‚ç”¨ï¼‰
    /// Tensor variance (f32-specific)
    pub fn var(&self) -> RusTorchResult<f32> {
        if self.data.is_empty() {
            return Err(crate::error::RusTorchError::InvalidParameters {
                operation: "F32Tensor::var".to_string(),
                message: "Cannot compute var of empty tensor".to_string(),
            });
        }

        let mean = self.mean()?;
        let variance = self.data.iter()
            .map(|&x| (x - mean).powi(2))
            .sum::<f32>() / self.data.len() as f32;

        Ok(variance)
    }

    /// è»¸æŒ‡å®šåˆè¨ˆï¼ˆf32å°‚ç”¨ï¼‰
    /// Axis-specific sum (f32-specific)
    pub fn sum_axis(&self, axis: usize) -> RusTorchResult<F32Tensor> {
        if axis >= self.shape.len() {
            return Err(crate::error::RusTorchError::InvalidParameters {
                operation: "F32Tensor::sum_axis".to_string(),
                message: format!("Axis {} out of bounds for {}D tensor", axis, self.shape.len()),
            });
        }

        // ç°¡å˜ãªå®Ÿè£…: 2æ¬¡å…ƒãƒ†ãƒ³ã‚½ãƒ«ã®å ´åˆã®ã¿å¯¾å¿œ
        if self.shape.len() == 2 {
            let (rows, cols) = (self.shape[0], self.shape[1]);
            if axis == 0 {
                // è¡Œæ–¹å‘ã«åˆè¨ˆï¼ˆçµæœã¯1xColsï¼‰
                let mut result_data = vec![0.0f32; cols];
                for j in 0..cols {
                    for i in 0..rows {
                        result_data[j] += self.data[[i, j]];
                    }
                }
                return F32Tensor::new(result_data, vec![cols]);
            } else if axis == 1 {
                // åˆ—æ–¹å‘ã«åˆè¨ˆï¼ˆçµæœã¯Rowsx1ï¼‰
                let mut result_data = vec![0.0f32; rows];
                for i in 0..rows {
                    for j in 0..cols {
                        result_data[i] += self.data[[i, j]];
                    }
                }
                return F32Tensor::new(result_data, vec![rows]);
            }
        }

        // ä»–ã®æ¬¡å…ƒã¯ã¾ã æœªå®Ÿè£…
        Err(crate::error::RusTorchError::InvalidParameters {
            operation: "F32Tensor::sum_axis".to_string(),
            message: "Only 2D tensors supported for axis operations".to_string(),
        })
    }

    /// è»¸æŒ‡å®šå¹³å‡ï¼ˆf32å°‚ç”¨ï¼‰
    /// Axis-specific mean (f32-specific)
    pub fn mean_axis(&self, axis: usize) -> RusTorchResult<F32Tensor> {
        let sum_result = self.sum_axis(axis)?;
        let divisor = if axis < self.shape.len() {
            self.shape[axis] as f32
        } else {
            1.0
        };
        sum_result.div_scalar(divisor)
    }

    /// è¡Œåˆ—ä¹—ç®—ï¼ˆf32å°‚ç”¨ï¼‰
    /// Matrix multiplication (f32-specific)
    pub fn matmul(&self, other: &F32Tensor) -> RusTorchResult<F32Tensor> {
        if self.shape.len() != 2 || other.shape.len() != 2 {
            return Err(crate::error::RusTorchError::InvalidParameters {
                operation: "F32Tensor::matmul".to_string(),
                message: "Both tensors must be 2D matrices".to_string(),
            });
        }

        let (m, k1) = (self.shape[0], self.shape[1]);
        let (k2, n) = (other.shape[0], other.shape[1]);

        if k1 != k2 {
            return Err(crate::error::RusTorchError::InvalidParameters {
                operation: "F32Tensor::matmul".to_string(),
                message: format!(
                    "Matrix dimension mismatch: {}x{} Ã— {}x{}",
                    m, k1, k2, n
                ),
            });
        }

        // ã‚·ãƒ³ãƒ—ãƒ«ãªf32è¡Œåˆ—ä¹—ç®—å®Ÿè£…
        let mut result_data = vec![0.0f32; m * n];

        for i in 0..m {
            for j in 0..n {
                let mut sum = 0.0f32;
                for k in 0..k1 {
                    let a_val = self.data[[i, k]];
                    let b_val = other.data[[k, j]];
                    sum += a_val * b_val;
                }
                result_data[i * n + j] = sum;
            }
        }

        F32Tensor::new(result_data, vec![m, n])
    }
}

/// Cloneãƒˆãƒ¬ã‚¤ãƒˆã®å®Ÿè£…
/// Clone trait implementation
impl Clone for F32Tensor {
    fn clone(&self) -> Self {
        Self {
            data: self.data.clone(),
            metal_buffer: self.metal_buffer.clone(),
            coreml_buffer: self.coreml_buffer.clone(),
            device_state: self.device_state.clone(),
            requires_grad: self.requires_grad,
            shape: self.shape.clone(),
        }
    }
}

impl F32Tensor {
    /// Metal GPUã«ç§»å‹•ï¼ˆå¤‰æ›ãªã—ï¼‰
    /// Move to Metal GPU (no conversion)
    pub fn to_metal(&mut self, device_id: usize) -> RusTorchResult<()> {
        crate::hybrid_f32_experimental!();

        // Metalå…±æœ‰ãƒãƒƒãƒ•ã‚¡ã‚’ä½œæˆï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ Metal API ã‚’ä½¿ç”¨ï¼‰
        let buffer_size = self.data.len() * std::mem::size_of::<f32>();
        self.metal_buffer = Some(Arc::new(MetalBuffer::new(device_id, buffer_size)));
        self.device_state = DeviceState::Metal { device_id };

        println!("ğŸš€ F32Tensor moved to Metal GPU {} (zero-copy)", device_id);
        Ok(())
    }

    /// Neural Engineã«ç§»å‹•ï¼ˆå¤‰æ›ãªã—ï¼‰
    /// Move to Neural Engine (no conversion)
    pub fn to_coreml(&mut self, device_id: usize) -> RusTorchResult<()> {
        crate::hybrid_f32_experimental!();

        // CoreMLå…±æœ‰ãƒãƒƒãƒ•ã‚¡ã‚’ä½œæˆï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ MLMultiArray ã‚’ä½¿ç”¨ï¼‰
        self.coreml_buffer = Some(Arc::new(CoreMLBuffer::new(device_id, self.shape.clone())));
        self.device_state = DeviceState::CoreML { device_id };

        println!("ğŸ§  F32Tensor moved to Neural Engine {} (zero-copy)", device_id);
        Ok(())
    }

    /// CPUã«ç§»å‹•
    /// Move to CPU
    pub fn to_cpu(&mut self) -> RusTorchResult<()> {
        self.metal_buffer = None;
        self.coreml_buffer = None;
        self.device_state = DeviceState::CPU;

        println!("ğŸ’» F32Tensor moved to CPU");
        Ok(())
    }

    /// å…¨ãƒ‡ãƒã‚¤ã‚¹åŒæœŸ
    /// Synchronize all devices
    pub fn synchronize_all(&mut self) -> RusTorchResult<()> {
        crate::hybrid_f32_experimental!();

        // å®Ÿéš›ã®å®Ÿè£…ã§ã¯å„ãƒ‡ãƒã‚¤ã‚¹é–“ã§ãƒ‡ãƒ¼ã‚¿åŒæœŸ
        self.device_state = DeviceState::Synchronized;

        println!("ğŸ”„ F32Tensor synchronized across all devices");
        Ok(())
    }

    /// è¡Œåˆ—ä¹—ç®—ï¼ˆå¤‰æ›ãƒ¬ã‚¹å®Ÿè¡Œï¼‰
    /// Matrix multiplication (conversion-less execution)
    pub fn matmul_optimized(&self, other: &F32Tensor) -> RusTorchResult<F32Tensor> {
        crate::hybrid_f32_experimental!();

        // æœ€é©ãƒ‡ãƒã‚¤ã‚¹é¸æŠ
        let optimal_device = self.select_optimal_device_for_matmul(&other);

        match optimal_device {
            DeviceState::Metal { device_id } => {
                println!("âš¡ Executing matmul on Metal GPU {} (f32 direct)", device_id);
                self.execute_metal_matmul_f32(other)
            }
            DeviceState::CoreML { device_id } => {
                println!("ğŸ§  Executing matmul on Neural Engine {} (f32 direct)", device_id);
                self.execute_coreml_matmul_f32(other)
            }
            DeviceState::CPU => {
                println!("ğŸ’» Executing matmul on CPU (f32 direct)");
                self.execute_cpu_matmul_f32(other)
            }
            DeviceState::Synchronized => {
                println!("ğŸ”„ Executing matmul on synchronized devices");
                self.execute_cpu_matmul_f32(other) // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            }
        }
    }

    /// æœ€é©ãƒ‡ãƒã‚¤ã‚¹é¸æŠï¼ˆè¡Œåˆ—ä¹—ç®—ç”¨ï¼‰
    /// Select optimal device (for matrix multiplication)
    fn select_optimal_device_for_matmul(&self, _other: &F32Tensor) -> DeviceState {
        let matrix_size = self.shape.iter().product::<usize>();

        match matrix_size {
            size if size > 50000 => DeviceState::Metal { device_id: 0 }, // å¤§è¦æ¨¡ â†’ Metal
            size if size > 1000 => DeviceState::CoreML { device_id: 0 }, // ä¸­è¦æ¨¡ â†’ Neural Engine
            _ => DeviceState::CPU, // å°è¦æ¨¡ â†’ CPU
        }
    }

    /// Metal GPU f32ç›´æ¥å®Ÿè¡Œ
    /// Metal GPU f32 direct execution
    fn execute_metal_matmul_f32(&self, other: &F32Tensor) -> RusTorchResult<F32Tensor> {
        // å®Ÿéš›ã®å®Ÿè£…ã§ã¯ Metal Performance Shaders ã‚’ä½¿ç”¨
        // ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼å®Ÿè£…: CPUè¨ˆç®—ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        self.execute_cpu_matmul_f32(other)
    }

    /// Neural Engine f32ç›´æ¥å®Ÿè¡Œ
    /// Neural Engine f32 direct execution
    fn execute_coreml_matmul_f32(&self, other: &F32Tensor) -> RusTorchResult<F32Tensor> {
        // å®Ÿéš›ã®å®Ÿè£…ã§ã¯ CoreML MLCompute ã‚’ä½¿ç”¨
        // ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼å®Ÿè£…: CPUè¨ˆç®—ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        self.execute_cpu_matmul_f32(other)
    }

    /// CPU f32ç›´æ¥å®Ÿè¡Œ
    /// CPU f32 direct execution
    fn execute_cpu_matmul_f32(&self, other: &F32Tensor) -> RusTorchResult<F32Tensor> {
        // ç°¡å˜ãªè¡Œåˆ—ä¹—ç®—å®Ÿè£…ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ BLAS ã‚’ä½¿ç”¨ï¼‰
        let a_shape = self.shape();
        let b_shape = other.shape();

        if a_shape.len() != 2 || b_shape.len() != 2 {
            return Err(crate::error::RusTorchError::InvalidParameters {
                operation: "matmul".to_string(),
                message: "Only 2D matrices supported in this experimental implementation".to_string(),
            });
        }

        if a_shape[1] != b_shape[0] {
            return Err(crate::error::RusTorchError::InvalidParameters {
                operation: "matmul".to_string(),
                message: format!(
                    "Matrix dimensions don't match: {}x{} and {}x{}",
                    a_shape[0], a_shape[1], b_shape[0], b_shape[1]
                ),
            });
        }

        let result_shape = vec![a_shape[0], b_shape[1]];
        let mut result_data = vec![0.0f32; result_shape.iter().product()];

        // å˜ç´”ãªè¡Œåˆ—ä¹—ç®—
        for i in 0..a_shape[0] {
            for j in 0..b_shape[1] {
                let mut sum = 0.0f32;
                for k in 0..a_shape[1] {
                    let a_idx = i * a_shape[1] + k;
                    let b_idx = k * b_shape[1] + j;
                    sum += self.data[[i, k]] * other.data[[k, j]];
                }
                let result_idx = i * b_shape[1] + j;
                result_data[result_idx] = sum;
            }
        }

        F32Tensor::new(result_data, result_shape)
    }

    /// ãƒ‡ãƒ¼ã‚¿ã‚’f32ã‚¹ãƒ©ã‚¤ã‚¹ã¨ã—ã¦å–å¾—
    /// Get data as f32 slice
    pub fn as_slice(&self) -> &[f32] {
        self.data.as_slice().unwrap()
    }

    /// ãƒ‡ãƒ¼ã‚¿ã®è¦ç´ æ•°ã‚’å–å¾—
    /// Get number of elements
    pub fn len(&self) -> usize {
        self.data.len()
    }

    /// ãƒ†ãƒ³ã‚½ãƒ«ãŒç©ºã‹ã©ã†ã‹
    /// Check if tensor is empty
    pub fn is_empty(&self) -> bool {
        self.data.is_empty()
    }
}