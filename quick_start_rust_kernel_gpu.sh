#!/bin/bash

# RusTorch GPU-Enabled Rust Kernel Quick Start Script - Multilingual Support
# Auto-detects system language for international users
# Supports: English, Japanese, Spanish, French, German, Chinese, Korean
# 
# Usage: curl -sSL https://raw.githubusercontent.com/JunSuzukiJapan/rustorch/main/quick_start_rust_kernel_gpu.sh | bash
# ä½¿ç”¨æ³•: curl -sSL https://raw.githubusercontent.com/JunSuzukiJapan/rustorch/main/quick_start_rust_kernel_gpu.sh | bash

set -e

# Language Detection and Message System
detect_language() {
    local lang_code
    
    # Try multiple methods to detect language
    if [[ -n "${LC_ALL:-}" ]]; then
        lang_code="${LC_ALL%.*}"
    elif [[ -n "${LC_MESSAGES:-}" ]]; then
        lang_code="${LC_MESSAGES%.*}"
    elif [[ -n "${LANG:-}" ]]; then
        lang_code="${LANG%.*}"
    else
        lang_code="en_US"
    fi
    
    # Extract language prefix
    lang_code="${lang_code%_*}"
    
    case "$lang_code" in
        ja) echo "ja" ;;
        es) echo "es" ;;
        fr) echo "fr" ;;
        de) echo "de" ;;
        zh|zh_CN|zh_TW) echo "zh" ;;
        ko) echo "ko" ;;
        *) echo "en" ;;
    esac
}

# Multilingual message function for GPU Rust Kernel
msg() {
    local key="$1"
    local lang="${DETECTED_LANG:-en}"
    
    case "$key" in
        "welcome_title")
            case "$lang" in
                en) echo "ðŸ¦€ðŸš€ RusTorch GPU-Enabled Rust Kernel Quick Start" ;;
                ja) echo "ðŸ¦€ðŸš€ RusTorch GPUå¯¾å¿œ Rust ã‚«ãƒ¼ãƒãƒ« ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ" ;;
                es) echo "ðŸ¦€ðŸš€ Inicio RÃ¡pido Kernel Rust GPU RusTorch" ;;
                fr) echo "ðŸ¦€ðŸš€ DÃ©marrage Rapide Noyau Rust GPU RusTorch" ;;
                de) echo "ðŸ¦€ðŸš€ RusTorch GPU Rust Kernel Schnellstart" ;;
                zh) echo "ðŸ¦€ðŸš€ RusTorch GPU Rust å†…æ ¸å¿«é€Ÿå¼€å§‹" ;;
                ko) echo "ðŸ¦€ðŸš€ RusTorch GPU Rust ì»¤ë„ ë¹ ë¥¸ ì‹œìž‘" ;;
            esac ;;
        "gpu_detection")
            case "$lang" in
                en) echo "ðŸŽ® Detecting GPU capabilities..." ;;
                ja) echo "ðŸŽ® GPUæ€§èƒ½ã‚’æ¤œå‡ºä¸­..." ;;
                es) echo "ðŸŽ® Detectando capacidades de GPU..." ;;
                fr) echo "ðŸŽ® DÃ©tection des capacitÃ©s GPU..." ;;
                de) echo "ðŸŽ® GPU-FÃ¤higkeiten erkennen..." ;;
                zh) echo "ðŸŽ® æ£€æµ‹ GPU åŠŸèƒ½..." ;;
                ko) echo "ðŸŽ® GPU ê¸°ëŠ¥ ê°ì§€ ì¤‘..." ;;
            esac ;;
        "gpu_kernel_complete")
            case "$lang" in
                en) echo "ðŸŽ‰ GPU-Enabled Rust Kernel Setup Complete!" ;;
                ja) echo "ðŸŽ‰ GPUå¯¾å¿œRustã‚«ãƒ¼ãƒãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ï¼" ;;
                es) echo "ðŸŽ‰ Â¡ConfiguraciÃ³n Kernel Rust GPU Completa!" ;;
                fr) echo "ðŸŽ‰ Configuration Noyau Rust GPU TerminÃ©e!" ;;
                de) echo "ðŸŽ‰ GPU Rust Kernel Setup Abgeschlossen!" ;;
                zh) echo "ðŸŽ‰ GPU Rust å†…æ ¸è®¾ç½®å®Œæˆï¼" ;;
                ko) echo "ðŸŽ‰ GPU Rust ì»¤ë„ ì„¤ì • ì™„ë£Œï¼" ;;
            esac ;;
        "detected_gpu_features")
            case "$lang" in
                en) echo "ðŸŽ® Detected GPU features:" ;;
                ja) echo "ðŸŽ® æ¤œå‡ºã•ã‚ŒãŸGPUæ©Ÿèƒ½:" ;;
                es) echo "ðŸŽ® CaracterÃ­sticas GPU detectadas:" ;;
                fr) echo "ðŸŽ® FonctionnalitÃ©s GPU dÃ©tectÃ©es:" ;;
                de) echo "ðŸŽ® Erkannte GPU-Features:" ;;
                zh) echo "ðŸŽ® æ£€æµ‹åˆ°çš„ GPU åŠŸèƒ½ï¼š" ;;
                ko) echo "ðŸŽ® ê°ì§€ëœ GPU ê¸°ëŠ¥:" ;;
            esac ;;
        "gpu_demo_loaded")
            case "$lang" in
                en) echo "ðŸ“ GPU Demo notebook loaded automatically" ;;
                ja) echo "ðŸ“ GPUãƒ‡ãƒ¢ãƒŽãƒ¼ãƒˆãƒ–ãƒƒã‚¯è‡ªå‹•èª­ã¿è¾¼ã¿æ¸ˆã¿" ;;
                es) echo "ðŸ“ Notebook demo GPU cargado automÃ¡ticamente" ;;
                fr) echo "ðŸ“ Notebook de dÃ©mo GPU chargÃ© automatiquement" ;;
                de) echo "ðŸ“ GPU-Demo-Notebook automatisch geladen" ;;
                zh) echo "ðŸ“ GPU æ¼”ç¤ºç¬”è®°æœ¬è‡ªåŠ¨åŠ è½½" ;;
                ko) echo "ðŸ“ GPU ë°ëª¨ ë…¸íŠ¸ë¶ ìžë™ ë¡œë“œë¨" ;;
            esac ;;
    esac
}

# Detect system language
DETECTED_LANG=$(detect_language)

# Display welcome message in user's language
echo "$(msg "welcome_title")"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "ðŸŒ Language detected: $DETECTED_LANG"
echo ""

# Create workspace
RUSTORCH_DIR="$HOME/rustorch-gpu-rust-kernel"
echo "ðŸ“ Creating RusTorch GPU Rust workspace: $RUSTORCH_DIR"

if [ -d "$RUSTORCH_DIR" ]; then
    echo "âš ï¸  Directory exists. Updating..."
    cd "$RUSTORCH_DIR"
    git pull origin main || echo "Git pull failed, continuing..."
else
    echo "ðŸ“¥ Downloading RusTorch..."
    git clone --depth 1 https://github.com/JunSuzukiJapan/rustorch.git "$RUSTORCH_DIR"
    cd "$RUSTORCH_DIR"
fi

echo ""
echo "ðŸ” Checking system requirements..."

# Check Rust
if command -v rustc &> /dev/null; then
    RUST_VERSION=$(rustc --version | cut -d' ' -f2)
    echo "âœ… Rust: $RUST_VERSION"
else
    echo "ðŸ“¦ Installing Rust..."
    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
    source $HOME/.cargo/env
    echo "âœ… Rust installed!"
fi

# Check Python
if command -v python3 &> /dev/null; then
    PYTHON_VERSION=$(python3 --version | cut -d' ' -f2)
    echo "âœ… Python: $PYTHON_VERSION"
else
    echo "âŒ Python 3 is required"
    exit 1
fi

# GPU Detection and Feature Configuration
echo ""
echo "$(msg "gpu_detection")"

GPU_FEATURES=""
GPU_FOUND=false

# NVIDIA CUDA Detection
if command -v nvidia-smi &> /dev/null; then
    CUDA_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader,nounits | head -1)
    echo "âœ… NVIDIA GPU detected (Driver: $CUDA_VERSION)"
    GPU_FEATURES="cuda"
    GPU_FOUND=true
elif [[ -d "/usr/local/cuda" ]] || [[ -d "/opt/cuda" ]]; then
    echo "âœ… CUDA installation detected"
    GPU_FEATURES="cuda"
    GPU_FOUND=true
fi

# Apple Metal Detection (macOS)
if [[ "$OSTYPE" == "darwin"* ]]; then
    METAL_CHECK=$(system_profiler SPDisplaysDataType 2>/dev/null | grep -i "metal" || echo "")
    if [[ -n "$METAL_CHECK" ]]; then
        echo "âœ… Apple Metal GPU detected"
        if [[ -n "$GPU_FEATURES" ]]; then
            GPU_FEATURES="$GPU_FEATURES,metal"
        else
            GPU_FEATURES="metal"
        fi
        GPU_FOUND=true
    fi
fi

# OpenCL Detection
if command -v clinfo &> /dev/null; then
    OPENCL_DEVICES=$(clinfo -l 2>/dev/null | grep -c "Platform #" || echo "0")
    if [[ "$OPENCL_DEVICES" -gt 0 ]]; then
        echo "âœ… OpenCL GPU detected ($OPENCL_DEVICES platforms)"
        if [[ -n "$GPU_FEATURES" ]]; then
            GPU_FEATURES="$GPU_FEATURES,opencl"
        else
            GPU_FEATURES="opencl"
        fi
        GPU_FOUND=true
    fi
fi

if [[ "$GPU_FOUND" == false ]]; then
    echo "âš ï¸  No GPU acceleration detected. Using CPU-only mode."
    echo "   ðŸ’¡ For GPU support, install:"
    echo "   - NVIDIA: CUDA toolkit"
    echo "   - Apple: Already available on macOS"
    echo "   - Generic: OpenCL drivers"
    GPU_FEATURES=""
else
    echo "ðŸš€ GPU features available: $GPU_FEATURES"
fi

# Check ZMQ (required for evcxr_jupyter)
echo ""
echo "ðŸ”§ Checking ZMQ dependency..."
if command -v pkg-config &> /dev/null && pkg-config --exists libzmq; then
    echo "âœ… ZMQ already installed"
elif [[ "$OSTYPE" == "darwin"* ]]; then
    if command -v brew &> /dev/null; then
        echo "ðŸ“¦ Installing ZMQ via Homebrew..."
        brew install zmq pkg-config
    else
        echo "âŒ Please install Homebrew first: https://brew.sh"
        exit 1
    fi
elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
    echo "ðŸ“¦ Installing ZMQ for Linux..."
    if command -v apt-get &> /dev/null; then
        sudo apt-get update && sudo apt-get install -y libzmq3-dev pkg-config
    elif command -v yum &> /dev/null; then
        sudo yum install -y zeromq-devel pkgconfig
    else
        echo "âŒ Please install libzmq3-dev manually"
        exit 1
    fi
else
    echo "âš ï¸  Unsupported OS for automatic ZMQ installation"
fi

echo ""
echo "ðŸ¦€ Installing Rust Jupyter kernel (evcxr_jupyter)..."

# Install evcxr_jupyter
if command -v evcxr_jupyter &> /dev/null; then
    echo "âœ… evcxr_jupyter already installed"
else
    echo "ðŸ“¦ Installing evcxr_jupyter..."
    cargo install evcxr_jupyter
fi

# Install the kernel
echo "ðŸ”§ Installing Rust kernel for Jupyter..."
evcxr_jupyter --install

echo ""
echo "ðŸ“š Installing Python dependencies..."
if [ ! -d ".venv" ]; then
    python3 -m venv .venv
fi
source .venv/bin/activate
pip install --upgrade pip jupyter jupyterlab matplotlib pandas numpy

# Create GPU-enabled Rust kernel demo notebook
echo ""
echo "ðŸ“ Creating GPU-enabled Rust kernel demo notebook..."
mkdir -p notebooks

cat > notebooks/rustorch_gpu_rust_kernel_demo.ipynb << 'EOF'
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¦€ðŸš€ RusTorch GPU-Enabled Rust Kernel Demo\n",
    "# ðŸ¦€ðŸš€ RusTorch GPUå¯¾å¿œ Rustã‚«ãƒ¼ãƒãƒ«ãƒ‡ãƒ¢\n",
    "\n",
    "This notebook demonstrates how to use RusTorch with GPU acceleration directly in Rust within Jupyter!\n",
    "\n",
    "ã“ã®ãƒŽãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€Jupyterå†…ã§Rustã‚’ç›´æŽ¥ä½¿ã£ã¦GPUåŠ é€Ÿã•ã‚ŒãŸRusTorchã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Install RusTorch with GPU Features\n",
    "## ðŸ“¦ GPUæ©Ÿèƒ½ä»˜ãRusTorchã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "\n",
    "First, let's add RusTorch with GPU features as a dependency:\n",
    "\n",
    "ã¾ãšã€GPUæ©Ÿèƒ½ä»˜ãRusTorchã‚’ä¾å­˜é–¢ä¿‚ã¨ã—ã¦è¿½åŠ ã—ã¾ã—ã‚‡ã†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Check which GPU features are available on this system\n",
    ":dep rustorch = { version = \"0.5.9\", features = [\"cuda\", \"metal\", \"opencl\"] }\n",
    ":dep ndarray = \"0.16\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Basic Tensor Operations with GPU\n",
    "## ðŸŽ¯ GPUåŸºæœ¬çš„ãªãƒ†ãƒ³ã‚½ãƒ«æ“ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use rustorch::*;\n",
    "use ndarray::prelude::*;\n",
    "\n",
    "// Check GPU availability\n",
    "let gpu_available = rustorch::cuda::is_available() || \n",
    "                   rustorch::metal::is_available() || \n",
    "                   rustorch::opencl::is_available();\n",
    "\n",
    "println!(\"ðŸŽ® GPU acceleration available: {}\", gpu_available);\n",
    "\n",
    "// Create tensors\n",
    "let a = Tensor::from_array(array![[1.0, 2.0], [3.0, 4.0]]);\n",
    "let b = Tensor::from_array(array![[5.0, 6.0], [7.0, 8.0]]);\n",
    "\n",
    "println!(\"Tensor a: {:?}\", a);\n",
    "println!(\"Tensor b: {:?}\", b);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Move tensors to GPU if available\n",
    "let device = if rustorch::cuda::is_available() {\n",
    "    println!(\"ðŸš€ Using CUDA GPU acceleration\");\n",
    "    Device::Cuda(0)\n",
    "} else if rustorch::metal::is_available() {\n",
    "    println!(\"ðŸŽ Using Apple Metal GPU acceleration\");\n",
    "    Device::Metal\n",
    "} else if rustorch::opencl::is_available() {\n",
    "    println!(\"âš¡ Using OpenCL GPU acceleration\");\n",
    "    Device::OpenCL(0)\n",
    "} else {\n",
    "    println!(\"ðŸ’» Using CPU (no GPU available)\");\n",
    "    Device::Cpu\n",
    "};\n",
    "\n",
    "let a_gpu = a.to_device(&device);\n",
    "let b_gpu = b.to_device(&device);\n",
    "\n",
    "// GPU-accelerated matrix multiplication\n",
    "let result = a_gpu.matmul(&b_gpu);\n",
    "println!(\"GPU matrix multiplication result: {:?}\", result);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§® GPU-Accelerated Advanced Operations\n",
    "## ðŸ§® GPUåŠ é€Ÿé«˜åº¦ãªæ“ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create larger tensors for GPU performance benefits\n",
    "let large_tensor = Tensor::randn(&[1000, 1000]).to_device(&device);\n",
    "println!(\"Large tensor shape: {:?}\", large_tensor.shape());\n",
    "println!(\"Device: {:?}\", large_tensor.device());\n",
    "\n",
    "// GPU-accelerated activation functions\n",
    "let relu_result = large_tensor.relu();\n",
    "println!(\"GPU ReLU completed on {}x{} tensor\", 1000, 1000);\n",
    "\n",
    "let sigmoid_result = large_tensor.sigmoid();\n",
    "println!(\"GPU Sigmoid completed on {}x{} tensor\", 1000, 1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤– GPU-Accelerated Neural Network\n",
    "## ðŸ¤– GPUåŠ é€Ÿãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use rustorch::nn::*;\n",
    "\n",
    "// Create a neural network on GPU\n",
    "let mut network = Sequential::new()\n",
    "    .add_layer(Linear::new(784, 256).to_device(&device))\n",
    "    .add_layer(ReLU::new())\n",
    "    .add_layer(Linear::new(256, 128).to_device(&device))\n",
    "    .add_layer(ReLU::new())\n",
    "    .add_layer(Linear::new(128, 10).to_device(&device))\n",
    "    .add_layer(Softmax::new());\n",
    "\n",
    "println!(\"ðŸ§  GPU Neural network created with {} parameters\", network.num_parameters());\n",
    "println!(\"ðŸŽ® Network device: {:?}\", device);\n",
    "\n",
    "// Create sample input on GPU\n",
    "let input = Tensor::randn(&[32, 784]).to_device(&device); // Batch size 32\n",
    "let output = network.forward(&input);\n",
    "\n",
    "println!(\"Input shape: {:?}\", input.shape());\n",
    "println!(\"Output shape: {:?}\", output.shape());\n",
    "println!(\"âœ… GPU forward pass completed!\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš¡ GPU Performance Benchmarks\n",
    "## âš¡ GPUãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use std::time::Instant;\n",
    "\n",
    "// Benchmark CPU vs GPU performance\n",
    "let size = 1000;\n",
    "let iterations = 5;\n",
    "\n",
    "println!(\"ðŸ Benchmarking {}x{} matrix operations ({} iterations)...\", size, size, iterations);\n",
    "println!(\"\");\n",
    "\n",
    "// CPU benchmark\n",
    "println!(\"ðŸ’» CPU Benchmark:\");\n",
    "let a_cpu = Tensor::randn(&[size, size]);\n",
    "let b_cpu = Tensor::randn(&[size, size]);\n",
    "\n",
    "let start = Instant::now();\n",
    "for i in 0..iterations {\n",
    "    let _result = a_cpu.matmul(&b_cpu);\n",
    "    if i == 0 { println!(\"  Iteration {} completed\", i + 1); }\n",
    "}\n",
    "let cpu_duration = start.elapsed();\n",
    "let cpu_gflops = (2.0 * size as f64 * size as f64 * size as f64 * iterations as f64) \n",
    "                / (cpu_duration.as_secs_f64() * 1e9);\n",
    "\n",
    "println!(\"  â±ï¸  CPU Time: {:?}\", cpu_duration);\n",
    "println!(\"  ðŸ“Š CPU GFLOPS: {:.2}\", cpu_gflops);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// GPU benchmark (if available)\n",
    "if gpu_available {\n",
    "    println!(\"\");\n",
    "    println!(\"ðŸŽ® GPU Benchmark:\");\n",
    "    let a_gpu = Tensor::randn(&[size, size]).to_device(&device);\n",
    "    let b_gpu = Tensor::randn(&[size, size]).to_device(&device);\n",
    "    \n",
    "    // Warm up GPU\n",
    "    let _ = a_gpu.matmul(&b_gpu);\n",
    "    \n",
    "    let start = Instant::now();\n",
    "    for i in 0..iterations {\n",
    "        let _result = a_gpu.matmul(&b_gpu);\n",
    "        if i == 0 { println!(\"  Iteration {} completed\", i + 1); }\n",
    "    }\n",
    "    let gpu_duration = start.elapsed();\n",
    "    let gpu_gflops = (2.0 * size as f64 * size as f64 * size as f64 * iterations as f64) \n",
    "                    / (gpu_duration.as_secs_f64() * 1e9);\n",
    "    \n",
    "    println!(\"  â±ï¸  GPU Time: {:?}\", gpu_duration);\n",
    "    println!(\"  ðŸ“Š GPU GFLOPS: {:.2}\", gpu_gflops);\n",
    "    \n",
    "    if gpu_duration < cpu_duration {\n",
    "        let speedup = cpu_duration.as_secs_f64() / gpu_duration.as_secs_f64();\n",
    "        println!(\"  ðŸš€ GPU Speedup: {:.2}x faster!\", speedup);\n",
    "    }\n",
    "} else {\n",
    "    println!(\"\");\n",
    "    println!(\"âš ï¸  GPU benchmark skipped (no GPU acceleration available)\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¥ Advanced GPU Examples\n",
    "## ðŸ”¥ é«˜åº¦ãªGPUã®ä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpu_available {\n",
    "    // Convolutional layer example on GPU\n",
    "    println!(\"ðŸ§  Creating GPU-accelerated CNN layer...\");\n",
    "    \n",
    "    // Create sample image tensor (batch_size=4, channels=3, height=32, width=32)\n",
    "    let image_batch = Tensor::randn(&[4, 3, 32, 32]).to_device(&device);\n",
    "    \n",
    "    // Create Conv2D layer on GPU\n",
    "    let conv_layer = Conv2d::new(3, 16, 3) // 3 input channels, 16 output, 3x3 kernel\n",
    "        .padding(1)\n",
    "        .to_device(&device);\n",
    "    \n",
    "    let conv_start = Instant::now();\n",
    "    let conv_output = conv_layer.forward(&image_batch);\n",
    "    let conv_duration = conv_start.elapsed();\n",
    "    \n",
    "    println!(\"ðŸ“ Input shape: {:?}\", image_batch.shape());\n",
    "    println!(\"ðŸ“ Output shape: {:?}\", conv_output.shape());\n",
    "    println!(\"â±ï¸  GPU Convolution time: {:?}\", conv_duration);\n",
    "    \n",
    "    // Batch processing example\n",
    "    println!(\"\");\n",
    "    println!(\"ðŸ“Š Batch processing with GPU acceleration...\");\n",
    "    \n",
    "    let batch_size = 128;\n",
    "    let feature_size = 512;\n",
    "    let large_batch = Tensor::randn(&[batch_size, feature_size]).to_device(&device);\n",
    "    \n",
    "    let batch_start = Instant::now();\n",
    "    let normalized = large_batch.layer_norm(&[feature_size]);\n",
    "    let activated = normalized.gelu();\n",
    "    let batch_duration = batch_start.elapsed();\n",
    "    \n",
    "    println!(\"âœ… Processed batch of {} samples in {:?}\", batch_size, batch_duration);\n",
    "    println!(\"ðŸ“ˆ Throughput: {:.0} samples/second\", \n",
    "        batch_size as f64 / batch_duration.as_secs_f64());\n",
    "} else {\n",
    "    println!(\"âš ï¸  Advanced GPU examples skipped (GPU acceleration not available)\");\n",
    "    println!(\"ðŸ’¡ To enable GPU acceleration:\");\n",
    "    println!(\"   - Install CUDA drivers for NVIDIA GPUs\");\n",
    "    println!(\"   - Use macOS for Apple Metal support\");\n",
    "    println!(\"   - Install OpenCL drivers for other GPUs\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Conclusion\n",
    "## ðŸŽ‰ ã¾ã¨ã‚\n",
    "\n",
    "You can now write and execute GPU-accelerated Rust code directly in Jupyter!\n",
    "\n",
    "ã“ã‚Œã§Jupyterå†…ã§ç›´æŽ¥GPUåŠ é€Ÿã•ã‚ŒãŸRustã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦å®Ÿè¡Œã§ãã¾ã™ï¼\n",
    "\n",
    "**Benefits / åˆ©ç‚¹:**\n",
    "- ðŸš€ Native Rust performance / ãƒã‚¤ãƒ†ã‚£ãƒ–Rustãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹\n",
    "- ðŸŽ® GPU acceleration / GPUåŠ é€Ÿ\n",
    "- ðŸ”§ Direct library access / ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¸ã®ç›´æŽ¥ã‚¢ã‚¯ã‚»ã‚¹\n",
    "- ðŸŽ¯ Type safety / åž‹å®‰å…¨æ€§\n",
    "- âš¡ Zero-cost abstractions / ã‚¼ãƒ­ã‚³ã‚¹ãƒˆæŠ½è±¡åŒ–\n",
    "- ðŸ§  Advanced ML operations / é«˜åº¦ãªMLæ“ä½œ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygment_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
EOF

echo ""
echo "ðŸŽ¯ Starting Jupyter Lab with GPU-enabled Rust kernel..."

jupyter lab --port=8889 --no-browser notebooks/rustorch_gpu_rust_kernel_demo.ipynb &

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "$(msg "gpu_kernel_complete")"
echo ""
echo "$(msg "how_to_use")"
echo "  $(msg "select_rust_kernel")"
echo "  $(msg "write_rust_code")"
echo "  3. Use GPU features with detected capabilities"
echo ""
echo "$(msg "detected_gpu_features") $GPU_FEATURES"
echo ""
echo "$(msg "available_at")"
echo ""
echo "$(msg "gpu_demo_loaded")"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"