[package]
name = "rustorch-cli"
version = "0.1.0"
edition = "2021"
authors = ["RusTorch Contributors"]
description = "Interactive CLI for local LLM inference using RusTorch"
license = "MIT OR Apache-2.0"
repository = "https://github.com/JunSuzukiJapan/rustorch"
keywords = ["llm", "inference", "cli", "repl", "transformer"]
categories = ["command-line-utilities", "science"]

[[bin]]
name = "rustorch-cli"
path = "src/main.rs"

[dependencies]
# RusTorch core
rustorch = { path = "..", default-features = false }

# CLI
clap = { version = "4.5", features = ["derive", "cargo", "env"] }
rustyline = "14.0"

# Tokenizer
tokenizers = "0.19"

# Model formats
safetensors = "0.4"
serde-pickle = "1.1"  # PyTorch .pt/.pth format support

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
toml = "0.8"

# Logging & Error handling
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
anyhow = "1.0"
thiserror = "1.0"

# Progress bar
indicatif = "0.17"

# Utilities
chrono = "0.4"
directories = "5.0"
colored = "2.1"
half = "2.4"
ctrlc = "3.4"

[dev-dependencies]
assert_cmd = "2.0"
predicates = "3.1"
tempfile = "3.12"

[features]
default = []

# Backend features
cuda = ["rustorch/cuda"]
metal = ["rustorch/metal"]
opencl = ["rustorch/opencl"]
coreml = ["rustorch/coreml"]
mac-hybrid = ["rustorch/mac-hybrid"]
hybrid-f32 = ["rustorch/hybrid-f32"]

# Optional features
mlx = []
async = []
